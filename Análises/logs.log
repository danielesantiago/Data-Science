2023-05-09 19:27:28,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 19:27:28,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 19:27:28,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 19:27:28,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 19:27:33,448:INFO:Soft dependency imported: prophet: 1.1.2
2023-05-09 19:27:36,658:INFO:PyCaret RegressionExperiment
2023-05-09 19:27:36,659:INFO:Logging name: charges
2023-05-09 19:27:36,659:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-09 19:27:36,659:INFO:version 3.0.0
2023-05-09 19:27:36,659:INFO:Initializing setup()
2023-05-09 19:27:36,659:INFO:self.USI: 91bf
2023-05-09 19:27:36,659:INFO:self._variable_keys: {'y_test', 'pipeline', 'exp_name_log', '_available_plots', 'y', 'gpu_param', 'fold_generator', 'X_test', 'n_jobs_param', 'X_train', 'gpu_n_jobs_param', 'exp_id', 'target_param', '_ml_usecase', 'fold_shuffle_param', 'data', 'X', 'USI', 'logging_param', 'transform_target_param', 'memory', 'log_plots_param', 'html_param', 'seed', 'y_train', 'fold_groups_param', 'idx'}
2023-05-09 19:27:36,659:INFO:Checking environment
2023-05-09 19:27:36,659:INFO:python_version: 3.10.11
2023-05-09 19:27:36,659:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-05-09 19:27:36,659:INFO:machine: AMD64
2023-05-09 19:27:36,659:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-09 19:27:36,659:INFO:Memory: svmem(total=8362713088, available=1215586304, percent=85.5, used=7147126784, free=1215586304)
2023-05-09 19:27:36,659:INFO:Physical Core: 4
2023-05-09 19:27:36,659:INFO:Logical Core: 8
2023-05-09 19:27:36,659:INFO:Checking libraries
2023-05-09 19:27:36,659:INFO:System:
2023-05-09 19:27:36,659:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-05-09 19:27:36,659:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-05-09 19:27:36,659:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-09 19:27:36,659:INFO:PyCaret required dependencies:
2023-05-09 19:27:36,659:INFO:                 pip: 23.0.1
2023-05-09 19:27:36,659:INFO:          setuptools: 65.5.0
2023-05-09 19:27:36,660:INFO:             pycaret: 3.0.0
2023-05-09 19:27:36,660:INFO:             IPython: 8.5.0
2023-05-09 19:27:36,660:INFO:          ipywidgets: 8.0.2
2023-05-09 19:27:36,660:INFO:                tqdm: 4.65.0
2023-05-09 19:27:36,660:INFO:               numpy: 1.23.3
2023-05-09 19:27:36,660:INFO:              pandas: 1.5.0
2023-05-09 19:27:36,660:INFO:              jinja2: 3.1.2
2023-05-09 19:27:36,660:INFO:               scipy: 1.9.1
2023-05-09 19:27:36,660:INFO:              joblib: 1.2.0
2023-05-09 19:27:36,660:INFO:             sklearn: 1.1.2
2023-05-09 19:27:36,660:INFO:                pyod: 1.0.9
2023-05-09 19:27:36,660:INFO:            imblearn: 0.10.1
2023-05-09 19:27:36,660:INFO:   category_encoders: 2.6.0
2023-05-09 19:27:36,660:INFO:            lightgbm: 3.3.5
2023-05-09 19:27:36,660:INFO:               numba: 0.56.4
2023-05-09 19:27:36,660:INFO:            requests: 2.28.1
2023-05-09 19:27:36,660:INFO:          matplotlib: 3.6.0
2023-05-09 19:27:36,660:INFO:          scikitplot: 0.3.7
2023-05-09 19:27:36,660:INFO:         yellowbrick: 1.5
2023-05-09 19:27:36,660:INFO:              plotly: 5.14.1
2023-05-09 19:27:36,660:INFO:             kaleido: 0.2.1
2023-05-09 19:27:36,660:INFO:         statsmodels: 0.13.5
2023-05-09 19:27:36,660:INFO:              sktime: 0.17.1
2023-05-09 19:27:36,660:INFO:               tbats: 1.1.3
2023-05-09 19:27:36,660:INFO:            pmdarima: 2.0.3
2023-05-09 19:27:36,660:INFO:              psutil: 5.9.2
2023-05-09 19:27:36,660:INFO:PyCaret optional dependencies:
2023-05-09 19:27:36,671:INFO:                shap: Not installed
2023-05-09 19:27:36,672:INFO:           interpret: Not installed
2023-05-09 19:27:36,672:INFO:                umap: Not installed
2023-05-09 19:27:36,672:INFO:    pandas_profiling: Not installed
2023-05-09 19:27:36,672:INFO:  explainerdashboard: Not installed
2023-05-09 19:27:36,672:INFO:             autoviz: Not installed
2023-05-09 19:27:36,672:INFO:           fairlearn: Not installed
2023-05-09 19:27:36,672:INFO:             xgboost: 1.7.5
2023-05-09 19:27:36,672:INFO:            catboost: Not installed
2023-05-09 19:27:36,672:INFO:              kmodes: Not installed
2023-05-09 19:27:36,672:INFO:             mlxtend: Not installed
2023-05-09 19:27:36,672:INFO:       statsforecast: Not installed
2023-05-09 19:27:36,672:INFO:        tune_sklearn: Not installed
2023-05-09 19:27:36,672:INFO:                 ray: Not installed
2023-05-09 19:27:36,672:INFO:            hyperopt: Not installed
2023-05-09 19:27:36,672:INFO:              optuna: Not installed
2023-05-09 19:27:36,672:INFO:               skopt: Not installed
2023-05-09 19:27:36,672:INFO:              mlflow: 2.3.0
2023-05-09 19:27:36,672:INFO:              gradio: Not installed
2023-05-09 19:27:36,672:INFO:             fastapi: Not installed
2023-05-09 19:27:36,672:INFO:             uvicorn: Not installed
2023-05-09 19:27:36,672:INFO:              m2cgen: Not installed
2023-05-09 19:27:36,672:INFO:           evidently: Not installed
2023-05-09 19:27:36,672:INFO:               fugue: Not installed
2023-05-09 19:27:36,672:INFO:           streamlit: Not installed
2023-05-09 19:27:36,672:INFO:             prophet: 1.1.2
2023-05-09 19:27:36,672:INFO:None
2023-05-09 19:27:36,672:INFO:Set up data.
2023-05-09 19:27:36,676:INFO:Set up train/test split.
2023-05-09 19:27:36,680:INFO:Set up index.
2023-05-09 19:27:36,680:INFO:Set up folding strategy.
2023-05-09 19:27:36,680:INFO:Assigning column types.
2023-05-09 19:27:36,683:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-09 19:27:36,683:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-09 19:27:36,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-09 19:27:36,686:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-09 19:27:36,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:36,784:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:36,785:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,002:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,005:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,010:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,096:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,096:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-09 19:27:38,096:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,096:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,179:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,195:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,296:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,299:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-09 19:27:38,306:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,397:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,418:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,511:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,512:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-09 19:27:38,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,607:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,696:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,709:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-09 19:27:38,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,806:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-09 19:27:38,902:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:38,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:38,905:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-09 19:27:38,999:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:39,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:39,092:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:39,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:39,104:INFO:Preparing preprocessing pipeline...
2023-05-09 19:27:39,104:INFO:Set up simple imputation.
2023-05-09 19:27:39,104:INFO:Set up feature normalization.
2023-05-09 19:27:39,124:INFO:Finished creating preprocessing pipeline.
2023-05-09 19:27:39,129:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-05-09 19:27:39,129:INFO:Creating final display dataframe.
2023-05-09 19:27:39,184:INFO:Setup _display_container:                     Description         Value
0                    Session id           153
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1204, 8)
4        Transformed data shape     (1204, 8)
5   Transformed train set shape      (842, 8)
6    Transformed test set shape      (362, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          91bf
2023-05-09 19:27:39,295:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:39,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:39,392:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-09 19:27:39,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 19:27:39,395:INFO:Logging experiment in loggers
2023-05-09 19:27:40,057:INFO:SubProcess save_model() called ==================================
2023-05-09 19:27:40,057:INFO:Initializing save_model()
2023-05-09 19:27:40,057:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmpbt56jaik\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-05-09 19:27:40,057:INFO:Adding model into prep_pipe
2023-05-09 19:27:40,057:WARNING:Only Model saved as it was a pipeline.
2023-05-09 19:27:40,057:INFO:C:\Users\danie\AppData\Local\Temp\tmpbt56jaik\Transformation Pipeline.pkl saved in current working directory
2023-05-09 19:27:40,057:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-05-09 19:27:40,057:INFO:save_model() successfully completed......................................
2023-05-09 19:27:40,381:INFO:SubProcess save_model() end ==================================
2023-05-09 19:27:40,436:INFO:setup() successfully completed in 3.31s...............
2023-05-09 19:27:40,456:INFO:Initializing compare_models()
2023-05-09 19:27:40,456:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, include=None, fold=5, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-09 19:27:40,456:INFO:Checking exceptions
2023-05-09 19:27:40,456:INFO:Preparing display monitor
2023-05-09 19:27:40,506:INFO:Initializing Linear Regression
2023-05-09 19:27:40,506:INFO:Total runtime is 0.0 minutes
2023-05-09 19:27:40,506:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:40,506:INFO:Initializing create_model()
2023-05-09 19:27:40,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:40,506:INFO:Checking exceptions
2023-05-09 19:27:40,506:INFO:Importing libraries
2023-05-09 19:27:40,506:INFO:Copying training dataset
2023-05-09 19:27:40,506:INFO:Defining folds
2023-05-09 19:27:40,506:INFO:Declaring metric variables
2023-05-09 19:27:40,522:INFO:Importing untrained model
2023-05-09 19:27:40,522:INFO:Linear Regression Imported successfully
2023-05-09 19:27:40,540:INFO:Starting cross validation
2023-05-09 19:27:40,573:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:46,024:INFO:Calculating mean and std
2023-05-09 19:27:46,026:INFO:Creating metrics dataframe
2023-05-09 19:27:46,361:INFO:Uploading results into container
2023-05-09 19:27:46,361:INFO:Uploading model into container now
2023-05-09 19:27:46,361:INFO:_master_model_container: 1
2023-05-09 19:27:46,361:INFO:_display_container: 2
2023-05-09 19:27:46,361:INFO:LinearRegression(n_jobs=-1)
2023-05-09 19:27:46,361:INFO:create_model() successfully completed......................................
2023-05-09 19:27:46,460:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:46,460:INFO:Creating metrics dataframe
2023-05-09 19:27:46,476:INFO:Initializing Lasso Regression
2023-05-09 19:27:46,476:INFO:Total runtime is 0.09950385491053264 minutes
2023-05-09 19:27:46,476:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:46,476:INFO:Initializing create_model()
2023-05-09 19:27:46,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:46,476:INFO:Checking exceptions
2023-05-09 19:27:46,476:INFO:Importing libraries
2023-05-09 19:27:46,476:INFO:Copying training dataset
2023-05-09 19:27:46,476:INFO:Defining folds
2023-05-09 19:27:46,476:INFO:Declaring metric variables
2023-05-09 19:27:46,476:INFO:Importing untrained model
2023-05-09 19:27:46,490:INFO:Lasso Regression Imported successfully
2023-05-09 19:27:46,496:INFO:Starting cross validation
2023-05-09 19:27:46,497:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:49,049:INFO:Calculating mean and std
2023-05-09 19:27:49,049:INFO:Creating metrics dataframe
2023-05-09 19:27:49,390:INFO:Uploading results into container
2023-05-09 19:27:49,390:INFO:Uploading model into container now
2023-05-09 19:27:49,391:INFO:_master_model_container: 2
2023-05-09 19:27:49,391:INFO:_display_container: 2
2023-05-09 19:27:49,391:INFO:Lasso(random_state=153)
2023-05-09 19:27:49,391:INFO:create_model() successfully completed......................................
2023-05-09 19:27:49,478:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:49,478:INFO:Creating metrics dataframe
2023-05-09 19:27:49,486:INFO:Initializing Ridge Regression
2023-05-09 19:27:49,486:INFO:Total runtime is 0.14967265923817952 minutes
2023-05-09 19:27:49,488:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:49,489:INFO:Initializing create_model()
2023-05-09 19:27:49,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:49,489:INFO:Checking exceptions
2023-05-09 19:27:49,489:INFO:Importing libraries
2023-05-09 19:27:49,489:INFO:Copying training dataset
2023-05-09 19:27:49,493:INFO:Defining folds
2023-05-09 19:27:49,493:INFO:Declaring metric variables
2023-05-09 19:27:49,497:INFO:Importing untrained model
2023-05-09 19:27:49,500:INFO:Ridge Regression Imported successfully
2023-05-09 19:27:49,505:INFO:Starting cross validation
2023-05-09 19:27:49,506:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:50,662:INFO:Calculating mean and std
2023-05-09 19:27:50,663:INFO:Creating metrics dataframe
2023-05-09 19:27:50,997:INFO:Uploading results into container
2023-05-09 19:27:50,997:INFO:Uploading model into container now
2023-05-09 19:27:50,997:INFO:_master_model_container: 3
2023-05-09 19:27:50,997:INFO:_display_container: 2
2023-05-09 19:27:50,997:INFO:Ridge(random_state=153)
2023-05-09 19:27:50,997:INFO:create_model() successfully completed......................................
2023-05-09 19:27:51,091:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:51,091:INFO:Creating metrics dataframe
2023-05-09 19:27:51,100:INFO:Initializing Elastic Net
2023-05-09 19:27:51,100:INFO:Total runtime is 0.1765722632408142 minutes
2023-05-09 19:27:51,104:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:51,104:INFO:Initializing create_model()
2023-05-09 19:27:51,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:51,104:INFO:Checking exceptions
2023-05-09 19:27:51,104:INFO:Importing libraries
2023-05-09 19:27:51,104:INFO:Copying training dataset
2023-05-09 19:27:51,108:INFO:Defining folds
2023-05-09 19:27:51,109:INFO:Declaring metric variables
2023-05-09 19:27:51,113:INFO:Importing untrained model
2023-05-09 19:27:51,115:INFO:Elastic Net Imported successfully
2023-05-09 19:27:51,120:INFO:Starting cross validation
2023-05-09 19:27:51,121:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:52,277:INFO:Calculating mean and std
2023-05-09 19:27:52,278:INFO:Creating metrics dataframe
2023-05-09 19:27:52,604:INFO:Uploading results into container
2023-05-09 19:27:52,604:INFO:Uploading model into container now
2023-05-09 19:27:52,604:INFO:_master_model_container: 4
2023-05-09 19:27:52,604:INFO:_display_container: 2
2023-05-09 19:27:52,604:INFO:ElasticNet(random_state=153)
2023-05-09 19:27:52,604:INFO:create_model() successfully completed......................................
2023-05-09 19:27:52,702:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:52,703:INFO:Creating metrics dataframe
2023-05-09 19:27:52,713:INFO:Initializing Least Angle Regression
2023-05-09 19:27:52,713:INFO:Total runtime is 0.20345633824666343 minutes
2023-05-09 19:27:52,716:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:52,716:INFO:Initializing create_model()
2023-05-09 19:27:52,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:52,717:INFO:Checking exceptions
2023-05-09 19:27:52,717:INFO:Importing libraries
2023-05-09 19:27:52,717:INFO:Copying training dataset
2023-05-09 19:27:52,722:INFO:Defining folds
2023-05-09 19:27:52,722:INFO:Declaring metric variables
2023-05-09 19:27:52,725:INFO:Importing untrained model
2023-05-09 19:27:52,729:INFO:Least Angle Regression Imported successfully
2023-05-09 19:27:52,733:INFO:Starting cross validation
2023-05-09 19:27:52,734:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:52,798:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:52,798:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:52,799:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:52,800:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:52,810:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:53,918:INFO:Calculating mean and std
2023-05-09 19:27:53,918:INFO:Creating metrics dataframe
2023-05-09 19:27:54,286:INFO:Uploading results into container
2023-05-09 19:27:54,287:INFO:Uploading model into container now
2023-05-09 19:27:54,287:INFO:_master_model_container: 5
2023-05-09 19:27:54,287:INFO:_display_container: 2
2023-05-09 19:27:54,288:INFO:Lars(random_state=153)
2023-05-09 19:27:54,288:INFO:create_model() successfully completed......................................
2023-05-09 19:27:54,368:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:54,368:INFO:Creating metrics dataframe
2023-05-09 19:27:54,384:INFO:Initializing Lasso Least Angle Regression
2023-05-09 19:27:54,384:INFO:Total runtime is 0.23130672772725425 minutes
2023-05-09 19:27:54,385:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:54,385:INFO:Initializing create_model()
2023-05-09 19:27:54,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:54,385:INFO:Checking exceptions
2023-05-09 19:27:54,385:INFO:Importing libraries
2023-05-09 19:27:54,385:INFO:Copying training dataset
2023-05-09 19:27:54,385:INFO:Defining folds
2023-05-09 19:27:54,385:INFO:Declaring metric variables
2023-05-09 19:27:54,385:INFO:Importing untrained model
2023-05-09 19:27:54,400:INFO:Lasso Least Angle Regression Imported successfully
2023-05-09 19:27:54,407:INFO:Starting cross validation
2023-05-09 19:27:54,407:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:54,450:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-09 19:27:54,460:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-09 19:27:54,471:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-09 19:27:54,477:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-09 19:27:54,486:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-09 19:27:55,550:INFO:Calculating mean and std
2023-05-09 19:27:55,550:INFO:Creating metrics dataframe
2023-05-09 19:27:55,881:INFO:Uploading results into container
2023-05-09 19:27:55,881:INFO:Uploading model into container now
2023-05-09 19:27:55,881:INFO:_master_model_container: 6
2023-05-09 19:27:55,881:INFO:_display_container: 2
2023-05-09 19:27:55,881:INFO:LassoLars(random_state=153)
2023-05-09 19:27:55,881:INFO:create_model() successfully completed......................................
2023-05-09 19:27:55,981:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:55,981:INFO:Creating metrics dataframe
2023-05-09 19:27:55,981:INFO:Initializing Orthogonal Matching Pursuit
2023-05-09 19:27:55,981:INFO:Total runtime is 0.257931919892629 minutes
2023-05-09 19:27:55,981:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:55,981:INFO:Initializing create_model()
2023-05-09 19:27:55,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:55,981:INFO:Checking exceptions
2023-05-09 19:27:55,981:INFO:Importing libraries
2023-05-09 19:27:55,981:INFO:Copying training dataset
2023-05-09 19:27:55,998:INFO:Defining folds
2023-05-09 19:27:55,998:INFO:Declaring metric variables
2023-05-09 19:27:55,998:INFO:Importing untrained model
2023-05-09 19:27:55,998:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-09 19:27:55,998:INFO:Starting cross validation
2023-05-09 19:27:56,013:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:56,055:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:56,060:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:56,072:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:56,082:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:56,089:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-09 19:27:57,104:INFO:Calculating mean and std
2023-05-09 19:27:57,104:INFO:Creating metrics dataframe
2023-05-09 19:27:57,442:INFO:Uploading results into container
2023-05-09 19:27:57,443:INFO:Uploading model into container now
2023-05-09 19:27:57,443:INFO:_master_model_container: 7
2023-05-09 19:27:57,443:INFO:_display_container: 2
2023-05-09 19:27:57,444:INFO:OrthogonalMatchingPursuit()
2023-05-09 19:27:57,444:INFO:create_model() successfully completed......................................
2023-05-09 19:27:57,523:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:57,525:INFO:Creating metrics dataframe
2023-05-09 19:27:57,532:INFO:Initializing Bayesian Ridge
2023-05-09 19:27:57,532:INFO:Total runtime is 0.2837675849596659 minutes
2023-05-09 19:27:57,535:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:57,535:INFO:Initializing create_model()
2023-05-09 19:27:57,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:57,535:INFO:Checking exceptions
2023-05-09 19:27:57,535:INFO:Importing libraries
2023-05-09 19:27:57,535:INFO:Copying training dataset
2023-05-09 19:27:57,538:INFO:Defining folds
2023-05-09 19:27:57,538:INFO:Declaring metric variables
2023-05-09 19:27:57,541:INFO:Importing untrained model
2023-05-09 19:27:57,544:INFO:Bayesian Ridge Imported successfully
2023-05-09 19:27:57,551:INFO:Starting cross validation
2023-05-09 19:27:57,552:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:27:58,614:INFO:Calculating mean and std
2023-05-09 19:27:58,615:INFO:Creating metrics dataframe
2023-05-09 19:27:58,952:INFO:Uploading results into container
2023-05-09 19:27:58,952:INFO:Uploading model into container now
2023-05-09 19:27:58,953:INFO:_master_model_container: 8
2023-05-09 19:27:58,953:INFO:_display_container: 2
2023-05-09 19:27:58,953:INFO:BayesianRidge()
2023-05-09 19:27:58,953:INFO:create_model() successfully completed......................................
2023-05-09 19:27:59,038:INFO:SubProcess create_model() end ==================================
2023-05-09 19:27:59,038:INFO:Creating metrics dataframe
2023-05-09 19:27:59,046:INFO:Initializing Passive Aggressive Regressor
2023-05-09 19:27:59,046:INFO:Total runtime is 0.30900586048762 minutes
2023-05-09 19:27:59,049:INFO:SubProcess create_model() called ==================================
2023-05-09 19:27:59,049:INFO:Initializing create_model()
2023-05-09 19:27:59,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:27:59,049:INFO:Checking exceptions
2023-05-09 19:27:59,050:INFO:Importing libraries
2023-05-09 19:27:59,050:INFO:Copying training dataset
2023-05-09 19:27:59,053:INFO:Defining folds
2023-05-09 19:27:59,053:INFO:Declaring metric variables
2023-05-09 19:27:59,055:INFO:Importing untrained model
2023-05-09 19:27:59,055:INFO:Passive Aggressive Regressor Imported successfully
2023-05-09 19:27:59,062:INFO:Starting cross validation
2023-05-09 19:27:59,062:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:00,189:INFO:Calculating mean and std
2023-05-09 19:28:00,191:INFO:Creating metrics dataframe
2023-05-09 19:28:00,500:INFO:Uploading results into container
2023-05-09 19:28:00,500:INFO:Uploading model into container now
2023-05-09 19:28:00,500:INFO:_master_model_container: 9
2023-05-09 19:28:00,500:INFO:_display_container: 2
2023-05-09 19:28:00,500:INFO:PassiveAggressiveRegressor(random_state=153)
2023-05-09 19:28:00,500:INFO:create_model() successfully completed......................................
2023-05-09 19:28:00,594:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:00,594:INFO:Creating metrics dataframe
2023-05-09 19:28:00,602:INFO:Initializing Huber Regressor
2023-05-09 19:28:00,602:INFO:Total runtime is 0.3349339048067729 minutes
2023-05-09 19:28:00,602:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:00,602:INFO:Initializing create_model()
2023-05-09 19:28:00,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:00,602:INFO:Checking exceptions
2023-05-09 19:28:00,602:INFO:Importing libraries
2023-05-09 19:28:00,602:INFO:Copying training dataset
2023-05-09 19:28:00,602:INFO:Defining folds
2023-05-09 19:28:00,602:INFO:Declaring metric variables
2023-05-09 19:28:00,602:INFO:Importing untrained model
2023-05-09 19:28:00,617:INFO:Huber Regressor Imported successfully
2023-05-09 19:28:00,617:INFO:Starting cross validation
2023-05-09 19:28:00,617:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:01,776:INFO:Calculating mean and std
2023-05-09 19:28:01,777:INFO:Creating metrics dataframe
2023-05-09 19:28:02,119:INFO:Uploading results into container
2023-05-09 19:28:02,119:INFO:Uploading model into container now
2023-05-09 19:28:02,119:INFO:_master_model_container: 10
2023-05-09 19:28:02,119:INFO:_display_container: 2
2023-05-09 19:28:02,119:INFO:HuberRegressor()
2023-05-09 19:28:02,119:INFO:create_model() successfully completed......................................
2023-05-09 19:28:02,214:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:02,214:INFO:Creating metrics dataframe
2023-05-09 19:28:02,214:INFO:Initializing K Neighbors Regressor
2023-05-09 19:28:02,214:INFO:Total runtime is 0.3618006388346354 minutes
2023-05-09 19:28:02,233:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:02,233:INFO:Initializing create_model()
2023-05-09 19:28:02,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:02,234:INFO:Checking exceptions
2023-05-09 19:28:02,234:INFO:Importing libraries
2023-05-09 19:28:02,234:INFO:Copying training dataset
2023-05-09 19:28:02,238:INFO:Defining folds
2023-05-09 19:28:02,238:INFO:Declaring metric variables
2023-05-09 19:28:02,240:INFO:Importing untrained model
2023-05-09 19:28:02,243:INFO:K Neighbors Regressor Imported successfully
2023-05-09 19:28:02,252:INFO:Starting cross validation
2023-05-09 19:28:02,252:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:03,455:INFO:Calculating mean and std
2023-05-09 19:28:03,456:INFO:Creating metrics dataframe
2023-05-09 19:28:03,836:INFO:Uploading results into container
2023-05-09 19:28:03,836:INFO:Uploading model into container now
2023-05-09 19:28:03,836:INFO:_master_model_container: 11
2023-05-09 19:28:03,836:INFO:_display_container: 2
2023-05-09 19:28:03,836:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-09 19:28:03,836:INFO:create_model() successfully completed......................................
2023-05-09 19:28:03,905:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:03,905:INFO:Creating metrics dataframe
2023-05-09 19:28:03,926:INFO:Initializing Decision Tree Regressor
2023-05-09 19:28:03,926:INFO:Total runtime is 0.39034384886423745 minutes
2023-05-09 19:28:03,930:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:03,930:INFO:Initializing create_model()
2023-05-09 19:28:03,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:03,931:INFO:Checking exceptions
2023-05-09 19:28:03,931:INFO:Importing libraries
2023-05-09 19:28:03,931:INFO:Copying training dataset
2023-05-09 19:28:03,934:INFO:Defining folds
2023-05-09 19:28:03,934:INFO:Declaring metric variables
2023-05-09 19:28:03,937:INFO:Importing untrained model
2023-05-09 19:28:03,941:INFO:Decision Tree Regressor Imported successfully
2023-05-09 19:28:03,958:INFO:Starting cross validation
2023-05-09 19:28:03,958:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:05,081:INFO:Calculating mean and std
2023-05-09 19:28:05,081:INFO:Creating metrics dataframe
2023-05-09 19:28:05,404:INFO:Uploading results into container
2023-05-09 19:28:05,404:INFO:Uploading model into container now
2023-05-09 19:28:05,404:INFO:_master_model_container: 12
2023-05-09 19:28:05,404:INFO:_display_container: 2
2023-05-09 19:28:05,404:INFO:DecisionTreeRegressor(random_state=153)
2023-05-09 19:28:05,404:INFO:create_model() successfully completed......................................
2023-05-09 19:28:05,497:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:05,498:INFO:Creating metrics dataframe
2023-05-09 19:28:05,507:INFO:Initializing Random Forest Regressor
2023-05-09 19:28:05,507:INFO:Total runtime is 0.41668468713760376 minutes
2023-05-09 19:28:05,510:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:05,511:INFO:Initializing create_model()
2023-05-09 19:28:05,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:05,511:INFO:Checking exceptions
2023-05-09 19:28:05,511:INFO:Importing libraries
2023-05-09 19:28:05,511:INFO:Copying training dataset
2023-05-09 19:28:05,515:INFO:Defining folds
2023-05-09 19:28:05,515:INFO:Declaring metric variables
2023-05-09 19:28:05,517:INFO:Importing untrained model
2023-05-09 19:28:05,521:INFO:Random Forest Regressor Imported successfully
2023-05-09 19:28:05,526:INFO:Starting cross validation
2023-05-09 19:28:05,527:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:06,998:INFO:Calculating mean and std
2023-05-09 19:28:06,999:INFO:Creating metrics dataframe
2023-05-09 19:28:07,369:INFO:Uploading results into container
2023-05-09 19:28:07,369:INFO:Uploading model into container now
2023-05-09 19:28:07,369:INFO:_master_model_container: 13
2023-05-09 19:28:07,369:INFO:_display_container: 2
2023-05-09 19:28:07,369:INFO:RandomForestRegressor(n_jobs=-1, random_state=153)
2023-05-09 19:28:07,375:INFO:create_model() successfully completed......................................
2023-05-09 19:28:07,445:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:07,445:INFO:Creating metrics dataframe
2023-05-09 19:28:07,461:INFO:Initializing Extra Trees Regressor
2023-05-09 19:28:07,461:INFO:Total runtime is 0.44925130605697633 minutes
2023-05-09 19:28:07,464:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:07,465:INFO:Initializing create_model()
2023-05-09 19:28:07,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:07,465:INFO:Checking exceptions
2023-05-09 19:28:07,465:INFO:Importing libraries
2023-05-09 19:28:07,465:INFO:Copying training dataset
2023-05-09 19:28:07,467:INFO:Defining folds
2023-05-09 19:28:07,467:INFO:Declaring metric variables
2023-05-09 19:28:07,471:INFO:Importing untrained model
2023-05-09 19:28:07,473:INFO:Extra Trees Regressor Imported successfully
2023-05-09 19:28:07,483:INFO:Starting cross validation
2023-05-09 19:28:07,485:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:09,144:INFO:Calculating mean and std
2023-05-09 19:28:09,144:INFO:Creating metrics dataframe
2023-05-09 19:28:09,544:INFO:Uploading results into container
2023-05-09 19:28:09,544:INFO:Uploading model into container now
2023-05-09 19:28:09,544:INFO:_master_model_container: 14
2023-05-09 19:28:09,544:INFO:_display_container: 2
2023-05-09 19:28:09,544:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=153)
2023-05-09 19:28:09,544:INFO:create_model() successfully completed......................................
2023-05-09 19:28:09,643:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:09,643:INFO:Creating metrics dataframe
2023-05-09 19:28:09,660:INFO:Initializing AdaBoost Regressor
2023-05-09 19:28:09,660:INFO:Total runtime is 0.4859071373939514 minutes
2023-05-09 19:28:09,660:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:09,660:INFO:Initializing create_model()
2023-05-09 19:28:09,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:09,660:INFO:Checking exceptions
2023-05-09 19:28:09,660:INFO:Importing libraries
2023-05-09 19:28:09,660:INFO:Copying training dataset
2023-05-09 19:28:09,670:INFO:Defining folds
2023-05-09 19:28:09,670:INFO:Declaring metric variables
2023-05-09 19:28:09,676:INFO:Importing untrained model
2023-05-09 19:28:09,679:INFO:AdaBoost Regressor Imported successfully
2023-05-09 19:28:09,684:INFO:Starting cross validation
2023-05-09 19:28:09,684:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:10,906:INFO:Calculating mean and std
2023-05-09 19:28:10,906:INFO:Creating metrics dataframe
2023-05-09 19:28:11,283:INFO:Uploading results into container
2023-05-09 19:28:11,283:INFO:Uploading model into container now
2023-05-09 19:28:11,284:INFO:_master_model_container: 15
2023-05-09 19:28:11,284:INFO:_display_container: 2
2023-05-09 19:28:11,284:INFO:AdaBoostRegressor(random_state=153)
2023-05-09 19:28:11,284:INFO:create_model() successfully completed......................................
2023-05-09 19:28:11,352:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:11,352:INFO:Creating metrics dataframe
2023-05-09 19:28:11,372:INFO:Initializing Gradient Boosting Regressor
2023-05-09 19:28:11,372:INFO:Total runtime is 0.5144331415494283 minutes
2023-05-09 19:28:11,376:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:11,377:INFO:Initializing create_model()
2023-05-09 19:28:11,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:11,377:INFO:Checking exceptions
2023-05-09 19:28:11,377:INFO:Importing libraries
2023-05-09 19:28:11,377:INFO:Copying training dataset
2023-05-09 19:28:11,380:INFO:Defining folds
2023-05-09 19:28:11,380:INFO:Declaring metric variables
2023-05-09 19:28:11,383:INFO:Importing untrained model
2023-05-09 19:28:11,387:INFO:Gradient Boosting Regressor Imported successfully
2023-05-09 19:28:11,389:INFO:Starting cross validation
2023-05-09 19:28:11,389:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:12,673:INFO:Calculating mean and std
2023-05-09 19:28:12,673:INFO:Creating metrics dataframe
2023-05-09 19:28:13,015:INFO:Uploading results into container
2023-05-09 19:28:13,015:INFO:Uploading model into container now
2023-05-09 19:28:13,015:INFO:_master_model_container: 16
2023-05-09 19:28:13,015:INFO:_display_container: 2
2023-05-09 19:28:13,015:INFO:GradientBoostingRegressor(random_state=153)
2023-05-09 19:28:13,015:INFO:create_model() successfully completed......................................
2023-05-09 19:28:13,099:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:13,099:INFO:Creating metrics dataframe
2023-05-09 19:28:13,110:INFO:Initializing Extreme Gradient Boosting
2023-05-09 19:28:13,110:INFO:Total runtime is 0.543412983417511 minutes
2023-05-09 19:28:13,113:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:13,114:INFO:Initializing create_model()
2023-05-09 19:28:13,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:13,114:INFO:Checking exceptions
2023-05-09 19:28:13,114:INFO:Importing libraries
2023-05-09 19:28:13,114:INFO:Copying training dataset
2023-05-09 19:28:13,117:INFO:Defining folds
2023-05-09 19:28:13,117:INFO:Declaring metric variables
2023-05-09 19:28:13,121:INFO:Importing untrained model
2023-05-09 19:28:13,124:INFO:Extreme Gradient Boosting Imported successfully
2023-05-09 19:28:13,133:INFO:Starting cross validation
2023-05-09 19:28:13,135:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:15,577:INFO:Calculating mean and std
2023-05-09 19:28:15,577:INFO:Creating metrics dataframe
2023-05-09 19:28:15,947:INFO:Uploading results into container
2023-05-09 19:28:15,948:INFO:Uploading model into container now
2023-05-09 19:28:15,948:INFO:_master_model_container: 17
2023-05-09 19:28:15,948:INFO:_display_container: 2
2023-05-09 19:28:15,949:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=153, ...)
2023-05-09 19:28:15,949:INFO:create_model() successfully completed......................................
2023-05-09 19:28:16,041:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:16,041:INFO:Creating metrics dataframe
2023-05-09 19:28:16,042:INFO:Initializing Light Gradient Boosting Machine
2023-05-09 19:28:16,042:INFO:Total runtime is 0.5922763824462891 minutes
2023-05-09 19:28:16,057:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:16,057:INFO:Initializing create_model()
2023-05-09 19:28:16,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:16,057:INFO:Checking exceptions
2023-05-09 19:28:16,057:INFO:Importing libraries
2023-05-09 19:28:16,057:INFO:Copying training dataset
2023-05-09 19:28:16,061:INFO:Defining folds
2023-05-09 19:28:16,061:INFO:Declaring metric variables
2023-05-09 19:28:16,064:INFO:Importing untrained model
2023-05-09 19:28:16,081:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 19:28:16,092:INFO:Starting cross validation
2023-05-09 19:28:16,094:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:18,048:INFO:Calculating mean and std
2023-05-09 19:28:18,050:INFO:Creating metrics dataframe
2023-05-09 19:28:18,377:INFO:Uploading results into container
2023-05-09 19:28:18,377:INFO:Uploading model into container now
2023-05-09 19:28:18,377:INFO:_master_model_container: 18
2023-05-09 19:28:18,377:INFO:_display_container: 2
2023-05-09 19:28:18,377:INFO:LGBMRegressor(random_state=153)
2023-05-09 19:28:18,377:INFO:create_model() successfully completed......................................
2023-05-09 19:28:18,449:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:18,465:INFO:Creating metrics dataframe
2023-05-09 19:28:18,465:INFO:Initializing Dummy Regressor
2023-05-09 19:28:18,465:INFO:Total runtime is 0.6326523939768474 minutes
2023-05-09 19:28:18,478:INFO:SubProcess create_model() called ==================================
2023-05-09 19:28:18,478:INFO:Initializing create_model()
2023-05-09 19:28:18,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D88B3130>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:18,479:INFO:Checking exceptions
2023-05-09 19:28:18,479:INFO:Importing libraries
2023-05-09 19:28:18,479:INFO:Copying training dataset
2023-05-09 19:28:18,485:INFO:Defining folds
2023-05-09 19:28:18,485:INFO:Declaring metric variables
2023-05-09 19:28:18,489:INFO:Importing untrained model
2023-05-09 19:28:18,491:INFO:Dummy Regressor Imported successfully
2023-05-09 19:28:18,502:INFO:Starting cross validation
2023-05-09 19:28:18,503:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:19,621:INFO:Calculating mean and std
2023-05-09 19:28:19,622:INFO:Creating metrics dataframe
2023-05-09 19:28:19,946:INFO:Uploading results into container
2023-05-09 19:28:19,947:INFO:Uploading model into container now
2023-05-09 19:28:19,947:INFO:_master_model_container: 19
2023-05-09 19:28:19,947:INFO:_display_container: 2
2023-05-09 19:28:19,948:INFO:DummyRegressor()
2023-05-09 19:28:19,948:INFO:create_model() successfully completed......................................
2023-05-09 19:28:20,026:INFO:SubProcess create_model() end ==================================
2023-05-09 19:28:20,026:INFO:Creating metrics dataframe
2023-05-09 19:28:20,044:INFO:Initializing create_model()
2023-05-09 19:28:20,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:20,044:INFO:Checking exceptions
2023-05-09 19:28:20,047:INFO:Importing libraries
2023-05-09 19:28:20,047:INFO:Copying training dataset
2023-05-09 19:28:20,049:INFO:Defining folds
2023-05-09 19:28:20,049:INFO:Declaring metric variables
2023-05-09 19:28:20,049:INFO:Importing untrained model
2023-05-09 19:28:20,049:INFO:Declaring custom model
2023-05-09 19:28:20,050:INFO:Gradient Boosting Regressor Imported successfully
2023-05-09 19:28:20,050:INFO:Cross validation set to False
2023-05-09 19:28:20,050:INFO:Fitting Model
2023-05-09 19:28:20,339:INFO:GradientBoostingRegressor(random_state=153)
2023-05-09 19:28:20,339:INFO:create_model() successfully completed......................................
2023-05-09 19:28:20,423:INFO:Creating Dashboard logs
2023-05-09 19:28:20,426:INFO:Model: Gradient Boosting Regressor
2023-05-09 19:28:20,481:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 153, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-05-09 19:28:20,560:INFO:Initializing predict_model()
2023-05-09 19:28:20,560:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D392EE60>)
2023-05-09 19:28:20,560:INFO:Checking exceptions
2023-05-09 19:28:20,560:INFO:Preloading libraries
2023-05-09 19:28:21,151:INFO:Creating Dashboard logs
2023-05-09 19:28:21,154:INFO:Model: Random Forest Regressor
2023-05-09 19:28:21,200:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 153, 'verbose': 0, 'warm_start': False}
2023-05-09 19:28:21,611:INFO:Creating Dashboard logs
2023-05-09 19:28:21,611:INFO:Model: Light Gradient Boosting Machine
2023-05-09 19:28:21,675:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 153, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-09 19:28:22,083:INFO:Creating Dashboard logs
2023-05-09 19:28:22,086:INFO:Model: K Neighbors Regressor
2023-05-09 19:28:22,131:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-05-09 19:28:22,558:INFO:Creating Dashboard logs
2023-05-09 19:28:22,558:INFO:Model: AdaBoost Regressor
2023-05-09 19:28:22,625:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 153}
2023-05-09 19:28:23,020:INFO:Creating Dashboard logs
2023-05-09 19:28:23,020:INFO:Model: Extra Trees Regressor
2023-05-09 19:28:23,073:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 153, 'verbose': 0, 'warm_start': False}
2023-05-09 19:28:23,511:INFO:Creating Dashboard logs
2023-05-09 19:28:23,514:INFO:Model: Extreme Gradient Boosting
2023-05-09 19:28:23,558:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 153, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-09 19:28:23,985:INFO:Creating Dashboard logs
2023-05-09 19:28:24,001:INFO:Model: Lasso Least Angle Regression
2023-05-09 19:28:24,046:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 153, 'verbose': False}
2023-05-09 19:28:24,446:INFO:Creating Dashboard logs
2023-05-09 19:28:24,449:INFO:Model: Bayesian Ridge
2023-05-09 19:28:24,486:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-05-09 19:28:24,882:INFO:Creating Dashboard logs
2023-05-09 19:28:24,882:INFO:Model: Ridge Regression
2023-05-09 19:28:24,935:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 153, 'solver': 'auto', 'tol': 0.001}
2023-05-09 19:28:25,327:INFO:Creating Dashboard logs
2023-05-09 19:28:25,330:INFO:Model: Lasso Regression
2023-05-09 19:28:25,369:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 153, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-05-09 19:28:25,800:INFO:Creating Dashboard logs
2023-05-09 19:28:25,800:INFO:Model: Least Angle Regression
2023-05-09 19:28:25,850:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 153, 'verbose': False}
2023-05-09 19:28:26,287:INFO:Creating Dashboard logs
2023-05-09 19:28:26,303:INFO:Model: Linear Regression
2023-05-09 19:28:26,348:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-05-09 19:28:26,740:INFO:Creating Dashboard logs
2023-05-09 19:28:26,743:INFO:Model: Decision Tree Regressor
2023-05-09 19:28:26,788:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 153, 'splitter': 'best'}
2023-05-09 19:28:27,191:INFO:Creating Dashboard logs
2023-05-09 19:28:27,193:INFO:Model: Elastic Net
2023-05-09 19:28:27,238:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 153, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-05-09 19:28:27,676:INFO:Creating Dashboard logs
2023-05-09 19:28:27,679:INFO:Model: Huber Regressor
2023-05-09 19:28:27,727:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-05-09 19:28:28,122:INFO:Creating Dashboard logs
2023-05-09 19:28:28,130:INFO:Model: Orthogonal Matching Pursuit
2023-05-09 19:28:28,194:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-05-09 19:28:28,589:INFO:Creating Dashboard logs
2023-05-09 19:28:28,592:INFO:Model: Passive Aggressive Regressor
2023-05-09 19:28:28,638:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 153, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-05-09 19:28:29,037:INFO:Creating Dashboard logs
2023-05-09 19:28:29,039:INFO:Model: Dummy Regressor
2023-05-09 19:28:29,087:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-05-09 19:28:29,516:INFO:_master_model_container: 19
2023-05-09 19:28:29,516:INFO:_display_container: 2
2023-05-09 19:28:29,517:INFO:GradientBoostingRegressor(random_state=153)
2023-05-09 19:28:29,517:INFO:compare_models() successfully completed......................................
2023-05-09 19:28:29,547:INFO:Initializing create_model()
2023-05-09 19:28:29,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:29,547:INFO:Checking exceptions
2023-05-09 19:28:29,570:INFO:Importing libraries
2023-05-09 19:28:29,570:INFO:Copying training dataset
2023-05-09 19:28:29,570:INFO:Defining folds
2023-05-09 19:28:29,570:INFO:Declaring metric variables
2023-05-09 19:28:29,587:INFO:Importing untrained model
2023-05-09 19:28:29,587:INFO:Gradient Boosting Regressor Imported successfully
2023-05-09 19:28:29,587:INFO:Starting cross validation
2023-05-09 19:28:29,602:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:30,816:INFO:Calculating mean and std
2023-05-09 19:28:30,816:INFO:Creating metrics dataframe
2023-05-09 19:28:30,816:INFO:Finalizing model
2023-05-09 19:28:31,216:INFO:Creating Dashboard logs
2023-05-09 19:28:31,219:INFO:Model: Gradient Boosting Regressor
2023-05-09 19:28:31,260:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 153, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-05-09 19:28:31,337:INFO:Initializing predict_model()
2023-05-09 19:28:31,337:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D392E560>)
2023-05-09 19:28:31,337:INFO:Checking exceptions
2023-05-09 19:28:31,337:INFO:Preloading libraries
2023-05-09 19:28:31,777:INFO:Uploading results into container
2023-05-09 19:28:31,778:INFO:Uploading model into container now
2023-05-09 19:28:31,780:INFO:_master_model_container: 20
2023-05-09 19:28:31,780:INFO:_display_container: 3
2023-05-09 19:28:31,780:INFO:GradientBoostingRegressor(random_state=153)
2023-05-09 19:28:31,780:INFO:create_model() successfully completed......................................
2023-05-09 19:28:31,908:INFO:Initializing create_model()
2023-05-09 19:28:31,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:31,908:INFO:Checking exceptions
2023-05-09 19:28:31,932:INFO:Importing libraries
2023-05-09 19:28:31,932:INFO:Copying training dataset
2023-05-09 19:28:31,936:INFO:Defining folds
2023-05-09 19:28:31,936:INFO:Declaring metric variables
2023-05-09 19:28:31,951:INFO:Importing untrained model
2023-05-09 19:28:31,956:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 19:28:31,964:INFO:Starting cross validation
2023-05-09 19:28:31,965:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:33,208:INFO:Calculating mean and std
2023-05-09 19:28:33,224:INFO:Creating metrics dataframe
2023-05-09 19:28:33,224:INFO:Finalizing model
2023-05-09 19:28:33,625:INFO:Creating Dashboard logs
2023-05-09 19:28:33,625:INFO:Model: Light Gradient Boosting Machine
2023-05-09 19:28:33,684:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 153, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-09 19:28:33,756:INFO:Initializing predict_model()
2023-05-09 19:28:33,756:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D392D1B0>)
2023-05-09 19:28:33,756:INFO:Checking exceptions
2023-05-09 19:28:33,756:INFO:Preloading libraries
2023-05-09 19:28:34,251:INFO:Uploading results into container
2023-05-09 19:28:34,251:INFO:Uploading model into container now
2023-05-09 19:28:34,259:INFO:_master_model_container: 21
2023-05-09 19:28:34,259:INFO:_display_container: 4
2023-05-09 19:28:34,259:INFO:LGBMRegressor(random_state=153)
2023-05-09 19:28:34,259:INFO:create_model() successfully completed......................................
2023-05-09 19:28:34,363:INFO:Initializing create_model()
2023-05-09 19:28:34,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:28:34,363:INFO:Checking exceptions
2023-05-09 19:28:34,394:INFO:Importing libraries
2023-05-09 19:28:34,394:INFO:Copying training dataset
2023-05-09 19:28:34,394:INFO:Defining folds
2023-05-09 19:28:34,394:INFO:Declaring metric variables
2023-05-09 19:28:34,409:INFO:Importing untrained model
2023-05-09 19:28:34,414:INFO:Random Forest Regressor Imported successfully
2023-05-09 19:28:34,420:INFO:Starting cross validation
2023-05-09 19:28:34,422:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:28:35,612:INFO:Calculating mean and std
2023-05-09 19:28:35,614:INFO:Creating metrics dataframe
2023-05-09 19:28:35,619:INFO:Finalizing model
2023-05-09 19:28:36,128:INFO:Creating Dashboard logs
2023-05-09 19:28:36,128:INFO:Model: Random Forest Regressor
2023-05-09 19:28:36,172:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 153, 'verbose': 0, 'warm_start': False}
2023-05-09 19:28:36,233:INFO:Initializing predict_model()
2023-05-09 19:28:36,233:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(n_jobs=-1, random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D392DEA0>)
2023-05-09 19:28:36,233:INFO:Checking exceptions
2023-05-09 19:28:36,233:INFO:Preloading libraries
2023-05-09 19:28:36,699:INFO:Uploading results into container
2023-05-09 19:28:36,709:INFO:Uploading model into container now
2023-05-09 19:28:36,717:INFO:_master_model_container: 22
2023-05-09 19:28:36,717:INFO:_display_container: 5
2023-05-09 19:28:36,718:INFO:RandomForestRegressor(n_jobs=-1, random_state=153)
2023-05-09 19:28:36,718:INFO:create_model() successfully completed......................................
2023-05-09 19:28:36,824:INFO:Initializing tune_model()
2023-05-09 19:28:36,824:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=153), fold=10, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>)
2023-05-09 19:28:36,824:INFO:Checking exceptions
2023-05-09 19:28:36,856:INFO:Copying training dataset
2023-05-09 19:28:36,856:INFO:Checking base model
2023-05-09 19:28:36,856:INFO:Base model : Gradient Boosting Regressor
2023-05-09 19:28:36,869:INFO:Declaring metric variables
2023-05-09 19:28:36,873:INFO:Defining Hyperparameters
2023-05-09 19:28:36,949:INFO:Tuning with n_jobs=-1
2023-05-09 19:28:36,949:INFO:Initializing RandomizedSearchCV
2023-05-09 19:29:07,592:INFO:best_params: {'actual_estimator__subsample': 0.4, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.2}
2023-05-09 19:29:07,592:INFO:Hyperparameter search completed
2023-05-09 19:29:07,592:INFO:SubProcess create_model() called ==================================
2023-05-09 19:29:07,592:INFO:Initializing create_model()
2023-05-09 19:29:07,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D3C22920>, model_only=True, return_train_score=False, kwargs={'subsample': 0.4, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 5, 'learning_rate': 0.2})
2023-05-09 19:29:07,592:INFO:Checking exceptions
2023-05-09 19:29:07,592:INFO:Importing libraries
2023-05-09 19:29:07,592:INFO:Copying training dataset
2023-05-09 19:29:07,609:INFO:Defining folds
2023-05-09 19:29:07,609:INFO:Declaring metric variables
2023-05-09 19:29:07,609:INFO:Importing untrained model
2023-05-09 19:29:07,609:INFO:Declaring custom model
2023-05-09 19:29:07,609:INFO:Gradient Boosting Regressor Imported successfully
2023-05-09 19:29:07,621:INFO:Starting cross validation
2023-05-09 19:29:07,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:29:10,077:INFO:Calculating mean and std
2023-05-09 19:29:10,077:INFO:Creating metrics dataframe
2023-05-09 19:29:10,085:INFO:Finalizing model
2023-05-09 19:29:10,474:INFO:Uploading results into container
2023-05-09 19:29:10,474:INFO:Uploading model into container now
2023-05-09 19:29:10,475:INFO:_master_model_container: 23
2023-05-09 19:29:10,475:INFO:_display_container: 6
2023-05-09 19:29:10,477:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=5, max_features=1.0,
                          min_impurity_decrease=0.002, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=10,
                          random_state=153, subsample=0.4)
2023-05-09 19:29:10,477:INFO:create_model() successfully completed......................................
2023-05-09 19:29:10,600:INFO:SubProcess create_model() end ==================================
2023-05-09 19:29:10,601:INFO:choose_better activated
2023-05-09 19:29:10,603:INFO:SubProcess create_model() called ==================================
2023-05-09 19:29:10,604:INFO:Initializing create_model()
2023-05-09 19:29:10,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:29:10,604:INFO:Checking exceptions
2023-05-09 19:29:10,605:INFO:Importing libraries
2023-05-09 19:29:10,606:INFO:Copying training dataset
2023-05-09 19:29:10,609:INFO:Defining folds
2023-05-09 19:29:10,610:INFO:Declaring metric variables
2023-05-09 19:29:10,610:INFO:Importing untrained model
2023-05-09 19:29:10,610:INFO:Declaring custom model
2023-05-09 19:29:10,610:INFO:Gradient Boosting Regressor Imported successfully
2023-05-09 19:29:10,610:INFO:Starting cross validation
2023-05-09 19:29:10,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:29:13,353:INFO:Calculating mean and std
2023-05-09 19:29:13,353:INFO:Creating metrics dataframe
2023-05-09 19:29:13,369:INFO:Finalizing model
2023-05-09 19:29:13,747:INFO:Uploading results into container
2023-05-09 19:29:13,747:INFO:Uploading model into container now
2023-05-09 19:29:13,747:INFO:_master_model_container: 24
2023-05-09 19:29:13,747:INFO:_display_container: 7
2023-05-09 19:29:13,747:INFO:GradientBoostingRegressor(random_state=153)
2023-05-09 19:29:13,747:INFO:create_model() successfully completed......................................
2023-05-09 19:29:13,825:INFO:SubProcess create_model() end ==================================
2023-05-09 19:29:13,825:INFO:GradientBoostingRegressor(random_state=153) result for RMSE is 4730.9785
2023-05-09 19:29:13,825:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=5, max_features=1.0,
                          min_impurity_decrease=0.002, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=10,
                          random_state=153, subsample=0.4) result for RMSE is 4958.9008
2023-05-09 19:29:13,825:INFO:GradientBoostingRegressor(random_state=153) is best model
2023-05-09 19:29:13,825:INFO:choose_better completed
2023-05-09 19:29:13,825:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-09 19:29:13,825:INFO:Creating Dashboard logs
2023-05-09 19:29:13,825:INFO:Model: Gradient Boosting Regressor
2023-05-09 19:29:13,872:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 153, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-05-09 19:29:13,966:INFO:Initializing predict_model()
2023-05-09 19:29:13,966:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D392F130>)
2023-05-09 19:29:13,966:INFO:Checking exceptions
2023-05-09 19:29:13,966:INFO:Preloading libraries
2023-05-09 19:29:14,421:INFO:_master_model_container: 24
2023-05-09 19:29:14,421:INFO:_display_container: 6
2023-05-09 19:29:14,421:INFO:GradientBoostingRegressor(random_state=153)
2023-05-09 19:29:14,421:INFO:tune_model() successfully completed......................................
2023-05-09 19:29:14,735:INFO:Initializing tune_model()
2023-05-09 19:29:14,735:INFO:tune_model(estimator=LGBMRegressor(random_state=153), fold=10, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>)
2023-05-09 19:29:14,735:INFO:Checking exceptions
2023-05-09 19:29:14,763:INFO:Copying training dataset
2023-05-09 19:29:14,766:INFO:Checking base model
2023-05-09 19:29:14,766:INFO:Base model : Light Gradient Boosting Machine
2023-05-09 19:29:14,769:INFO:Declaring metric variables
2023-05-09 19:29:14,772:INFO:Defining Hyperparameters
2023-05-09 19:29:14,844:INFO:Tuning with n_jobs=-1
2023-05-09 19:29:14,844:INFO:Initializing RandomizedSearchCV
2023-05-09 19:29:43,591:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0, 'actual_estimator__min_child_samples': 46, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.6}
2023-05-09 19:29:43,592:INFO:Hyperparameter search completed
2023-05-09 19:29:43,592:INFO:SubProcess create_model() called ==================================
2023-05-09 19:29:43,593:INFO:Initializing create_model()
2023-05-09 19:29:43,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(random_state=153), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124D14989A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 0.005, 'num_leaves': 10, 'n_estimators': 80, 'min_split_gain': 0, 'min_child_samples': 46, 'learning_rate': 0.3, 'feature_fraction': 0.4, 'bagging_freq': 1, 'bagging_fraction': 0.6})
2023-05-09 19:29:43,593:INFO:Checking exceptions
2023-05-09 19:29:43,593:INFO:Importing libraries
2023-05-09 19:29:43,593:INFO:Copying training dataset
2023-05-09 19:29:43,596:INFO:Defining folds
2023-05-09 19:29:43,596:INFO:Declaring metric variables
2023-05-09 19:29:43,598:INFO:Importing untrained model
2023-05-09 19:29:43,599:INFO:Declaring custom model
2023-05-09 19:29:43,603:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 19:29:43,610:INFO:Starting cross validation
2023-05-09 19:29:43,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:29:46,189:INFO:Calculating mean and std
2023-05-09 19:29:46,190:INFO:Creating metrics dataframe
2023-05-09 19:29:46,194:INFO:Finalizing model
2023-05-09 19:29:46,215:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-05-09 19:29:46,215:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-05-09 19:29:46,215:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2023-05-09 19:29:46,629:INFO:Uploading results into container
2023-05-09 19:29:46,630:INFO:Uploading model into container now
2023-05-09 19:29:46,630:INFO:_master_model_container: 25
2023-05-09 19:29:46,630:INFO:_display_container: 7
2023-05-09 19:29:46,631:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06)
2023-05-09 19:29:46,631:INFO:create_model() successfully completed......................................
2023-05-09 19:29:46,724:INFO:SubProcess create_model() end ==================================
2023-05-09 19:29:46,724:INFO:choose_better activated
2023-05-09 19:29:46,728:INFO:SubProcess create_model() called ==================================
2023-05-09 19:29:46,728:INFO:Initializing create_model()
2023-05-09 19:29:46,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(random_state=153), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:29:46,728:INFO:Checking exceptions
2023-05-09 19:29:46,728:INFO:Importing libraries
2023-05-09 19:29:46,728:INFO:Copying training dataset
2023-05-09 19:29:46,728:INFO:Defining folds
2023-05-09 19:29:46,728:INFO:Declaring metric variables
2023-05-09 19:29:46,728:INFO:Importing untrained model
2023-05-09 19:29:46,728:INFO:Declaring custom model
2023-05-09 19:29:46,728:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 19:29:46,728:INFO:Starting cross validation
2023-05-09 19:29:46,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:29:49,314:INFO:Calculating mean and std
2023-05-09 19:29:49,314:INFO:Creating metrics dataframe
2023-05-09 19:29:49,314:INFO:Finalizing model
2023-05-09 19:29:49,740:INFO:Uploading results into container
2023-05-09 19:29:49,740:INFO:Uploading model into container now
2023-05-09 19:29:49,740:INFO:_master_model_container: 26
2023-05-09 19:29:49,740:INFO:_display_container: 8
2023-05-09 19:29:49,740:INFO:LGBMRegressor(random_state=153)
2023-05-09 19:29:49,740:INFO:create_model() successfully completed......................................
2023-05-09 19:29:49,818:INFO:SubProcess create_model() end ==================================
2023-05-09 19:29:49,818:INFO:LGBMRegressor(random_state=153) result for RMSE is 5045.7317
2023-05-09 19:29:49,818:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06) result for RMSE is 4977.9224
2023-05-09 19:29:49,818:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06) is best model
2023-05-09 19:29:49,818:INFO:choose_better completed
2023-05-09 19:29:49,818:INFO:Creating Dashboard logs
2023-05-09 19:29:49,818:INFO:Model: Light Gradient Boosting Machine
2023-05-09 19:29:49,867:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': -1, 'min_child_samples': 46, 'min_child_weight': 0.001, 'min_split_gain': 0, 'n_estimators': 80, 'n_jobs': -1, 'num_leaves': 10, 'objective': None, 'random_state': 153, 'reg_alpha': 0.005, 'reg_lambda': 1e-06, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 1, 'bagging_fraction': 0.6}
2023-05-09 19:29:49,962:INFO:Initializing predict_model()
2023-05-09 19:29:49,962:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D392D630>)
2023-05-09 19:29:49,962:INFO:Checking exceptions
2023-05-09 19:29:49,962:INFO:Preloading libraries
2023-05-09 19:29:50,471:INFO:_master_model_container: 26
2023-05-09 19:29:50,471:INFO:_display_container: 7
2023-05-09 19:29:50,471:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06)
2023-05-09 19:29:50,471:INFO:tune_model() successfully completed......................................
2023-05-09 19:29:50,803:INFO:Initializing tune_model()
2023-05-09 19:29:50,803:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=153), fold=10, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>)
2023-05-09 19:29:50,803:INFO:Checking exceptions
2023-05-09 19:29:50,830:INFO:Copying training dataset
2023-05-09 19:29:50,834:INFO:Checking base model
2023-05-09 19:29:50,834:INFO:Base model : Random Forest Regressor
2023-05-09 19:29:50,837:INFO:Declaring metric variables
2023-05-09 19:29:50,840:INFO:Defining Hyperparameters
2023-05-09 19:29:50,933:INFO:Tuning with n_jobs=-1
2023-05-09 19:29:50,933:INFO:Initializing RandomizedSearchCV
2023-05-09 19:30:34,228:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-05-09 19:30:34,228:INFO:Hyperparameter search completed
2023-05-09 19:30:34,228:INFO:SubProcess create_model() called ==================================
2023-05-09 19:30:34,228:INFO:Initializing create_model()
2023-05-09 19:30:34,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(n_jobs=-1, random_state=153), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000124ACCBC100>, model_only=True, return_train_score=False, kwargs={'n_estimators': 240, 'min_samples_split': 7, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'squared_error', 'bootstrap': True})
2023-05-09 19:30:34,228:INFO:Checking exceptions
2023-05-09 19:30:34,228:INFO:Importing libraries
2023-05-09 19:30:34,228:INFO:Copying training dataset
2023-05-09 19:30:34,243:INFO:Defining folds
2023-05-09 19:30:34,243:INFO:Declaring metric variables
2023-05-09 19:30:34,243:INFO:Importing untrained model
2023-05-09 19:30:34,243:INFO:Declaring custom model
2023-05-09 19:30:34,243:INFO:Random Forest Regressor Imported successfully
2023-05-09 19:30:34,243:INFO:Starting cross validation
2023-05-09 19:30:34,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:30:37,356:INFO:Calculating mean and std
2023-05-09 19:30:37,356:INFO:Creating metrics dataframe
2023-05-09 19:30:37,373:INFO:Finalizing model
2023-05-09 19:30:38,159:INFO:Uploading results into container
2023-05-09 19:30:38,160:INFO:Uploading model into container now
2023-05-09 19:30:38,161:INFO:_master_model_container: 27
2023-05-09 19:30:38,161:INFO:_display_container: 8
2023-05-09 19:30:38,161:INFO:RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153)
2023-05-09 19:30:38,162:INFO:create_model() successfully completed......................................
2023-05-09 19:30:38,260:INFO:SubProcess create_model() end ==================================
2023-05-09 19:30:38,260:INFO:choose_better activated
2023-05-09 19:30:38,264:INFO:SubProcess create_model() called ==================================
2023-05-09 19:30:38,265:INFO:Initializing create_model()
2023-05-09 19:30:38,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(n_jobs=-1, random_state=153), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 19:30:38,265:INFO:Checking exceptions
2023-05-09 19:30:38,266:INFO:Importing libraries
2023-05-09 19:30:38,267:INFO:Copying training dataset
2023-05-09 19:30:38,269:INFO:Defining folds
2023-05-09 19:30:38,269:INFO:Declaring metric variables
2023-05-09 19:30:38,269:INFO:Importing untrained model
2023-05-09 19:30:38,269:INFO:Declaring custom model
2023-05-09 19:30:38,270:INFO:Random Forest Regressor Imported successfully
2023-05-09 19:30:38,271:INFO:Starting cross validation
2023-05-09 19:30:38,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 19:30:41,961:INFO:Calculating mean and std
2023-05-09 19:30:41,961:INFO:Creating metrics dataframe
2023-05-09 19:30:41,961:INFO:Finalizing model
2023-05-09 19:30:42,417:INFO:Uploading results into container
2023-05-09 19:30:42,418:INFO:Uploading model into container now
2023-05-09 19:30:42,418:INFO:_master_model_container: 28
2023-05-09 19:30:42,418:INFO:_display_container: 9
2023-05-09 19:30:42,419:INFO:RandomForestRegressor(n_jobs=-1, random_state=153)
2023-05-09 19:30:42,419:INFO:create_model() successfully completed......................................
2023-05-09 19:30:42,502:INFO:SubProcess create_model() end ==================================
2023-05-09 19:30:42,502:INFO:RandomForestRegressor(n_jobs=-1, random_state=153) result for RMSE is 5074.166
2023-05-09 19:30:42,504:INFO:RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153) result for RMSE is 4674.2859
2023-05-09 19:30:42,504:INFO:RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153) is best model
2023-05-09 19:30:42,504:INFO:choose_better completed
2023-05-09 19:30:42,504:INFO:Creating Dashboard logs
2023-05-09 19:30:42,506:INFO:Model: Random Forest Regressor
2023-05-09 19:30:42,552:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.005, 'min_samples_leaf': 6, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 240, 'n_jobs': -1, 'oob_score': False, 'random_state': 153, 'verbose': 0, 'warm_start': False}
2023-05-09 19:30:42,621:INFO:Initializing predict_model()
2023-05-09 19:30:42,621:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D80B3AC0>)
2023-05-09 19:30:42,621:INFO:Checking exceptions
2023-05-09 19:30:42,621:INFO:Preloading libraries
2023-05-09 19:30:43,149:INFO:_master_model_container: 28
2023-05-09 19:30:43,149:INFO:_display_container: 8
2023-05-09 19:30:43,150:INFO:RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153)
2023-05-09 19:30:43,150:INFO:tune_model() successfully completed......................................
2023-05-09 19:30:43,531:INFO:Initializing plot_model()
2023-05-09 19:30:43,531:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=153), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, system=True)
2023-05-09 19:30:43,531:INFO:Checking exceptions
2023-05-09 19:30:43,535:INFO:Preloading libraries
2023-05-09 19:30:43,540:INFO:Copying training dataset
2023-05-09 19:30:43,540:INFO:Plot type: error
2023-05-09 19:30:43,686:INFO:Fitting Model
2023-05-09 19:30:43,686:INFO:Scoring test/hold-out set
2023-05-09 19:30:43,965:INFO:Visual Rendered Successfully
2023-05-09 19:30:44,051:INFO:plot_model() successfully completed......................................
2023-05-09 19:30:44,051:INFO:Initializing plot_model()
2023-05-09 19:30:44,051:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, system=True)
2023-05-09 19:30:44,051:INFO:Checking exceptions
2023-05-09 19:30:44,051:INFO:Preloading libraries
2023-05-09 19:30:44,067:INFO:Copying training dataset
2023-05-09 19:30:44,067:INFO:Plot type: error
2023-05-09 19:30:44,136:INFO:Fitting Model
2023-05-09 19:30:44,136:INFO:Scoring test/hold-out set
2023-05-09 19:30:44,326:INFO:Visual Rendered Successfully
2023-05-09 19:30:44,421:INFO:plot_model() successfully completed......................................
2023-05-09 19:30:44,436:INFO:Initializing plot_model()
2023-05-09 19:30:44,436:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, system=True)
2023-05-09 19:30:44,436:INFO:Checking exceptions
2023-05-09 19:30:44,454:INFO:Preloading libraries
2023-05-09 19:30:44,470:INFO:Copying training dataset
2023-05-09 19:30:44,470:INFO:Plot type: error
2023-05-09 19:30:44,520:INFO:Fitting Model
2023-05-09 19:30:44,520:INFO:Scoring test/hold-out set
2023-05-09 19:30:44,738:INFO:Visual Rendered Successfully
2023-05-09 19:30:44,853:INFO:plot_model() successfully completed......................................
2023-05-09 19:30:44,902:INFO:Initializing plot_model()
2023-05-09 19:30:44,902:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=153), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, system=True)
2023-05-09 19:30:44,902:INFO:Checking exceptions
2023-05-09 19:30:44,904:INFO:Preloading libraries
2023-05-09 19:30:44,904:INFO:Copying training dataset
2023-05-09 19:30:44,904:INFO:Plot type: feature
2023-05-09 19:30:44,904:WARNING:No coef_ found. Trying feature_importances_
2023-05-09 19:30:45,065:INFO:Visual Rendered Successfully
2023-05-09 19:30:45,181:INFO:plot_model() successfully completed......................................
2023-05-09 19:30:45,181:INFO:Initializing plot_model()
2023-05-09 19:30:45,197:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, system=True)
2023-05-09 19:30:45,197:INFO:Checking exceptions
2023-05-09 19:30:45,197:INFO:Preloading libraries
2023-05-09 19:30:45,203:INFO:Copying training dataset
2023-05-09 19:30:45,203:INFO:Plot type: feature
2023-05-09 19:30:45,204:WARNING:No coef_ found. Trying feature_importances_
2023-05-09 19:30:45,364:INFO:Visual Rendered Successfully
2023-05-09 19:30:45,446:INFO:plot_model() successfully completed......................................
2023-05-09 19:30:45,446:INFO:Initializing plot_model()
2023-05-09 19:30:45,446:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, system=True)
2023-05-09 19:30:45,446:INFO:Checking exceptions
2023-05-09 19:30:45,462:INFO:Preloading libraries
2023-05-09 19:30:45,484:INFO:Copying training dataset
2023-05-09 19:30:45,485:INFO:Plot type: feature
2023-05-09 19:30:45,485:WARNING:No coef_ found. Trying feature_importances_
2023-05-09 19:30:45,650:INFO:Visual Rendered Successfully
2023-05-09 19:30:45,750:INFO:plot_model() successfully completed......................................
2023-05-09 19:30:45,773:INFO:Initializing predict_model()
2023-05-09 19:30:45,773:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D8ABFE20>)
2023-05-09 19:30:45,773:INFO:Checking exceptions
2023-05-09 19:30:45,773:INFO:Preloading libraries
2023-05-09 19:30:45,940:INFO:Initializing predict_model()
2023-05-09 19:30:45,940:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D8ABF2E0>)
2023-05-09 19:30:45,940:INFO:Checking exceptions
2023-05-09 19:30:45,940:INFO:Preloading libraries
2023-05-09 19:30:46,126:INFO:Initializing predict_model()
2023-05-09 19:30:46,126:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D8ABF2E0>)
2023-05-09 19:30:46,126:INFO:Checking exceptions
2023-05-09 19:30:46,126:INFO:Preloading libraries
2023-05-09 19:30:46,318:INFO:Initializing finalize_model()
2023-05-09 19:30:46,318:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-05-09 19:30:46,318:INFO:Finalizing GradientBoostingRegressor(random_state=153)
2023-05-09 19:30:46,320:INFO:Initializing create_model()
2023-05-09 19:30:46,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=GradientBoostingRegressor(random_state=153), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-05-09 19:30:46,320:INFO:Checking exceptions
2023-05-09 19:30:46,320:INFO:Importing libraries
2023-05-09 19:30:46,320:INFO:Copying training dataset
2023-05-09 19:30:46,320:INFO:Defining folds
2023-05-09 19:30:46,320:INFO:Declaring metric variables
2023-05-09 19:30:46,320:INFO:Importing untrained model
2023-05-09 19:30:46,320:INFO:Declaring custom model
2023-05-09 19:30:46,320:INFO:Gradient Boosting Regressor Imported successfully
2023-05-09 19:30:46,320:INFO:Cross validation set to False
2023-05-09 19:30:46,320:INFO:Fitting Model
2023-05-09 19:30:46,412:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=153))])
2023-05-09 19:30:46,412:INFO:create_model() successfully completed......................................
2023-05-09 19:30:46,503:INFO:Creating Dashboard logs
2023-05-09 19:30:46,503:INFO:Model: Gradient Boosting Regressor
2023-05-09 19:30:46,538:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 153, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-05-09 19:30:46,944:INFO:_master_model_container: 28
2023-05-09 19:30:46,944:INFO:_display_container: 11
2023-05-09 19:30:46,944:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=153))])
2023-05-09 19:30:46,944:INFO:finalize_model() successfully completed......................................
2023-05-09 19:30:47,023:INFO:Initializing finalize_model()
2023-05-09 19:30:47,023:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-05-09 19:30:47,023:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06)
2023-05-09 19:30:47,023:INFO:Initializing create_model()
2023-05-09 19:30:47,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=1, feature_fraction=0.4,
              learning_rate=0.3, min_child_samples=46, min_split_gain=0,
              n_estimators=80, num_leaves=10, random_state=153, reg_alpha=0.005,
              reg_lambda=1e-06), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-05-09 19:30:47,023:INFO:Checking exceptions
2023-05-09 19:30:47,023:INFO:Importing libraries
2023-05-09 19:30:47,023:INFO:Copying training dataset
2023-05-09 19:30:47,023:INFO:Defining folds
2023-05-09 19:30:47,023:INFO:Declaring metric variables
2023-05-09 19:30:47,023:INFO:Importing untrained model
2023-05-09 19:30:47,023:INFO:Declaring custom model
2023-05-09 19:30:47,023:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 19:30:47,023:INFO:Cross validation set to False
2023-05-09 19:30:47,023:INFO:Fitting Model
2023-05-09 19:30:47,039:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-05-09 19:30:47,039:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-05-09 19:30:47,039:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2023-05-09 19:30:47,070:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=1,
                               feature_fraction=0.4, learning_rate=0.3,
                               min_child_samples=46, min_split_gain=0,
                               n_estimators=80, num_leaves=10, random_state=153,
                               reg_alpha=0.005, reg_lambda=1e-06))])
2023-05-09 19:30:47,070:INFO:create_model() successfully completed......................................
2023-05-09 19:30:47,181:INFO:Creating Dashboard logs
2023-05-09 19:30:47,181:INFO:Model: Light Gradient Boosting Machine
2023-05-09 19:30:47,221:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': -1, 'min_child_samples': 46, 'min_child_weight': 0.001, 'min_split_gain': 0, 'n_estimators': 80, 'n_jobs': -1, 'num_leaves': 10, 'objective': None, 'random_state': 153, 'reg_alpha': 0.005, 'reg_lambda': 1e-06, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 1, 'bagging_fraction': 0.6}
2023-05-09 19:30:47,676:INFO:_master_model_container: 28
2023-05-09 19:30:47,676:INFO:_display_container: 11
2023-05-09 19:30:47,692:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=1,
                               feature_fraction=0.4, learning_rate=0.3,
                               min_child_samples=46, min_split_gain=0,
                               n_estimators=80, num_leaves=10, random_state=153,
                               reg_alpha=0.005, reg_lambda=1e-06))])
2023-05-09 19:30:47,692:INFO:finalize_model() successfully completed......................................
2023-05-09 19:30:47,761:INFO:Initializing finalize_model()
2023-05-09 19:30:47,761:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-05-09 19:30:47,776:INFO:Finalizing RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153)
2023-05-09 19:30:47,778:INFO:Initializing create_model()
2023-05-09 19:30:47,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                      min_samples_leaf=6, min_samples_split=7, n_estimators=240,
                      n_jobs=-1, random_state=153), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-05-09 19:30:47,778:INFO:Checking exceptions
2023-05-09 19:30:47,779:INFO:Importing libraries
2023-05-09 19:30:47,779:INFO:Copying training dataset
2023-05-09 19:30:47,779:INFO:Defining folds
2023-05-09 19:30:47,779:INFO:Declaring metric variables
2023-05-09 19:30:47,779:INFO:Importing untrained model
2023-05-09 19:30:47,780:INFO:Declaring custom model
2023-05-09 19:30:47,780:INFO:Random Forest Regressor Imported successfully
2023-05-09 19:30:47,780:INFO:Cross validation set to False
2023-05-09 19:30:47,780:INFO:Fitting Model
2023-05-09 19:30:48,101:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                                       min_samples_leaf=6, min_samples_split=7,
                                       n_estimators=240, n_jobs=-1,
                                       random_state=153))])
2023-05-09 19:30:48,101:INFO:create_model() successfully completed......................................
2023-05-09 19:30:48,205:INFO:Creating Dashboard logs
2023-05-09 19:30:48,205:INFO:Model: Random Forest Regressor
2023-05-09 19:30:48,258:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.005, 'min_samples_leaf': 6, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 240, 'n_jobs': -1, 'oob_score': False, 'random_state': 153, 'verbose': 0, 'warm_start': False}
2023-05-09 19:30:48,705:INFO:_master_model_container: 28
2023-05-09 19:30:48,705:INFO:_display_container: 11
2023-05-09 19:30:48,705:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                                       min_samples_leaf=6, min_samples_split=7,
                                       n_estimators=240, n_jobs=-1,
                                       random_state=153))])
2023-05-09 19:30:48,705:INFO:finalize_model() successfully completed......................................
2023-05-09 19:30:48,807:INFO:Initializing predict_model()
2023-05-09 19:30:48,807:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=153))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D8ABF1C0>)
2023-05-09 19:30:48,807:INFO:Checking exceptions
2023-05-09 19:30:48,807:INFO:Preloading libraries
2023-05-09 19:30:48,807:INFO:Set up data.
2023-05-09 19:30:48,807:INFO:Set up index.
2023-05-09 19:30:48,992:INFO:Initializing predict_model()
2023-05-09 19:30:48,992:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=1,
                               feature_fraction=0.4, learning_rate=0.3,
                               min_child_samples=46, min_split_gain=0,
                               n_estimators=80, num_leaves=10, random_state=153,
                               reg_alpha=0.005, reg_lambda=1e-06))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D8ABF370>)
2023-05-09 19:30:48,992:INFO:Checking exceptions
2023-05-09 19:30:48,992:INFO:Preloading libraries
2023-05-09 19:30:48,993:INFO:Set up data.
2023-05-09 19:30:48,993:INFO:Set up index.
2023-05-09 19:30:49,155:INFO:Initializing predict_model()
2023-05-09 19:30:49,155:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000124D7366380>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(max_depth=3, min_impurity_decrease=0.005,
                                       min_samples_leaf=6, min_samples_split=7,
                                       n_estimators=240, n_jobs=-1,
                                       random_state=153))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000124D8ABECB0>)
2023-05-09 19:30:49,155:INFO:Checking exceptions
2023-05-09 19:30:49,155:INFO:Preloading libraries
2023-05-09 19:30:49,155:INFO:Set up data.
2023-05-09 19:30:49,175:INFO:Set up index.
