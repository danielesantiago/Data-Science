2023-04-24 16:33:43,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:33:43,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:33:43,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:33:43,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:33:47,588:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 16:33:54,264:INFO:PyCaret RegressionExperiment
2023-04-24 16:33:54,265:INFO:Logging name: reg-default-name
2023-04-24 16:33:54,265:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:33:54,265:INFO:version 3.0.0
2023-04-24 16:33:54,265:INFO:Initializing setup()
2023-04-24 16:33:54,265:INFO:self.USI: 9ab3
2023-04-24 16:33:54,265:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', 'X', 'pipeline', 'n_jobs_param', 'y_test', 'memory', 'y_train', 'log_plots_param', 'fold_shuffle_param', 'seed', '_available_plots', 'fold_groups_param', '_ml_usecase', 'y', 'X_test', 'idx', 'target_param', 'USI', 'html_param', 'fold_generator', 'exp_id', 'transform_target_param', 'gpu_param', 'gpu_n_jobs_param', 'data'}
2023-04-24 16:33:54,265:INFO:Checking environment
2023-04-24 16:33:54,265:INFO:python_version: 3.10.11
2023-04-24 16:33:54,265:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:33:54,265:INFO:machine: AMD64
2023-04-24 16:33:54,265:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:33:54,266:INFO:Memory: svmem(total=8362713088, available=720629760, percent=91.4, used=7642083328, free=720629760)
2023-04-24 16:33:54,266:INFO:Physical Core: 4
2023-04-24 16:33:54,266:INFO:Logical Core: 8
2023-04-24 16:33:54,266:INFO:Checking libraries
2023-04-24 16:33:54,266:INFO:System:
2023-04-24 16:33:54,266:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:33:54,266:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:33:54,266:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:33:54,266:INFO:PyCaret required dependencies:
2023-04-24 16:33:54,266:INFO:                 pip: 23.0.1
2023-04-24 16:33:54,266:INFO:          setuptools: 65.5.0
2023-04-24 16:33:54,266:INFO:             pycaret: 3.0.0
2023-04-24 16:33:54,266:INFO:             IPython: 8.5.0
2023-04-24 16:33:54,266:INFO:          ipywidgets: 8.0.2
2023-04-24 16:33:54,266:INFO:                tqdm: 4.65.0
2023-04-24 16:33:54,266:INFO:               numpy: 1.23.3
2023-04-24 16:33:54,266:INFO:              pandas: 1.5.0
2023-04-24 16:33:54,266:INFO:              jinja2: 3.1.2
2023-04-24 16:33:54,266:INFO:               scipy: 1.9.1
2023-04-24 16:33:54,266:INFO:              joblib: 1.2.0
2023-04-24 16:33:54,266:INFO:             sklearn: 1.1.2
2023-04-24 16:33:54,266:INFO:                pyod: 1.0.9
2023-04-24 16:33:54,266:INFO:            imblearn: 0.10.1
2023-04-24 16:33:54,266:INFO:   category_encoders: 2.6.0
2023-04-24 16:33:54,266:INFO:            lightgbm: 3.3.5
2023-04-24 16:33:54,266:INFO:               numba: 0.56.4
2023-04-24 16:33:54,266:INFO:            requests: 2.28.1
2023-04-24 16:33:54,266:INFO:          matplotlib: 3.6.0
2023-04-24 16:33:54,266:INFO:          scikitplot: 0.3.7
2023-04-24 16:33:54,266:INFO:         yellowbrick: 1.5
2023-04-24 16:33:54,266:INFO:              plotly: 5.10.0
2023-04-24 16:33:54,266:INFO:             kaleido: 0.2.1
2023-04-24 16:33:54,266:INFO:         statsmodels: 0.13.5
2023-04-24 16:33:54,267:INFO:              sktime: 0.17.1
2023-04-24 16:33:54,267:INFO:               tbats: 1.1.3
2023-04-24 16:33:54,267:INFO:            pmdarima: 2.0.3
2023-04-24 16:33:54,267:INFO:              psutil: 5.9.2
2023-04-24 16:33:54,267:INFO:PyCaret optional dependencies:
2023-04-24 16:33:54,278:INFO:                shap: Not installed
2023-04-24 16:33:54,278:INFO:           interpret: Not installed
2023-04-24 16:33:54,278:INFO:                umap: Not installed
2023-04-24 16:33:54,278:INFO:    pandas_profiling: Not installed
2023-04-24 16:33:54,278:INFO:  explainerdashboard: Not installed
2023-04-24 16:33:54,278:INFO:             autoviz: Not installed
2023-04-24 16:33:54,278:INFO:           fairlearn: Not installed
2023-04-24 16:33:54,278:INFO:             xgboost: 1.7.5
2023-04-24 16:33:54,278:INFO:            catboost: Not installed
2023-04-24 16:33:54,278:INFO:              kmodes: Not installed
2023-04-24 16:33:54,278:INFO:             mlxtend: Not installed
2023-04-24 16:33:54,278:INFO:       statsforecast: Not installed
2023-04-24 16:33:54,278:INFO:        tune_sklearn: Not installed
2023-04-24 16:33:54,279:INFO:                 ray: Not installed
2023-04-24 16:33:54,279:INFO:            hyperopt: Not installed
2023-04-24 16:33:54,279:INFO:              optuna: Not installed
2023-04-24 16:33:54,279:INFO:               skopt: Not installed
2023-04-24 16:33:54,279:INFO:              mlflow: Not installed
2023-04-24 16:33:54,279:INFO:              gradio: Not installed
2023-04-24 16:33:54,279:INFO:             fastapi: Not installed
2023-04-24 16:33:54,279:INFO:             uvicorn: Not installed
2023-04-24 16:33:54,279:INFO:              m2cgen: Not installed
2023-04-24 16:33:54,279:INFO:           evidently: Not installed
2023-04-24 16:33:54,279:INFO:               fugue: Not installed
2023-04-24 16:33:54,279:INFO:           streamlit: Not installed
2023-04-24 16:33:54,279:INFO:             prophet: Not installed
2023-04-24 16:33:54,279:INFO:None
2023-04-24 16:33:54,279:INFO:Set up data.
2023-04-24 16:33:54,286:INFO:Set up train/test split.
2023-04-24 16:33:54,289:INFO:Set up index.
2023-04-24 16:33:54,290:INFO:Set up folding strategy.
2023-04-24 16:33:54,290:INFO:Assigning column types.
2023-04-24 16:33:54,292:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:33:54,292:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,298:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,303:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,354:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,385:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:54,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:54,798:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,798:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,814:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,879:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:54,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:54,895:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:33:54,895:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,973:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:54,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:54,973:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:33:54,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,051:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,067:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:33:55,067:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,153:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,349:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,418:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,418:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:33:55,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,518:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,606:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,608:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:33:55,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,681:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:33:55,775:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,775:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:33:55,868:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,959:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:55,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:55,964:INFO:Preparing preprocessing pipeline...
2023-04-24 16:33:55,964:INFO:Set up simple imputation.
2023-04-24 16:33:55,966:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:33:55,982:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-24 16:33:55,982:INFO:Creating final display dataframe.
2023-04-24 16:33:56,025:INFO:Setup _display_container:                     Description             Value
0                    Session id               521
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1204, 8)
4        Transformed data shape         (1204, 8)
5   Transformed train set shape          (842, 8)
6    Transformed test set shape          (362, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9ab3
2023-04-24 16:33:56,125:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:56,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:56,213:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:33:56,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:33:56,216:INFO:setup() successfully completed in 1.95s...............
2023-04-24 16:37:55,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:37:55,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:37:55,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:37:55,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:37:55,802:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 16:37:56,021:INFO:PyCaret RegressionExperiment
2023-04-24 16:37:56,022:INFO:Logging name: reg-default-name
2023-04-24 16:37:56,022:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:37:56,022:INFO:version 3.0.0
2023-04-24 16:37:56,022:INFO:Initializing setup()
2023-04-24 16:37:56,022:INFO:self.USI: fb2b
2023-04-24 16:37:56,022:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 16:37:56,022:INFO:Checking environment
2023-04-24 16:37:56,022:INFO:python_version: 3.10.11
2023-04-24 16:37:56,022:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:37:56,022:INFO:machine: AMD64
2023-04-24 16:37:56,022:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:37:56,022:INFO:Memory: svmem(total=8362713088, available=902213632, percent=89.2, used=7460499456, free=902213632)
2023-04-24 16:37:56,022:INFO:Physical Core: 4
2023-04-24 16:37:56,022:INFO:Logical Core: 8
2023-04-24 16:37:56,022:INFO:Checking libraries
2023-04-24 16:37:56,022:INFO:System:
2023-04-24 16:37:56,022:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:37:56,023:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:37:56,023:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:37:56,023:INFO:PyCaret required dependencies:
2023-04-24 16:37:56,023:INFO:                 pip: 23.0.1
2023-04-24 16:37:56,023:INFO:          setuptools: 65.5.0
2023-04-24 16:37:56,023:INFO:             pycaret: 3.0.0
2023-04-24 16:37:56,023:INFO:             IPython: 8.5.0
2023-04-24 16:37:56,023:INFO:          ipywidgets: 8.0.2
2023-04-24 16:37:56,023:INFO:                tqdm: 4.65.0
2023-04-24 16:37:56,023:INFO:               numpy: 1.23.3
2023-04-24 16:37:56,023:INFO:              pandas: 1.5.0
2023-04-24 16:37:56,023:INFO:              jinja2: 3.1.2
2023-04-24 16:37:56,023:INFO:               scipy: 1.9.1
2023-04-24 16:37:56,023:INFO:              joblib: 1.2.0
2023-04-24 16:37:56,023:INFO:             sklearn: 1.1.2
2023-04-24 16:37:56,023:INFO:                pyod: 1.0.9
2023-04-24 16:37:56,023:INFO:            imblearn: 0.10.1
2023-04-24 16:37:56,023:INFO:   category_encoders: 2.6.0
2023-04-24 16:37:56,023:INFO:            lightgbm: 3.3.5
2023-04-24 16:37:56,023:INFO:               numba: 0.56.4
2023-04-24 16:37:56,023:INFO:            requests: 2.28.1
2023-04-24 16:37:56,023:INFO:          matplotlib: 3.6.0
2023-04-24 16:37:56,023:INFO:          scikitplot: 0.3.7
2023-04-24 16:37:56,023:INFO:         yellowbrick: 1.5
2023-04-24 16:37:56,023:INFO:              plotly: 5.10.0
2023-04-24 16:37:56,023:INFO:             kaleido: 0.2.1
2023-04-24 16:37:56,023:INFO:         statsmodels: 0.13.5
2023-04-24 16:37:56,023:INFO:              sktime: 0.17.1
2023-04-24 16:37:56,023:INFO:               tbats: 1.1.3
2023-04-24 16:37:56,023:INFO:            pmdarima: 2.0.3
2023-04-24 16:37:56,023:INFO:              psutil: 5.9.2
2023-04-24 16:37:56,023:INFO:PyCaret optional dependencies:
2023-04-24 16:37:56,037:INFO:                shap: Not installed
2023-04-24 16:37:56,037:INFO:           interpret: Not installed
2023-04-24 16:37:56,037:INFO:                umap: Not installed
2023-04-24 16:37:56,037:INFO:    pandas_profiling: Not installed
2023-04-24 16:37:56,037:INFO:  explainerdashboard: Not installed
2023-04-24 16:37:56,037:INFO:             autoviz: Not installed
2023-04-24 16:37:56,037:INFO:           fairlearn: Not installed
2023-04-24 16:37:56,037:INFO:             xgboost: 1.7.5
2023-04-24 16:37:56,037:INFO:            catboost: Not installed
2023-04-24 16:37:56,037:INFO:              kmodes: Not installed
2023-04-24 16:37:56,037:INFO:             mlxtend: Not installed
2023-04-24 16:37:56,037:INFO:       statsforecast: Not installed
2023-04-24 16:37:56,037:INFO:        tune_sklearn: Not installed
2023-04-24 16:37:56,037:INFO:                 ray: Not installed
2023-04-24 16:37:56,037:INFO:            hyperopt: Not installed
2023-04-24 16:37:56,037:INFO:              optuna: Not installed
2023-04-24 16:37:56,037:INFO:               skopt: Not installed
2023-04-24 16:37:56,037:INFO:              mlflow: 2.3.0
2023-04-24 16:37:56,037:INFO:              gradio: Not installed
2023-04-24 16:37:56,037:INFO:             fastapi: Not installed
2023-04-24 16:37:56,037:INFO:             uvicorn: Not installed
2023-04-24 16:37:56,037:INFO:              m2cgen: Not installed
2023-04-24 16:37:56,037:INFO:           evidently: Not installed
2023-04-24 16:37:56,037:INFO:               fugue: Not installed
2023-04-24 16:37:56,037:INFO:           streamlit: Not installed
2023-04-24 16:37:56,037:INFO:             prophet: Not installed
2023-04-24 16:37:56,037:INFO:None
2023-04-24 16:37:56,037:INFO:Set up data.
2023-04-24 16:37:56,046:INFO:Set up train/test split.
2023-04-24 16:37:56,046:INFO:Set up index.
2023-04-24 16:37:56,046:INFO:Set up folding strategy.
2023-04-24 16:37:56,046:INFO:Assigning column types.
2023-04-24 16:37:56,046:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:37:56,046:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,046:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,046:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,142:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,186:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,190:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,259:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,259:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:37:56,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,353:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,353:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,353:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,431:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,431:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:37:56,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,524:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,540:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,602:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,618:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:37:56,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,696:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,790:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,790:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:37:56,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,884:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:56,962:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:56,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:56,962:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:37:57,062:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,146:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,146:INFO:Preparing preprocessing pipeline...
2023-04-24 16:37:57,146:INFO:Set up simple imputation.
2023-04-24 16:37:57,176:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:37:57,180:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-24 16:37:57,180:INFO:Creating final display dataframe.
2023-04-24 16:37:57,223:INFO:Setup _display_container:                     Description             Value
0                    Session id              3031
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1204, 8)
4        Transformed data shape         (1204, 8)
5   Transformed train set shape          (842, 8)
6    Transformed test set shape          (362, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              fb2b
2023-04-24 16:37:57,326:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,414:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,421:INFO:setup() successfully completed in 1.4s...............
2023-04-24 16:37:57,431:INFO:PyCaret RegressionExperiment
2023-04-24 16:37:57,432:INFO:Logging name: charge_01
2023-04-24 16:37:57,432:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:37:57,432:INFO:version 3.0.0
2023-04-24 16:37:57,432:INFO:Initializing setup()
2023-04-24 16:37:57,432:INFO:self.USI: ef00
2023-04-24 16:37:57,432:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 16:37:57,432:INFO:Checking environment
2023-04-24 16:37:57,432:INFO:python_version: 3.10.11
2023-04-24 16:37:57,432:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:37:57,432:INFO:machine: AMD64
2023-04-24 16:37:57,432:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:37:57,432:INFO:Memory: svmem(total=8362713088, available=898834432, percent=89.3, used=7463878656, free=898834432)
2023-04-24 16:37:57,432:INFO:Physical Core: 4
2023-04-24 16:37:57,433:INFO:Logical Core: 8
2023-04-24 16:37:57,433:INFO:Checking libraries
2023-04-24 16:37:57,433:INFO:System:
2023-04-24 16:37:57,433:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:37:57,433:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:37:57,433:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:37:57,433:INFO:PyCaret required dependencies:
2023-04-24 16:37:57,434:INFO:                 pip: 23.0.1
2023-04-24 16:37:57,434:INFO:          setuptools: 65.5.0
2023-04-24 16:37:57,434:INFO:             pycaret: 3.0.0
2023-04-24 16:37:57,434:INFO:             IPython: 8.5.0
2023-04-24 16:37:57,434:INFO:          ipywidgets: 8.0.2
2023-04-24 16:37:57,434:INFO:                tqdm: 4.65.0
2023-04-24 16:37:57,434:INFO:               numpy: 1.23.3
2023-04-24 16:37:57,434:INFO:              pandas: 1.5.0
2023-04-24 16:37:57,434:INFO:              jinja2: 3.1.2
2023-04-24 16:37:57,434:INFO:               scipy: 1.9.1
2023-04-24 16:37:57,434:INFO:              joblib: 1.2.0
2023-04-24 16:37:57,434:INFO:             sklearn: 1.1.2
2023-04-24 16:37:57,434:INFO:                pyod: 1.0.9
2023-04-24 16:37:57,434:INFO:            imblearn: 0.10.1
2023-04-24 16:37:57,434:INFO:   category_encoders: 2.6.0
2023-04-24 16:37:57,434:INFO:            lightgbm: 3.3.5
2023-04-24 16:37:57,435:INFO:               numba: 0.56.4
2023-04-24 16:37:57,435:INFO:            requests: 2.28.1
2023-04-24 16:37:57,435:INFO:          matplotlib: 3.6.0
2023-04-24 16:37:57,435:INFO:          scikitplot: 0.3.7
2023-04-24 16:37:57,435:INFO:         yellowbrick: 1.5
2023-04-24 16:37:57,435:INFO:              plotly: 5.10.0
2023-04-24 16:37:57,435:INFO:             kaleido: 0.2.1
2023-04-24 16:37:57,435:INFO:         statsmodels: 0.13.5
2023-04-24 16:37:57,435:INFO:              sktime: 0.17.1
2023-04-24 16:37:57,435:INFO:               tbats: 1.1.3
2023-04-24 16:37:57,435:INFO:            pmdarima: 2.0.3
2023-04-24 16:37:57,435:INFO:              psutil: 5.9.2
2023-04-24 16:37:57,435:INFO:PyCaret optional dependencies:
2023-04-24 16:37:57,435:INFO:                shap: Not installed
2023-04-24 16:37:57,435:INFO:           interpret: Not installed
2023-04-24 16:37:57,435:INFO:                umap: Not installed
2023-04-24 16:37:57,435:INFO:    pandas_profiling: Not installed
2023-04-24 16:37:57,435:INFO:  explainerdashboard: Not installed
2023-04-24 16:37:57,435:INFO:             autoviz: Not installed
2023-04-24 16:37:57,435:INFO:           fairlearn: Not installed
2023-04-24 16:37:57,435:INFO:             xgboost: 1.7.5
2023-04-24 16:37:57,435:INFO:            catboost: Not installed
2023-04-24 16:37:57,435:INFO:              kmodes: Not installed
2023-04-24 16:37:57,435:INFO:             mlxtend: Not installed
2023-04-24 16:37:57,435:INFO:       statsforecast: Not installed
2023-04-24 16:37:57,435:INFO:        tune_sklearn: Not installed
2023-04-24 16:37:57,435:INFO:                 ray: Not installed
2023-04-24 16:37:57,435:INFO:            hyperopt: Not installed
2023-04-24 16:37:57,435:INFO:              optuna: Not installed
2023-04-24 16:37:57,435:INFO:               skopt: Not installed
2023-04-24 16:37:57,435:INFO:              mlflow: 2.3.0
2023-04-24 16:37:57,435:INFO:              gradio: Not installed
2023-04-24 16:37:57,435:INFO:             fastapi: Not installed
2023-04-24 16:37:57,436:INFO:             uvicorn: Not installed
2023-04-24 16:37:57,436:INFO:              m2cgen: Not installed
2023-04-24 16:37:57,436:INFO:           evidently: Not installed
2023-04-24 16:37:57,436:INFO:               fugue: Not installed
2023-04-24 16:37:57,436:INFO:           streamlit: Not installed
2023-04-24 16:37:57,436:INFO:             prophet: Not installed
2023-04-24 16:37:57,436:INFO:None
2023-04-24 16:37:57,436:INFO:Set up data.
2023-04-24 16:37:57,439:INFO:Set up train/test split.
2023-04-24 16:37:57,442:INFO:Set up index.
2023-04-24 16:37:57,442:INFO:Set up folding strategy.
2023-04-24 16:37:57,443:INFO:Assigning column types.
2023-04-24 16:37:57,444:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:37:57,446:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,453:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,534:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,534:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,536:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,539:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,543:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,622:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,622:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:37:57,622:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,622:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,710:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,715:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,719:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,805:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,808:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:37:57,816:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,892:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,892:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:57,989:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:57,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:57,993:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:37:58,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:58,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:58,076:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:58,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:37:58,162:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,164:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:37:58,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:58,241:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:37:58,342:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,342:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:37:58,421:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,505:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,521:INFO:Preparing preprocessing pipeline...
2023-04-24 16:37:58,521:INFO:Set up simple imputation.
2023-04-24 16:37:58,521:INFO:Set up feature normalization.
2023-04-24 16:37:58,536:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:37:58,536:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 16:37:58,536:INFO:Creating final display dataframe.
2023-04-24 16:37:58,583:INFO:Setup _display_container:                     Description         Value
0                    Session id          8446
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1338, 8)
4        Transformed data shape     (1338, 8)
5   Transformed train set shape      (936, 8)
6    Transformed test set shape      (402, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name     charge_01
20                          USI          ef00
2023-04-24 16:37:58,686:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,769:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:37:58,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:37:58,769:INFO:Logging experiment in loggers
2023-04-24 16:37:59,189:INFO:SubProcess save_model() called ==================================
2023-04-24 16:37:59,189:INFO:Initializing save_model()
2023-04-24 16:37:59,189:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmp6ywp1s7m\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-24 16:37:59,189:INFO:Adding model into prep_pipe
2023-04-24 16:37:59,189:WARNING:Only Model saved as it was a pipeline.
2023-04-24 16:37:59,205:INFO:C:\Users\danie\AppData\Local\Temp\tmp6ywp1s7m\Transformation Pipeline.pkl saved in current working directory
2023-04-24 16:37:59,206:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 16:37:59,206:INFO:save_model() successfully completed......................................
2023-04-24 16:37:59,305:INFO:SubProcess save_model() end ==================================
2023-04-24 16:37:59,373:INFO:setup() successfully completed in 1.34s...............
2023-04-24 16:38:17,180:INFO:Initializing compare_models()
2023-04-24 16:38:17,180:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 16:38:17,180:INFO:Checking exceptions
2023-04-24 16:38:17,182:INFO:Preparing display monitor
2023-04-24 16:38:17,211:INFO:Initializing Linear Regression
2023-04-24 16:38:17,211:INFO:Total runtime is 0.0 minutes
2023-04-24 16:38:17,214:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:17,214:INFO:Initializing create_model()
2023-04-24 16:38:17,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:17,214:INFO:Checking exceptions
2023-04-24 16:38:17,214:INFO:Importing libraries
2023-04-24 16:38:17,214:INFO:Copying training dataset
2023-04-24 16:38:17,222:INFO:Defining folds
2023-04-24 16:38:17,222:INFO:Declaring metric variables
2023-04-24 16:38:17,227:INFO:Importing untrained model
2023-04-24 16:38:17,229:INFO:Linear Regression Imported successfully
2023-04-24 16:38:17,242:INFO:Starting cross validation
2023-04-24 16:38:17,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:21,701:INFO:Calculating mean and std
2023-04-24 16:38:21,703:INFO:Creating metrics dataframe
2023-04-24 16:38:21,709:INFO:Uploading results into container
2023-04-24 16:38:21,710:INFO:Uploading model into container now
2023-04-24 16:38:21,710:INFO:_master_model_container: 1
2023-04-24 16:38:21,710:INFO:_display_container: 2
2023-04-24 16:38:21,710:INFO:LinearRegression(n_jobs=-1)
2023-04-24 16:38:21,710:INFO:create_model() successfully completed......................................
2023-04-24 16:38:21,804:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:21,805:INFO:Creating metrics dataframe
2023-04-24 16:38:21,808:INFO:Initializing Lasso Regression
2023-04-24 16:38:21,808:INFO:Total runtime is 0.07661422491073608 minutes
2023-04-24 16:38:21,808:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:21,808:INFO:Initializing create_model()
2023-04-24 16:38:21,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:21,808:INFO:Checking exceptions
2023-04-24 16:38:21,808:INFO:Importing libraries
2023-04-24 16:38:21,808:INFO:Copying training dataset
2023-04-24 16:38:21,808:INFO:Defining folds
2023-04-24 16:38:21,808:INFO:Declaring metric variables
2023-04-24 16:38:21,808:INFO:Importing untrained model
2023-04-24 16:38:21,826:INFO:Lasso Regression Imported successfully
2023-04-24 16:38:21,830:INFO:Starting cross validation
2023-04-24 16:38:21,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:22,008:INFO:Calculating mean and std
2023-04-24 16:38:22,008:INFO:Creating metrics dataframe
2023-04-24 16:38:22,024:INFO:Uploading results into container
2023-04-24 16:38:22,024:INFO:Uploading model into container now
2023-04-24 16:38:22,024:INFO:_master_model_container: 2
2023-04-24 16:38:22,024:INFO:_display_container: 2
2023-04-24 16:38:22,024:INFO:Lasso(random_state=8446)
2023-04-24 16:38:22,024:INFO:create_model() successfully completed......................................
2023-04-24 16:38:22,124:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:22,124:INFO:Creating metrics dataframe
2023-04-24 16:38:22,124:INFO:Initializing Ridge Regression
2023-04-24 16:38:22,124:INFO:Total runtime is 0.08189124266306559 minutes
2023-04-24 16:38:22,124:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:22,124:INFO:Initializing create_model()
2023-04-24 16:38:22,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:22,124:INFO:Checking exceptions
2023-04-24 16:38:22,124:INFO:Importing libraries
2023-04-24 16:38:22,124:INFO:Copying training dataset
2023-04-24 16:38:22,144:INFO:Defining folds
2023-04-24 16:38:22,145:INFO:Declaring metric variables
2023-04-24 16:38:22,146:INFO:Importing untrained model
2023-04-24 16:38:22,146:INFO:Ridge Regression Imported successfully
2023-04-24 16:38:22,161:INFO:Starting cross validation
2023-04-24 16:38:22,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:22,317:INFO:Calculating mean and std
2023-04-24 16:38:22,317:INFO:Creating metrics dataframe
2023-04-24 16:38:22,317:INFO:Uploading results into container
2023-04-24 16:38:22,317:INFO:Uploading model into container now
2023-04-24 16:38:22,328:INFO:_master_model_container: 3
2023-04-24 16:38:22,328:INFO:_display_container: 2
2023-04-24 16:38:22,328:INFO:Ridge(random_state=8446)
2023-04-24 16:38:22,328:INFO:create_model() successfully completed......................................
2023-04-24 16:38:22,389:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:22,389:INFO:Creating metrics dataframe
2023-04-24 16:38:22,411:INFO:Initializing Elastic Net
2023-04-24 16:38:22,411:INFO:Total runtime is 0.0866723616917928 minutes
2023-04-24 16:38:22,413:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:22,413:INFO:Initializing create_model()
2023-04-24 16:38:22,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:22,414:INFO:Checking exceptions
2023-04-24 16:38:22,414:INFO:Importing libraries
2023-04-24 16:38:22,414:INFO:Copying training dataset
2023-04-24 16:38:22,416:INFO:Defining folds
2023-04-24 16:38:22,416:INFO:Declaring metric variables
2023-04-24 16:38:22,419:INFO:Importing untrained model
2023-04-24 16:38:22,422:INFO:Elastic Net Imported successfully
2023-04-24 16:38:22,428:INFO:Starting cross validation
2023-04-24 16:38:22,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:22,568:INFO:Calculating mean and std
2023-04-24 16:38:22,568:INFO:Creating metrics dataframe
2023-04-24 16:38:22,572:INFO:Uploading results into container
2023-04-24 16:38:22,572:INFO:Uploading model into container now
2023-04-24 16:38:22,572:INFO:_master_model_container: 4
2023-04-24 16:38:22,572:INFO:_display_container: 2
2023-04-24 16:38:22,572:INFO:ElasticNet(random_state=8446)
2023-04-24 16:38:22,572:INFO:create_model() successfully completed......................................
2023-04-24 16:38:22,638:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:22,638:INFO:Creating metrics dataframe
2023-04-24 16:38:22,654:INFO:Initializing Least Angle Regression
2023-04-24 16:38:22,654:INFO:Total runtime is 0.09071242014567057 minutes
2023-04-24 16:38:22,661:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:22,662:INFO:Initializing create_model()
2023-04-24 16:38:22,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:22,662:INFO:Checking exceptions
2023-04-24 16:38:22,662:INFO:Importing libraries
2023-04-24 16:38:22,662:INFO:Copying training dataset
2023-04-24 16:38:22,662:INFO:Defining folds
2023-04-24 16:38:22,662:INFO:Declaring metric variables
2023-04-24 16:38:22,662:INFO:Importing untrained model
2023-04-24 16:38:22,662:INFO:Least Angle Regression Imported successfully
2023-04-24 16:38:22,675:INFO:Starting cross validation
2023-04-24 16:38:22,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:22,737:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,738:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,739:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,739:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,739:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,755:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,755:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,770:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,802:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,802:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:22,818:INFO:Calculating mean and std
2023-04-24 16:38:22,818:INFO:Creating metrics dataframe
2023-04-24 16:38:22,825:INFO:Uploading results into container
2023-04-24 16:38:22,825:INFO:Uploading model into container now
2023-04-24 16:38:22,825:INFO:_master_model_container: 5
2023-04-24 16:38:22,825:INFO:_display_container: 2
2023-04-24 16:38:22,825:INFO:Lars(random_state=8446)
2023-04-24 16:38:22,825:INFO:create_model() successfully completed......................................
2023-04-24 16:38:22,901:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:22,901:INFO:Creating metrics dataframe
2023-04-24 16:38:22,906:INFO:Initializing Lasso Least Angle Regression
2023-04-24 16:38:22,906:INFO:Total runtime is 0.09492822090784708 minutes
2023-04-24 16:38:22,906:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:22,906:INFO:Initializing create_model()
2023-04-24 16:38:22,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:22,906:INFO:Checking exceptions
2023-04-24 16:38:22,906:INFO:Importing libraries
2023-04-24 16:38:22,906:INFO:Copying training dataset
2023-04-24 16:38:22,906:INFO:Defining folds
2023-04-24 16:38:22,906:INFO:Declaring metric variables
2023-04-24 16:38:22,906:INFO:Importing untrained model
2023-04-24 16:38:22,923:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 16:38:22,927:INFO:Starting cross validation
2023-04-24 16:38:22,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:22,975:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:22,995:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:22,995:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,014:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,014:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,021:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,038:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,038:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,055:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,071:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:38:23,088:INFO:Calculating mean and std
2023-04-24 16:38:23,088:INFO:Creating metrics dataframe
2023-04-24 16:38:23,088:INFO:Uploading results into container
2023-04-24 16:38:23,104:INFO:Uploading model into container now
2023-04-24 16:38:23,105:INFO:_master_model_container: 6
2023-04-24 16:38:23,105:INFO:_display_container: 2
2023-04-24 16:38:23,105:INFO:LassoLars(random_state=8446)
2023-04-24 16:38:23,105:INFO:create_model() successfully completed......................................
2023-04-24 16:38:23,185:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:23,185:INFO:Creating metrics dataframe
2023-04-24 16:38:23,185:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 16:38:23,185:INFO:Total runtime is 0.0995769460995992 minutes
2023-04-24 16:38:23,185:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:23,185:INFO:Initializing create_model()
2023-04-24 16:38:23,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:23,185:INFO:Checking exceptions
2023-04-24 16:38:23,185:INFO:Importing libraries
2023-04-24 16:38:23,185:INFO:Copying training dataset
2023-04-24 16:38:23,198:INFO:Defining folds
2023-04-24 16:38:23,198:INFO:Declaring metric variables
2023-04-24 16:38:23,202:INFO:Importing untrained model
2023-04-24 16:38:23,208:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 16:38:23,210:INFO:Starting cross validation
2023-04-24 16:38:23,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:23,261:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,261:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,270:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,270:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,270:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,286:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,286:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,302:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,317:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,317:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:38:23,333:INFO:Calculating mean and std
2023-04-24 16:38:23,333:INFO:Creating metrics dataframe
2023-04-24 16:38:23,349:INFO:Uploading results into container
2023-04-24 16:38:23,349:INFO:Uploading model into container now
2023-04-24 16:38:23,349:INFO:_master_model_container: 7
2023-04-24 16:38:23,349:INFO:_display_container: 2
2023-04-24 16:38:23,349:INFO:OrthogonalMatchingPursuit()
2023-04-24 16:38:23,349:INFO:create_model() successfully completed......................................
2023-04-24 16:38:23,428:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:23,428:INFO:Creating metrics dataframe
2023-04-24 16:38:23,437:INFO:Initializing Bayesian Ridge
2023-04-24 16:38:23,437:INFO:Total runtime is 0.10376186370849609 minutes
2023-04-24 16:38:23,439:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:23,440:INFO:Initializing create_model()
2023-04-24 16:38:23,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:23,440:INFO:Checking exceptions
2023-04-24 16:38:23,440:INFO:Importing libraries
2023-04-24 16:38:23,440:INFO:Copying training dataset
2023-04-24 16:38:23,442:INFO:Defining folds
2023-04-24 16:38:23,442:INFO:Declaring metric variables
2023-04-24 16:38:23,445:INFO:Importing untrained model
2023-04-24 16:38:23,447:INFO:Bayesian Ridge Imported successfully
2023-04-24 16:38:23,458:INFO:Starting cross validation
2023-04-24 16:38:23,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:23,586:INFO:Calculating mean and std
2023-04-24 16:38:23,586:INFO:Creating metrics dataframe
2023-04-24 16:38:23,586:INFO:Uploading results into container
2023-04-24 16:38:23,586:INFO:Uploading model into container now
2023-04-24 16:38:23,586:INFO:_master_model_container: 8
2023-04-24 16:38:23,586:INFO:_display_container: 2
2023-04-24 16:38:23,586:INFO:BayesianRidge()
2023-04-24 16:38:23,586:INFO:create_model() successfully completed......................................
2023-04-24 16:38:23,664:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:23,664:INFO:Creating metrics dataframe
2023-04-24 16:38:23,680:INFO:Initializing Passive Aggressive Regressor
2023-04-24 16:38:23,680:INFO:Total runtime is 0.10782027244567871 minutes
2023-04-24 16:38:23,686:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:23,686:INFO:Initializing create_model()
2023-04-24 16:38:23,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:23,687:INFO:Checking exceptions
2023-04-24 16:38:23,687:INFO:Importing libraries
2023-04-24 16:38:23,687:INFO:Copying training dataset
2023-04-24 16:38:23,688:INFO:Defining folds
2023-04-24 16:38:23,688:INFO:Declaring metric variables
2023-04-24 16:38:23,688:INFO:Importing untrained model
2023-04-24 16:38:23,688:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 16:38:23,706:INFO:Starting cross validation
2023-04-24 16:38:23,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:23,864:INFO:Calculating mean and std
2023-04-24 16:38:23,864:INFO:Creating metrics dataframe
2023-04-24 16:38:23,864:INFO:Uploading results into container
2023-04-24 16:38:23,864:INFO:Uploading model into container now
2023-04-24 16:38:23,864:INFO:_master_model_container: 9
2023-04-24 16:38:23,864:INFO:_display_container: 2
2023-04-24 16:38:23,864:INFO:PassiveAggressiveRegressor(random_state=8446)
2023-04-24 16:38:23,864:INFO:create_model() successfully completed......................................
2023-04-24 16:38:23,950:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:23,950:INFO:Creating metrics dataframe
2023-04-24 16:38:23,950:INFO:Initializing Huber Regressor
2023-04-24 16:38:23,950:INFO:Total runtime is 0.11231962442398072 minutes
2023-04-24 16:38:23,966:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:23,966:INFO:Initializing create_model()
2023-04-24 16:38:23,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:23,966:INFO:Checking exceptions
2023-04-24 16:38:23,966:INFO:Importing libraries
2023-04-24 16:38:23,966:INFO:Copying training dataset
2023-04-24 16:38:23,969:INFO:Defining folds
2023-04-24 16:38:23,969:INFO:Declaring metric variables
2023-04-24 16:38:23,969:INFO:Importing untrained model
2023-04-24 16:38:23,969:INFO:Huber Regressor Imported successfully
2023-04-24 16:38:23,969:INFO:Starting cross validation
2023-04-24 16:38:23,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:24,135:INFO:Calculating mean and std
2023-04-24 16:38:24,135:INFO:Creating metrics dataframe
2023-04-24 16:38:24,135:INFO:Uploading results into container
2023-04-24 16:38:24,135:INFO:Uploading model into container now
2023-04-24 16:38:24,135:INFO:_master_model_container: 10
2023-04-24 16:38:24,135:INFO:_display_container: 2
2023-04-24 16:38:24,135:INFO:HuberRegressor()
2023-04-24 16:38:24,135:INFO:create_model() successfully completed......................................
2023-04-24 16:38:24,216:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:24,216:INFO:Creating metrics dataframe
2023-04-24 16:38:24,224:INFO:Initializing K Neighbors Regressor
2023-04-24 16:38:24,224:INFO:Total runtime is 0.11688596407572428 minutes
2023-04-24 16:38:24,224:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:24,224:INFO:Initializing create_model()
2023-04-24 16:38:24,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:24,234:INFO:Checking exceptions
2023-04-24 16:38:24,234:INFO:Importing libraries
2023-04-24 16:38:24,234:INFO:Copying training dataset
2023-04-24 16:38:24,237:INFO:Defining folds
2023-04-24 16:38:24,237:INFO:Declaring metric variables
2023-04-24 16:38:24,239:INFO:Importing untrained model
2023-04-24 16:38:24,239:INFO:K Neighbors Regressor Imported successfully
2023-04-24 16:38:24,253:INFO:Starting cross validation
2023-04-24 16:38:24,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:24,413:INFO:Calculating mean and std
2023-04-24 16:38:24,413:INFO:Creating metrics dataframe
2023-04-24 16:38:24,413:INFO:Uploading results into container
2023-04-24 16:38:24,413:INFO:Uploading model into container now
2023-04-24 16:38:24,413:INFO:_master_model_container: 11
2023-04-24 16:38:24,413:INFO:_display_container: 2
2023-04-24 16:38:24,413:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 16:38:24,413:INFO:create_model() successfully completed......................................
2023-04-24 16:38:24,498:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:24,498:INFO:Creating metrics dataframe
2023-04-24 16:38:24,498:INFO:Initializing Decision Tree Regressor
2023-04-24 16:38:24,498:INFO:Total runtime is 0.12145464420318604 minutes
2023-04-24 16:38:24,498:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:24,498:INFO:Initializing create_model()
2023-04-24 16:38:24,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:24,498:INFO:Checking exceptions
2023-04-24 16:38:24,498:INFO:Importing libraries
2023-04-24 16:38:24,498:INFO:Copying training dataset
2023-04-24 16:38:24,514:INFO:Defining folds
2023-04-24 16:38:24,514:INFO:Declaring metric variables
2023-04-24 16:38:24,517:INFO:Importing untrained model
2023-04-24 16:38:24,520:INFO:Decision Tree Regressor Imported successfully
2023-04-24 16:38:24,520:INFO:Starting cross validation
2023-04-24 16:38:24,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:24,660:INFO:Calculating mean and std
2023-04-24 16:38:24,661:INFO:Creating metrics dataframe
2023-04-24 16:38:24,664:INFO:Uploading results into container
2023-04-24 16:38:24,666:INFO:Uploading model into container now
2023-04-24 16:38:24,666:INFO:_master_model_container: 12
2023-04-24 16:38:24,666:INFO:_display_container: 2
2023-04-24 16:38:24,667:INFO:DecisionTreeRegressor(random_state=8446)
2023-04-24 16:38:24,667:INFO:create_model() successfully completed......................................
2023-04-24 16:38:24,732:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:24,732:INFO:Creating metrics dataframe
2023-04-24 16:38:24,752:INFO:Initializing Random Forest Regressor
2023-04-24 16:38:24,752:INFO:Total runtime is 0.12568774223327636 minutes
2023-04-24 16:38:24,755:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:24,755:INFO:Initializing create_model()
2023-04-24 16:38:24,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:24,756:INFO:Checking exceptions
2023-04-24 16:38:24,756:INFO:Importing libraries
2023-04-24 16:38:24,756:INFO:Copying training dataset
2023-04-24 16:38:24,758:INFO:Defining folds
2023-04-24 16:38:24,758:INFO:Declaring metric variables
2023-04-24 16:38:24,762:INFO:Importing untrained model
2023-04-24 16:38:24,767:INFO:Random Forest Regressor Imported successfully
2023-04-24 16:38:24,771:INFO:Starting cross validation
2023-04-24 16:38:24,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:25,885:INFO:Calculating mean and std
2023-04-24 16:38:25,885:INFO:Creating metrics dataframe
2023-04-24 16:38:25,906:INFO:Uploading results into container
2023-04-24 16:38:25,907:INFO:Uploading model into container now
2023-04-24 16:38:25,907:INFO:_master_model_container: 13
2023-04-24 16:38:25,907:INFO:_display_container: 2
2023-04-24 16:38:25,907:INFO:RandomForestRegressor(n_jobs=-1, random_state=8446)
2023-04-24 16:38:25,907:INFO:create_model() successfully completed......................................
2023-04-24 16:38:25,977:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:25,977:INFO:Creating metrics dataframe
2023-04-24 16:38:25,977:INFO:Initializing Extra Trees Regressor
2023-04-24 16:38:25,993:INFO:Total runtime is 0.14636725187301636 minutes
2023-04-24 16:38:25,996:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:25,996:INFO:Initializing create_model()
2023-04-24 16:38:25,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:25,996:INFO:Checking exceptions
2023-04-24 16:38:25,996:INFO:Importing libraries
2023-04-24 16:38:25,996:INFO:Copying training dataset
2023-04-24 16:38:26,000:INFO:Defining folds
2023-04-24 16:38:26,000:INFO:Declaring metric variables
2023-04-24 16:38:26,002:INFO:Importing untrained model
2023-04-24 16:38:26,007:INFO:Extra Trees Regressor Imported successfully
2023-04-24 16:38:26,016:INFO:Starting cross validation
2023-04-24 16:38:26,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:26,872:INFO:Calculating mean and std
2023-04-24 16:38:26,872:INFO:Creating metrics dataframe
2023-04-24 16:38:26,887:INFO:Uploading results into container
2023-04-24 16:38:26,887:INFO:Uploading model into container now
2023-04-24 16:38:26,887:INFO:_master_model_container: 14
2023-04-24 16:38:26,887:INFO:_display_container: 2
2023-04-24 16:38:26,887:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8446)
2023-04-24 16:38:26,887:INFO:create_model() successfully completed......................................
2023-04-24 16:38:26,975:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:26,975:INFO:Creating metrics dataframe
2023-04-24 16:38:26,975:INFO:Initializing AdaBoost Regressor
2023-04-24 16:38:26,975:INFO:Total runtime is 0.16273852586746215 minutes
2023-04-24 16:38:26,988:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:26,988:INFO:Initializing create_model()
2023-04-24 16:38:26,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:26,988:INFO:Checking exceptions
2023-04-24 16:38:26,988:INFO:Importing libraries
2023-04-24 16:38:26,989:INFO:Copying training dataset
2023-04-24 16:38:26,992:INFO:Defining folds
2023-04-24 16:38:26,992:INFO:Declaring metric variables
2023-04-24 16:38:26,995:INFO:Importing untrained model
2023-04-24 16:38:26,995:INFO:AdaBoost Regressor Imported successfully
2023-04-24 16:38:26,995:INFO:Starting cross validation
2023-04-24 16:38:26,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:27,186:INFO:Calculating mean and std
2023-04-24 16:38:27,186:INFO:Creating metrics dataframe
2023-04-24 16:38:27,202:INFO:Uploading results into container
2023-04-24 16:38:27,202:INFO:Uploading model into container now
2023-04-24 16:38:27,202:INFO:_master_model_container: 15
2023-04-24 16:38:27,202:INFO:_display_container: 2
2023-04-24 16:38:27,202:INFO:AdaBoostRegressor(random_state=8446)
2023-04-24 16:38:27,202:INFO:create_model() successfully completed......................................
2023-04-24 16:38:27,274:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:27,274:INFO:Creating metrics dataframe
2023-04-24 16:38:27,291:INFO:Initializing Gradient Boosting Regressor
2023-04-24 16:38:27,291:INFO:Total runtime is 0.16800849040349325 minutes
2023-04-24 16:38:27,296:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:27,296:INFO:Initializing create_model()
2023-04-24 16:38:27,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:27,296:INFO:Checking exceptions
2023-04-24 16:38:27,296:INFO:Importing libraries
2023-04-24 16:38:27,296:INFO:Copying training dataset
2023-04-24 16:38:27,299:INFO:Defining folds
2023-04-24 16:38:27,299:INFO:Declaring metric variables
2023-04-24 16:38:27,301:INFO:Importing untrained model
2023-04-24 16:38:27,304:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:38:27,314:INFO:Starting cross validation
2023-04-24 16:38:27,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:27,675:INFO:Calculating mean and std
2023-04-24 16:38:27,675:INFO:Creating metrics dataframe
2023-04-24 16:38:27,691:INFO:Uploading results into container
2023-04-24 16:38:27,691:INFO:Uploading model into container now
2023-04-24 16:38:27,691:INFO:_master_model_container: 16
2023-04-24 16:38:27,691:INFO:_display_container: 2
2023-04-24 16:38:27,691:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:38:27,691:INFO:create_model() successfully completed......................................
2023-04-24 16:38:27,772:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:27,772:INFO:Creating metrics dataframe
2023-04-24 16:38:27,784:INFO:Initializing Extreme Gradient Boosting
2023-04-24 16:38:27,784:INFO:Total runtime is 0.1762130578358968 minutes
2023-04-24 16:38:27,793:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:27,793:INFO:Initializing create_model()
2023-04-24 16:38:27,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:27,793:INFO:Checking exceptions
2023-04-24 16:38:27,793:INFO:Importing libraries
2023-04-24 16:38:27,793:INFO:Copying training dataset
2023-04-24 16:38:27,796:INFO:Defining folds
2023-04-24 16:38:27,797:INFO:Declaring metric variables
2023-04-24 16:38:27,800:INFO:Importing untrained model
2023-04-24 16:38:27,801:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 16:38:27,812:INFO:Starting cross validation
2023-04-24 16:38:27,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:29,387:INFO:Calculating mean and std
2023-04-24 16:38:29,387:INFO:Creating metrics dataframe
2023-04-24 16:38:29,405:INFO:Uploading results into container
2023-04-24 16:38:29,405:INFO:Uploading model into container now
2023-04-24 16:38:29,405:INFO:_master_model_container: 17
2023-04-24 16:38:29,405:INFO:_display_container: 2
2023-04-24 16:38:29,405:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8446, ...)
2023-04-24 16:38:29,405:INFO:create_model() successfully completed......................................
2023-04-24 16:38:29,484:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:29,484:INFO:Creating metrics dataframe
2023-04-24 16:38:29,491:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 16:38:29,491:INFO:Total runtime is 0.20467718044916788 minutes
2023-04-24 16:38:29,491:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:29,491:INFO:Initializing create_model()
2023-04-24 16:38:29,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:29,491:INFO:Checking exceptions
2023-04-24 16:38:29,491:INFO:Importing libraries
2023-04-24 16:38:29,491:INFO:Copying training dataset
2023-04-24 16:38:29,506:INFO:Defining folds
2023-04-24 16:38:29,507:INFO:Declaring metric variables
2023-04-24 16:38:29,511:INFO:Importing untrained model
2023-04-24 16:38:29,511:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:38:29,524:INFO:Starting cross validation
2023-04-24 16:38:29,525:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:29,891:INFO:Calculating mean and std
2023-04-24 16:38:29,891:INFO:Creating metrics dataframe
2023-04-24 16:38:29,914:INFO:Uploading results into container
2023-04-24 16:38:29,915:INFO:Uploading model into container now
2023-04-24 16:38:29,915:INFO:_master_model_container: 18
2023-04-24 16:38:29,915:INFO:_display_container: 2
2023-04-24 16:38:29,915:INFO:LGBMRegressor(random_state=8446)
2023-04-24 16:38:29,915:INFO:create_model() successfully completed......................................
2023-04-24 16:38:29,984:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:29,984:INFO:Creating metrics dataframe
2023-04-24 16:38:30,000:INFO:Initializing Dummy Regressor
2023-04-24 16:38:30,000:INFO:Total runtime is 0.2131474773089091 minutes
2023-04-24 16:38:30,000:INFO:SubProcess create_model() called ==================================
2023-04-24 16:38:30,000:INFO:Initializing create_model()
2023-04-24 16:38:30,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA05E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:30,000:INFO:Checking exceptions
2023-04-24 16:38:30,000:INFO:Importing libraries
2023-04-24 16:38:30,000:INFO:Copying training dataset
2023-04-24 16:38:30,010:INFO:Defining folds
2023-04-24 16:38:30,010:INFO:Declaring metric variables
2023-04-24 16:38:30,014:INFO:Importing untrained model
2023-04-24 16:38:30,017:INFO:Dummy Regressor Imported successfully
2023-04-24 16:38:30,020:INFO:Starting cross validation
2023-04-24 16:38:30,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:38:30,195:INFO:Calculating mean and std
2023-04-24 16:38:30,196:INFO:Creating metrics dataframe
2023-04-24 16:38:30,201:INFO:Uploading results into container
2023-04-24 16:38:30,201:INFO:Uploading model into container now
2023-04-24 16:38:30,201:INFO:_master_model_container: 19
2023-04-24 16:38:30,201:INFO:_display_container: 2
2023-04-24 16:38:30,201:INFO:DummyRegressor()
2023-04-24 16:38:30,201:INFO:create_model() successfully completed......................................
2023-04-24 16:38:30,283:INFO:SubProcess create_model() end ==================================
2023-04-24 16:38:30,283:INFO:Creating metrics dataframe
2023-04-24 16:38:30,308:INFO:Initializing create_model()
2023-04-24 16:38:30,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:38:30,308:INFO:Checking exceptions
2023-04-24 16:38:30,310:INFO:Importing libraries
2023-04-24 16:38:30,310:INFO:Copying training dataset
2023-04-24 16:38:30,312:INFO:Defining folds
2023-04-24 16:38:30,313:INFO:Declaring metric variables
2023-04-24 16:38:30,313:INFO:Importing untrained model
2023-04-24 16:38:30,313:INFO:Declaring custom model
2023-04-24 16:38:30,313:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:38:30,313:INFO:Cross validation set to False
2023-04-24 16:38:30,313:INFO:Fitting Model
2023-04-24 16:38:30,399:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:38:30,399:INFO:create_model() successfully completed......................................
2023-04-24 16:38:30,482:INFO:Creating Dashboard logs
2023-04-24 16:38:30,485:INFO:Model: Gradient Boosting Regressor
2023-04-24 16:38:30,527:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8446, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:38:30,603:INFO:Initializing predict_model()
2023-04-24 16:38:30,603:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560CB67A0>)
2023-04-24 16:38:30,603:INFO:Checking exceptions
2023-04-24 16:38:30,603:INFO:Preloading libraries
2023-04-24 16:38:30,962:INFO:Creating Dashboard logs
2023-04-24 16:38:30,962:INFO:Model: Light Gradient Boosting Machine
2023-04-24 16:38:31,008:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8446, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 16:38:31,193:INFO:Creating Dashboard logs
2023-04-24 16:38:31,197:INFO:Model: Random Forest Regressor
2023-04-24 16:38:31,248:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8446, 'verbose': 0, 'warm_start': False}
2023-04-24 16:38:31,451:INFO:Creating Dashboard logs
2023-04-24 16:38:31,451:INFO:Model: AdaBoost Regressor
2023-04-24 16:38:31,503:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 8446}
2023-04-24 16:38:31,686:INFO:Creating Dashboard logs
2023-04-24 16:38:31,689:INFO:Model: Extra Trees Regressor
2023-04-24 16:38:31,733:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8446, 'verbose': 0, 'warm_start': False}
2023-04-24 16:38:31,936:INFO:Creating Dashboard logs
2023-04-24 16:38:31,939:INFO:Model: K Neighbors Regressor
2023-04-24 16:38:31,978:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 16:38:32,168:INFO:Creating Dashboard logs
2023-04-24 16:38:32,171:INFO:Model: Extreme Gradient Boosting
2023-04-24 16:38:32,212:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 8446, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-24 16:38:32,409:INFO:Creating Dashboard logs
2023-04-24 16:38:32,425:INFO:Model: Lasso Least Angle Regression
2023-04-24 16:38:32,463:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 8446, 'verbose': False}
2023-04-24 16:38:32,644:INFO:Creating Dashboard logs
2023-04-24 16:38:32,644:INFO:Model: Bayesian Ridge
2023-04-24 16:38:32,692:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 16:38:32,878:INFO:Creating Dashboard logs
2023-04-24 16:38:32,881:INFO:Model: Ridge Regression
2023-04-24 16:38:32,918:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 8446, 'solver': 'auto', 'tol': 0.001}
2023-04-24 16:38:33,112:INFO:Creating Dashboard logs
2023-04-24 16:38:33,112:INFO:Model: Lasso Regression
2023-04-24 16:38:33,167:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 8446, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 16:38:33,352:INFO:Creating Dashboard logs
2023-04-24 16:38:33,354:INFO:Model: Linear Regression
2023-04-24 16:38:33,392:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 16:38:33,554:INFO:Creating Dashboard logs
2023-04-24 16:38:33,554:INFO:Model: Least Angle Regression
2023-04-24 16:38:33,610:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 8446, 'verbose': False}
2023-04-24 16:38:33,792:INFO:Creating Dashboard logs
2023-04-24 16:38:33,795:INFO:Model: Decision Tree Regressor
2023-04-24 16:38:33,835:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 8446, 'splitter': 'best'}
2023-04-24 16:38:34,017:INFO:Creating Dashboard logs
2023-04-24 16:38:34,020:INFO:Model: Huber Regressor
2023-04-24 16:38:34,062:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 16:38:34,239:INFO:Creating Dashboard logs
2023-04-24 16:38:34,239:INFO:Model: Passive Aggressive Regressor
2023-04-24 16:38:34,287:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 8446, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:38:34,472:INFO:Creating Dashboard logs
2023-04-24 16:38:34,476:INFO:Model: Elastic Net
2023-04-24 16:38:34,515:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 8446, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 16:38:34,688:INFO:Creating Dashboard logs
2023-04-24 16:38:34,688:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 16:38:34,737:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 16:38:34,913:INFO:Creating Dashboard logs
2023-04-24 16:38:34,916:INFO:Model: Dummy Regressor
2023-04-24 16:38:34,956:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 16:38:35,141:INFO:_master_model_container: 19
2023-04-24 16:38:35,141:INFO:_display_container: 2
2023-04-24 16:38:35,141:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:38:35,141:INFO:compare_models() successfully completed......................................
2023-04-24 16:39:11,429:INFO:Initializing create_model()
2023-04-24 16:39:11,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:39:11,429:INFO:Checking exceptions
2023-04-24 16:39:11,451:INFO:Importing libraries
2023-04-24 16:39:11,451:INFO:Copying training dataset
2023-04-24 16:39:11,456:INFO:Defining folds
2023-04-24 16:39:11,456:INFO:Declaring metric variables
2023-04-24 16:39:11,459:INFO:Importing untrained model
2023-04-24 16:39:11,462:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:39:11,466:INFO:Starting cross validation
2023-04-24 16:39:11,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:39:11,847:INFO:Calculating mean and std
2023-04-24 16:39:11,848:INFO:Creating metrics dataframe
2023-04-24 16:39:11,854:INFO:Finalizing model
2023-04-24 16:39:11,941:INFO:Creating Dashboard logs
2023-04-24 16:39:11,944:INFO:Model: Gradient Boosting Regressor
2023-04-24 16:39:11,980:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8446, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:39:12,065:INFO:Initializing predict_model()
2023-04-24 16:39:12,065:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560CB7AC0>)
2023-04-24 16:39:12,066:INFO:Checking exceptions
2023-04-24 16:39:12,066:INFO:Preloading libraries
2023-04-24 16:39:12,339:INFO:Uploading results into container
2023-04-24 16:39:12,339:INFO:Uploading model into container now
2023-04-24 16:39:12,339:INFO:_master_model_container: 20
2023-04-24 16:39:12,339:INFO:_display_container: 3
2023-04-24 16:39:12,339:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:39:12,339:INFO:create_model() successfully completed......................................
2023-04-24 16:39:23,621:INFO:Initializing create_model()
2023-04-24 16:39:23,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:39:23,621:INFO:Checking exceptions
2023-04-24 16:39:23,644:INFO:Importing libraries
2023-04-24 16:39:23,644:INFO:Copying training dataset
2023-04-24 16:39:23,649:INFO:Defining folds
2023-04-24 16:39:23,649:INFO:Declaring metric variables
2023-04-24 16:39:23,653:INFO:Importing untrained model
2023-04-24 16:39:23,656:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:39:23,660:INFO:Starting cross validation
2023-04-24 16:39:23,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:39:24,041:INFO:Calculating mean and std
2023-04-24 16:39:24,041:INFO:Creating metrics dataframe
2023-04-24 16:39:24,041:INFO:Finalizing model
2023-04-24 16:39:24,140:INFO:Creating Dashboard logs
2023-04-24 16:39:24,140:INFO:Model: Gradient Boosting Regressor
2023-04-24 16:39:24,190:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8446, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:39:24,269:INFO:Initializing predict_model()
2023-04-24 16:39:24,269:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560CB6E60>)
2023-04-24 16:39:24,269:INFO:Checking exceptions
2023-04-24 16:39:24,269:INFO:Preloading libraries
2023-04-24 16:39:24,504:INFO:Uploading results into container
2023-04-24 16:39:24,505:INFO:Uploading model into container now
2023-04-24 16:39:24,507:INFO:_master_model_container: 21
2023-04-24 16:39:24,507:INFO:_display_container: 4
2023-04-24 16:39:24,507:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:39:24,507:INFO:create_model() successfully completed......................................
2023-04-24 16:40:04,381:INFO:Initializing tune_model()
2023-04-24 16:40:04,381:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=8446), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>)
2023-04-24 16:40:04,381:INFO:Checking exceptions
2023-04-24 16:40:04,397:INFO:Copying training dataset
2023-04-24 16:40:04,411:INFO:Checking base model
2023-04-24 16:40:04,411:INFO:Base model : Gradient Boosting Regressor
2023-04-24 16:40:04,411:INFO:Declaring metric variables
2023-04-24 16:40:04,411:INFO:Defining Hyperparameters
2023-04-24 16:40:04,516:INFO:Tuning with n_jobs=-1
2023-04-24 16:40:04,516:INFO:Initializing RandomizedSearchCV
2023-04-24 16:40:09,764:INFO:best_params: {'actual_estimator__subsample': 0.95, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 2, 'actual_estimator__learning_rate': 0.15}
2023-04-24 16:40:09,765:INFO:Hyperparameter search completed
2023-04-24 16:40:09,765:INFO:SubProcess create_model() called ==================================
2023-04-24 16:40:09,765:INFO:Initializing create_model()
2023-04-24 16:40:09,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560DA0580>, model_only=True, return_train_score=False, kwargs={'subsample': 0.95, 'n_estimators': 230, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 2, 'learning_rate': 0.15})
2023-04-24 16:40:09,765:INFO:Checking exceptions
2023-04-24 16:40:09,765:INFO:Importing libraries
2023-04-24 16:40:09,765:INFO:Copying training dataset
2023-04-24 16:40:09,768:INFO:Defining folds
2023-04-24 16:40:09,768:INFO:Declaring metric variables
2023-04-24 16:40:09,771:INFO:Importing untrained model
2023-04-24 16:40:09,772:INFO:Declaring custom model
2023-04-24 16:40:09,775:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:40:09,781:INFO:Starting cross validation
2023-04-24 16:40:09,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:40:10,297:INFO:Calculating mean and std
2023-04-24 16:40:10,297:INFO:Creating metrics dataframe
2023-04-24 16:40:10,312:INFO:Finalizing model
2023-04-24 16:40:10,430:INFO:Uploading results into container
2023-04-24 16:40:10,430:INFO:Uploading model into container now
2023-04-24 16:40:10,445:INFO:_master_model_container: 22
2023-04-24 16:40:10,445:INFO:_display_container: 5
2023-04-24 16:40:10,445:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=2, max_features='log2',
                          min_impurity_decrease=0.0002, min_samples_leaf=5,
                          n_estimators=230, random_state=8446, subsample=0.95)
2023-04-24 16:40:10,445:INFO:create_model() successfully completed......................................
2023-04-24 16:40:10,540:INFO:SubProcess create_model() end ==================================
2023-04-24 16:40:10,540:INFO:choose_better activated
2023-04-24 16:40:10,544:INFO:SubProcess create_model() called ==================================
2023-04-24 16:40:10,544:INFO:Initializing create_model()
2023-04-24 16:40:10,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:40:10,545:INFO:Checking exceptions
2023-04-24 16:40:10,547:INFO:Importing libraries
2023-04-24 16:40:10,547:INFO:Copying training dataset
2023-04-24 16:40:10,550:INFO:Defining folds
2023-04-24 16:40:10,550:INFO:Declaring metric variables
2023-04-24 16:40:10,550:INFO:Importing untrained model
2023-04-24 16:40:10,550:INFO:Declaring custom model
2023-04-24 16:40:10,551:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:40:10,551:INFO:Starting cross validation
2023-04-24 16:40:10,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:40:11,029:INFO:Calculating mean and std
2023-04-24 16:40:11,029:INFO:Creating metrics dataframe
2023-04-24 16:40:11,029:INFO:Finalizing model
2023-04-24 16:40:11,141:INFO:Uploading results into container
2023-04-24 16:40:11,141:INFO:Uploading model into container now
2023-04-24 16:40:11,141:INFO:_master_model_container: 23
2023-04-24 16:40:11,141:INFO:_display_container: 6
2023-04-24 16:40:11,141:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:40:11,141:INFO:create_model() successfully completed......................................
2023-04-24 16:40:11,213:INFO:SubProcess create_model() end ==================================
2023-04-24 16:40:11,213:INFO:GradientBoostingRegressor(random_state=8446) result for R2 is 0.8647
2023-04-24 16:40:11,213:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=2, max_features='log2',
                          min_impurity_decrease=0.0002, min_samples_leaf=5,
                          n_estimators=230, random_state=8446, subsample=0.95) result for R2 is 0.8636
2023-04-24 16:40:11,213:INFO:GradientBoostingRegressor(random_state=8446) is best model
2023-04-24 16:40:11,213:INFO:choose_better completed
2023-04-24 16:40:11,213:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 16:40:11,213:INFO:Creating Dashboard logs
2023-04-24 16:40:11,229:INFO:Model: Gradient Boosting Regressor
2023-04-24 16:40:11,272:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8446, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:40:11,344:INFO:Initializing predict_model()
2023-04-24 16:40:11,344:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560CB7640>)
2023-04-24 16:40:11,344:INFO:Checking exceptions
2023-04-24 16:40:11,344:INFO:Preloading libraries
2023-04-24 16:40:11,610:INFO:_master_model_container: 23
2023-04-24 16:40:11,610:INFO:_display_container: 5
2023-04-24 16:40:11,610:INFO:GradientBoostingRegressor(random_state=8446)
2023-04-24 16:40:11,610:INFO:tune_model() successfully completed......................................
2023-04-24 16:40:17,016:INFO:Initializing plot_model()
2023-04-24 16:40:17,016:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=8446), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, system=True)
2023-04-24 16:40:17,016:INFO:Checking exceptions
2023-04-24 16:40:17,020:INFO:Preloading libraries
2023-04-24 16:40:17,027:INFO:Copying training dataset
2023-04-24 16:40:17,027:INFO:Plot type: error
2023-04-24 16:40:17,196:INFO:Fitting Model
2023-04-24 16:40:17,196:INFO:Scoring test/hold-out set
2023-04-24 16:40:17,499:INFO:Visual Rendered Successfully
2023-04-24 16:40:17,576:INFO:plot_model() successfully completed......................................
2023-04-24 16:40:27,534:INFO:Initializing plot_model()
2023-04-24 16:40:27,534:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=8446), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, system=True)
2023-04-24 16:40:27,534:INFO:Checking exceptions
2023-04-24 16:40:27,538:INFO:Preloading libraries
2023-04-24 16:40:27,545:INFO:Copying training dataset
2023-04-24 16:40:27,545:INFO:Plot type: feature
2023-04-24 16:40:27,545:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 16:40:27,692:INFO:Visual Rendered Successfully
2023-04-24 16:40:27,775:INFO:plot_model() successfully completed......................................
2023-04-24 16:40:45,533:INFO:Initializing evaluate_model()
2023-04-24 16:40:45,533:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-24 16:40:45,571:INFO:Initializing plot_model()
2023-04-24 16:40:45,571:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=8446), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, system=True)
2023-04-24 16:40:45,571:INFO:Checking exceptions
2023-04-24 16:40:45,572:INFO:Preloading libraries
2023-04-24 16:40:45,572:INFO:Copying training dataset
2023-04-24 16:40:45,572:INFO:Plot type: pipeline
2023-04-24 16:40:56,183:INFO:Initializing plot_model()
2023-04-24 16:40:56,183:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=8446), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, system=True)
2023-04-24 16:40:56,183:INFO:Checking exceptions
2023-04-24 16:40:56,186:INFO:Preloading libraries
2023-04-24 16:40:56,191:INFO:Copying training dataset
2023-04-24 16:40:56,191:INFO:Plot type: parameter
2023-04-24 16:40:56,193:INFO:Visual Rendered Successfully
2023-04-24 16:40:56,284:INFO:plot_model() successfully completed......................................
2023-04-24 16:41:01,442:INFO:Initializing predict_model()
2023-04-24 16:41:01,442:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560E48670>)
2023-04-24 16:41:01,442:INFO:Checking exceptions
2023-04-24 16:41:01,442:INFO:Preloading libraries
2023-04-24 16:41:25,372:INFO:Initializing finalize_model()
2023-04-24 16:41:25,373:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-24 16:41:25,373:INFO:Finalizing GradientBoostingRegressor(random_state=8446)
2023-04-24 16:41:25,377:INFO:Initializing create_model()
2023-04-24 16:41:25,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=GradientBoostingRegressor(random_state=8446), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-24 16:41:25,377:INFO:Checking exceptions
2023-04-24 16:41:25,378:INFO:Importing libraries
2023-04-24 16:41:25,378:INFO:Copying training dataset
2023-04-24 16:41:25,378:INFO:Defining folds
2023-04-24 16:41:25,378:INFO:Declaring metric variables
2023-04-24 16:41:25,379:INFO:Importing untrained model
2023-04-24 16:41:25,379:INFO:Declaring custom model
2023-04-24 16:41:25,379:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:41:25,380:INFO:Cross validation set to False
2023-04-24 16:41:25,380:INFO:Fitting Model
2023-04-24 16:41:25,473:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=8446))])
2023-04-24 16:41:25,473:INFO:create_model() successfully completed......................................
2023-04-24 16:41:25,567:INFO:Creating Dashboard logs
2023-04-24 16:41:25,567:INFO:Model: Gradient Boosting Regressor
2023-04-24 16:41:25,614:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8446, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:41:25,801:INFO:_master_model_container: 23
2023-04-24 16:41:25,801:INFO:_display_container: 6
2023-04-24 16:41:25,817:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=8446))])
2023-04-24 16:41:25,817:INFO:finalize_model() successfully completed......................................
2023-04-24 16:41:26,339:INFO:Initializing predict_model()
2023-04-24 16:41:26,339:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D560937970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=8446))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560478040>)
2023-04-24 16:41:26,339:INFO:Checking exceptions
2023-04-24 16:41:26,339:INFO:Preloading libraries
2023-04-24 16:41:26,342:INFO:Set up data.
2023-04-24 16:41:26,346:INFO:Set up index.
2023-04-24 16:46:47,746:INFO:PyCaret RegressionExperiment
2023-04-24 16:46:47,746:INFO:Logging name: reg-default-name
2023-04-24 16:46:47,746:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:46:47,746:INFO:version 3.0.0
2023-04-24 16:46:47,746:INFO:Initializing setup()
2023-04-24 16:46:47,746:INFO:self.USI: 8841
2023-04-24 16:46:47,746:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 16:46:47,746:INFO:Checking environment
2023-04-24 16:46:47,746:INFO:python_version: 3.10.11
2023-04-24 16:46:47,746:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:46:47,746:INFO:machine: AMD64
2023-04-24 16:46:47,746:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:46:47,746:INFO:Memory: svmem(total=8362713088, available=2009460736, percent=76.0, used=6353252352, free=2009460736)
2023-04-24 16:46:47,746:INFO:Physical Core: 4
2023-04-24 16:46:47,746:INFO:Logical Core: 8
2023-04-24 16:46:47,746:INFO:Checking libraries
2023-04-24 16:46:47,746:INFO:System:
2023-04-24 16:46:47,746:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:46:47,746:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:46:47,746:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:46:47,746:INFO:PyCaret required dependencies:
2023-04-24 16:46:47,746:INFO:                 pip: 23.0.1
2023-04-24 16:46:47,746:INFO:          setuptools: 65.5.0
2023-04-24 16:46:47,746:INFO:             pycaret: 3.0.0
2023-04-24 16:46:47,746:INFO:             IPython: 8.5.0
2023-04-24 16:46:47,746:INFO:          ipywidgets: 8.0.2
2023-04-24 16:46:47,746:INFO:                tqdm: 4.65.0
2023-04-24 16:46:47,746:INFO:               numpy: 1.23.3
2023-04-24 16:46:47,746:INFO:              pandas: 1.5.0
2023-04-24 16:46:47,746:INFO:              jinja2: 3.1.2
2023-04-24 16:46:47,746:INFO:               scipy: 1.9.1
2023-04-24 16:46:47,746:INFO:              joblib: 1.2.0
2023-04-24 16:46:47,746:INFO:             sklearn: 1.1.2
2023-04-24 16:46:47,746:INFO:                pyod: 1.0.9
2023-04-24 16:46:47,746:INFO:            imblearn: 0.10.1
2023-04-24 16:46:47,746:INFO:   category_encoders: 2.6.0
2023-04-24 16:46:47,746:INFO:            lightgbm: 3.3.5
2023-04-24 16:46:47,746:INFO:               numba: 0.56.4
2023-04-24 16:46:47,746:INFO:            requests: 2.28.1
2023-04-24 16:46:47,746:INFO:          matplotlib: 3.6.0
2023-04-24 16:46:47,746:INFO:          scikitplot: 0.3.7
2023-04-24 16:46:47,746:INFO:         yellowbrick: 1.5
2023-04-24 16:46:47,746:INFO:              plotly: 5.10.0
2023-04-24 16:46:47,746:INFO:             kaleido: 0.2.1
2023-04-24 16:46:47,746:INFO:         statsmodels: 0.13.5
2023-04-24 16:46:47,746:INFO:              sktime: 0.17.1
2023-04-24 16:46:47,746:INFO:               tbats: 1.1.3
2023-04-24 16:46:47,746:INFO:            pmdarima: 2.0.3
2023-04-24 16:46:47,746:INFO:              psutil: 5.9.2
2023-04-24 16:46:47,746:INFO:PyCaret optional dependencies:
2023-04-24 16:46:47,746:INFO:                shap: Not installed
2023-04-24 16:46:47,746:INFO:           interpret: Not installed
2023-04-24 16:46:47,746:INFO:                umap: Not installed
2023-04-24 16:46:47,746:INFO:    pandas_profiling: Not installed
2023-04-24 16:46:47,746:INFO:  explainerdashboard: Not installed
2023-04-24 16:46:47,746:INFO:             autoviz: Not installed
2023-04-24 16:46:47,746:INFO:           fairlearn: Not installed
2023-04-24 16:46:47,746:INFO:             xgboost: 1.7.5
2023-04-24 16:46:47,746:INFO:            catboost: Not installed
2023-04-24 16:46:47,746:INFO:              kmodes: Not installed
2023-04-24 16:46:47,746:INFO:             mlxtend: Not installed
2023-04-24 16:46:47,746:INFO:       statsforecast: Not installed
2023-04-24 16:46:47,746:INFO:        tune_sklearn: Not installed
2023-04-24 16:46:47,746:INFO:                 ray: Not installed
2023-04-24 16:46:47,746:INFO:            hyperopt: Not installed
2023-04-24 16:46:47,746:INFO:              optuna: Not installed
2023-04-24 16:46:47,746:INFO:               skopt: Not installed
2023-04-24 16:46:47,746:INFO:              mlflow: 2.3.0
2023-04-24 16:46:47,746:INFO:              gradio: Not installed
2023-04-24 16:46:47,746:INFO:             fastapi: Not installed
2023-04-24 16:46:47,746:INFO:             uvicorn: Not installed
2023-04-24 16:46:47,746:INFO:              m2cgen: Not installed
2023-04-24 16:46:47,746:INFO:           evidently: Not installed
2023-04-24 16:46:47,746:INFO:               fugue: Not installed
2023-04-24 16:46:47,746:INFO:           streamlit: Not installed
2023-04-24 16:46:47,746:INFO:             prophet: Not installed
2023-04-24 16:46:47,746:INFO:None
2023-04-24 16:46:47,746:INFO:Set up data.
2023-04-24 16:46:47,761:INFO:Set up train/test split.
2023-04-24 16:46:47,761:INFO:Set up index.
2023-04-24 16:46:47,761:INFO:Set up folding strategy.
2023-04-24 16:46:47,761:INFO:Assigning column types.
2023-04-24 16:46:47,761:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:46:47,761:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,761:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,847:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:47,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:47,863:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,867:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,871:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,950:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:47,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:47,952:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:46:47,956:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:46:47,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,003:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,029:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,044:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,127:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,129:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:46:48,136:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,214:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,223:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,295:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,295:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:46:48,345:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,395:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,488:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,490:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:46:48,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,575:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:46:48,666:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,668:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:46:48,753:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,843:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:48,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:48,843:INFO:Preparing preprocessing pipeline...
2023-04-24 16:46:48,843:INFO:Set up simple imputation.
2023-04-24 16:46:48,860:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:46:48,860:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-24 16:46:48,860:INFO:Creating final display dataframe.
2023-04-24 16:46:48,910:INFO:Setup _display_container:                     Description             Value
0                    Session id              3232
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1204, 8)
4        Transformed data shape         (1204, 8)
5   Transformed train set shape          (842, 8)
6    Transformed test set shape          (362, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8841
2023-04-24 16:46:49,008:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:49,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:49,089:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:46:49,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:46:49,089:INFO:setup() successfully completed in 1.36s...............
2023-04-24 16:49:34,912:INFO:Initializing compare_models()
2023-04-24 16:49:34,913:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 16:49:34,913:INFO:Checking exceptions
2023-04-24 16:49:34,915:INFO:Preparing display monitor
2023-04-24 16:49:34,959:INFO:Initializing Linear Regression
2023-04-24 16:49:34,960:INFO:Total runtime is 1.655419667561849e-05 minutes
2023-04-24 16:49:34,962:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:34,962:INFO:Initializing create_model()
2023-04-24 16:49:34,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:34,962:INFO:Checking exceptions
2023-04-24 16:49:34,962:INFO:Importing libraries
2023-04-24 16:49:34,962:INFO:Copying training dataset
2023-04-24 16:49:34,962:INFO:Defining folds
2023-04-24 16:49:34,962:INFO:Declaring metric variables
2023-04-24 16:49:34,975:INFO:Importing untrained model
2023-04-24 16:49:34,979:INFO:Linear Regression Imported successfully
2023-04-24 16:49:34,979:INFO:Starting cross validation
2023-04-24 16:49:34,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:39,562:INFO:Calculating mean and std
2023-04-24 16:49:39,562:INFO:Creating metrics dataframe
2023-04-24 16:49:39,616:INFO:Uploading results into container
2023-04-24 16:49:39,617:INFO:Uploading model into container now
2023-04-24 16:49:39,617:INFO:_master_model_container: 1
2023-04-24 16:49:39,617:INFO:_display_container: 2
2023-04-24 16:49:39,618:INFO:LinearRegression(n_jobs=-1)
2023-04-24 16:49:39,618:INFO:create_model() successfully completed......................................
2023-04-24 16:49:39,754:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:39,754:INFO:Creating metrics dataframe
2023-04-24 16:49:39,762:INFO:Initializing Lasso Regression
2023-04-24 16:49:39,763:INFO:Total runtime is 0.08006456295649211 minutes
2023-04-24 16:49:39,769:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:39,769:INFO:Initializing create_model()
2023-04-24 16:49:39,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:39,769:INFO:Checking exceptions
2023-04-24 16:49:39,769:INFO:Importing libraries
2023-04-24 16:49:39,769:INFO:Copying training dataset
2023-04-24 16:49:39,774:INFO:Defining folds
2023-04-24 16:49:39,774:INFO:Declaring metric variables
2023-04-24 16:49:39,779:INFO:Importing untrained model
2023-04-24 16:49:39,785:INFO:Lasso Regression Imported successfully
2023-04-24 16:49:39,790:INFO:Starting cross validation
2023-04-24 16:49:39,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:40,163:INFO:Calculating mean and std
2023-04-24 16:49:40,165:INFO:Creating metrics dataframe
2023-04-24 16:49:40,232:INFO:Uploading results into container
2023-04-24 16:49:40,234:INFO:Uploading model into container now
2023-04-24 16:49:40,235:INFO:_master_model_container: 2
2023-04-24 16:49:40,235:INFO:_display_container: 2
2023-04-24 16:49:40,237:INFO:Lasso(random_state=3232)
2023-04-24 16:49:40,238:INFO:create_model() successfully completed......................................
2023-04-24 16:49:40,407:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:40,407:INFO:Creating metrics dataframe
2023-04-24 16:49:40,422:INFO:Initializing Ridge Regression
2023-04-24 16:49:40,422:INFO:Total runtime is 0.09105476538340251 minutes
2023-04-24 16:49:40,425:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:40,425:INFO:Initializing create_model()
2023-04-24 16:49:40,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:40,425:INFO:Checking exceptions
2023-04-24 16:49:40,425:INFO:Importing libraries
2023-04-24 16:49:40,425:INFO:Copying training dataset
2023-04-24 16:49:40,425:INFO:Defining folds
2023-04-24 16:49:40,425:INFO:Declaring metric variables
2023-04-24 16:49:40,425:INFO:Importing untrained model
2023-04-24 16:49:40,440:INFO:Ridge Regression Imported successfully
2023-04-24 16:49:40,449:INFO:Starting cross validation
2023-04-24 16:49:40,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:40,758:INFO:Calculating mean and std
2023-04-24 16:49:40,759:INFO:Creating metrics dataframe
2023-04-24 16:49:40,794:INFO:Uploading results into container
2023-04-24 16:49:40,794:INFO:Uploading model into container now
2023-04-24 16:49:40,794:INFO:_master_model_container: 3
2023-04-24 16:49:40,794:INFO:_display_container: 2
2023-04-24 16:49:40,795:INFO:Ridge(random_state=3232)
2023-04-24 16:49:40,795:INFO:create_model() successfully completed......................................
2023-04-24 16:49:40,917:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:40,917:INFO:Creating metrics dataframe
2023-04-24 16:49:40,925:INFO:Initializing Elastic Net
2023-04-24 16:49:40,925:INFO:Total runtime is 0.09942567348480225 minutes
2023-04-24 16:49:40,932:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:40,933:INFO:Initializing create_model()
2023-04-24 16:49:40,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:40,933:INFO:Checking exceptions
2023-04-24 16:49:40,933:INFO:Importing libraries
2023-04-24 16:49:40,933:INFO:Copying training dataset
2023-04-24 16:49:40,937:INFO:Defining folds
2023-04-24 16:49:40,937:INFO:Declaring metric variables
2023-04-24 16:49:40,941:INFO:Importing untrained model
2023-04-24 16:49:40,950:INFO:Elastic Net Imported successfully
2023-04-24 16:49:40,957:INFO:Starting cross validation
2023-04-24 16:49:40,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:41,256:INFO:Calculating mean and std
2023-04-24 16:49:41,271:INFO:Creating metrics dataframe
2023-04-24 16:49:41,307:INFO:Uploading results into container
2023-04-24 16:49:41,307:INFO:Uploading model into container now
2023-04-24 16:49:41,307:INFO:_master_model_container: 4
2023-04-24 16:49:41,307:INFO:_display_container: 2
2023-04-24 16:49:41,307:INFO:ElasticNet(random_state=3232)
2023-04-24 16:49:41,307:INFO:create_model() successfully completed......................................
2023-04-24 16:49:41,406:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:41,406:INFO:Creating metrics dataframe
2023-04-24 16:49:41,422:INFO:Initializing Least Angle Regression
2023-04-24 16:49:41,422:INFO:Total runtime is 0.10771018664042155 minutes
2023-04-24 16:49:41,423:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:41,423:INFO:Initializing create_model()
2023-04-24 16:49:41,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:41,423:INFO:Checking exceptions
2023-04-24 16:49:41,423:INFO:Importing libraries
2023-04-24 16:49:41,423:INFO:Copying training dataset
2023-04-24 16:49:41,423:INFO:Defining folds
2023-04-24 16:49:41,423:INFO:Declaring metric variables
2023-04-24 16:49:41,423:INFO:Importing untrained model
2023-04-24 16:49:41,423:INFO:Least Angle Regression Imported successfully
2023-04-24 16:49:41,439:INFO:Starting cross validation
2023-04-24 16:49:41,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:41,474:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,474:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,490:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,491:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,503:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,507:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,516:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,520:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,567:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,567:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:41,749:INFO:Calculating mean and std
2023-04-24 16:49:41,751:INFO:Creating metrics dataframe
2023-04-24 16:49:41,786:INFO:Uploading results into container
2023-04-24 16:49:41,787:INFO:Uploading model into container now
2023-04-24 16:49:41,787:INFO:_master_model_container: 5
2023-04-24 16:49:41,787:INFO:_display_container: 2
2023-04-24 16:49:41,788:INFO:Lars(random_state=3232)
2023-04-24 16:49:41,788:INFO:create_model() successfully completed......................................
2023-04-24 16:49:41,879:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:41,879:INFO:Creating metrics dataframe
2023-04-24 16:49:41,887:INFO:Initializing Lasso Least Angle Regression
2023-04-24 16:49:41,887:INFO:Total runtime is 0.11546472708384196 minutes
2023-04-24 16:49:41,890:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:41,891:INFO:Initializing create_model()
2023-04-24 16:49:41,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:41,891:INFO:Checking exceptions
2023-04-24 16:49:41,891:INFO:Importing libraries
2023-04-24 16:49:41,891:INFO:Copying training dataset
2023-04-24 16:49:41,895:INFO:Defining folds
2023-04-24 16:49:41,895:INFO:Declaring metric variables
2023-04-24 16:49:41,897:INFO:Importing untrained model
2023-04-24 16:49:41,900:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 16:49:41,907:INFO:Starting cross validation
2023-04-24 16:49:41,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:41,937:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,945:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,954:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,957:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,965:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,972:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,988:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:41,997:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:42,045:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:42,052:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:49:42,221:INFO:Calculating mean and std
2023-04-24 16:49:42,222:INFO:Creating metrics dataframe
2023-04-24 16:49:42,259:INFO:Uploading results into container
2023-04-24 16:49:42,259:INFO:Uploading model into container now
2023-04-24 16:49:42,260:INFO:_master_model_container: 6
2023-04-24 16:49:42,260:INFO:_display_container: 2
2023-04-24 16:49:42,260:INFO:LassoLars(random_state=3232)
2023-04-24 16:49:42,260:INFO:create_model() successfully completed......................................
2023-04-24 16:49:42,348:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:42,348:INFO:Creating metrics dataframe
2023-04-24 16:49:42,357:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 16:49:42,357:INFO:Total runtime is 0.12329840660095215 minutes
2023-04-24 16:49:42,359:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:42,359:INFO:Initializing create_model()
2023-04-24 16:49:42,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:42,360:INFO:Checking exceptions
2023-04-24 16:49:42,360:INFO:Importing libraries
2023-04-24 16:49:42,360:INFO:Copying training dataset
2023-04-24 16:49:42,363:INFO:Defining folds
2023-04-24 16:49:42,364:INFO:Declaring metric variables
2023-04-24 16:49:42,366:INFO:Importing untrained model
2023-04-24 16:49:42,369:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 16:49:42,369:INFO:Starting cross validation
2023-04-24 16:49:42,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:42,400:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,400:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,400:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,416:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,416:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,432:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,432:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,447:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,478:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,494:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:49:42,652:INFO:Calculating mean and std
2023-04-24 16:49:42,652:INFO:Creating metrics dataframe
2023-04-24 16:49:42,684:INFO:Uploading results into container
2023-04-24 16:49:42,684:INFO:Uploading model into container now
2023-04-24 16:49:42,684:INFO:_master_model_container: 7
2023-04-24 16:49:42,684:INFO:_display_container: 2
2023-04-24 16:49:42,684:INFO:OrthogonalMatchingPursuit()
2023-04-24 16:49:42,684:INFO:create_model() successfully completed......................................
2023-04-24 16:49:42,784:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:42,784:INFO:Creating metrics dataframe
2023-04-24 16:49:42,784:INFO:Initializing Bayesian Ridge
2023-04-24 16:49:42,784:INFO:Total runtime is 0.13041178385416666 minutes
2023-04-24 16:49:42,784:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:42,784:INFO:Initializing create_model()
2023-04-24 16:49:42,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:42,784:INFO:Checking exceptions
2023-04-24 16:49:42,784:INFO:Importing libraries
2023-04-24 16:49:42,784:INFO:Copying training dataset
2023-04-24 16:49:42,799:INFO:Defining folds
2023-04-24 16:49:42,799:INFO:Declaring metric variables
2023-04-24 16:49:42,799:INFO:Importing untrained model
2023-04-24 16:49:42,799:INFO:Bayesian Ridge Imported successfully
2023-04-24 16:49:42,799:INFO:Starting cross validation
2023-04-24 16:49:42,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:43,105:INFO:Calculating mean and std
2023-04-24 16:49:43,107:INFO:Creating metrics dataframe
2023-04-24 16:49:43,142:INFO:Uploading results into container
2023-04-24 16:49:43,142:INFO:Uploading model into container now
2023-04-24 16:49:43,143:INFO:_master_model_container: 8
2023-04-24 16:49:43,143:INFO:_display_container: 2
2023-04-24 16:49:43,143:INFO:BayesianRidge()
2023-04-24 16:49:43,143:INFO:create_model() successfully completed......................................
2023-04-24 16:49:43,228:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:43,228:INFO:Creating metrics dataframe
2023-04-24 16:49:43,228:INFO:Initializing Passive Aggressive Regressor
2023-04-24 16:49:43,228:INFO:Total runtime is 0.13781520128250122 minutes
2023-04-24 16:49:43,228:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:43,228:INFO:Initializing create_model()
2023-04-24 16:49:43,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:43,228:INFO:Checking exceptions
2023-04-24 16:49:43,228:INFO:Importing libraries
2023-04-24 16:49:43,228:INFO:Copying training dataset
2023-04-24 16:49:43,244:INFO:Defining folds
2023-04-24 16:49:43,244:INFO:Declaring metric variables
2023-04-24 16:49:43,247:INFO:Importing untrained model
2023-04-24 16:49:43,251:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 16:49:43,257:INFO:Starting cross validation
2023-04-24 16:49:43,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:43,556:INFO:Calculating mean and std
2023-04-24 16:49:43,557:INFO:Creating metrics dataframe
2023-04-24 16:49:43,593:INFO:Uploading results into container
2023-04-24 16:49:43,594:INFO:Uploading model into container now
2023-04-24 16:49:43,594:INFO:_master_model_container: 9
2023-04-24 16:49:43,594:INFO:_display_container: 2
2023-04-24 16:49:43,594:INFO:PassiveAggressiveRegressor(random_state=3232)
2023-04-24 16:49:43,594:INFO:create_model() successfully completed......................................
2023-04-24 16:49:43,719:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:43,719:INFO:Creating metrics dataframe
2023-04-24 16:49:43,739:INFO:Initializing Huber Regressor
2023-04-24 16:49:43,739:INFO:Total runtime is 0.14633203347524007 minutes
2023-04-24 16:49:43,741:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:43,741:INFO:Initializing create_model()
2023-04-24 16:49:43,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:43,742:INFO:Checking exceptions
2023-04-24 16:49:43,742:INFO:Importing libraries
2023-04-24 16:49:43,742:INFO:Copying training dataset
2023-04-24 16:49:43,745:INFO:Defining folds
2023-04-24 16:49:43,745:INFO:Declaring metric variables
2023-04-24 16:49:43,750:INFO:Importing untrained model
2023-04-24 16:49:43,755:INFO:Huber Regressor Imported successfully
2023-04-24 16:49:43,763:INFO:Starting cross validation
2023-04-24 16:49:43,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:43,847:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,847:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,862:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,865:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,865:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,865:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,882:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,897:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,984:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:43,991:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:49:44,142:INFO:Calculating mean and std
2023-04-24 16:49:44,143:INFO:Creating metrics dataframe
2023-04-24 16:49:44,187:INFO:Uploading results into container
2023-04-24 16:49:44,188:INFO:Uploading model into container now
2023-04-24 16:49:44,189:INFO:_master_model_container: 10
2023-04-24 16:49:44,189:INFO:_display_container: 2
2023-04-24 16:49:44,189:INFO:HuberRegressor()
2023-04-24 16:49:44,189:INFO:create_model() successfully completed......................................
2023-04-24 16:49:44,315:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:44,315:INFO:Creating metrics dataframe
2023-04-24 16:49:44,315:INFO:Initializing K Neighbors Regressor
2023-04-24 16:49:44,315:INFO:Total runtime is 0.15592365662256877 minutes
2023-04-24 16:49:44,315:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:44,315:INFO:Initializing create_model()
2023-04-24 16:49:44,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:44,315:INFO:Checking exceptions
2023-04-24 16:49:44,315:INFO:Importing libraries
2023-04-24 16:49:44,315:INFO:Copying training dataset
2023-04-24 16:49:44,330:INFO:Defining folds
2023-04-24 16:49:44,330:INFO:Declaring metric variables
2023-04-24 16:49:44,330:INFO:Importing untrained model
2023-04-24 16:49:44,330:INFO:K Neighbors Regressor Imported successfully
2023-04-24 16:49:44,330:INFO:Starting cross validation
2023-04-24 16:49:44,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:44,660:INFO:Calculating mean and std
2023-04-24 16:49:44,660:INFO:Creating metrics dataframe
2023-04-24 16:49:44,692:INFO:Uploading results into container
2023-04-24 16:49:44,692:INFO:Uploading model into container now
2023-04-24 16:49:44,692:INFO:_master_model_container: 11
2023-04-24 16:49:44,692:INFO:_display_container: 2
2023-04-24 16:49:44,692:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 16:49:44,692:INFO:create_model() successfully completed......................................
2023-04-24 16:49:44,785:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:44,785:INFO:Creating metrics dataframe
2023-04-24 16:49:44,793:INFO:Initializing Decision Tree Regressor
2023-04-24 16:49:44,793:INFO:Total runtime is 0.16388943592707317 minutes
2023-04-24 16:49:44,795:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:44,795:INFO:Initializing create_model()
2023-04-24 16:49:44,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:44,795:INFO:Checking exceptions
2023-04-24 16:49:44,795:INFO:Importing libraries
2023-04-24 16:49:44,795:INFO:Copying training dataset
2023-04-24 16:49:44,799:INFO:Defining folds
2023-04-24 16:49:44,800:INFO:Declaring metric variables
2023-04-24 16:49:44,803:INFO:Importing untrained model
2023-04-24 16:49:44,806:INFO:Decision Tree Regressor Imported successfully
2023-04-24 16:49:44,811:INFO:Starting cross validation
2023-04-24 16:49:44,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:45,111:INFO:Calculating mean and std
2023-04-24 16:49:45,112:INFO:Creating metrics dataframe
2023-04-24 16:49:45,147:INFO:Uploading results into container
2023-04-24 16:49:45,147:INFO:Uploading model into container now
2023-04-24 16:49:45,148:INFO:_master_model_container: 12
2023-04-24 16:49:45,148:INFO:_display_container: 2
2023-04-24 16:49:45,148:INFO:DecisionTreeRegressor(random_state=3232)
2023-04-24 16:49:45,148:INFO:create_model() successfully completed......................................
2023-04-24 16:49:45,239:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:45,239:INFO:Creating metrics dataframe
2023-04-24 16:49:45,249:INFO:Initializing Random Forest Regressor
2023-04-24 16:49:45,249:INFO:Total runtime is 0.17149593035380045 minutes
2023-04-24 16:49:45,251:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:45,252:INFO:Initializing create_model()
2023-04-24 16:49:45,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:45,252:INFO:Checking exceptions
2023-04-24 16:49:45,252:INFO:Importing libraries
2023-04-24 16:49:45,252:INFO:Copying training dataset
2023-04-24 16:49:45,256:INFO:Defining folds
2023-04-24 16:49:45,256:INFO:Declaring metric variables
2023-04-24 16:49:45,259:INFO:Importing untrained model
2023-04-24 16:49:45,264:INFO:Random Forest Regressor Imported successfully
2023-04-24 16:49:45,269:INFO:Starting cross validation
2023-04-24 16:49:45,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:46,344:INFO:Calculating mean and std
2023-04-24 16:49:46,346:INFO:Creating metrics dataframe
2023-04-24 16:49:46,397:INFO:Uploading results into container
2023-04-24 16:49:46,397:INFO:Uploading model into container now
2023-04-24 16:49:46,397:INFO:_master_model_container: 13
2023-04-24 16:49:46,397:INFO:_display_container: 2
2023-04-24 16:49:46,398:INFO:RandomForestRegressor(n_jobs=-1, random_state=3232)
2023-04-24 16:49:46,398:INFO:create_model() successfully completed......................................
2023-04-24 16:49:46,491:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:46,491:INFO:Creating metrics dataframe
2023-04-24 16:49:46,507:INFO:Initializing Extra Trees Regressor
2023-04-24 16:49:46,507:INFO:Total runtime is 0.1924694538116455 minutes
2023-04-24 16:49:46,507:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:46,507:INFO:Initializing create_model()
2023-04-24 16:49:46,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:46,507:INFO:Checking exceptions
2023-04-24 16:49:46,507:INFO:Importing libraries
2023-04-24 16:49:46,507:INFO:Copying training dataset
2023-04-24 16:49:46,507:INFO:Defining folds
2023-04-24 16:49:46,507:INFO:Declaring metric variables
2023-04-24 16:49:46,524:INFO:Importing untrained model
2023-04-24 16:49:46,524:INFO:Extra Trees Regressor Imported successfully
2023-04-24 16:49:46,524:INFO:Starting cross validation
2023-04-24 16:49:46,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:47,557:INFO:Calculating mean and std
2023-04-24 16:49:47,557:INFO:Creating metrics dataframe
2023-04-24 16:49:47,588:INFO:Uploading results into container
2023-04-24 16:49:47,588:INFO:Uploading model into container now
2023-04-24 16:49:47,588:INFO:_master_model_container: 14
2023-04-24 16:49:47,588:INFO:_display_container: 2
2023-04-24 16:49:47,588:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3232)
2023-04-24 16:49:47,588:INFO:create_model() successfully completed......................................
2023-04-24 16:49:47,691:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:47,691:INFO:Creating metrics dataframe
2023-04-24 16:49:47,707:INFO:Initializing AdaBoost Regressor
2023-04-24 16:49:47,707:INFO:Total runtime is 0.21246118942896525 minutes
2023-04-24 16:49:47,707:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:47,707:INFO:Initializing create_model()
2023-04-24 16:49:47,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:47,707:INFO:Checking exceptions
2023-04-24 16:49:47,707:INFO:Importing libraries
2023-04-24 16:49:47,707:INFO:Copying training dataset
2023-04-24 16:49:47,707:INFO:Defining folds
2023-04-24 16:49:47,707:INFO:Declaring metric variables
2023-04-24 16:49:47,707:INFO:Importing untrained model
2023-04-24 16:49:47,721:INFO:AdaBoost Regressor Imported successfully
2023-04-24 16:49:47,725:INFO:Starting cross validation
2023-04-24 16:49:47,725:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:48,134:INFO:Calculating mean and std
2023-04-24 16:49:48,134:INFO:Creating metrics dataframe
2023-04-24 16:49:48,179:INFO:Uploading results into container
2023-04-24 16:49:48,179:INFO:Uploading model into container now
2023-04-24 16:49:48,180:INFO:_master_model_container: 15
2023-04-24 16:49:48,180:INFO:_display_container: 2
2023-04-24 16:49:48,180:INFO:AdaBoostRegressor(random_state=3232)
2023-04-24 16:49:48,180:INFO:create_model() successfully completed......................................
2023-04-24 16:49:48,268:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:48,268:INFO:Creating metrics dataframe
2023-04-24 16:49:48,268:INFO:Initializing Gradient Boosting Regressor
2023-04-24 16:49:48,268:INFO:Total runtime is 0.22182167768478392 minutes
2023-04-24 16:49:48,268:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:48,268:INFO:Initializing create_model()
2023-04-24 16:49:48,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:48,268:INFO:Checking exceptions
2023-04-24 16:49:48,268:INFO:Importing libraries
2023-04-24 16:49:48,268:INFO:Copying training dataset
2023-04-24 16:49:48,283:INFO:Defining folds
2023-04-24 16:49:48,283:INFO:Declaring metric variables
2023-04-24 16:49:48,283:INFO:Importing untrained model
2023-04-24 16:49:48,283:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:49:48,303:INFO:Starting cross validation
2023-04-24 16:49:48,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:48,755:INFO:Calculating mean and std
2023-04-24 16:49:48,756:INFO:Creating metrics dataframe
2023-04-24 16:49:48,782:INFO:Uploading results into container
2023-04-24 16:49:48,782:INFO:Uploading model into container now
2023-04-24 16:49:48,782:INFO:_master_model_container: 16
2023-04-24 16:49:48,782:INFO:_display_container: 2
2023-04-24 16:49:48,782:INFO:GradientBoostingRegressor(random_state=3232)
2023-04-24 16:49:48,782:INFO:create_model() successfully completed......................................
2023-04-24 16:49:48,875:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:48,875:INFO:Creating metrics dataframe
2023-04-24 16:49:48,891:INFO:Initializing Extreme Gradient Boosting
2023-04-24 16:49:48,891:INFO:Total runtime is 0.23219879070917765 minutes
2023-04-24 16:49:48,891:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:48,891:INFO:Initializing create_model()
2023-04-24 16:49:48,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:48,891:INFO:Checking exceptions
2023-04-24 16:49:48,891:INFO:Importing libraries
2023-04-24 16:49:48,891:INFO:Copying training dataset
2023-04-24 16:49:48,891:INFO:Defining folds
2023-04-24 16:49:48,891:INFO:Declaring metric variables
2023-04-24 16:49:48,891:INFO:Importing untrained model
2023-04-24 16:49:48,907:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 16:49:48,907:INFO:Starting cross validation
2023-04-24 16:49:48,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:50,599:INFO:Calculating mean and std
2023-04-24 16:49:50,600:INFO:Creating metrics dataframe
2023-04-24 16:49:50,648:INFO:Uploading results into container
2023-04-24 16:49:50,648:INFO:Uploading model into container now
2023-04-24 16:49:50,649:INFO:_master_model_container: 17
2023-04-24 16:49:50,649:INFO:_display_container: 2
2023-04-24 16:49:50,652:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3232, ...)
2023-04-24 16:49:50,652:INFO:create_model() successfully completed......................................
2023-04-24 16:49:50,777:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:50,777:INFO:Creating metrics dataframe
2023-04-24 16:49:50,787:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 16:49:50,787:INFO:Total runtime is 0.26379941701889037 minutes
2023-04-24 16:49:50,790:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:50,791:INFO:Initializing create_model()
2023-04-24 16:49:50,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:50,791:INFO:Checking exceptions
2023-04-24 16:49:50,791:INFO:Importing libraries
2023-04-24 16:49:50,791:INFO:Copying training dataset
2023-04-24 16:49:50,801:INFO:Defining folds
2023-04-24 16:49:50,801:INFO:Declaring metric variables
2023-04-24 16:49:50,805:INFO:Importing untrained model
2023-04-24 16:49:50,810:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:49:50,819:INFO:Starting cross validation
2023-04-24 16:49:50,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:51,376:INFO:Calculating mean and std
2023-04-24 16:49:51,376:INFO:Creating metrics dataframe
2023-04-24 16:49:51,409:INFO:Uploading results into container
2023-04-24 16:49:51,409:INFO:Uploading model into container now
2023-04-24 16:49:51,409:INFO:_master_model_container: 18
2023-04-24 16:49:51,409:INFO:_display_container: 2
2023-04-24 16:49:51,409:INFO:LGBMRegressor(random_state=3232)
2023-04-24 16:49:51,409:INFO:create_model() successfully completed......................................
2023-04-24 16:49:51,511:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:51,511:INFO:Creating metrics dataframe
2023-04-24 16:49:51,511:INFO:Initializing Dummy Regressor
2023-04-24 16:49:51,511:INFO:Total runtime is 0.2758560140927633 minutes
2023-04-24 16:49:51,511:INFO:SubProcess create_model() called ==================================
2023-04-24 16:49:51,511:INFO:Initializing create_model()
2023-04-24 16:49:51,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3C640>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:51,511:INFO:Checking exceptions
2023-04-24 16:49:51,511:INFO:Importing libraries
2023-04-24 16:49:51,511:INFO:Copying training dataset
2023-04-24 16:49:51,527:INFO:Defining folds
2023-04-24 16:49:51,527:INFO:Declaring metric variables
2023-04-24 16:49:51,528:INFO:Importing untrained model
2023-04-24 16:49:51,528:INFO:Dummy Regressor Imported successfully
2023-04-24 16:49:51,528:INFO:Starting cross validation
2023-04-24 16:49:51,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:49:51,892:INFO:Calculating mean and std
2023-04-24 16:49:51,892:INFO:Creating metrics dataframe
2023-04-24 16:49:51,958:INFO:Uploading results into container
2023-04-24 16:49:51,959:INFO:Uploading model into container now
2023-04-24 16:49:51,959:INFO:_master_model_container: 19
2023-04-24 16:49:51,959:INFO:_display_container: 2
2023-04-24 16:49:51,959:INFO:DummyRegressor()
2023-04-24 16:49:51,959:INFO:create_model() successfully completed......................................
2023-04-24 16:49:52,077:INFO:SubProcess create_model() end ==================================
2023-04-24 16:49:52,077:INFO:Creating metrics dataframe
2023-04-24 16:49:52,098:INFO:Initializing create_model()
2023-04-24 16:49:52,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=GradientBoostingRegressor(random_state=3232), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:49:52,098:INFO:Checking exceptions
2023-04-24 16:49:52,100:INFO:Importing libraries
2023-04-24 16:49:52,100:INFO:Copying training dataset
2023-04-24 16:49:52,102:INFO:Defining folds
2023-04-24 16:49:52,102:INFO:Declaring metric variables
2023-04-24 16:49:52,102:INFO:Importing untrained model
2023-04-24 16:49:52,102:INFO:Declaring custom model
2023-04-24 16:49:52,103:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:49:52,103:INFO:Cross validation set to False
2023-04-24 16:49:52,103:INFO:Fitting Model
2023-04-24 16:49:52,202:INFO:GradientBoostingRegressor(random_state=3232)
2023-04-24 16:49:52,202:INFO:create_model() successfully completed......................................
2023-04-24 16:49:52,325:INFO:_master_model_container: 19
2023-04-24 16:49:52,325:INFO:_display_container: 2
2023-04-24 16:49:52,326:INFO:GradientBoostingRegressor(random_state=3232)
2023-04-24 16:49:52,326:INFO:compare_models() successfully completed......................................
2023-04-24 16:51:08,573:INFO:Initializing compare_models()
2023-04-24 16:51:08,573:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 16:51:08,573:INFO:Checking exceptions
2023-04-24 16:51:08,575:INFO:Preparing display monitor
2023-04-24 16:51:08,599:INFO:Initializing Linear Regression
2023-04-24 16:51:08,599:INFO:Total runtime is 0.0 minutes
2023-04-24 16:51:08,599:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:08,599:INFO:Initializing create_model()
2023-04-24 16:51:08,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:08,599:INFO:Checking exceptions
2023-04-24 16:51:08,599:INFO:Importing libraries
2023-04-24 16:51:08,599:INFO:Copying training dataset
2023-04-24 16:51:08,620:INFO:Defining folds
2023-04-24 16:51:08,620:INFO:Declaring metric variables
2023-04-24 16:51:08,623:INFO:Importing untrained model
2023-04-24 16:51:08,626:INFO:Linear Regression Imported successfully
2023-04-24 16:51:08,635:INFO:Starting cross validation
2023-04-24 16:51:08,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:09,010:INFO:Calculating mean and std
2023-04-24 16:51:09,010:INFO:Creating metrics dataframe
2023-04-24 16:51:09,057:INFO:Uploading results into container
2023-04-24 16:51:09,057:INFO:Uploading model into container now
2023-04-24 16:51:09,057:INFO:_master_model_container: 20
2023-04-24 16:51:09,057:INFO:_display_container: 3
2023-04-24 16:51:09,057:INFO:LinearRegression(n_jobs=-1)
2023-04-24 16:51:09,057:INFO:create_model() successfully completed......................................
2023-04-24 16:51:09,158:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:09,159:INFO:Creating metrics dataframe
2023-04-24 16:51:09,164:INFO:Initializing Lasso Regression
2023-04-24 16:51:09,164:INFO:Total runtime is 0.0094169020652771 minutes
2023-04-24 16:51:09,168:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:09,168:INFO:Initializing create_model()
2023-04-24 16:51:09,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:09,169:INFO:Checking exceptions
2023-04-24 16:51:09,169:INFO:Importing libraries
2023-04-24 16:51:09,169:INFO:Copying training dataset
2023-04-24 16:51:09,171:INFO:Defining folds
2023-04-24 16:51:09,171:INFO:Declaring metric variables
2023-04-24 16:51:09,174:INFO:Importing untrained model
2023-04-24 16:51:09,177:INFO:Lasso Regression Imported successfully
2023-04-24 16:51:09,183:INFO:Starting cross validation
2023-04-24 16:51:09,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:09,545:INFO:Calculating mean and std
2023-04-24 16:51:09,545:INFO:Creating metrics dataframe
2023-04-24 16:51:09,601:INFO:Uploading results into container
2023-04-24 16:51:09,602:INFO:Uploading model into container now
2023-04-24 16:51:09,603:INFO:_master_model_container: 21
2023-04-24 16:51:09,603:INFO:_display_container: 3
2023-04-24 16:51:09,603:INFO:Lasso(random_state=3232)
2023-04-24 16:51:09,603:INFO:create_model() successfully completed......................................
2023-04-24 16:51:09,695:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:09,695:INFO:Creating metrics dataframe
2023-04-24 16:51:09,700:INFO:Initializing Ridge Regression
2023-04-24 16:51:09,700:INFO:Total runtime is 0.018350295225779217 minutes
2023-04-24 16:51:09,700:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:09,700:INFO:Initializing create_model()
2023-04-24 16:51:09,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:09,700:INFO:Checking exceptions
2023-04-24 16:51:09,700:INFO:Importing libraries
2023-04-24 16:51:09,700:INFO:Copying training dataset
2023-04-24 16:51:09,700:INFO:Defining folds
2023-04-24 16:51:09,700:INFO:Declaring metric variables
2023-04-24 16:51:09,714:INFO:Importing untrained model
2023-04-24 16:51:09,718:INFO:Ridge Regression Imported successfully
2023-04-24 16:51:09,719:INFO:Starting cross validation
2023-04-24 16:51:09,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:10,083:INFO:Calculating mean and std
2023-04-24 16:51:10,083:INFO:Creating metrics dataframe
2023-04-24 16:51:10,135:INFO:Uploading results into container
2023-04-24 16:51:10,135:INFO:Uploading model into container now
2023-04-24 16:51:10,135:INFO:_master_model_container: 22
2023-04-24 16:51:10,135:INFO:_display_container: 3
2023-04-24 16:51:10,136:INFO:Ridge(random_state=3232)
2023-04-24 16:51:10,136:INFO:create_model() successfully completed......................................
2023-04-24 16:51:10,210:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:10,210:INFO:Creating metrics dataframe
2023-04-24 16:51:10,226:INFO:Initializing Elastic Net
2023-04-24 16:51:10,226:INFO:Total runtime is 0.02711337407430013 minutes
2023-04-24 16:51:10,226:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:10,226:INFO:Initializing create_model()
2023-04-24 16:51:10,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:10,226:INFO:Checking exceptions
2023-04-24 16:51:10,226:INFO:Importing libraries
2023-04-24 16:51:10,226:INFO:Copying training dataset
2023-04-24 16:51:10,236:INFO:Defining folds
2023-04-24 16:51:10,236:INFO:Declaring metric variables
2023-04-24 16:51:10,239:INFO:Importing untrained model
2023-04-24 16:51:10,240:INFO:Elastic Net Imported successfully
2023-04-24 16:51:10,250:INFO:Starting cross validation
2023-04-24 16:51:10,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:10,610:INFO:Calculating mean and std
2023-04-24 16:51:10,610:INFO:Creating metrics dataframe
2023-04-24 16:51:10,656:INFO:Uploading results into container
2023-04-24 16:51:10,656:INFO:Uploading model into container now
2023-04-24 16:51:10,656:INFO:_master_model_container: 23
2023-04-24 16:51:10,656:INFO:_display_container: 3
2023-04-24 16:51:10,657:INFO:ElasticNet(random_state=3232)
2023-04-24 16:51:10,657:INFO:create_model() successfully completed......................................
2023-04-24 16:51:10,741:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:10,741:INFO:Creating metrics dataframe
2023-04-24 16:51:10,741:INFO:Initializing Least Angle Regression
2023-04-24 16:51:10,741:INFO:Total runtime is 0.03569780985514323 minutes
2023-04-24 16:51:10,741:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:10,741:INFO:Initializing create_model()
2023-04-24 16:51:10,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:10,741:INFO:Checking exceptions
2023-04-24 16:51:10,741:INFO:Importing libraries
2023-04-24 16:51:10,741:INFO:Copying training dataset
2023-04-24 16:51:10,757:INFO:Defining folds
2023-04-24 16:51:10,757:INFO:Declaring metric variables
2023-04-24 16:51:10,760:INFO:Importing untrained model
2023-04-24 16:51:10,763:INFO:Least Angle Regression Imported successfully
2023-04-24 16:51:10,763:INFO:Starting cross validation
2023-04-24 16:51:10,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:10,810:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,830:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,837:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,844:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,847:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,852:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,860:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,860:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,922:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:10,938:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,162:INFO:Calculating mean and std
2023-04-24 16:51:11,162:INFO:Creating metrics dataframe
2023-04-24 16:51:11,211:INFO:Uploading results into container
2023-04-24 16:51:11,211:INFO:Uploading model into container now
2023-04-24 16:51:11,211:INFO:_master_model_container: 24
2023-04-24 16:51:11,211:INFO:_display_container: 3
2023-04-24 16:51:11,211:INFO:Lars(random_state=3232)
2023-04-24 16:51:11,211:INFO:create_model() successfully completed......................................
2023-04-24 16:51:11,308:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:11,308:INFO:Creating metrics dataframe
2023-04-24 16:51:11,308:INFO:Initializing Lasso Least Angle Regression
2023-04-24 16:51:11,308:INFO:Total runtime is 0.04515056610107422 minutes
2023-04-24 16:51:11,308:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:11,308:INFO:Initializing create_model()
2023-04-24 16:51:11,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:11,308:INFO:Checking exceptions
2023-04-24 16:51:11,308:INFO:Importing libraries
2023-04-24 16:51:11,308:INFO:Copying training dataset
2023-04-24 16:51:11,326:INFO:Defining folds
2023-04-24 16:51:11,327:INFO:Declaring metric variables
2023-04-24 16:51:11,330:INFO:Importing untrained model
2023-04-24 16:51:11,333:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 16:51:11,343:INFO:Starting cross validation
2023-04-24 16:51:11,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:11,378:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,384:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,389:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,397:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,401:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,407:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,408:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,408:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,477:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,494:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:51:11,723:INFO:Calculating mean and std
2023-04-24 16:51:11,723:INFO:Creating metrics dataframe
2023-04-24 16:51:11,770:INFO:Uploading results into container
2023-04-24 16:51:11,770:INFO:Uploading model into container now
2023-04-24 16:51:11,770:INFO:_master_model_container: 25
2023-04-24 16:51:11,771:INFO:_display_container: 3
2023-04-24 16:51:11,771:INFO:LassoLars(random_state=3232)
2023-04-24 16:51:11,771:INFO:create_model() successfully completed......................................
2023-04-24 16:51:11,851:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:11,851:INFO:Creating metrics dataframe
2023-04-24 16:51:11,851:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 16:51:11,851:INFO:Total runtime is 0.05420345465342204 minutes
2023-04-24 16:51:11,851:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:11,851:INFO:Initializing create_model()
2023-04-24 16:51:11,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:11,851:INFO:Checking exceptions
2023-04-24 16:51:11,851:INFO:Importing libraries
2023-04-24 16:51:11,851:INFO:Copying training dataset
2023-04-24 16:51:11,870:INFO:Defining folds
2023-04-24 16:51:11,871:INFO:Declaring metric variables
2023-04-24 16:51:11,873:INFO:Importing untrained model
2023-04-24 16:51:11,875:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 16:51:11,875:INFO:Starting cross validation
2023-04-24 16:51:11,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:11,917:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,919:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,926:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,934:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,941:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,941:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,941:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:11,957:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:12,006:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:12,006:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:51:12,227:INFO:Calculating mean and std
2023-04-24 16:51:12,227:INFO:Creating metrics dataframe
2023-04-24 16:51:12,281:INFO:Uploading results into container
2023-04-24 16:51:12,281:INFO:Uploading model into container now
2023-04-24 16:51:12,282:INFO:_master_model_container: 26
2023-04-24 16:51:12,282:INFO:_display_container: 3
2023-04-24 16:51:12,282:INFO:OrthogonalMatchingPursuit()
2023-04-24 16:51:12,282:INFO:create_model() successfully completed......................................
2023-04-24 16:51:12,371:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:12,371:INFO:Creating metrics dataframe
2023-04-24 16:51:12,379:INFO:Initializing Bayesian Ridge
2023-04-24 16:51:12,379:INFO:Total runtime is 0.06299159129460652 minutes
2023-04-24 16:51:12,381:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:12,382:INFO:Initializing create_model()
2023-04-24 16:51:12,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:12,382:INFO:Checking exceptions
2023-04-24 16:51:12,382:INFO:Importing libraries
2023-04-24 16:51:12,382:INFO:Copying training dataset
2023-04-24 16:51:12,385:INFO:Defining folds
2023-04-24 16:51:12,385:INFO:Declaring metric variables
2023-04-24 16:51:12,388:INFO:Importing untrained model
2023-04-24 16:51:12,391:INFO:Bayesian Ridge Imported successfully
2023-04-24 16:51:12,396:INFO:Starting cross validation
2023-04-24 16:51:12,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:12,760:INFO:Calculating mean and std
2023-04-24 16:51:12,760:INFO:Creating metrics dataframe
2023-04-24 16:51:12,803:INFO:Uploading results into container
2023-04-24 16:51:12,803:INFO:Uploading model into container now
2023-04-24 16:51:12,804:INFO:_master_model_container: 27
2023-04-24 16:51:12,804:INFO:_display_container: 3
2023-04-24 16:51:12,804:INFO:BayesianRidge()
2023-04-24 16:51:12,804:INFO:create_model() successfully completed......................................
2023-04-24 16:51:12,882:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:12,882:INFO:Creating metrics dataframe
2023-04-24 16:51:12,882:INFO:Initializing Passive Aggressive Regressor
2023-04-24 16:51:12,882:INFO:Total runtime is 0.07138630151748657 minutes
2023-04-24 16:51:12,901:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:12,902:INFO:Initializing create_model()
2023-04-24 16:51:12,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:12,902:INFO:Checking exceptions
2023-04-24 16:51:12,902:INFO:Importing libraries
2023-04-24 16:51:12,902:INFO:Copying training dataset
2023-04-24 16:51:12,906:INFO:Defining folds
2023-04-24 16:51:12,906:INFO:Declaring metric variables
2023-04-24 16:51:12,909:INFO:Importing untrained model
2023-04-24 16:51:12,909:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 16:51:12,909:INFO:Starting cross validation
2023-04-24 16:51:12,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:13,304:INFO:Calculating mean and std
2023-04-24 16:51:13,306:INFO:Creating metrics dataframe
2023-04-24 16:51:13,354:INFO:Uploading results into container
2023-04-24 16:51:13,354:INFO:Uploading model into container now
2023-04-24 16:51:13,355:INFO:_master_model_container: 28
2023-04-24 16:51:13,355:INFO:_display_container: 3
2023-04-24 16:51:13,355:INFO:PassiveAggressiveRegressor(random_state=3232)
2023-04-24 16:51:13,355:INFO:create_model() successfully completed......................................
2023-04-24 16:51:13,434:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:13,434:INFO:Creating metrics dataframe
2023-04-24 16:51:13,434:INFO:Initializing Huber Regressor
2023-04-24 16:51:13,434:INFO:Total runtime is 0.08058801094690958 minutes
2023-04-24 16:51:13,453:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:13,453:INFO:Initializing create_model()
2023-04-24 16:51:13,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:13,453:INFO:Checking exceptions
2023-04-24 16:51:13,453:INFO:Importing libraries
2023-04-24 16:51:13,453:INFO:Copying training dataset
2023-04-24 16:51:13,457:INFO:Defining folds
2023-04-24 16:51:13,457:INFO:Declaring metric variables
2023-04-24 16:51:13,459:INFO:Importing untrained model
2023-04-24 16:51:13,462:INFO:Huber Regressor Imported successfully
2023-04-24 16:51:13,472:INFO:Starting cross validation
2023-04-24 16:51:13,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:13,536:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,536:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,536:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,552:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,552:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,567:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,567:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,583:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,650:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,666:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 16:51:13,863:INFO:Calculating mean and std
2023-04-24 16:51:13,864:INFO:Creating metrics dataframe
2023-04-24 16:51:13,906:INFO:Uploading results into container
2023-04-24 16:51:13,907:INFO:Uploading model into container now
2023-04-24 16:51:13,907:INFO:_master_model_container: 29
2023-04-24 16:51:13,907:INFO:_display_container: 3
2023-04-24 16:51:13,908:INFO:HuberRegressor()
2023-04-24 16:51:13,908:INFO:create_model() successfully completed......................................
2023-04-24 16:51:13,998:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:13,998:INFO:Creating metrics dataframe
2023-04-24 16:51:14,003:INFO:Initializing K Neighbors Regressor
2023-04-24 16:51:14,003:INFO:Total runtime is 0.09006191492080688 minutes
2023-04-24 16:51:14,003:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:14,003:INFO:Initializing create_model()
2023-04-24 16:51:14,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:14,003:INFO:Checking exceptions
2023-04-24 16:51:14,003:INFO:Importing libraries
2023-04-24 16:51:14,003:INFO:Copying training dataset
2023-04-24 16:51:14,003:INFO:Defining folds
2023-04-24 16:51:14,003:INFO:Declaring metric variables
2023-04-24 16:51:14,019:INFO:Importing untrained model
2023-04-24 16:51:14,022:INFO:K Neighbors Regressor Imported successfully
2023-04-24 16:51:14,027:INFO:Starting cross validation
2023-04-24 16:51:14,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:14,419:INFO:Calculating mean and std
2023-04-24 16:51:14,419:INFO:Creating metrics dataframe
2023-04-24 16:51:14,468:INFO:Uploading results into container
2023-04-24 16:51:14,468:INFO:Uploading model into container now
2023-04-24 16:51:14,468:INFO:_master_model_container: 30
2023-04-24 16:51:14,468:INFO:_display_container: 3
2023-04-24 16:51:14,468:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 16:51:14,468:INFO:create_model() successfully completed......................................
2023-04-24 16:51:14,569:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:14,569:INFO:Creating metrics dataframe
2023-04-24 16:51:14,582:INFO:Initializing Decision Tree Regressor
2023-04-24 16:51:14,582:INFO:Total runtime is 0.09972334305445353 minutes
2023-04-24 16:51:14,585:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:14,585:INFO:Initializing create_model()
2023-04-24 16:51:14,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:14,585:INFO:Checking exceptions
2023-04-24 16:51:14,585:INFO:Importing libraries
2023-04-24 16:51:14,585:INFO:Copying training dataset
2023-04-24 16:51:14,585:INFO:Defining folds
2023-04-24 16:51:14,585:INFO:Declaring metric variables
2023-04-24 16:51:14,585:INFO:Importing untrained model
2023-04-24 16:51:14,585:INFO:Decision Tree Regressor Imported successfully
2023-04-24 16:51:14,604:INFO:Starting cross validation
2023-04-24 16:51:14,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:14,976:INFO:Calculating mean and std
2023-04-24 16:51:14,977:INFO:Creating metrics dataframe
2023-04-24 16:51:15,020:INFO:Uploading results into container
2023-04-24 16:51:15,021:INFO:Uploading model into container now
2023-04-24 16:51:15,021:INFO:_master_model_container: 31
2023-04-24 16:51:15,022:INFO:_display_container: 3
2023-04-24 16:51:15,022:INFO:DecisionTreeRegressor(random_state=3232)
2023-04-24 16:51:15,022:INFO:create_model() successfully completed......................................
2023-04-24 16:51:15,117:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:15,117:INFO:Creating metrics dataframe
2023-04-24 16:51:15,125:INFO:Initializing Random Forest Regressor
2023-04-24 16:51:15,125:INFO:Total runtime is 0.10876076221466065 minutes
2023-04-24 16:51:15,128:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:15,128:INFO:Initializing create_model()
2023-04-24 16:51:15,128:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:15,128:INFO:Checking exceptions
2023-04-24 16:51:15,129:INFO:Importing libraries
2023-04-24 16:51:15,129:INFO:Copying training dataset
2023-04-24 16:51:15,133:INFO:Defining folds
2023-04-24 16:51:15,133:INFO:Declaring metric variables
2023-04-24 16:51:15,136:INFO:Importing untrained model
2023-04-24 16:51:15,140:INFO:Random Forest Regressor Imported successfully
2023-04-24 16:51:15,150:INFO:Starting cross validation
2023-04-24 16:51:15,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:15,765:INFO:Calculating mean and std
2023-04-24 16:51:15,775:INFO:Creating metrics dataframe
2023-04-24 16:51:15,820:INFO:Uploading results into container
2023-04-24 16:51:15,820:INFO:Uploading model into container now
2023-04-24 16:51:15,820:INFO:_master_model_container: 32
2023-04-24 16:51:15,820:INFO:_display_container: 3
2023-04-24 16:51:15,820:INFO:RandomForestRegressor(n_jobs=-1, random_state=3232)
2023-04-24 16:51:15,820:INFO:create_model() successfully completed......................................
2023-04-24 16:51:15,950:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:15,950:INFO:Creating metrics dataframe
2023-04-24 16:51:15,963:INFO:Initializing Extra Trees Regressor
2023-04-24 16:51:15,964:INFO:Total runtime is 0.12274355888366699 minutes
2023-04-24 16:51:15,968:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:15,969:INFO:Initializing create_model()
2023-04-24 16:51:15,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:15,969:INFO:Checking exceptions
2023-04-24 16:51:15,969:INFO:Importing libraries
2023-04-24 16:51:15,969:INFO:Copying training dataset
2023-04-24 16:51:15,971:INFO:Defining folds
2023-04-24 16:51:15,971:INFO:Declaring metric variables
2023-04-24 16:51:15,979:INFO:Importing untrained model
2023-04-24 16:51:15,983:INFO:Extra Trees Regressor Imported successfully
2023-04-24 16:51:15,986:INFO:Starting cross validation
2023-04-24 16:51:15,986:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:16,734:INFO:Calculating mean and std
2023-04-24 16:51:16,734:INFO:Creating metrics dataframe
2023-04-24 16:51:16,785:INFO:Uploading results into container
2023-04-24 16:51:16,787:INFO:Uploading model into container now
2023-04-24 16:51:16,787:INFO:_master_model_container: 33
2023-04-24 16:51:16,787:INFO:_display_container: 3
2023-04-24 16:51:16,787:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3232)
2023-04-24 16:51:16,787:INFO:create_model() successfully completed......................................
2023-04-24 16:51:16,908:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:16,908:INFO:Creating metrics dataframe
2023-04-24 16:51:16,922:INFO:Initializing AdaBoost Regressor
2023-04-24 16:51:16,922:INFO:Total runtime is 0.13871369361877442 minutes
2023-04-24 16:51:16,924:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:16,924:INFO:Initializing create_model()
2023-04-24 16:51:16,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:16,925:INFO:Checking exceptions
2023-04-24 16:51:16,925:INFO:Importing libraries
2023-04-24 16:51:16,925:INFO:Copying training dataset
2023-04-24 16:51:16,930:INFO:Defining folds
2023-04-24 16:51:16,930:INFO:Declaring metric variables
2023-04-24 16:51:16,935:INFO:Importing untrained model
2023-04-24 16:51:16,943:INFO:AdaBoost Regressor Imported successfully
2023-04-24 16:51:16,954:INFO:Starting cross validation
2023-04-24 16:51:16,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:17,411:INFO:Calculating mean and std
2023-04-24 16:51:17,413:INFO:Creating metrics dataframe
2023-04-24 16:51:17,466:INFO:Uploading results into container
2023-04-24 16:51:17,466:INFO:Uploading model into container now
2023-04-24 16:51:17,466:INFO:_master_model_container: 34
2023-04-24 16:51:17,466:INFO:_display_container: 3
2023-04-24 16:51:17,466:INFO:AdaBoostRegressor(random_state=3232)
2023-04-24 16:51:17,466:INFO:create_model() successfully completed......................................
2023-04-24 16:51:17,579:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:17,579:INFO:Creating metrics dataframe
2023-04-24 16:51:17,594:INFO:Initializing Gradient Boosting Regressor
2023-04-24 16:51:17,594:INFO:Total runtime is 0.14991329113642377 minutes
2023-04-24 16:51:17,597:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:17,597:INFO:Initializing create_model()
2023-04-24 16:51:17,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:17,597:INFO:Checking exceptions
2023-04-24 16:51:17,597:INFO:Importing libraries
2023-04-24 16:51:17,597:INFO:Copying training dataset
2023-04-24 16:51:17,597:INFO:Defining folds
2023-04-24 16:51:17,597:INFO:Declaring metric variables
2023-04-24 16:51:17,597:INFO:Importing untrained model
2023-04-24 16:51:17,608:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:51:17,614:INFO:Starting cross validation
2023-04-24 16:51:17,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:18,161:INFO:Calculating mean and std
2023-04-24 16:51:18,161:INFO:Creating metrics dataframe
2023-04-24 16:51:18,193:INFO:Uploading results into container
2023-04-24 16:51:18,193:INFO:Uploading model into container now
2023-04-24 16:51:18,193:INFO:_master_model_container: 35
2023-04-24 16:51:18,193:INFO:_display_container: 3
2023-04-24 16:51:18,193:INFO:GradientBoostingRegressor(random_state=3232)
2023-04-24 16:51:18,193:INFO:create_model() successfully completed......................................
2023-04-24 16:51:18,286:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:18,286:INFO:Creating metrics dataframe
2023-04-24 16:51:18,306:INFO:Initializing Extreme Gradient Boosting
2023-04-24 16:51:18,306:INFO:Total runtime is 0.1617865562438965 minutes
2023-04-24 16:51:18,306:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:18,306:INFO:Initializing create_model()
2023-04-24 16:51:18,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:18,306:INFO:Checking exceptions
2023-04-24 16:51:18,306:INFO:Importing libraries
2023-04-24 16:51:18,306:INFO:Copying training dataset
2023-04-24 16:51:18,306:INFO:Defining folds
2023-04-24 16:51:18,306:INFO:Declaring metric variables
2023-04-24 16:51:18,306:INFO:Importing untrained model
2023-04-24 16:51:18,306:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 16:51:18,322:INFO:Starting cross validation
2023-04-24 16:51:18,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:18,806:INFO:Calculating mean and std
2023-04-24 16:51:18,809:INFO:Creating metrics dataframe
2023-04-24 16:51:18,872:INFO:Uploading results into container
2023-04-24 16:51:18,873:INFO:Uploading model into container now
2023-04-24 16:51:18,873:INFO:_master_model_container: 36
2023-04-24 16:51:18,873:INFO:_display_container: 3
2023-04-24 16:51:18,874:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3232, ...)
2023-04-24 16:51:18,874:INFO:create_model() successfully completed......................................
2023-04-24 16:51:19,015:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:19,015:INFO:Creating metrics dataframe
2023-04-24 16:51:19,024:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 16:51:19,024:INFO:Total runtime is 0.1737581849098206 minutes
2023-04-24 16:51:19,027:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:19,027:INFO:Initializing create_model()
2023-04-24 16:51:19,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:19,027:INFO:Checking exceptions
2023-04-24 16:51:19,027:INFO:Importing libraries
2023-04-24 16:51:19,027:INFO:Copying training dataset
2023-04-24 16:51:19,032:INFO:Defining folds
2023-04-24 16:51:19,033:INFO:Declaring metric variables
2023-04-24 16:51:19,036:INFO:Importing untrained model
2023-04-24 16:51:19,038:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:51:19,044:INFO:Starting cross validation
2023-04-24 16:51:19,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:19,452:INFO:Calculating mean and std
2023-04-24 16:51:19,452:INFO:Creating metrics dataframe
2023-04-24 16:51:19,499:INFO:Uploading results into container
2023-04-24 16:51:19,499:INFO:Uploading model into container now
2023-04-24 16:51:19,499:INFO:_master_model_container: 37
2023-04-24 16:51:19,499:INFO:_display_container: 3
2023-04-24 16:51:19,499:INFO:LGBMRegressor(random_state=3232)
2023-04-24 16:51:19,499:INFO:create_model() successfully completed......................................
2023-04-24 16:51:19,587:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:19,587:INFO:Creating metrics dataframe
2023-04-24 16:51:19,602:INFO:Initializing Dummy Regressor
2023-04-24 16:51:19,602:INFO:Total runtime is 0.1833858132362366 minutes
2023-04-24 16:51:19,602:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:19,602:INFO:Initializing create_model()
2023-04-24 16:51:19,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55FB3CF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:19,602:INFO:Checking exceptions
2023-04-24 16:51:19,602:INFO:Importing libraries
2023-04-24 16:51:19,602:INFO:Copying training dataset
2023-04-24 16:51:19,602:INFO:Defining folds
2023-04-24 16:51:19,602:INFO:Declaring metric variables
2023-04-24 16:51:19,602:INFO:Importing untrained model
2023-04-24 16:51:19,602:INFO:Dummy Regressor Imported successfully
2023-04-24 16:51:19,618:INFO:Starting cross validation
2023-04-24 16:51:19,618:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:20,053:INFO:Calculating mean and std
2023-04-24 16:51:20,054:INFO:Creating metrics dataframe
2023-04-24 16:51:20,108:INFO:Uploading results into container
2023-04-24 16:51:20,108:INFO:Uploading model into container now
2023-04-24 16:51:20,108:INFO:_master_model_container: 38
2023-04-24 16:51:20,109:INFO:_display_container: 3
2023-04-24 16:51:20,109:INFO:DummyRegressor()
2023-04-24 16:51:20,109:INFO:create_model() successfully completed......................................
2023-04-24 16:51:20,196:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:20,196:INFO:Creating metrics dataframe
2023-04-24 16:51:20,212:INFO:Initializing create_model()
2023-04-24 16:51:20,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5364C4C40>, estimator=GradientBoostingRegressor(random_state=3232), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:20,212:INFO:Checking exceptions
2023-04-24 16:51:20,212:INFO:Importing libraries
2023-04-24 16:51:20,212:INFO:Copying training dataset
2023-04-24 16:51:20,212:INFO:Defining folds
2023-04-24 16:51:20,212:INFO:Declaring metric variables
2023-04-24 16:51:20,212:INFO:Importing untrained model
2023-04-24 16:51:20,212:INFO:Declaring custom model
2023-04-24 16:51:20,227:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:51:20,227:INFO:Cross validation set to False
2023-04-24 16:51:20,227:INFO:Fitting Model
2023-04-24 16:51:20,307:INFO:GradientBoostingRegressor(random_state=3232)
2023-04-24 16:51:20,307:INFO:create_model() successfully completed......................................
2023-04-24 16:51:20,419:INFO:_master_model_container: 38
2023-04-24 16:51:20,419:INFO:_display_container: 3
2023-04-24 16:51:20,419:INFO:GradientBoostingRegressor(random_state=3232)
2023-04-24 16:51:20,419:INFO:compare_models() successfully completed......................................
2023-04-24 16:52:23,985:INFO:PyCaret RegressionExperiment
2023-04-24 16:52:23,985:INFO:Logging name: reg-default-name
2023-04-24 16:52:23,985:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:52:23,985:INFO:version 3.0.0
2023-04-24 16:52:23,985:INFO:Initializing setup()
2023-04-24 16:52:23,985:INFO:self.USI: 3dfb
2023-04-24 16:52:23,985:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 16:52:23,985:INFO:Checking environment
2023-04-24 16:52:23,985:INFO:python_version: 3.10.11
2023-04-24 16:52:23,985:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:52:23,985:INFO:machine: AMD64
2023-04-24 16:52:23,985:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:52:23,985:INFO:Memory: svmem(total=8362713088, available=1088307200, percent=87.0, used=7274405888, free=1088307200)
2023-04-24 16:52:23,985:INFO:Physical Core: 4
2023-04-24 16:52:23,985:INFO:Logical Core: 8
2023-04-24 16:52:23,985:INFO:Checking libraries
2023-04-24 16:52:23,985:INFO:System:
2023-04-24 16:52:23,985:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:52:23,985:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:52:23,985:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:52:23,985:INFO:PyCaret required dependencies:
2023-04-24 16:52:23,985:INFO:                 pip: 23.0.1
2023-04-24 16:52:23,985:INFO:          setuptools: 65.5.0
2023-04-24 16:52:23,985:INFO:             pycaret: 3.0.0
2023-04-24 16:52:23,985:INFO:             IPython: 8.5.0
2023-04-24 16:52:23,985:INFO:          ipywidgets: 8.0.2
2023-04-24 16:52:23,985:INFO:                tqdm: 4.65.0
2023-04-24 16:52:23,985:INFO:               numpy: 1.23.3
2023-04-24 16:52:23,985:INFO:              pandas: 1.5.0
2023-04-24 16:52:23,985:INFO:              jinja2: 3.1.2
2023-04-24 16:52:23,985:INFO:               scipy: 1.9.1
2023-04-24 16:52:23,985:INFO:              joblib: 1.2.0
2023-04-24 16:52:23,985:INFO:             sklearn: 1.1.2
2023-04-24 16:52:23,985:INFO:                pyod: 1.0.9
2023-04-24 16:52:23,985:INFO:            imblearn: 0.10.1
2023-04-24 16:52:23,985:INFO:   category_encoders: 2.6.0
2023-04-24 16:52:23,985:INFO:            lightgbm: 3.3.5
2023-04-24 16:52:23,985:INFO:               numba: 0.56.4
2023-04-24 16:52:23,985:INFO:            requests: 2.28.1
2023-04-24 16:52:23,985:INFO:          matplotlib: 3.6.0
2023-04-24 16:52:23,985:INFO:          scikitplot: 0.3.7
2023-04-24 16:52:23,985:INFO:         yellowbrick: 1.5
2023-04-24 16:52:23,985:INFO:              plotly: 5.10.0
2023-04-24 16:52:23,985:INFO:             kaleido: 0.2.1
2023-04-24 16:52:23,985:INFO:         statsmodels: 0.13.5
2023-04-24 16:52:23,985:INFO:              sktime: 0.17.1
2023-04-24 16:52:23,985:INFO:               tbats: 1.1.3
2023-04-24 16:52:23,985:INFO:            pmdarima: 2.0.3
2023-04-24 16:52:23,985:INFO:              psutil: 5.9.2
2023-04-24 16:52:23,985:INFO:PyCaret optional dependencies:
2023-04-24 16:52:23,993:INFO:                shap: Not installed
2023-04-24 16:52:23,993:INFO:           interpret: Not installed
2023-04-24 16:52:23,993:INFO:                umap: Not installed
2023-04-24 16:52:23,993:INFO:    pandas_profiling: Not installed
2023-04-24 16:52:23,993:INFO:  explainerdashboard: Not installed
2023-04-24 16:52:23,993:INFO:             autoviz: Not installed
2023-04-24 16:52:23,993:INFO:           fairlearn: Not installed
2023-04-24 16:52:23,993:INFO:             xgboost: 1.7.5
2023-04-24 16:52:23,993:INFO:            catboost: Not installed
2023-04-24 16:52:23,993:INFO:              kmodes: Not installed
2023-04-24 16:52:23,993:INFO:             mlxtend: Not installed
2023-04-24 16:52:23,993:INFO:       statsforecast: Not installed
2023-04-24 16:52:23,993:INFO:        tune_sklearn: Not installed
2023-04-24 16:52:23,993:INFO:                 ray: Not installed
2023-04-24 16:52:23,993:INFO:            hyperopt: Not installed
2023-04-24 16:52:23,993:INFO:              optuna: Not installed
2023-04-24 16:52:23,994:INFO:               skopt: Not installed
2023-04-24 16:52:23,994:INFO:              mlflow: 2.3.0
2023-04-24 16:52:23,994:INFO:              gradio: Not installed
2023-04-24 16:52:23,994:INFO:             fastapi: Not installed
2023-04-24 16:52:23,994:INFO:             uvicorn: Not installed
2023-04-24 16:52:23,994:INFO:              m2cgen: Not installed
2023-04-24 16:52:23,994:INFO:           evidently: Not installed
2023-04-24 16:52:23,994:INFO:               fugue: Not installed
2023-04-24 16:52:23,994:INFO:           streamlit: Not installed
2023-04-24 16:52:23,994:INFO:             prophet: Not installed
2023-04-24 16:52:23,994:INFO:None
2023-04-24 16:52:23,994:INFO:Set up data.
2023-04-24 16:52:23,999:INFO:Set up train/test split.
2023-04-24 16:52:24,002:INFO:Set up index.
2023-04-24 16:52:24,002:INFO:Set up folding strategy.
2023-04-24 16:52:24,002:INFO:Assigning column types.
2023-04-24 16:52:24,004:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:52:24,005:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,008:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,012:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,090:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,093:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,097:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,169:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,169:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:52:24,169:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,169:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,216:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,247:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,263:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,343:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,343:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,343:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:52:24,358:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,442:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,451:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,524:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,524:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:52:24,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,616:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,693:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,693:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:52:24,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,791:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:52:24,876:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:24,876:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:52:24,960:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:24,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:25,059:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:25,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:25,060:INFO:Preparing preprocessing pipeline...
2023-04-24 16:52:25,060:INFO:Set up simple imputation.
2023-04-24 16:52:25,080:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:52:25,082:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-24 16:52:25,082:INFO:Creating final display dataframe.
2023-04-24 16:52:25,107:INFO:Setup _display_container:                     Description             Value
0                    Session id              1831
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1204, 8)
4        Transformed data shape         (1204, 8)
5   Transformed train set shape          (842, 8)
6    Transformed test set shape          (362, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3dfb
2023-04-24 16:52:25,206:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:25,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:25,288:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:52:25,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:52:25,288:INFO:setup() successfully completed in 1.33s...............
2023-04-24 16:53:17,415:INFO:PyCaret RegressionExperiment
2023-04-24 16:53:17,415:INFO:Logging name: charges
2023-04-24 16:53:17,415:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:53:17,415:INFO:version 3.0.0
2023-04-24 16:53:17,415:INFO:Initializing setup()
2023-04-24 16:53:17,415:INFO:self.USI: 8077
2023-04-24 16:53:17,415:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 16:53:17,415:INFO:Checking environment
2023-04-24 16:53:17,415:INFO:python_version: 3.10.11
2023-04-24 16:53:17,415:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:53:17,415:INFO:machine: AMD64
2023-04-24 16:53:17,415:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:53:17,415:INFO:Memory: svmem(total=8362713088, available=1055559680, percent=87.4, used=7307153408, free=1055559680)
2023-04-24 16:53:17,415:INFO:Physical Core: 4
2023-04-24 16:53:17,415:INFO:Logical Core: 8
2023-04-24 16:53:17,415:INFO:Checking libraries
2023-04-24 16:53:17,415:INFO:System:
2023-04-24 16:53:17,415:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:53:17,415:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:53:17,415:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:53:17,415:INFO:PyCaret required dependencies:
2023-04-24 16:53:17,415:INFO:                 pip: 23.0.1
2023-04-24 16:53:17,415:INFO:          setuptools: 65.5.0
2023-04-24 16:53:17,415:INFO:             pycaret: 3.0.0
2023-04-24 16:53:17,415:INFO:             IPython: 8.5.0
2023-04-24 16:53:17,415:INFO:          ipywidgets: 8.0.2
2023-04-24 16:53:17,415:INFO:                tqdm: 4.65.0
2023-04-24 16:53:17,415:INFO:               numpy: 1.23.3
2023-04-24 16:53:17,415:INFO:              pandas: 1.5.0
2023-04-24 16:53:17,415:INFO:              jinja2: 3.1.2
2023-04-24 16:53:17,415:INFO:               scipy: 1.9.1
2023-04-24 16:53:17,415:INFO:              joblib: 1.2.0
2023-04-24 16:53:17,415:INFO:             sklearn: 1.1.2
2023-04-24 16:53:17,415:INFO:                pyod: 1.0.9
2023-04-24 16:53:17,415:INFO:            imblearn: 0.10.1
2023-04-24 16:53:17,415:INFO:   category_encoders: 2.6.0
2023-04-24 16:53:17,415:INFO:            lightgbm: 3.3.5
2023-04-24 16:53:17,415:INFO:               numba: 0.56.4
2023-04-24 16:53:17,415:INFO:            requests: 2.28.1
2023-04-24 16:53:17,415:INFO:          matplotlib: 3.6.0
2023-04-24 16:53:17,415:INFO:          scikitplot: 0.3.7
2023-04-24 16:53:17,415:INFO:         yellowbrick: 1.5
2023-04-24 16:53:17,415:INFO:              plotly: 5.10.0
2023-04-24 16:53:17,415:INFO:             kaleido: 0.2.1
2023-04-24 16:53:17,415:INFO:         statsmodels: 0.13.5
2023-04-24 16:53:17,415:INFO:              sktime: 0.17.1
2023-04-24 16:53:17,415:INFO:               tbats: 1.1.3
2023-04-24 16:53:17,415:INFO:            pmdarima: 2.0.3
2023-04-24 16:53:17,415:INFO:              psutil: 5.9.2
2023-04-24 16:53:17,415:INFO:PyCaret optional dependencies:
2023-04-24 16:53:17,415:INFO:                shap: Not installed
2023-04-24 16:53:17,415:INFO:           interpret: Not installed
2023-04-24 16:53:17,415:INFO:                umap: Not installed
2023-04-24 16:53:17,415:INFO:    pandas_profiling: Not installed
2023-04-24 16:53:17,415:INFO:  explainerdashboard: Not installed
2023-04-24 16:53:17,415:INFO:             autoviz: Not installed
2023-04-24 16:53:17,415:INFO:           fairlearn: Not installed
2023-04-24 16:53:17,415:INFO:             xgboost: 1.7.5
2023-04-24 16:53:17,415:INFO:            catboost: Not installed
2023-04-24 16:53:17,415:INFO:              kmodes: Not installed
2023-04-24 16:53:17,415:INFO:             mlxtend: Not installed
2023-04-24 16:53:17,415:INFO:       statsforecast: Not installed
2023-04-24 16:53:17,415:INFO:        tune_sklearn: Not installed
2023-04-24 16:53:17,415:INFO:                 ray: Not installed
2023-04-24 16:53:17,415:INFO:            hyperopt: Not installed
2023-04-24 16:53:17,415:INFO:              optuna: Not installed
2023-04-24 16:53:17,415:INFO:               skopt: Not installed
2023-04-24 16:53:17,415:INFO:              mlflow: 2.3.0
2023-04-24 16:53:17,415:INFO:              gradio: Not installed
2023-04-24 16:53:17,415:INFO:             fastapi: Not installed
2023-04-24 16:53:17,415:INFO:             uvicorn: Not installed
2023-04-24 16:53:17,415:INFO:              m2cgen: Not installed
2023-04-24 16:53:17,415:INFO:           evidently: Not installed
2023-04-24 16:53:17,415:INFO:               fugue: Not installed
2023-04-24 16:53:17,415:INFO:           streamlit: Not installed
2023-04-24 16:53:17,415:INFO:             prophet: Not installed
2023-04-24 16:53:17,415:INFO:None
2023-04-24 16:53:17,415:INFO:Set up data.
2023-04-24 16:53:17,415:INFO:Set up train/test split.
2023-04-24 16:53:17,415:INFO:Set up index.
2023-04-24 16:53:17,415:INFO:Set up folding strategy.
2023-04-24 16:53:17,415:INFO:Assigning column types.
2023-04-24 16:53:17,431:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:53:17,431:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,435:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,439:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,521:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:17,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:17,524:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,528:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,597:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:17,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:17,597:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:53:17,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,691:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:17,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:17,691:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,778:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:17,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:17,781:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:53:17,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,866:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:17,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:17,874:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:17,955:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:17,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:17,957:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:53:18,010:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:18,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:18,045:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:18,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:53:18,132:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,132:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:53:18,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:18,228:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,281:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:53:18,326:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,329:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:53:18,416:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,493:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,493:INFO:Preparing preprocessing pipeline...
2023-04-24 16:53:18,493:INFO:Set up simple imputation.
2023-04-24 16:53:18,493:INFO:Set up feature normalization.
2023-04-24 16:53:18,510:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:53:18,525:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 16:53:18,525:INFO:Creating final display dataframe.
2023-04-24 16:53:18,572:INFO:Setup _display_container:                     Description         Value
0                    Session id          7426
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1338, 8)
4        Transformed data shape     (1338, 8)
5   Transformed train set shape      (936, 8)
6    Transformed test set shape      (402, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          8077
2023-04-24 16:53:18,677:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,770:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:53:18,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:53:18,773:INFO:Logging experiment in loggers
2023-04-24 16:53:18,858:INFO:SubProcess save_model() called ==================================
2023-04-24 16:53:18,863:INFO:Initializing save_model()
2023-04-24 16:53:18,863:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmpd3wgo4d5\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-24 16:53:18,863:INFO:Adding model into prep_pipe
2023-04-24 16:53:18,863:WARNING:Only Model saved as it was a pipeline.
2023-04-24 16:53:18,863:INFO:C:\Users\danie\AppData\Local\Temp\tmpd3wgo4d5\Transformation Pipeline.pkl saved in current working directory
2023-04-24 16:53:18,863:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 16:53:18,863:INFO:save_model() successfully completed......................................
2023-04-24 16:53:19,014:INFO:SubProcess save_model() end ==================================
2023-04-24 16:53:19,058:INFO:setup() successfully completed in 1.39s...............
2023-04-24 16:54:06,439:INFO:Initializing compare_models()
2023-04-24 16:54:06,439:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 16:54:06,439:INFO:Checking exceptions
2023-04-24 16:54:06,441:INFO:Preparing display monitor
2023-04-24 16:54:06,474:INFO:Initializing Linear Regression
2023-04-24 16:54:06,474:INFO:Total runtime is 0.0 minutes
2023-04-24 16:54:06,478:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:06,479:INFO:Initializing create_model()
2023-04-24 16:54:06,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:06,479:INFO:Checking exceptions
2023-04-24 16:54:06,479:INFO:Importing libraries
2023-04-24 16:54:06,479:INFO:Copying training dataset
2023-04-24 16:54:06,482:INFO:Defining folds
2023-04-24 16:54:06,482:INFO:Declaring metric variables
2023-04-24 16:54:06,482:INFO:Importing untrained model
2023-04-24 16:54:06,482:INFO:Linear Regression Imported successfully
2023-04-24 16:54:06,502:INFO:Starting cross validation
2023-04-24 16:54:06,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:06,900:INFO:Calculating mean and std
2023-04-24 16:54:06,900:INFO:Creating metrics dataframe
2023-04-24 16:54:06,942:INFO:Uploading results into container
2023-04-24 16:54:06,943:INFO:Uploading model into container now
2023-04-24 16:54:06,943:INFO:_master_model_container: 1
2023-04-24 16:54:06,943:INFO:_display_container: 2
2023-04-24 16:54:06,943:INFO:LinearRegression(n_jobs=-1)
2023-04-24 16:54:06,943:INFO:create_model() successfully completed......................................
2023-04-24 16:54:07,048:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:07,048:INFO:Creating metrics dataframe
2023-04-24 16:54:07,054:INFO:Initializing Lasso Regression
2023-04-24 16:54:07,054:INFO:Total runtime is 0.009673357009887695 minutes
2023-04-24 16:54:07,054:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:07,054:INFO:Initializing create_model()
2023-04-24 16:54:07,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:07,054:INFO:Checking exceptions
2023-04-24 16:54:07,054:INFO:Importing libraries
2023-04-24 16:54:07,054:INFO:Copying training dataset
2023-04-24 16:54:07,065:INFO:Defining folds
2023-04-24 16:54:07,065:INFO:Declaring metric variables
2023-04-24 16:54:07,067:INFO:Importing untrained model
2023-04-24 16:54:07,070:INFO:Lasso Regression Imported successfully
2023-04-24 16:54:07,080:INFO:Starting cross validation
2023-04-24 16:54:07,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:07,474:INFO:Calculating mean and std
2023-04-24 16:54:07,475:INFO:Creating metrics dataframe
2023-04-24 16:54:07,522:INFO:Uploading results into container
2023-04-24 16:54:07,522:INFO:Uploading model into container now
2023-04-24 16:54:07,523:INFO:_master_model_container: 2
2023-04-24 16:54:07,523:INFO:_display_container: 2
2023-04-24 16:54:07,523:INFO:Lasso(random_state=7426)
2023-04-24 16:54:07,523:INFO:create_model() successfully completed......................................
2023-04-24 16:54:07,608:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:07,608:INFO:Creating metrics dataframe
2023-04-24 16:54:07,608:INFO:Initializing Ridge Regression
2023-04-24 16:54:07,608:INFO:Total runtime is 0.018909819920857746 minutes
2023-04-24 16:54:07,608:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:07,608:INFO:Initializing create_model()
2023-04-24 16:54:07,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:07,608:INFO:Checking exceptions
2023-04-24 16:54:07,608:INFO:Importing libraries
2023-04-24 16:54:07,608:INFO:Copying training dataset
2023-04-24 16:54:07,623:INFO:Defining folds
2023-04-24 16:54:07,623:INFO:Declaring metric variables
2023-04-24 16:54:07,627:INFO:Importing untrained model
2023-04-24 16:54:07,628:INFO:Ridge Regression Imported successfully
2023-04-24 16:54:07,628:INFO:Starting cross validation
2023-04-24 16:54:07,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:08,010:INFO:Calculating mean and std
2023-04-24 16:54:08,010:INFO:Creating metrics dataframe
2023-04-24 16:54:08,062:INFO:Uploading results into container
2023-04-24 16:54:08,062:INFO:Uploading model into container now
2023-04-24 16:54:08,063:INFO:_master_model_container: 3
2023-04-24 16:54:08,063:INFO:_display_container: 2
2023-04-24 16:54:08,063:INFO:Ridge(random_state=7426)
2023-04-24 16:54:08,063:INFO:create_model() successfully completed......................................
2023-04-24 16:54:08,139:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:08,139:INFO:Creating metrics dataframe
2023-04-24 16:54:08,154:INFO:Initializing Elastic Net
2023-04-24 16:54:08,154:INFO:Total runtime is 0.028011059761047362 minutes
2023-04-24 16:54:08,154:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:08,154:INFO:Initializing create_model()
2023-04-24 16:54:08,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:08,154:INFO:Checking exceptions
2023-04-24 16:54:08,154:INFO:Importing libraries
2023-04-24 16:54:08,154:INFO:Copying training dataset
2023-04-24 16:54:08,163:INFO:Defining folds
2023-04-24 16:54:08,163:INFO:Declaring metric variables
2023-04-24 16:54:08,166:INFO:Importing untrained model
2023-04-24 16:54:08,168:INFO:Elastic Net Imported successfully
2023-04-24 16:54:08,179:INFO:Starting cross validation
2023-04-24 16:54:08,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:08,557:INFO:Calculating mean and std
2023-04-24 16:54:08,557:INFO:Creating metrics dataframe
2023-04-24 16:54:08,612:INFO:Uploading results into container
2023-04-24 16:54:08,613:INFO:Uploading model into container now
2023-04-24 16:54:08,613:INFO:_master_model_container: 4
2023-04-24 16:54:08,613:INFO:_display_container: 2
2023-04-24 16:54:08,613:INFO:ElasticNet(random_state=7426)
2023-04-24 16:54:08,613:INFO:create_model() successfully completed......................................
2023-04-24 16:54:08,687:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:08,687:INFO:Creating metrics dataframe
2023-04-24 16:54:08,702:INFO:Initializing Least Angle Regression
2023-04-24 16:54:08,702:INFO:Total runtime is 0.03714497089385986 minutes
2023-04-24 16:54:08,702:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:08,702:INFO:Initializing create_model()
2023-04-24 16:54:08,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:08,702:INFO:Checking exceptions
2023-04-24 16:54:08,702:INFO:Importing libraries
2023-04-24 16:54:08,702:INFO:Copying training dataset
2023-04-24 16:54:08,713:INFO:Defining folds
2023-04-24 16:54:08,713:INFO:Declaring metric variables
2023-04-24 16:54:08,716:INFO:Importing untrained model
2023-04-24 16:54:08,718:INFO:Least Angle Regression Imported successfully
2023-04-24 16:54:08,728:INFO:Starting cross validation
2023-04-24 16:54:08,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:08,773:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,789:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,790:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,790:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,806:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,806:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,822:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,822:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,900:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:08,916:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,105:INFO:Calculating mean and std
2023-04-24 16:54:09,105:INFO:Creating metrics dataframe
2023-04-24 16:54:09,165:INFO:Uploading results into container
2023-04-24 16:54:09,166:INFO:Uploading model into container now
2023-04-24 16:54:09,166:INFO:_master_model_container: 5
2023-04-24 16:54:09,166:INFO:_display_container: 2
2023-04-24 16:54:09,166:INFO:Lars(random_state=7426)
2023-04-24 16:54:09,166:INFO:create_model() successfully completed......................................
2023-04-24 16:54:09,238:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:09,238:INFO:Creating metrics dataframe
2023-04-24 16:54:09,254:INFO:Initializing Lasso Least Angle Regression
2023-04-24 16:54:09,254:INFO:Total runtime is 0.046334175268808994 minutes
2023-04-24 16:54:09,254:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:09,254:INFO:Initializing create_model()
2023-04-24 16:54:09,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:09,254:INFO:Checking exceptions
2023-04-24 16:54:09,254:INFO:Importing libraries
2023-04-24 16:54:09,254:INFO:Copying training dataset
2023-04-24 16:54:09,267:INFO:Defining folds
2023-04-24 16:54:09,267:INFO:Declaring metric variables
2023-04-24 16:54:09,270:INFO:Importing untrained model
2023-04-24 16:54:09,273:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 16:54:09,281:INFO:Starting cross validation
2023-04-24 16:54:09,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:09,327:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,335:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,339:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,339:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,339:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,354:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,370:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,370:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,449:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,449:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 16:54:09,653:INFO:Calculating mean and std
2023-04-24 16:54:09,653:INFO:Creating metrics dataframe
2023-04-24 16:54:09,708:INFO:Uploading results into container
2023-04-24 16:54:09,709:INFO:Uploading model into container now
2023-04-24 16:54:09,709:INFO:_master_model_container: 6
2023-04-24 16:54:09,709:INFO:_display_container: 2
2023-04-24 16:54:09,709:INFO:LassoLars(random_state=7426)
2023-04-24 16:54:09,709:INFO:create_model() successfully completed......................................
2023-04-24 16:54:09,783:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:09,783:INFO:Creating metrics dataframe
2023-04-24 16:54:09,799:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 16:54:09,799:INFO:Total runtime is 0.05542305707931518 minutes
2023-04-24 16:54:09,799:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:09,799:INFO:Initializing create_model()
2023-04-24 16:54:09,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:09,799:INFO:Checking exceptions
2023-04-24 16:54:09,799:INFO:Importing libraries
2023-04-24 16:54:09,799:INFO:Copying training dataset
2023-04-24 16:54:09,812:INFO:Defining folds
2023-04-24 16:54:09,812:INFO:Declaring metric variables
2023-04-24 16:54:09,815:INFO:Importing untrained model
2023-04-24 16:54:09,817:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 16:54:09,827:INFO:Starting cross validation
2023-04-24 16:54:09,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:09,869:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,874:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,879:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,887:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,887:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,902:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,902:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,918:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,965:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:09,981:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 16:54:10,202:INFO:Calculating mean and std
2023-04-24 16:54:10,202:INFO:Creating metrics dataframe
2023-04-24 16:54:10,258:INFO:Uploading results into container
2023-04-24 16:54:10,258:INFO:Uploading model into container now
2023-04-24 16:54:10,259:INFO:_master_model_container: 7
2023-04-24 16:54:10,259:INFO:_display_container: 2
2023-04-24 16:54:10,259:INFO:OrthogonalMatchingPursuit()
2023-04-24 16:54:10,259:INFO:create_model() successfully completed......................................
2023-04-24 16:54:10,332:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:10,332:INFO:Creating metrics dataframe
2023-04-24 16:54:10,348:INFO:Initializing Bayesian Ridge
2023-04-24 16:54:10,348:INFO:Total runtime is 0.06457146803538004 minutes
2023-04-24 16:54:10,348:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:10,348:INFO:Initializing create_model()
2023-04-24 16:54:10,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:10,348:INFO:Checking exceptions
2023-04-24 16:54:10,348:INFO:Importing libraries
2023-04-24 16:54:10,348:INFO:Copying training dataset
2023-04-24 16:54:10,360:INFO:Defining folds
2023-04-24 16:54:10,360:INFO:Declaring metric variables
2023-04-24 16:54:10,363:INFO:Importing untrained model
2023-04-24 16:54:10,367:INFO:Bayesian Ridge Imported successfully
2023-04-24 16:54:10,375:INFO:Starting cross validation
2023-04-24 16:54:10,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:10,750:INFO:Calculating mean and std
2023-04-24 16:54:10,750:INFO:Creating metrics dataframe
2023-04-24 16:54:10,798:INFO:Uploading results into container
2023-04-24 16:54:10,799:INFO:Uploading model into container now
2023-04-24 16:54:10,799:INFO:_master_model_container: 8
2023-04-24 16:54:10,799:INFO:_display_container: 2
2023-04-24 16:54:10,799:INFO:BayesianRidge()
2023-04-24 16:54:10,799:INFO:create_model() successfully completed......................................
2023-04-24 16:54:10,883:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:10,883:INFO:Creating metrics dataframe
2023-04-24 16:54:10,883:INFO:Initializing Passive Aggressive Regressor
2023-04-24 16:54:10,883:INFO:Total runtime is 0.07348193724950154 minutes
2023-04-24 16:54:10,898:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:10,898:INFO:Initializing create_model()
2023-04-24 16:54:10,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:10,898:INFO:Checking exceptions
2023-04-24 16:54:10,898:INFO:Importing libraries
2023-04-24 16:54:10,898:INFO:Copying training dataset
2023-04-24 16:54:10,902:INFO:Defining folds
2023-04-24 16:54:10,903:INFO:Declaring metric variables
2023-04-24 16:54:10,905:INFO:Importing untrained model
2023-04-24 16:54:10,922:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 16:54:10,928:INFO:Starting cross validation
2023-04-24 16:54:10,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:11,317:INFO:Calculating mean and std
2023-04-24 16:54:11,317:INFO:Creating metrics dataframe
2023-04-24 16:54:11,363:INFO:Uploading results into container
2023-04-24 16:54:11,364:INFO:Uploading model into container now
2023-04-24 16:54:11,364:INFO:_master_model_container: 9
2023-04-24 16:54:11,364:INFO:_display_container: 2
2023-04-24 16:54:11,364:INFO:PassiveAggressiveRegressor(random_state=7426)
2023-04-24 16:54:11,365:INFO:create_model() successfully completed......................................
2023-04-24 16:54:11,447:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:11,447:INFO:Creating metrics dataframe
2023-04-24 16:54:11,447:INFO:Initializing Huber Regressor
2023-04-24 16:54:11,447:INFO:Total runtime is 0.08288496335347494 minutes
2023-04-24 16:54:11,447:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:11,462:INFO:Initializing create_model()
2023-04-24 16:54:11,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:11,462:INFO:Checking exceptions
2023-04-24 16:54:11,462:INFO:Importing libraries
2023-04-24 16:54:11,462:INFO:Copying training dataset
2023-04-24 16:54:11,466:INFO:Defining folds
2023-04-24 16:54:11,466:INFO:Declaring metric variables
2023-04-24 16:54:11,469:INFO:Importing untrained model
2023-04-24 16:54:11,470:INFO:Huber Regressor Imported successfully
2023-04-24 16:54:11,470:INFO:Starting cross validation
2023-04-24 16:54:11,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:11,881:INFO:Calculating mean and std
2023-04-24 16:54:11,881:INFO:Creating metrics dataframe
2023-04-24 16:54:11,928:INFO:Uploading results into container
2023-04-24 16:54:11,929:INFO:Uploading model into container now
2023-04-24 16:54:11,929:INFO:_master_model_container: 10
2023-04-24 16:54:11,929:INFO:_display_container: 2
2023-04-24 16:54:11,929:INFO:HuberRegressor()
2023-04-24 16:54:11,930:INFO:create_model() successfully completed......................................
2023-04-24 16:54:12,012:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:12,012:INFO:Creating metrics dataframe
2023-04-24 16:54:12,012:INFO:Initializing K Neighbors Regressor
2023-04-24 16:54:12,012:INFO:Total runtime is 0.09230194886525472 minutes
2023-04-24 16:54:12,012:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:12,012:INFO:Initializing create_model()
2023-04-24 16:54:12,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:12,012:INFO:Checking exceptions
2023-04-24 16:54:12,012:INFO:Importing libraries
2023-04-24 16:54:12,027:INFO:Copying training dataset
2023-04-24 16:54:12,031:INFO:Defining folds
2023-04-24 16:54:12,032:INFO:Declaring metric variables
2023-04-24 16:54:12,034:INFO:Importing untrained model
2023-04-24 16:54:12,038:INFO:K Neighbors Regressor Imported successfully
2023-04-24 16:54:12,038:INFO:Starting cross validation
2023-04-24 16:54:12,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:12,430:INFO:Calculating mean and std
2023-04-24 16:54:12,430:INFO:Creating metrics dataframe
2023-04-24 16:54:12,487:INFO:Uploading results into container
2023-04-24 16:54:12,488:INFO:Uploading model into container now
2023-04-24 16:54:12,488:INFO:_master_model_container: 11
2023-04-24 16:54:12,488:INFO:_display_container: 2
2023-04-24 16:54:12,488:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 16:54:12,488:INFO:create_model() successfully completed......................................
2023-04-24 16:54:12,561:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:12,561:INFO:Creating metrics dataframe
2023-04-24 16:54:12,577:INFO:Initializing Decision Tree Regressor
2023-04-24 16:54:12,577:INFO:Total runtime is 0.1017235040664673 minutes
2023-04-24 16:54:12,577:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:12,577:INFO:Initializing create_model()
2023-04-24 16:54:12,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:12,577:INFO:Checking exceptions
2023-04-24 16:54:12,577:INFO:Importing libraries
2023-04-24 16:54:12,577:INFO:Copying training dataset
2023-04-24 16:54:12,591:INFO:Defining folds
2023-04-24 16:54:12,591:INFO:Declaring metric variables
2023-04-24 16:54:12,594:INFO:Importing untrained model
2023-04-24 16:54:12,598:INFO:Decision Tree Regressor Imported successfully
2023-04-24 16:54:12,598:INFO:Starting cross validation
2023-04-24 16:54:12,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:12,995:INFO:Calculating mean and std
2023-04-24 16:54:12,995:INFO:Creating metrics dataframe
2023-04-24 16:54:13,054:INFO:Uploading results into container
2023-04-24 16:54:13,055:INFO:Uploading model into container now
2023-04-24 16:54:13,055:INFO:_master_model_container: 12
2023-04-24 16:54:13,055:INFO:_display_container: 2
2023-04-24 16:54:13,056:INFO:DecisionTreeRegressor(random_state=7426)
2023-04-24 16:54:13,056:INFO:create_model() successfully completed......................................
2023-04-24 16:54:13,142:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:13,142:INFO:Creating metrics dataframe
2023-04-24 16:54:13,142:INFO:Initializing Random Forest Regressor
2023-04-24 16:54:13,142:INFO:Total runtime is 0.11114316383997601 minutes
2023-04-24 16:54:13,142:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:13,142:INFO:Initializing create_model()
2023-04-24 16:54:13,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:13,142:INFO:Checking exceptions
2023-04-24 16:54:13,142:INFO:Importing libraries
2023-04-24 16:54:13,142:INFO:Copying training dataset
2023-04-24 16:54:13,158:INFO:Defining folds
2023-04-24 16:54:13,159:INFO:Declaring metric variables
2023-04-24 16:54:13,163:INFO:Importing untrained model
2023-04-24 16:54:13,166:INFO:Random Forest Regressor Imported successfully
2023-04-24 16:54:13,166:INFO:Starting cross validation
2023-04-24 16:54:13,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:14,139:INFO:Calculating mean and std
2023-04-24 16:54:14,139:INFO:Creating metrics dataframe
2023-04-24 16:54:14,192:INFO:Uploading results into container
2023-04-24 16:54:14,193:INFO:Uploading model into container now
2023-04-24 16:54:14,193:INFO:_master_model_container: 13
2023-04-24 16:54:14,193:INFO:_display_container: 2
2023-04-24 16:54:14,194:INFO:RandomForestRegressor(n_jobs=-1, random_state=7426)
2023-04-24 16:54:14,194:INFO:create_model() successfully completed......................................
2023-04-24 16:54:14,272:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:14,272:INFO:Creating metrics dataframe
2023-04-24 16:54:14,288:INFO:Initializing Extra Trees Regressor
2023-04-24 16:54:14,288:INFO:Total runtime is 0.13023691574732466 minutes
2023-04-24 16:54:14,288:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:14,288:INFO:Initializing create_model()
2023-04-24 16:54:14,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:14,288:INFO:Checking exceptions
2023-04-24 16:54:14,288:INFO:Importing libraries
2023-04-24 16:54:14,288:INFO:Copying training dataset
2023-04-24 16:54:14,296:INFO:Defining folds
2023-04-24 16:54:14,296:INFO:Declaring metric variables
2023-04-24 16:54:14,299:INFO:Importing untrained model
2023-04-24 16:54:14,302:INFO:Extra Trees Regressor Imported successfully
2023-04-24 16:54:14,311:INFO:Starting cross validation
2023-04-24 16:54:14,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:15,351:INFO:Calculating mean and std
2023-04-24 16:54:15,352:INFO:Creating metrics dataframe
2023-04-24 16:54:15,402:INFO:Uploading results into container
2023-04-24 16:54:15,402:INFO:Uploading model into container now
2023-04-24 16:54:15,402:INFO:_master_model_container: 14
2023-04-24 16:54:15,403:INFO:_display_container: 2
2023-04-24 16:54:15,403:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7426)
2023-04-24 16:54:15,403:INFO:create_model() successfully completed......................................
2023-04-24 16:54:15,495:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:15,496:INFO:Creating metrics dataframe
2023-04-24 16:54:15,504:INFO:Initializing AdaBoost Regressor
2023-04-24 16:54:15,505:INFO:Total runtime is 0.15052614212036136 minutes
2023-04-24 16:54:15,508:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:15,508:INFO:Initializing create_model()
2023-04-24 16:54:15,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:15,508:INFO:Checking exceptions
2023-04-24 16:54:15,508:INFO:Importing libraries
2023-04-24 16:54:15,508:INFO:Copying training dataset
2023-04-24 16:54:15,512:INFO:Defining folds
2023-04-24 16:54:15,512:INFO:Declaring metric variables
2023-04-24 16:54:15,515:INFO:Importing untrained model
2023-04-24 16:54:15,519:INFO:AdaBoost Regressor Imported successfully
2023-04-24 16:54:15,525:INFO:Starting cross validation
2023-04-24 16:54:15,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:15,976:INFO:Calculating mean and std
2023-04-24 16:54:15,976:INFO:Creating metrics dataframe
2023-04-24 16:54:16,030:INFO:Uploading results into container
2023-04-24 16:54:16,030:INFO:Uploading model into container now
2023-04-24 16:54:16,031:INFO:_master_model_container: 15
2023-04-24 16:54:16,031:INFO:_display_container: 2
2023-04-24 16:54:16,031:INFO:AdaBoostRegressor(random_state=7426)
2023-04-24 16:54:16,031:INFO:create_model() successfully completed......................................
2023-04-24 16:54:16,121:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:16,121:INFO:Creating metrics dataframe
2023-04-24 16:54:16,130:INFO:Initializing Gradient Boosting Regressor
2023-04-24 16:54:16,130:INFO:Total runtime is 0.1609405040740967 minutes
2023-04-24 16:54:16,132:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:16,133:INFO:Initializing create_model()
2023-04-24 16:54:16,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:16,133:INFO:Checking exceptions
2023-04-24 16:54:16,133:INFO:Importing libraries
2023-04-24 16:54:16,133:INFO:Copying training dataset
2023-04-24 16:54:16,138:INFO:Defining folds
2023-04-24 16:54:16,138:INFO:Declaring metric variables
2023-04-24 16:54:16,141:INFO:Importing untrained model
2023-04-24 16:54:16,144:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:54:16,148:INFO:Starting cross validation
2023-04-24 16:54:16,154:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:16,722:INFO:Calculating mean and std
2023-04-24 16:54:16,722:INFO:Creating metrics dataframe
2023-04-24 16:54:16,774:INFO:Uploading results into container
2023-04-24 16:54:16,774:INFO:Uploading model into container now
2023-04-24 16:54:16,774:INFO:_master_model_container: 16
2023-04-24 16:54:16,774:INFO:_display_container: 2
2023-04-24 16:54:16,775:INFO:GradientBoostingRegressor(random_state=7426)
2023-04-24 16:54:16,775:INFO:create_model() successfully completed......................................
2023-04-24 16:54:16,848:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:16,848:INFO:Creating metrics dataframe
2023-04-24 16:54:16,864:INFO:Initializing Extreme Gradient Boosting
2023-04-24 16:54:16,864:INFO:Total runtime is 0.17317386865615847 minutes
2023-04-24 16:54:16,864:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:16,864:INFO:Initializing create_model()
2023-04-24 16:54:16,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:16,864:INFO:Checking exceptions
2023-04-24 16:54:16,864:INFO:Importing libraries
2023-04-24 16:54:16,864:INFO:Copying training dataset
2023-04-24 16:54:16,878:INFO:Defining folds
2023-04-24 16:54:16,879:INFO:Declaring metric variables
2023-04-24 16:54:16,882:INFO:Importing untrained model
2023-04-24 16:54:16,886:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 16:54:16,904:INFO:Starting cross validation
2023-04-24 16:54:16,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:17,439:INFO:Calculating mean and std
2023-04-24 16:54:17,439:INFO:Creating metrics dataframe
2023-04-24 16:54:17,507:INFO:Uploading results into container
2023-04-24 16:54:17,507:INFO:Uploading model into container now
2023-04-24 16:54:17,508:INFO:_master_model_container: 17
2023-04-24 16:54:17,508:INFO:_display_container: 2
2023-04-24 16:54:17,508:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=7426, ...)
2023-04-24 16:54:17,508:INFO:create_model() successfully completed......................................
2023-04-24 16:54:17,580:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:17,580:INFO:Creating metrics dataframe
2023-04-24 16:54:17,595:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 16:54:17,595:INFO:Total runtime is 0.18536347150802615 minutes
2023-04-24 16:54:17,595:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:17,595:INFO:Initializing create_model()
2023-04-24 16:54:17,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:17,595:INFO:Checking exceptions
2023-04-24 16:54:17,595:INFO:Importing libraries
2023-04-24 16:54:17,595:INFO:Copying training dataset
2023-04-24 16:54:17,611:INFO:Defining folds
2023-04-24 16:54:17,611:INFO:Declaring metric variables
2023-04-24 16:54:17,614:INFO:Importing untrained model
2023-04-24 16:54:17,618:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:54:17,619:INFO:Starting cross validation
2023-04-24 16:54:17,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:18,123:INFO:Calculating mean and std
2023-04-24 16:54:18,123:INFO:Creating metrics dataframe
2023-04-24 16:54:18,187:INFO:Uploading results into container
2023-04-24 16:54:18,187:INFO:Uploading model into container now
2023-04-24 16:54:18,188:INFO:_master_model_container: 18
2023-04-24 16:54:18,188:INFO:_display_container: 2
2023-04-24 16:54:18,188:INFO:LGBMRegressor(random_state=7426)
2023-04-24 16:54:18,188:INFO:create_model() successfully completed......................................
2023-04-24 16:54:18,261:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:18,261:INFO:Creating metrics dataframe
2023-04-24 16:54:18,277:INFO:Initializing Dummy Regressor
2023-04-24 16:54:18,277:INFO:Total runtime is 0.19672259887059532 minutes
2023-04-24 16:54:18,277:INFO:SubProcess create_model() called ==================================
2023-04-24 16:54:18,277:INFO:Initializing create_model()
2023-04-24 16:54:18,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560588C10>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:18,277:INFO:Checking exceptions
2023-04-24 16:54:18,277:INFO:Importing libraries
2023-04-24 16:54:18,277:INFO:Copying training dataset
2023-04-24 16:54:18,291:INFO:Defining folds
2023-04-24 16:54:18,291:INFO:Declaring metric variables
2023-04-24 16:54:18,295:INFO:Importing untrained model
2023-04-24 16:54:18,298:INFO:Dummy Regressor Imported successfully
2023-04-24 16:54:18,301:INFO:Starting cross validation
2023-04-24 16:54:18,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:54:18,723:INFO:Calculating mean and std
2023-04-24 16:54:18,723:INFO:Creating metrics dataframe
2023-04-24 16:54:18,787:INFO:Uploading results into container
2023-04-24 16:54:18,788:INFO:Uploading model into container now
2023-04-24 16:54:18,788:INFO:_master_model_container: 19
2023-04-24 16:54:18,788:INFO:_display_container: 2
2023-04-24 16:54:18,788:INFO:DummyRegressor()
2023-04-24 16:54:18,788:INFO:create_model() successfully completed......................................
2023-04-24 16:54:18,876:INFO:SubProcess create_model() end ==================================
2023-04-24 16:54:18,876:INFO:Creating metrics dataframe
2023-04-24 16:54:18,895:INFO:Initializing create_model()
2023-04-24 16:54:18,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=GradientBoostingRegressor(random_state=7426), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:54:18,895:INFO:Checking exceptions
2023-04-24 16:54:18,897:INFO:Importing libraries
2023-04-24 16:54:18,897:INFO:Copying training dataset
2023-04-24 16:54:18,900:INFO:Defining folds
2023-04-24 16:54:18,900:INFO:Declaring metric variables
2023-04-24 16:54:18,900:INFO:Importing untrained model
2023-04-24 16:54:18,900:INFO:Declaring custom model
2023-04-24 16:54:18,901:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 16:54:18,901:INFO:Cross validation set to False
2023-04-24 16:54:18,902:INFO:Fitting Model
2023-04-24 16:54:19,010:INFO:GradientBoostingRegressor(random_state=7426)
2023-04-24 16:54:19,010:INFO:create_model() successfully completed......................................
2023-04-24 16:54:19,105:INFO:Creating Dashboard logs
2023-04-24 16:54:19,108:INFO:Model: Gradient Boosting Regressor
2023-04-24 16:54:19,154:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7426, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:54:19,211:INFO:Initializing predict_model()
2023-04-24 16:54:19,211:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D5607A7A00>, estimator=GradientBoostingRegressor(random_state=7426), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D5607E51B0>)
2023-04-24 16:54:19,211:INFO:Checking exceptions
2023-04-24 16:54:19,211:INFO:Preloading libraries
2023-04-24 16:54:19,494:INFO:Creating Dashboard logs
2023-04-24 16:54:19,494:INFO:Model: Light Gradient Boosting Machine
2023-04-24 16:54:19,552:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 7426, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 16:54:19,766:INFO:Creating Dashboard logs
2023-04-24 16:54:19,766:INFO:Model: Random Forest Regressor
2023-04-24 16:54:19,819:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7426, 'verbose': 0, 'warm_start': False}
2023-04-24 16:54:20,032:INFO:Creating Dashboard logs
2023-04-24 16:54:20,032:INFO:Model: K Neighbors Regressor
2023-04-24 16:54:20,078:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 16:54:20,281:INFO:Creating Dashboard logs
2023-04-24 16:54:20,296:INFO:Model: Extra Trees Regressor
2023-04-24 16:54:20,336:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7426, 'verbose': 0, 'warm_start': False}
2023-04-24 16:54:20,547:INFO:Creating Dashboard logs
2023-04-24 16:54:20,547:INFO:Model: Extreme Gradient Boosting
2023-04-24 16:54:20,597:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 7426, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-24 16:54:20,828:INFO:Creating Dashboard logs
2023-04-24 16:54:20,844:INFO:Model: AdaBoost Regressor
2023-04-24 16:54:20,888:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 7426}
2023-04-24 16:54:21,094:INFO:Creating Dashboard logs
2023-04-24 16:54:21,094:INFO:Model: Lasso Least Angle Regression
2023-04-24 16:54:21,137:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 7426, 'verbose': False}
2023-04-24 16:54:21,345:INFO:Creating Dashboard logs
2023-04-24 16:54:21,361:INFO:Model: Ridge Regression
2023-04-24 16:54:21,397:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 7426, 'solver': 'auto', 'tol': 0.001}
2023-04-24 16:54:21,595:INFO:Creating Dashboard logs
2023-04-24 16:54:21,595:INFO:Model: Lasso Regression
2023-04-24 16:54:21,649:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 7426, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 16:54:21,859:INFO:Creating Dashboard logs
2023-04-24 16:54:21,859:INFO:Model: Linear Regression
2023-04-24 16:54:21,910:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 16:54:22,109:INFO:Creating Dashboard logs
2023-04-24 16:54:22,124:INFO:Model: Least Angle Regression
2023-04-24 16:54:22,162:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 7426, 'verbose': False}
2023-04-24 16:54:22,375:INFO:Creating Dashboard logs
2023-04-24 16:54:22,375:INFO:Model: Bayesian Ridge
2023-04-24 16:54:22,419:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 16:54:22,639:INFO:Creating Dashboard logs
2023-04-24 16:54:22,639:INFO:Model: Decision Tree Regressor
2023-04-24 16:54:22,690:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 7426, 'splitter': 'best'}
2023-04-24 16:54:22,892:INFO:Creating Dashboard logs
2023-04-24 16:54:22,892:INFO:Model: Huber Regressor
2023-04-24 16:54:22,943:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 16:54:23,160:INFO:Creating Dashboard logs
2023-04-24 16:54:23,163:INFO:Model: Passive Aggressive Regressor
2023-04-24 16:54:23,204:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 7426, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 16:54:23,451:INFO:Creating Dashboard logs
2023-04-24 16:54:23,451:INFO:Model: Elastic Net
2023-04-24 16:54:23,505:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 7426, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 16:54:23,725:INFO:Creating Dashboard logs
2023-04-24 16:54:23,728:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 16:54:23,770:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 16:54:23,974:INFO:Creating Dashboard logs
2023-04-24 16:54:23,974:INFO:Model: Dummy Regressor
2023-04-24 16:54:24,024:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 16:54:24,236:INFO:_master_model_container: 19
2023-04-24 16:54:24,236:INFO:_display_container: 2
2023-04-24 16:54:24,236:INFO:GradientBoostingRegressor(random_state=7426)
2023-04-24 16:54:24,236:INFO:compare_models() successfully completed......................................
2023-04-24 16:56:54,294:INFO:PyCaret RegressionExperiment
2023-04-24 16:56:54,294:INFO:Logging name: charges
2023-04-24 16:56:54,294:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 16:56:54,294:INFO:version 3.0.0
2023-04-24 16:56:54,295:INFO:Initializing setup()
2023-04-24 16:56:54,295:INFO:self.USI: 7904
2023-04-24 16:56:54,295:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 16:56:54,295:INFO:Checking environment
2023-04-24 16:56:54,295:INFO:python_version: 3.10.11
2023-04-24 16:56:54,295:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 16:56:54,295:INFO:machine: AMD64
2023-04-24 16:56:54,295:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 16:56:54,295:INFO:Memory: svmem(total=8362713088, available=999989248, percent=88.0, used=7362723840, free=999989248)
2023-04-24 16:56:54,295:INFO:Physical Core: 4
2023-04-24 16:56:54,295:INFO:Logical Core: 8
2023-04-24 16:56:54,295:INFO:Checking libraries
2023-04-24 16:56:54,295:INFO:System:
2023-04-24 16:56:54,295:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 16:56:54,295:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 16:56:54,295:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 16:56:54,295:INFO:PyCaret required dependencies:
2023-04-24 16:56:54,295:INFO:                 pip: 23.0.1
2023-04-24 16:56:54,295:INFO:          setuptools: 65.5.0
2023-04-24 16:56:54,295:INFO:             pycaret: 3.0.0
2023-04-24 16:56:54,295:INFO:             IPython: 8.5.0
2023-04-24 16:56:54,296:INFO:          ipywidgets: 8.0.2
2023-04-24 16:56:54,296:INFO:                tqdm: 4.65.0
2023-04-24 16:56:54,296:INFO:               numpy: 1.23.3
2023-04-24 16:56:54,296:INFO:              pandas: 1.5.0
2023-04-24 16:56:54,296:INFO:              jinja2: 3.1.2
2023-04-24 16:56:54,296:INFO:               scipy: 1.9.1
2023-04-24 16:56:54,296:INFO:              joblib: 1.2.0
2023-04-24 16:56:54,296:INFO:             sklearn: 1.1.2
2023-04-24 16:56:54,296:INFO:                pyod: 1.0.9
2023-04-24 16:56:54,296:INFO:            imblearn: 0.10.1
2023-04-24 16:56:54,296:INFO:   category_encoders: 2.6.0
2023-04-24 16:56:54,296:INFO:            lightgbm: 3.3.5
2023-04-24 16:56:54,296:INFO:               numba: 0.56.4
2023-04-24 16:56:54,296:INFO:            requests: 2.28.1
2023-04-24 16:56:54,296:INFO:          matplotlib: 3.6.0
2023-04-24 16:56:54,296:INFO:          scikitplot: 0.3.7
2023-04-24 16:56:54,296:INFO:         yellowbrick: 1.5
2023-04-24 16:56:54,296:INFO:              plotly: 5.10.0
2023-04-24 16:56:54,296:INFO:             kaleido: 0.2.1
2023-04-24 16:56:54,296:INFO:         statsmodels: 0.13.5
2023-04-24 16:56:54,296:INFO:              sktime: 0.17.1
2023-04-24 16:56:54,296:INFO:               tbats: 1.1.3
2023-04-24 16:56:54,296:INFO:            pmdarima: 2.0.3
2023-04-24 16:56:54,296:INFO:              psutil: 5.9.2
2023-04-24 16:56:54,296:INFO:PyCaret optional dependencies:
2023-04-24 16:56:54,296:INFO:                shap: Not installed
2023-04-24 16:56:54,296:INFO:           interpret: Not installed
2023-04-24 16:56:54,296:INFO:                umap: Not installed
2023-04-24 16:56:54,296:INFO:    pandas_profiling: Not installed
2023-04-24 16:56:54,297:INFO:  explainerdashboard: Not installed
2023-04-24 16:56:54,297:INFO:             autoviz: Not installed
2023-04-24 16:56:54,297:INFO:           fairlearn: Not installed
2023-04-24 16:56:54,297:INFO:             xgboost: 1.7.5
2023-04-24 16:56:54,297:INFO:            catboost: Not installed
2023-04-24 16:56:54,297:INFO:              kmodes: Not installed
2023-04-24 16:56:54,297:INFO:             mlxtend: Not installed
2023-04-24 16:56:54,297:INFO:       statsforecast: Not installed
2023-04-24 16:56:54,297:INFO:        tune_sklearn: Not installed
2023-04-24 16:56:54,297:INFO:                 ray: Not installed
2023-04-24 16:56:54,297:INFO:            hyperopt: Not installed
2023-04-24 16:56:54,297:INFO:              optuna: Not installed
2023-04-24 16:56:54,297:INFO:               skopt: Not installed
2023-04-24 16:56:54,297:INFO:              mlflow: 2.3.0
2023-04-24 16:56:54,297:INFO:              gradio: Not installed
2023-04-24 16:56:54,297:INFO:             fastapi: Not installed
2023-04-24 16:56:54,297:INFO:             uvicorn: Not installed
2023-04-24 16:56:54,297:INFO:              m2cgen: Not installed
2023-04-24 16:56:54,297:INFO:           evidently: Not installed
2023-04-24 16:56:54,297:INFO:               fugue: Not installed
2023-04-24 16:56:54,297:INFO:           streamlit: Not installed
2023-04-24 16:56:54,297:INFO:             prophet: Not installed
2023-04-24 16:56:54,297:INFO:None
2023-04-24 16:56:54,297:INFO:Set up data.
2023-04-24 16:56:54,301:INFO:Set up train/test split.
2023-04-24 16:56:54,303:INFO:Set up index.
2023-04-24 16:56:54,303:INFO:Set up folding strategy.
2023-04-24 16:56:54,303:INFO:Assigning column types.
2023-04-24 16:56:54,306:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 16:56:54,306:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,310:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,395:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,397:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,401:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,475:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,475:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 16:56:54,489:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,492:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,554:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,570:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,570:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,654:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,656:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 16:56:54,657:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,741:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,741:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,824:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,837:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 16:56:54,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,920:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 16:56:54,998:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:54,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:54,998:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 16:56:55,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:55,076:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:55,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:55,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 16:56:55,170:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:55,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:55,170:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 16:56:55,252:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:55,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:55,337:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:55,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:55,352:INFO:Preparing preprocessing pipeline...
2023-04-24 16:56:55,352:INFO:Set up simple imputation.
2023-04-24 16:56:55,352:INFO:Set up feature normalization.
2023-04-24 16:56:55,352:INFO:Finished creating preprocessing pipeline.
2023-04-24 16:56:55,368:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 16:56:55,368:INFO:Creating final display dataframe.
2023-04-24 16:56:55,415:INFO:Setup _display_container:                     Description         Value
0                    Session id          5504
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1338, 8)
4        Transformed data shape     (1338, 8)
5   Transformed train set shape      (936, 8)
6    Transformed test set shape      (402, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          7904
2023-04-24 16:56:55,501:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:55,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:55,595:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 16:56:55,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 16:56:55,598:INFO:Logging experiment in loggers
2023-04-24 16:56:55,659:INFO:SubProcess save_model() called ==================================
2023-04-24 16:56:55,666:INFO:Initializing save_model()
2023-04-24 16:56:55,666:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmpcsujymsr\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-24 16:56:55,666:INFO:Adding model into prep_pipe
2023-04-24 16:56:55,666:WARNING:Only Model saved as it was a pipeline.
2023-04-24 16:56:55,668:INFO:C:\Users\danie\AppData\Local\Temp\tmpcsujymsr\Transformation Pipeline.pkl saved in current working directory
2023-04-24 16:56:55,671:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 16:56:55,671:INFO:save_model() successfully completed......................................
2023-04-24 16:56:55,821:INFO:SubProcess save_model() end ==================================
2023-04-24 16:56:55,854:INFO:setup() successfully completed in 1.35s...............
2023-04-24 21:34:14,234:INFO:Initializing compare_models()
2023-04-24 21:34:14,241:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 21:34:14,241:INFO:Checking exceptions
2023-04-24 21:34:14,290:INFO:Preparing display monitor
2023-04-24 21:34:14,420:INFO:Initializing Linear Regression
2023-04-24 21:34:14,420:INFO:Total runtime is 0.0 minutes
2023-04-24 21:34:14,423:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:14,428:INFO:Initializing create_model()
2023-04-24 21:34:14,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:14,428:INFO:Checking exceptions
2023-04-24 21:34:14,428:INFO:Importing libraries
2023-04-24 21:34:14,428:INFO:Copying training dataset
2023-04-24 21:34:14,432:INFO:Defining folds
2023-04-24 21:34:14,433:INFO:Declaring metric variables
2023-04-24 21:34:14,436:INFO:Importing untrained model
2023-04-24 21:34:14,444:INFO:Linear Regression Imported successfully
2023-04-24 21:34:14,449:INFO:Starting cross validation
2023-04-24 21:34:14,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:20,806:INFO:Calculating mean and std
2023-04-24 21:34:20,810:INFO:Creating metrics dataframe
2023-04-24 21:34:20,879:INFO:Uploading results into container
2023-04-24 21:34:20,882:INFO:Uploading model into container now
2023-04-24 21:34:20,891:INFO:_master_model_container: 1
2023-04-24 21:34:20,891:INFO:_display_container: 2
2023-04-24 21:34:20,897:INFO:LinearRegression(n_jobs=-1)
2023-04-24 21:34:20,898:INFO:create_model() successfully completed......................................
2023-04-24 21:34:21,950:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:21,950:INFO:Creating metrics dataframe
2023-04-24 21:34:21,960:INFO:Initializing Lasso Regression
2023-04-24 21:34:21,960:INFO:Total runtime is 0.12567118008931477 minutes
2023-04-24 21:34:21,963:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:21,963:INFO:Initializing create_model()
2023-04-24 21:34:21,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:21,963:INFO:Checking exceptions
2023-04-24 21:34:21,963:INFO:Importing libraries
2023-04-24 21:34:21,963:INFO:Copying training dataset
2023-04-24 21:34:21,966:INFO:Defining folds
2023-04-24 21:34:21,967:INFO:Declaring metric variables
2023-04-24 21:34:21,970:INFO:Importing untrained model
2023-04-24 21:34:21,972:INFO:Lasso Regression Imported successfully
2023-04-24 21:34:21,978:INFO:Starting cross validation
2023-04-24 21:34:21,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:22,501:INFO:Calculating mean and std
2023-04-24 21:34:22,502:INFO:Creating metrics dataframe
2023-04-24 21:34:22,559:INFO:Uploading results into container
2023-04-24 21:34:22,559:INFO:Uploading model into container now
2023-04-24 21:34:22,559:INFO:_master_model_container: 2
2023-04-24 21:34:22,559:INFO:_display_container: 2
2023-04-24 21:34:22,559:INFO:Lasso(random_state=5504)
2023-04-24 21:34:22,559:INFO:create_model() successfully completed......................................
2023-04-24 21:34:22,701:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:22,701:INFO:Creating metrics dataframe
2023-04-24 21:34:22,708:INFO:Initializing Ridge Regression
2023-04-24 21:34:22,708:INFO:Total runtime is 0.1381487011909485 minutes
2023-04-24 21:34:22,711:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:22,712:INFO:Initializing create_model()
2023-04-24 21:34:22,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:22,712:INFO:Checking exceptions
2023-04-24 21:34:22,712:INFO:Importing libraries
2023-04-24 21:34:22,712:INFO:Copying training dataset
2023-04-24 21:34:22,714:INFO:Defining folds
2023-04-24 21:34:22,714:INFO:Declaring metric variables
2023-04-24 21:34:22,714:INFO:Importing untrained model
2023-04-24 21:34:22,722:INFO:Ridge Regression Imported successfully
2023-04-24 21:34:22,728:INFO:Starting cross validation
2023-04-24 21:34:22,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:23,174:INFO:Calculating mean and std
2023-04-24 21:34:23,190:INFO:Creating metrics dataframe
2023-04-24 21:34:23,238:INFO:Uploading results into container
2023-04-24 21:34:23,238:INFO:Uploading model into container now
2023-04-24 21:34:23,239:INFO:_master_model_container: 3
2023-04-24 21:34:23,239:INFO:_display_container: 2
2023-04-24 21:34:23,239:INFO:Ridge(random_state=5504)
2023-04-24 21:34:23,239:INFO:create_model() successfully completed......................................
2023-04-24 21:34:23,324:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:23,324:INFO:Creating metrics dataframe
2023-04-24 21:34:23,324:INFO:Initializing Elastic Net
2023-04-24 21:34:23,324:INFO:Total runtime is 0.14840406974156697 minutes
2023-04-24 21:34:23,324:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:23,324:INFO:Initializing create_model()
2023-04-24 21:34:23,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:23,324:INFO:Checking exceptions
2023-04-24 21:34:23,324:INFO:Importing libraries
2023-04-24 21:34:23,324:INFO:Copying training dataset
2023-04-24 21:34:23,338:INFO:Defining folds
2023-04-24 21:34:23,338:INFO:Declaring metric variables
2023-04-24 21:34:23,342:INFO:Importing untrained model
2023-04-24 21:34:23,347:INFO:Elastic Net Imported successfully
2023-04-24 21:34:23,354:INFO:Starting cross validation
2023-04-24 21:34:23,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:23,815:INFO:Calculating mean and std
2023-04-24 21:34:23,816:INFO:Creating metrics dataframe
2023-04-24 21:34:23,863:INFO:Uploading results into container
2023-04-24 21:34:23,864:INFO:Uploading model into container now
2023-04-24 21:34:23,864:INFO:_master_model_container: 4
2023-04-24 21:34:23,864:INFO:_display_container: 2
2023-04-24 21:34:23,864:INFO:ElasticNet(random_state=5504)
2023-04-24 21:34:23,864:INFO:create_model() successfully completed......................................
2023-04-24 21:34:23,942:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:23,942:INFO:Creating metrics dataframe
2023-04-24 21:34:23,951:INFO:Initializing Least Angle Regression
2023-04-24 21:34:23,951:INFO:Total runtime is 0.15885322491327922 minutes
2023-04-24 21:34:23,951:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:23,951:INFO:Initializing create_model()
2023-04-24 21:34:23,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:23,951:INFO:Checking exceptions
2023-04-24 21:34:23,951:INFO:Importing libraries
2023-04-24 21:34:23,951:INFO:Copying training dataset
2023-04-24 21:34:23,963:INFO:Defining folds
2023-04-24 21:34:23,963:INFO:Declaring metric variables
2023-04-24 21:34:23,966:INFO:Importing untrained model
2023-04-24 21:34:23,971:INFO:Least Angle Regression Imported successfully
2023-04-24 21:34:23,979:INFO:Starting cross validation
2023-04-24 21:34:23,980:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:24,024:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,028:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,035:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,042:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,042:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,051:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,051:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,067:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,157:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,166:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:24,425:INFO:Calculating mean and std
2023-04-24 21:34:24,426:INFO:Creating metrics dataframe
2023-04-24 21:34:24,469:INFO:Uploading results into container
2023-04-24 21:34:24,483:INFO:Uploading model into container now
2023-04-24 21:34:24,483:INFO:_master_model_container: 5
2023-04-24 21:34:24,485:INFO:_display_container: 2
2023-04-24 21:34:24,485:INFO:Lars(random_state=5504)
2023-04-24 21:34:24,485:INFO:create_model() successfully completed......................................
2023-04-24 21:34:24,578:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:24,578:INFO:Creating metrics dataframe
2023-04-24 21:34:24,585:INFO:Initializing Lasso Least Angle Regression
2023-04-24 21:34:24,585:INFO:Total runtime is 0.16942468484242756 minutes
2023-04-24 21:34:24,587:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:24,588:INFO:Initializing create_model()
2023-04-24 21:34:24,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:24,588:INFO:Checking exceptions
2023-04-24 21:34:24,588:INFO:Importing libraries
2023-04-24 21:34:24,588:INFO:Copying training dataset
2023-04-24 21:34:24,592:INFO:Defining folds
2023-04-24 21:34:24,592:INFO:Declaring metric variables
2023-04-24 21:34:24,595:INFO:Importing untrained model
2023-04-24 21:34:24,599:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 21:34:24,607:INFO:Starting cross validation
2023-04-24 21:34:24,607:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:24,649:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,654:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,668:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,674:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,688:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,694:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,703:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,721:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,775:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:24,791:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:34:25,079:INFO:Calculating mean and std
2023-04-24 21:34:25,081:INFO:Creating metrics dataframe
2023-04-24 21:34:25,135:INFO:Uploading results into container
2023-04-24 21:34:25,135:INFO:Uploading model into container now
2023-04-24 21:34:25,136:INFO:_master_model_container: 6
2023-04-24 21:34:25,136:INFO:_display_container: 2
2023-04-24 21:34:25,136:INFO:LassoLars(random_state=5504)
2023-04-24 21:34:25,136:INFO:create_model() successfully completed......................................
2023-04-24 21:34:25,221:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:25,221:INFO:Creating metrics dataframe
2023-04-24 21:34:25,228:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 21:34:25,228:INFO:Total runtime is 0.18014416694641114 minutes
2023-04-24 21:34:25,230:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:25,230:INFO:Initializing create_model()
2023-04-24 21:34:25,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:25,231:INFO:Checking exceptions
2023-04-24 21:34:25,231:INFO:Importing libraries
2023-04-24 21:34:25,231:INFO:Copying training dataset
2023-04-24 21:34:25,234:INFO:Defining folds
2023-04-24 21:34:25,234:INFO:Declaring metric variables
2023-04-24 21:34:25,239:INFO:Importing untrained model
2023-04-24 21:34:25,241:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 21:34:25,250:INFO:Starting cross validation
2023-04-24 21:34:25,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:25,289:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,299:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,301:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,307:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,322:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,328:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,335:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,341:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,420:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,420:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:34:25,680:INFO:Calculating mean and std
2023-04-24 21:34:25,681:INFO:Creating metrics dataframe
2023-04-24 21:34:25,731:INFO:Uploading results into container
2023-04-24 21:34:25,732:INFO:Uploading model into container now
2023-04-24 21:34:25,732:INFO:_master_model_container: 7
2023-04-24 21:34:25,732:INFO:_display_container: 2
2023-04-24 21:34:25,732:INFO:OrthogonalMatchingPursuit()
2023-04-24 21:34:25,732:INFO:create_model() successfully completed......................................
2023-04-24 21:34:25,814:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:25,814:INFO:Creating metrics dataframe
2023-04-24 21:34:25,814:INFO:Initializing Bayesian Ridge
2023-04-24 21:34:25,814:INFO:Total runtime is 0.18991612990697226 minutes
2023-04-24 21:34:25,814:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:25,814:INFO:Initializing create_model()
2023-04-24 21:34:25,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:25,830:INFO:Checking exceptions
2023-04-24 21:34:25,830:INFO:Importing libraries
2023-04-24 21:34:25,830:INFO:Copying training dataset
2023-04-24 21:34:25,833:INFO:Defining folds
2023-04-24 21:34:25,834:INFO:Declaring metric variables
2023-04-24 21:34:25,836:INFO:Importing untrained model
2023-04-24 21:34:25,840:INFO:Bayesian Ridge Imported successfully
2023-04-24 21:34:25,851:INFO:Starting cross validation
2023-04-24 21:34:25,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:26,278:INFO:Calculating mean and std
2023-04-24 21:34:26,279:INFO:Creating metrics dataframe
2023-04-24 21:34:26,329:INFO:Uploading results into container
2023-04-24 21:34:26,330:INFO:Uploading model into container now
2023-04-24 21:34:26,330:INFO:_master_model_container: 8
2023-04-24 21:34:26,330:INFO:_display_container: 2
2023-04-24 21:34:26,331:INFO:BayesianRidge()
2023-04-24 21:34:26,331:INFO:create_model() successfully completed......................................
2023-04-24 21:34:26,420:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:26,420:INFO:Creating metrics dataframe
2023-04-24 21:34:26,429:INFO:Initializing Passive Aggressive Regressor
2023-04-24 21:34:26,429:INFO:Total runtime is 0.2001547932624817 minutes
2023-04-24 21:34:26,431:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:26,432:INFO:Initializing create_model()
2023-04-24 21:34:26,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:26,432:INFO:Checking exceptions
2023-04-24 21:34:26,432:INFO:Importing libraries
2023-04-24 21:34:26,432:INFO:Copying training dataset
2023-04-24 21:34:26,436:INFO:Defining folds
2023-04-24 21:34:26,436:INFO:Declaring metric variables
2023-04-24 21:34:26,439:INFO:Importing untrained model
2023-04-24 21:34:26,442:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 21:34:26,447:INFO:Starting cross validation
2023-04-24 21:34:26,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:26,895:INFO:Calculating mean and std
2023-04-24 21:34:26,896:INFO:Creating metrics dataframe
2023-04-24 21:34:26,948:INFO:Uploading results into container
2023-04-24 21:34:26,948:INFO:Uploading model into container now
2023-04-24 21:34:26,949:INFO:_master_model_container: 9
2023-04-24 21:34:26,949:INFO:_display_container: 2
2023-04-24 21:34:26,949:INFO:PassiveAggressiveRegressor(random_state=5504)
2023-04-24 21:34:26,949:INFO:create_model() successfully completed......................................
2023-04-24 21:34:27,034:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:27,034:INFO:Creating metrics dataframe
2023-04-24 21:34:27,037:INFO:Initializing Huber Regressor
2023-04-24 21:34:27,037:INFO:Total runtime is 0.2102945367495219 minutes
2023-04-24 21:34:27,037:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:27,037:INFO:Initializing create_model()
2023-04-24 21:34:27,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:27,037:INFO:Checking exceptions
2023-04-24 21:34:27,037:INFO:Importing libraries
2023-04-24 21:34:27,037:INFO:Copying training dataset
2023-04-24 21:34:27,048:INFO:Defining folds
2023-04-24 21:34:27,048:INFO:Declaring metric variables
2023-04-24 21:34:27,051:INFO:Importing untrained model
2023-04-24 21:34:27,055:INFO:Huber Regressor Imported successfully
2023-04-24 21:34:27,063:INFO:Starting cross validation
2023-04-24 21:34:27,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:27,466:INFO:Calculating mean and std
2023-04-24 21:34:27,482:INFO:Creating metrics dataframe
2023-04-24 21:34:27,531:INFO:Uploading results into container
2023-04-24 21:34:27,531:INFO:Uploading model into container now
2023-04-24 21:34:27,532:INFO:_master_model_container: 10
2023-04-24 21:34:27,532:INFO:_display_container: 2
2023-04-24 21:34:27,532:INFO:HuberRegressor()
2023-04-24 21:34:27,532:INFO:create_model() successfully completed......................................
2023-04-24 21:34:27,616:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:27,617:INFO:Creating metrics dataframe
2023-04-24 21:34:27,624:INFO:Initializing K Neighbors Regressor
2023-04-24 21:34:27,624:INFO:Total runtime is 0.2200785795847575 minutes
2023-04-24 21:34:27,626:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:27,626:INFO:Initializing create_model()
2023-04-24 21:34:27,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:27,626:INFO:Checking exceptions
2023-04-24 21:34:27,626:INFO:Importing libraries
2023-04-24 21:34:27,626:INFO:Copying training dataset
2023-04-24 21:34:27,631:INFO:Defining folds
2023-04-24 21:34:27,631:INFO:Declaring metric variables
2023-04-24 21:34:27,633:INFO:Importing untrained model
2023-04-24 21:34:27,636:INFO:K Neighbors Regressor Imported successfully
2023-04-24 21:34:27,644:INFO:Starting cross validation
2023-04-24 21:34:27,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:28,100:INFO:Calculating mean and std
2023-04-24 21:34:28,102:INFO:Creating metrics dataframe
2023-04-24 21:34:28,155:INFO:Uploading results into container
2023-04-24 21:34:28,155:INFO:Uploading model into container now
2023-04-24 21:34:28,155:INFO:_master_model_container: 11
2023-04-24 21:34:28,155:INFO:_display_container: 2
2023-04-24 21:34:28,155:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 21:34:28,155:INFO:create_model() successfully completed......................................
2023-04-24 21:34:28,241:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:28,241:INFO:Creating metrics dataframe
2023-04-24 21:34:28,249:INFO:Initializing Decision Tree Regressor
2023-04-24 21:34:28,249:INFO:Total runtime is 0.23049122095108032 minutes
2023-04-24 21:34:28,251:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:28,251:INFO:Initializing create_model()
2023-04-24 21:34:28,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:28,251:INFO:Checking exceptions
2023-04-24 21:34:28,251:INFO:Importing libraries
2023-04-24 21:34:28,251:INFO:Copying training dataset
2023-04-24 21:34:28,256:INFO:Defining folds
2023-04-24 21:34:28,256:INFO:Declaring metric variables
2023-04-24 21:34:28,258:INFO:Importing untrained model
2023-04-24 21:34:28,258:INFO:Decision Tree Regressor Imported successfully
2023-04-24 21:34:28,258:INFO:Starting cross validation
2023-04-24 21:34:28,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:28,703:INFO:Calculating mean and std
2023-04-24 21:34:28,704:INFO:Creating metrics dataframe
2023-04-24 21:34:28,755:INFO:Uploading results into container
2023-04-24 21:34:28,755:INFO:Uploading model into container now
2023-04-24 21:34:28,756:INFO:_master_model_container: 12
2023-04-24 21:34:28,756:INFO:_display_container: 2
2023-04-24 21:34:28,756:INFO:DecisionTreeRegressor(random_state=5504)
2023-04-24 21:34:28,756:INFO:create_model() successfully completed......................................
2023-04-24 21:34:28,842:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:28,842:INFO:Creating metrics dataframe
2023-04-24 21:34:28,850:INFO:Initializing Random Forest Regressor
2023-04-24 21:34:28,850:INFO:Total runtime is 0.24050110181172688 minutes
2023-04-24 21:34:28,852:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:28,852:INFO:Initializing create_model()
2023-04-24 21:34:28,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:28,852:INFO:Checking exceptions
2023-04-24 21:34:28,852:INFO:Importing libraries
2023-04-24 21:34:28,852:INFO:Copying training dataset
2023-04-24 21:34:28,852:INFO:Defining folds
2023-04-24 21:34:28,852:INFO:Declaring metric variables
2023-04-24 21:34:28,861:INFO:Importing untrained model
2023-04-24 21:34:28,864:INFO:Random Forest Regressor Imported successfully
2023-04-24 21:34:28,871:INFO:Starting cross validation
2023-04-24 21:34:28,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:29,868:INFO:Calculating mean and std
2023-04-24 21:34:29,870:INFO:Creating metrics dataframe
2023-04-24 21:34:29,927:INFO:Uploading results into container
2023-04-24 21:34:29,927:INFO:Uploading model into container now
2023-04-24 21:34:29,927:INFO:_master_model_container: 13
2023-04-24 21:34:29,927:INFO:_display_container: 2
2023-04-24 21:34:29,928:INFO:RandomForestRegressor(n_jobs=-1, random_state=5504)
2023-04-24 21:34:29,928:INFO:create_model() successfully completed......................................
2023-04-24 21:34:30,018:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:30,018:INFO:Creating metrics dataframe
2023-04-24 21:34:30,028:INFO:Initializing Extra Trees Regressor
2023-04-24 21:34:30,028:INFO:Total runtime is 0.2601460933685303 minutes
2023-04-24 21:34:30,033:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:30,035:INFO:Initializing create_model()
2023-04-24 21:34:30,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:30,035:INFO:Checking exceptions
2023-04-24 21:34:30,035:INFO:Importing libraries
2023-04-24 21:34:30,035:INFO:Copying training dataset
2023-04-24 21:34:30,041:INFO:Defining folds
2023-04-24 21:34:30,041:INFO:Declaring metric variables
2023-04-24 21:34:30,046:INFO:Importing untrained model
2023-04-24 21:34:30,051:INFO:Extra Trees Regressor Imported successfully
2023-04-24 21:34:30,060:INFO:Starting cross validation
2023-04-24 21:34:30,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:31,128:INFO:Calculating mean and std
2023-04-24 21:34:31,128:INFO:Creating metrics dataframe
2023-04-24 21:34:31,194:INFO:Uploading results into container
2023-04-24 21:34:31,194:INFO:Uploading model into container now
2023-04-24 21:34:31,194:INFO:_master_model_container: 14
2023-04-24 21:34:31,195:INFO:_display_container: 2
2023-04-24 21:34:31,195:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5504)
2023-04-24 21:34:31,195:INFO:create_model() successfully completed......................................
2023-04-24 21:34:31,303:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:31,303:INFO:Creating metrics dataframe
2023-04-24 21:34:31,313:INFO:Initializing AdaBoost Regressor
2023-04-24 21:34:31,313:INFO:Total runtime is 0.2815518538157145 minutes
2023-04-24 21:34:31,315:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:31,316:INFO:Initializing create_model()
2023-04-24 21:34:31,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:31,316:INFO:Checking exceptions
2023-04-24 21:34:31,316:INFO:Importing libraries
2023-04-24 21:34:31,316:INFO:Copying training dataset
2023-04-24 21:34:31,321:INFO:Defining folds
2023-04-24 21:34:31,321:INFO:Declaring metric variables
2023-04-24 21:34:31,323:INFO:Importing untrained model
2023-04-24 21:34:31,327:INFO:AdaBoost Regressor Imported successfully
2023-04-24 21:34:31,333:INFO:Starting cross validation
2023-04-24 21:34:31,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:31,827:INFO:Calculating mean and std
2023-04-24 21:34:31,828:INFO:Creating metrics dataframe
2023-04-24 21:34:31,888:INFO:Uploading results into container
2023-04-24 21:34:31,888:INFO:Uploading model into container now
2023-04-24 21:34:31,889:INFO:_master_model_container: 15
2023-04-24 21:34:31,889:INFO:_display_container: 2
2023-04-24 21:34:31,889:INFO:AdaBoostRegressor(random_state=5504)
2023-04-24 21:34:31,889:INFO:create_model() successfully completed......................................
2023-04-24 21:34:31,980:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:31,980:INFO:Creating metrics dataframe
2023-04-24 21:34:31,992:INFO:Initializing Gradient Boosting Regressor
2023-04-24 21:34:31,992:INFO:Total runtime is 0.2928688208262126 minutes
2023-04-24 21:34:31,995:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:31,995:INFO:Initializing create_model()
2023-04-24 21:34:31,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:31,995:INFO:Checking exceptions
2023-04-24 21:34:31,995:INFO:Importing libraries
2023-04-24 21:34:31,995:INFO:Copying training dataset
2023-04-24 21:34:31,999:INFO:Defining folds
2023-04-24 21:34:31,999:INFO:Declaring metric variables
2023-04-24 21:34:32,002:INFO:Importing untrained model
2023-04-24 21:34:32,006:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:34:32,015:INFO:Starting cross validation
2023-04-24 21:34:32,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:32,619:INFO:Calculating mean and std
2023-04-24 21:34:32,620:INFO:Creating metrics dataframe
2023-04-24 21:34:32,677:INFO:Uploading results into container
2023-04-24 21:34:32,677:INFO:Uploading model into container now
2023-04-24 21:34:32,678:INFO:_master_model_container: 16
2023-04-24 21:34:32,678:INFO:_display_container: 2
2023-04-24 21:34:32,678:INFO:GradientBoostingRegressor(random_state=5504)
2023-04-24 21:34:32,678:INFO:create_model() successfully completed......................................
2023-04-24 21:34:32,762:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:32,762:INFO:Creating metrics dataframe
2023-04-24 21:34:32,762:INFO:Initializing Extreme Gradient Boosting
2023-04-24 21:34:32,762:INFO:Total runtime is 0.3057012518246969 minutes
2023-04-24 21:34:32,762:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:32,762:INFO:Initializing create_model()
2023-04-24 21:34:32,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:32,762:INFO:Checking exceptions
2023-04-24 21:34:32,762:INFO:Importing libraries
2023-04-24 21:34:32,762:INFO:Copying training dataset
2023-04-24 21:34:32,780:INFO:Defining folds
2023-04-24 21:34:32,780:INFO:Declaring metric variables
2023-04-24 21:34:32,783:INFO:Importing untrained model
2023-04-24 21:34:32,787:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 21:34:32,805:INFO:Starting cross validation
2023-04-24 21:34:32,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:34,693:INFO:Calculating mean and std
2023-04-24 21:34:34,693:INFO:Creating metrics dataframe
2023-04-24 21:34:34,766:INFO:Uploading results into container
2023-04-24 21:34:34,766:INFO:Uploading model into container now
2023-04-24 21:34:34,766:INFO:_master_model_container: 17
2023-04-24 21:34:34,766:INFO:_display_container: 2
2023-04-24 21:34:34,767:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5504, ...)
2023-04-24 21:34:34,767:INFO:create_model() successfully completed......................................
2023-04-24 21:34:34,841:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:34,841:INFO:Creating metrics dataframe
2023-04-24 21:34:34,856:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 21:34:34,856:INFO:Total runtime is 0.3406140486399333 minutes
2023-04-24 21:34:34,856:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:34,856:INFO:Initializing create_model()
2023-04-24 21:34:34,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:34,856:INFO:Checking exceptions
2023-04-24 21:34:34,856:INFO:Importing libraries
2023-04-24 21:34:34,856:INFO:Copying training dataset
2023-04-24 21:34:34,869:INFO:Defining folds
2023-04-24 21:34:34,869:INFO:Declaring metric variables
2023-04-24 21:34:34,871:INFO:Importing untrained model
2023-04-24 21:34:34,874:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 21:34:34,883:INFO:Starting cross validation
2023-04-24 21:34:34,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:35,519:INFO:Calculating mean and std
2023-04-24 21:34:35,521:INFO:Creating metrics dataframe
2023-04-24 21:34:35,580:INFO:Uploading results into container
2023-04-24 21:34:35,581:INFO:Uploading model into container now
2023-04-24 21:34:35,581:INFO:_master_model_container: 18
2023-04-24 21:34:35,581:INFO:_display_container: 2
2023-04-24 21:34:35,581:INFO:LGBMRegressor(random_state=5504)
2023-04-24 21:34:35,581:INFO:create_model() successfully completed......................................
2023-04-24 21:34:35,669:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:35,669:INFO:Creating metrics dataframe
2023-04-24 21:34:35,678:INFO:Initializing Dummy Regressor
2023-04-24 21:34:35,678:INFO:Total runtime is 0.35430922905604045 minutes
2023-04-24 21:34:35,680:INFO:SubProcess create_model() called ==================================
2023-04-24 21:34:35,680:INFO:Initializing create_model()
2023-04-24 21:34:35,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A3B340>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:35,681:INFO:Checking exceptions
2023-04-24 21:34:35,681:INFO:Importing libraries
2023-04-24 21:34:35,681:INFO:Copying training dataset
2023-04-24 21:34:35,685:INFO:Defining folds
2023-04-24 21:34:35,685:INFO:Declaring metric variables
2023-04-24 21:34:35,688:INFO:Importing untrained model
2023-04-24 21:34:35,691:INFO:Dummy Regressor Imported successfully
2023-04-24 21:34:35,698:INFO:Starting cross validation
2023-04-24 21:34:35,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:36,176:INFO:Calculating mean and std
2023-04-24 21:34:36,176:INFO:Creating metrics dataframe
2023-04-24 21:34:36,241:INFO:Uploading results into container
2023-04-24 21:34:36,242:INFO:Uploading model into container now
2023-04-24 21:34:36,242:INFO:_master_model_container: 19
2023-04-24 21:34:36,242:INFO:_display_container: 2
2023-04-24 21:34:36,242:INFO:DummyRegressor()
2023-04-24 21:34:36,242:INFO:create_model() successfully completed......................................
2023-04-24 21:34:36,327:INFO:SubProcess create_model() end ==================================
2023-04-24 21:34:36,327:INFO:Creating metrics dataframe
2023-04-24 21:34:36,346:INFO:Initializing create_model()
2023-04-24 21:34:36,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:36,346:INFO:Checking exceptions
2023-04-24 21:34:36,348:INFO:Importing libraries
2023-04-24 21:34:36,349:INFO:Copying training dataset
2023-04-24 21:34:36,351:INFO:Defining folds
2023-04-24 21:34:36,352:INFO:Declaring metric variables
2023-04-24 21:34:36,352:INFO:Importing untrained model
2023-04-24 21:34:36,352:INFO:Declaring custom model
2023-04-24 21:34:36,352:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:34:36,353:INFO:Cross validation set to False
2023-04-24 21:34:36,353:INFO:Fitting Model
2023-04-24 21:34:36,472:INFO:GradientBoostingRegressor(random_state=5504)
2023-04-24 21:34:36,472:INFO:create_model() successfully completed......................................
2023-04-24 21:34:36,561:INFO:Creating Dashboard logs
2023-04-24 21:34:36,565:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:34:36,624:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5504, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:34:36,725:INFO:Initializing predict_model()
2023-04-24 21:34:36,725:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561DD1E10>)
2023-04-24 21:34:36,726:INFO:Checking exceptions
2023-04-24 21:34:36,726:INFO:Preloading libraries
2023-04-24 21:34:37,003:INFO:Creating Dashboard logs
2023-04-24 21:34:37,019:INFO:Model: Light Gradient Boosting Machine
2023-04-24 21:34:37,060:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5504, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 21:34:37,293:INFO:Creating Dashboard logs
2023-04-24 21:34:37,296:INFO:Model: Random Forest Regressor
2023-04-24 21:34:37,334:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5504, 'verbose': 0, 'warm_start': False}
2023-04-24 21:34:37,560:INFO:Creating Dashboard logs
2023-04-24 21:34:37,562:INFO:Model: AdaBoost Regressor
2023-04-24 21:34:37,598:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 5504}
2023-04-24 21:34:37,812:INFO:Creating Dashboard logs
2023-04-24 21:34:37,815:INFO:Model: K Neighbors Regressor
2023-04-24 21:34:37,855:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 21:34:38,057:INFO:Creating Dashboard logs
2023-04-24 21:34:38,057:INFO:Model: Extra Trees Regressor
2023-04-24 21:34:38,112:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5504, 'verbose': 0, 'warm_start': False}
2023-04-24 21:34:38,323:INFO:Creating Dashboard logs
2023-04-24 21:34:38,323:INFO:Model: Extreme Gradient Boosting
2023-04-24 21:34:38,380:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 5504, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-24 21:34:38,616:INFO:Creating Dashboard logs
2023-04-24 21:34:38,619:INFO:Model: Bayesian Ridge
2023-04-24 21:34:38,655:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 21:34:38,889:INFO:Creating Dashboard logs
2023-04-24 21:34:38,891:INFO:Model: Lasso Least Angle Regression
2023-04-24 21:34:38,930:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 5504, 'verbose': False}
2023-04-24 21:34:39,164:INFO:Creating Dashboard logs
2023-04-24 21:34:39,164:INFO:Model: Lasso Regression
2023-04-24 21:34:39,204:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 5504, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 21:34:39,412:INFO:Creating Dashboard logs
2023-04-24 21:34:39,412:INFO:Model: Ridge Regression
2023-04-24 21:34:39,465:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 5504, 'solver': 'auto', 'tol': 0.001}
2023-04-24 21:34:39,678:INFO:Creating Dashboard logs
2023-04-24 21:34:39,682:INFO:Model: Linear Regression
2023-04-24 21:34:39,720:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 21:34:39,952:INFO:Creating Dashboard logs
2023-04-24 21:34:39,956:INFO:Model: Least Angle Regression
2023-04-24 21:34:39,995:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 5504, 'verbose': False}
2023-04-24 21:34:40,209:INFO:Creating Dashboard logs
2023-04-24 21:34:40,211:INFO:Model: Decision Tree Regressor
2023-04-24 21:34:40,250:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 5504, 'splitter': 'best'}
2023-04-24 21:34:40,462:INFO:Creating Dashboard logs
2023-04-24 21:34:40,464:INFO:Model: Huber Regressor
2023-04-24 21:34:40,504:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 21:34:40,713:INFO:Creating Dashboard logs
2023-04-24 21:34:40,713:INFO:Model: Passive Aggressive Regressor
2023-04-24 21:34:40,764:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 5504, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:34:40,988:INFO:Creating Dashboard logs
2023-04-24 21:34:40,990:INFO:Model: Elastic Net
2023-04-24 21:34:41,030:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 5504, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 21:34:41,256:INFO:Creating Dashboard logs
2023-04-24 21:34:41,256:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 21:34:41,306:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 21:34:41,590:INFO:Creating Dashboard logs
2023-04-24 21:34:41,590:INFO:Model: Dummy Regressor
2023-04-24 21:34:41,632:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 21:34:41,867:INFO:_master_model_container: 19
2023-04-24 21:34:41,867:INFO:_display_container: 2
2023-04-24 21:34:41,868:INFO:GradientBoostingRegressor(random_state=5504)
2023-04-24 21:34:41,868:INFO:compare_models() successfully completed......................................
2023-04-24 21:34:54,098:INFO:Initializing create_model()
2023-04-24 21:34:54,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:34:54,099:INFO:Checking exceptions
2023-04-24 21:34:54,120:INFO:Importing libraries
2023-04-24 21:34:54,120:INFO:Copying training dataset
2023-04-24 21:34:54,121:INFO:Defining folds
2023-04-24 21:34:54,121:INFO:Declaring metric variables
2023-04-24 21:34:54,121:INFO:Importing untrained model
2023-04-24 21:34:54,136:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:34:54,153:INFO:Starting cross validation
2023-04-24 21:34:54,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:34:55,207:INFO:Calculating mean and std
2023-04-24 21:34:55,209:INFO:Creating metrics dataframe
2023-04-24 21:34:55,214:INFO:Finalizing model
2023-04-24 21:34:55,373:INFO:Creating Dashboard logs
2023-04-24 21:34:55,375:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:34:55,416:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5504, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:34:55,503:INFO:Initializing predict_model()
2023-04-24 21:34:55,504:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561DD1A20>)
2023-04-24 21:34:55,504:INFO:Checking exceptions
2023-04-24 21:34:55,504:INFO:Preloading libraries
2023-04-24 21:34:55,866:INFO:Uploading results into container
2023-04-24 21:34:55,867:INFO:Uploading model into container now
2023-04-24 21:34:55,878:INFO:_master_model_container: 20
2023-04-24 21:34:55,879:INFO:_display_container: 3
2023-04-24 21:34:55,879:INFO:GradientBoostingRegressor(random_state=5504)
2023-04-24 21:34:55,879:INFO:create_model() successfully completed......................................
2023-04-24 21:35:24,419:INFO:Initializing tune_model()
2023-04-24 21:35:24,419:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=5504), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>)
2023-04-24 21:35:24,419:INFO:Checking exceptions
2023-04-24 21:35:24,449:INFO:Copying training dataset
2023-04-24 21:35:24,453:INFO:Checking base model
2023-04-24 21:35:24,453:INFO:Base model : Gradient Boosting Regressor
2023-04-24 21:35:24,462:INFO:Declaring metric variables
2023-04-24 21:35:24,467:INFO:Defining Hyperparameters
2023-04-24 21:35:24,575:INFO:Tuning with n_jobs=-1
2023-04-24 21:35:24,575:INFO:Initializing RandomizedSearchCV
2023-04-24 21:35:31,947:INFO:best_params: {'actual_estimator__subsample': 0.65, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 2, 'actual_estimator__learning_rate': 0.2}
2023-04-24 21:35:31,950:INFO:Hyperparameter search completed
2023-04-24 21:35:31,951:INFO:SubProcess create_model() called ==================================
2023-04-24 21:35:31,951:INFO:Initializing create_model()
2023-04-24 21:35:31,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560485D20>, model_only=True, return_train_score=False, kwargs={'subsample': 0.65, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.5, 'max_features': 1.0, 'max_depth': 2, 'learning_rate': 0.2})
2023-04-24 21:35:31,951:INFO:Checking exceptions
2023-04-24 21:35:31,952:INFO:Importing libraries
2023-04-24 21:35:31,952:INFO:Copying training dataset
2023-04-24 21:35:31,956:INFO:Defining folds
2023-04-24 21:35:31,956:INFO:Declaring metric variables
2023-04-24 21:35:31,960:INFO:Importing untrained model
2023-04-24 21:35:31,960:INFO:Declaring custom model
2023-04-24 21:35:31,970:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:35:31,976:INFO:Starting cross validation
2023-04-24 21:35:31,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:35:32,796:INFO:Calculating mean and std
2023-04-24 21:35:32,797:INFO:Creating metrics dataframe
2023-04-24 21:35:32,803:INFO:Finalizing model
2023-04-24 21:35:33,063:INFO:Uploading results into container
2023-04-24 21:35:33,064:INFO:Uploading model into container now
2023-04-24 21:35:33,064:INFO:_master_model_container: 21
2023-04-24 21:35:33,064:INFO:_display_container: 4
2023-04-24 21:35:33,064:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=2, max_features=1.0,
                          min_impurity_decrease=0.5, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=230,
                          random_state=5504, subsample=0.65)
2023-04-24 21:35:33,065:INFO:create_model() successfully completed......................................
2023-04-24 21:35:33,158:INFO:SubProcess create_model() end ==================================
2023-04-24 21:35:33,159:INFO:choose_better activated
2023-04-24 21:35:33,161:INFO:SubProcess create_model() called ==================================
2023-04-24 21:35:33,162:INFO:Initializing create_model()
2023-04-24 21:35:33,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:35:33,162:INFO:Checking exceptions
2023-04-24 21:35:33,164:INFO:Importing libraries
2023-04-24 21:35:33,164:INFO:Copying training dataset
2023-04-24 21:35:33,165:INFO:Defining folds
2023-04-24 21:35:33,165:INFO:Declaring metric variables
2023-04-24 21:35:33,167:INFO:Importing untrained model
2023-04-24 21:35:33,167:INFO:Declaring custom model
2023-04-24 21:35:33,167:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:35:33,167:INFO:Starting cross validation
2023-04-24 21:35:33,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:35:33,867:INFO:Calculating mean and std
2023-04-24 21:35:33,867:INFO:Creating metrics dataframe
2023-04-24 21:35:33,869:INFO:Finalizing model
2023-04-24 21:35:34,003:INFO:Uploading results into container
2023-04-24 21:35:34,004:INFO:Uploading model into container now
2023-04-24 21:35:34,004:INFO:_master_model_container: 22
2023-04-24 21:35:34,004:INFO:_display_container: 5
2023-04-24 21:35:34,004:INFO:GradientBoostingRegressor(random_state=5504)
2023-04-24 21:35:34,004:INFO:create_model() successfully completed......................................
2023-04-24 21:35:34,106:INFO:SubProcess create_model() end ==================================
2023-04-24 21:35:34,106:INFO:GradientBoostingRegressor(random_state=5504) result for R2 is 0.8541
2023-04-24 21:35:34,108:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=2, max_features=1.0,
                          min_impurity_decrease=0.5, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=230,
                          random_state=5504, subsample=0.65) result for R2 is 0.8406
2023-04-24 21:35:34,108:INFO:GradientBoostingRegressor(random_state=5504) is best model
2023-04-24 21:35:34,108:INFO:choose_better completed
2023-04-24 21:35:34,108:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 21:35:34,110:INFO:Creating Dashboard logs
2023-04-24 21:35:34,113:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:35:34,163:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5504, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:35:34,315:INFO:Initializing predict_model()
2023-04-24 21:35:34,315:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561DD2950>)
2023-04-24 21:35:34,315:INFO:Checking exceptions
2023-04-24 21:35:34,315:INFO:Preloading libraries
2023-04-24 21:35:34,662:INFO:_master_model_container: 22
2023-04-24 21:35:34,662:INFO:_display_container: 4
2023-04-24 21:35:34,662:INFO:GradientBoostingRegressor(random_state=5504)
2023-04-24 21:35:34,662:INFO:tune_model() successfully completed......................................
2023-04-24 21:35:43,465:INFO:Initializing plot_model()
2023-04-24 21:35:43,465:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=5504), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, system=True)
2023-04-24 21:35:43,465:INFO:Checking exceptions
2023-04-24 21:35:43,472:INFO:Preloading libraries
2023-04-24 21:35:43,479:INFO:Copying training dataset
2023-04-24 21:35:43,479:INFO:Plot type: error
2023-04-24 21:35:43,554:INFO:Fitting Model
2023-04-24 21:35:43,555:INFO:Scoring test/hold-out set
2023-04-24 21:35:43,825:INFO:Visual Rendered Successfully
2023-04-24 21:35:43,936:INFO:plot_model() successfully completed......................................
2023-04-24 21:35:48,250:INFO:Initializing plot_model()
2023-04-24 21:35:48,250:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=5504), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, system=True)
2023-04-24 21:35:48,250:INFO:Checking exceptions
2023-04-24 21:35:48,254:INFO:Preloading libraries
2023-04-24 21:35:48,261:INFO:Copying training dataset
2023-04-24 21:35:48,261:INFO:Plot type: feature
2023-04-24 21:35:48,261:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 21:35:48,408:INFO:Visual Rendered Successfully
2023-04-24 21:35:48,509:INFO:plot_model() successfully completed......................................
2023-04-24 21:35:51,931:INFO:Initializing predict_model()
2023-04-24 21:35:51,931:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561DD0280>)
2023-04-24 21:35:51,931:INFO:Checking exceptions
2023-04-24 21:35:51,931:INFO:Preloading libraries
2023-04-24 21:35:54,873:INFO:Initializing finalize_model()
2023-04-24 21:35:54,873:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-24 21:35:54,874:INFO:Finalizing GradientBoostingRegressor(random_state=5504)
2023-04-24 21:35:54,876:INFO:Initializing create_model()
2023-04-24 21:35:54,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=GradientBoostingRegressor(random_state=5504), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-24 21:35:54,876:INFO:Checking exceptions
2023-04-24 21:35:54,879:INFO:Importing libraries
2023-04-24 21:35:54,879:INFO:Copying training dataset
2023-04-24 21:35:54,879:INFO:Defining folds
2023-04-24 21:35:54,879:INFO:Declaring metric variables
2023-04-24 21:35:54,879:INFO:Importing untrained model
2023-04-24 21:35:54,879:INFO:Declaring custom model
2023-04-24 21:35:54,880:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:35:54,881:INFO:Cross validation set to False
2023-04-24 21:35:54,881:INFO:Fitting Model
2023-04-24 21:35:54,985:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=5504))])
2023-04-24 21:35:54,985:INFO:create_model() successfully completed......................................
2023-04-24 21:35:55,078:INFO:Creating Dashboard logs
2023-04-24 21:35:55,078:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:35:55,115:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5504, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:35:55,334:INFO:_master_model_container: 22
2023-04-24 21:35:55,335:INFO:_display_container: 5
2023-04-24 21:35:55,340:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=5504))])
2023-04-24 21:35:55,340:INFO:finalize_model() successfully completed......................................
2023-04-24 21:36:01,863:INFO:Initializing predict_model()
2023-04-24 21:36:01,863:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D562290A60>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=5504))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D560CB7400>)
2023-04-24 21:36:01,863:INFO:Checking exceptions
2023-04-24 21:36:01,864:INFO:Preloading libraries
2023-04-24 21:36:01,866:INFO:Set up data.
2023-04-24 21:36:01,872:INFO:Set up index.
2023-04-24 21:36:57,688:INFO:PyCaret RegressionExperiment
2023-04-24 21:36:57,688:INFO:Logging name: charges
2023-04-24 21:36:57,688:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 21:36:57,688:INFO:version 3.0.0
2023-04-24 21:36:57,688:INFO:Initializing setup()
2023-04-24 21:36:57,689:INFO:self.USI: fab7
2023-04-24 21:36:57,689:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-24 21:36:57,689:INFO:Checking environment
2023-04-24 21:36:57,689:INFO:python_version: 3.10.11
2023-04-24 21:36:57,689:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-24 21:36:57,689:INFO:machine: AMD64
2023-04-24 21:36:57,689:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-24 21:36:57,689:INFO:Memory: svmem(total=8362713088, available=1072160768, percent=87.2, used=7290552320, free=1072160768)
2023-04-24 21:36:57,689:INFO:Physical Core: 4
2023-04-24 21:36:57,689:INFO:Logical Core: 8
2023-04-24 21:36:57,689:INFO:Checking libraries
2023-04-24 21:36:57,689:INFO:System:
2023-04-24 21:36:57,689:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-24 21:36:57,689:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-24 21:36:57,689:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-24 21:36:57,689:INFO:PyCaret required dependencies:
2023-04-24 21:36:57,690:INFO:                 pip: 23.0.1
2023-04-24 21:36:57,690:INFO:          setuptools: 65.5.0
2023-04-24 21:36:57,690:INFO:             pycaret: 3.0.0
2023-04-24 21:36:57,690:INFO:             IPython: 8.5.0
2023-04-24 21:36:57,690:INFO:          ipywidgets: 8.0.2
2023-04-24 21:36:57,690:INFO:                tqdm: 4.65.0
2023-04-24 21:36:57,690:INFO:               numpy: 1.23.3
2023-04-24 21:36:57,690:INFO:              pandas: 1.5.0
2023-04-24 21:36:57,690:INFO:              jinja2: 3.1.2
2023-04-24 21:36:57,690:INFO:               scipy: 1.9.1
2023-04-24 21:36:57,690:INFO:              joblib: 1.2.0
2023-04-24 21:36:57,690:INFO:             sklearn: 1.1.2
2023-04-24 21:36:57,690:INFO:                pyod: 1.0.9
2023-04-24 21:36:57,690:INFO:            imblearn: 0.10.1
2023-04-24 21:36:57,690:INFO:   category_encoders: 2.6.0
2023-04-24 21:36:57,690:INFO:            lightgbm: 3.3.5
2023-04-24 21:36:57,690:INFO:               numba: 0.56.4
2023-04-24 21:36:57,690:INFO:            requests: 2.28.1
2023-04-24 21:36:57,690:INFO:          matplotlib: 3.6.0
2023-04-24 21:36:57,690:INFO:          scikitplot: 0.3.7
2023-04-24 21:36:57,690:INFO:         yellowbrick: 1.5
2023-04-24 21:36:57,690:INFO:              plotly: 5.10.0
2023-04-24 21:36:57,690:INFO:             kaleido: 0.2.1
2023-04-24 21:36:57,690:INFO:         statsmodels: 0.13.5
2023-04-24 21:36:57,690:INFO:              sktime: 0.17.1
2023-04-24 21:36:57,690:INFO:               tbats: 1.1.3
2023-04-24 21:36:57,690:INFO:            pmdarima: 2.0.3
2023-04-24 21:36:57,690:INFO:              psutil: 5.9.2
2023-04-24 21:36:57,690:INFO:PyCaret optional dependencies:
2023-04-24 21:36:57,690:INFO:                shap: Not installed
2023-04-24 21:36:57,690:INFO:           interpret: Not installed
2023-04-24 21:36:57,690:INFO:                umap: Not installed
2023-04-24 21:36:57,690:INFO:    pandas_profiling: Not installed
2023-04-24 21:36:57,690:INFO:  explainerdashboard: Not installed
2023-04-24 21:36:57,690:INFO:             autoviz: Not installed
2023-04-24 21:36:57,690:INFO:           fairlearn: Not installed
2023-04-24 21:36:57,690:INFO:             xgboost: 1.7.5
2023-04-24 21:36:57,690:INFO:            catboost: Not installed
2023-04-24 21:36:57,690:INFO:              kmodes: Not installed
2023-04-24 21:36:57,690:INFO:             mlxtend: Not installed
2023-04-24 21:36:57,690:INFO:       statsforecast: Not installed
2023-04-24 21:36:57,690:INFO:        tune_sklearn: Not installed
2023-04-24 21:36:57,690:INFO:                 ray: Not installed
2023-04-24 21:36:57,691:INFO:            hyperopt: Not installed
2023-04-24 21:36:57,691:INFO:              optuna: Not installed
2023-04-24 21:36:57,691:INFO:               skopt: Not installed
2023-04-24 21:36:57,691:INFO:              mlflow: 2.3.0
2023-04-24 21:36:57,691:INFO:              gradio: Not installed
2023-04-24 21:36:57,691:INFO:             fastapi: Not installed
2023-04-24 21:36:57,691:INFO:             uvicorn: Not installed
2023-04-24 21:36:57,691:INFO:              m2cgen: Not installed
2023-04-24 21:36:57,691:INFO:           evidently: Not installed
2023-04-24 21:36:57,691:INFO:               fugue: Not installed
2023-04-24 21:36:57,691:INFO:           streamlit: Not installed
2023-04-24 21:36:57,691:INFO:             prophet: Not installed
2023-04-24 21:36:57,691:INFO:None
2023-04-24 21:36:57,691:INFO:Set up data.
2023-04-24 21:36:57,697:INFO:Set up train/test split.
2023-04-24 21:36:57,701:INFO:Set up index.
2023-04-24 21:36:57,701:INFO:Set up folding strategy.
2023-04-24 21:36:57,701:INFO:Assigning column types.
2023-04-24 21:36:57,702:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 21:36:57,703:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,708:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,763:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,801:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:57,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:57,804:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,807:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,894:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:57,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:57,897:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 21:36:57,901:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,984:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:57,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:57,992:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 21:36:57,995:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,074:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,076:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 21:36:58,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,130:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,166:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,220:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,256:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,258:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 21:36:58,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,349:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,441:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,447:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 21:36:58,498:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,532:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 21:36:58,621:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,623:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 21:36:58,712:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,807:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:58,809:INFO:Preparing preprocessing pipeline...
2023-04-24 21:36:58,810:INFO:Set up simple imputation.
2023-04-24 21:36:58,810:INFO:Set up feature normalization.
2023-04-24 21:36:58,828:INFO:Finished creating preprocessing pipeline.
2023-04-24 21:36:58,831:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 21:36:58,831:INFO:Creating final display dataframe.
2023-04-24 21:36:58,888:INFO:Setup _display_container:                     Description         Value
0                    Session id          3041
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1204, 8)
4        Transformed data shape     (1204, 8)
5   Transformed train set shape      (842, 8)
6    Transformed test set shape      (362, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          fab7
2023-04-24 21:36:58,984:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:58,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:59,080:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 21:36:59,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 21:36:59,082:INFO:Logging experiment in loggers
2023-04-24 21:36:59,149:INFO:SubProcess save_model() called ==================================
2023-04-24 21:36:59,155:INFO:Initializing save_model()
2023-04-24 21:36:59,155:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmpfnbarj5e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-24 21:36:59,155:INFO:Adding model into prep_pipe
2023-04-24 21:36:59,155:WARNING:Only Model saved as it was a pipeline.
2023-04-24 21:36:59,156:INFO:C:\Users\danie\AppData\Local\Temp\tmpfnbarj5e\Transformation Pipeline.pkl saved in current working directory
2023-04-24 21:36:59,160:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-24 21:36:59,160:INFO:save_model() successfully completed......................................
2023-04-24 21:36:59,333:INFO:SubProcess save_model() end ==================================
2023-04-24 21:36:59,385:INFO:setup() successfully completed in 1.46s...............
2023-04-24 21:36:59,445:INFO:Initializing compare_models()
2023-04-24 21:36:59,445:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 21:36:59,445:INFO:Checking exceptions
2023-04-24 21:36:59,447:INFO:Preparing display monitor
2023-04-24 21:36:59,482:INFO:Initializing Linear Regression
2023-04-24 21:36:59,482:INFO:Total runtime is 0.0 minutes
2023-04-24 21:36:59,488:INFO:SubProcess create_model() called ==================================
2023-04-24 21:36:59,489:INFO:Initializing create_model()
2023-04-24 21:36:59,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:36:59,489:INFO:Checking exceptions
2023-04-24 21:36:59,489:INFO:Importing libraries
2023-04-24 21:36:59,489:INFO:Copying training dataset
2023-04-24 21:36:59,491:INFO:Defining folds
2023-04-24 21:36:59,492:INFO:Declaring metric variables
2023-04-24 21:36:59,495:INFO:Importing untrained model
2023-04-24 21:36:59,498:INFO:Linear Regression Imported successfully
2023-04-24 21:36:59,506:INFO:Starting cross validation
2023-04-24 21:36:59,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:00,111:INFO:Calculating mean and std
2023-04-24 21:37:00,112:INFO:Creating metrics dataframe
2023-04-24 21:37:00,183:INFO:Uploading results into container
2023-04-24 21:37:00,184:INFO:Uploading model into container now
2023-04-24 21:37:00,184:INFO:_master_model_container: 1
2023-04-24 21:37:00,184:INFO:_display_container: 2
2023-04-24 21:37:00,184:INFO:LinearRegression(n_jobs=-1)
2023-04-24 21:37:00,184:INFO:create_model() successfully completed......................................
2023-04-24 21:37:00,284:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:00,284:INFO:Creating metrics dataframe
2023-04-24 21:37:00,290:INFO:Initializing Lasso Regression
2023-04-24 21:37:00,290:INFO:Total runtime is 0.013459599018096924 minutes
2023-04-24 21:37:00,292:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:00,292:INFO:Initializing create_model()
2023-04-24 21:37:00,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:00,292:INFO:Checking exceptions
2023-04-24 21:37:00,293:INFO:Importing libraries
2023-04-24 21:37:00,293:INFO:Copying training dataset
2023-04-24 21:37:00,296:INFO:Defining folds
2023-04-24 21:37:00,296:INFO:Declaring metric variables
2023-04-24 21:37:00,299:INFO:Importing untrained model
2023-04-24 21:37:00,303:INFO:Lasso Regression Imported successfully
2023-04-24 21:37:00,311:INFO:Starting cross validation
2023-04-24 21:37:00,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:00,923:INFO:Calculating mean and std
2023-04-24 21:37:00,924:INFO:Creating metrics dataframe
2023-04-24 21:37:00,999:INFO:Uploading results into container
2023-04-24 21:37:00,999:INFO:Uploading model into container now
2023-04-24 21:37:01,000:INFO:_master_model_container: 2
2023-04-24 21:37:01,000:INFO:_display_container: 2
2023-04-24 21:37:01,000:INFO:Lasso(random_state=3041)
2023-04-24 21:37:01,000:INFO:create_model() successfully completed......................................
2023-04-24 21:37:01,095:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:01,095:INFO:Creating metrics dataframe
2023-04-24 21:37:01,105:INFO:Initializing Ridge Regression
2023-04-24 21:37:01,105:INFO:Total runtime is 0.027035653591156006 minutes
2023-04-24 21:37:01,107:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:01,107:INFO:Initializing create_model()
2023-04-24 21:37:01,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:01,107:INFO:Checking exceptions
2023-04-24 21:37:01,107:INFO:Importing libraries
2023-04-24 21:37:01,107:INFO:Copying training dataset
2023-04-24 21:37:01,112:INFO:Defining folds
2023-04-24 21:37:01,112:INFO:Declaring metric variables
2023-04-24 21:37:01,116:INFO:Importing untrained model
2023-04-24 21:37:01,122:INFO:Ridge Regression Imported successfully
2023-04-24 21:37:01,130:INFO:Starting cross validation
2023-04-24 21:37:01,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:01,712:INFO:Calculating mean and std
2023-04-24 21:37:01,714:INFO:Creating metrics dataframe
2023-04-24 21:37:01,789:INFO:Uploading results into container
2023-04-24 21:37:01,790:INFO:Uploading model into container now
2023-04-24 21:37:01,790:INFO:_master_model_container: 3
2023-04-24 21:37:01,790:INFO:_display_container: 2
2023-04-24 21:37:01,790:INFO:Ridge(random_state=3041)
2023-04-24 21:37:01,790:INFO:create_model() successfully completed......................................
2023-04-24 21:37:01,888:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:01,888:INFO:Creating metrics dataframe
2023-04-24 21:37:01,895:INFO:Initializing Elastic Net
2023-04-24 21:37:01,895:INFO:Total runtime is 0.0402039368947347 minutes
2023-04-24 21:37:01,897:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:01,898:INFO:Initializing create_model()
2023-04-24 21:37:01,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:01,898:INFO:Checking exceptions
2023-04-24 21:37:01,898:INFO:Importing libraries
2023-04-24 21:37:01,898:INFO:Copying training dataset
2023-04-24 21:37:01,903:INFO:Defining folds
2023-04-24 21:37:01,903:INFO:Declaring metric variables
2023-04-24 21:37:01,907:INFO:Importing untrained model
2023-04-24 21:37:01,913:INFO:Elastic Net Imported successfully
2023-04-24 21:37:01,919:INFO:Starting cross validation
2023-04-24 21:37:01,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:02,579:INFO:Calculating mean and std
2023-04-24 21:37:02,581:INFO:Creating metrics dataframe
2023-04-24 21:37:02,666:INFO:Uploading results into container
2023-04-24 21:37:02,666:INFO:Uploading model into container now
2023-04-24 21:37:02,667:INFO:_master_model_container: 4
2023-04-24 21:37:02,667:INFO:_display_container: 2
2023-04-24 21:37:02,667:INFO:ElasticNet(random_state=3041)
2023-04-24 21:37:02,667:INFO:create_model() successfully completed......................................
2023-04-24 21:37:02,772:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:02,772:INFO:Creating metrics dataframe
2023-04-24 21:37:02,778:INFO:Initializing Least Angle Regression
2023-04-24 21:37:02,778:INFO:Total runtime is 0.05493295987447103 minutes
2023-04-24 21:37:02,782:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:02,783:INFO:Initializing create_model()
2023-04-24 21:37:02,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:02,783:INFO:Checking exceptions
2023-04-24 21:37:02,783:INFO:Importing libraries
2023-04-24 21:37:02,783:INFO:Copying training dataset
2023-04-24 21:37:02,789:INFO:Defining folds
2023-04-24 21:37:02,789:INFO:Declaring metric variables
2023-04-24 21:37:02,793:INFO:Importing untrained model
2023-04-24 21:37:02,813:INFO:Least Angle Regression Imported successfully
2023-04-24 21:37:02,823:INFO:Starting cross validation
2023-04-24 21:37:02,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:02,875:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,879:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,892:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,897:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,900:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,912:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,930:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:02,934:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:03,059:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:03,064:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:03,420:INFO:Calculating mean and std
2023-04-24 21:37:03,422:INFO:Creating metrics dataframe
2023-04-24 21:37:03,503:INFO:Uploading results into container
2023-04-24 21:37:03,504:INFO:Uploading model into container now
2023-04-24 21:37:03,504:INFO:_master_model_container: 5
2023-04-24 21:37:03,504:INFO:_display_container: 2
2023-04-24 21:37:03,504:INFO:Lars(random_state=3041)
2023-04-24 21:37:03,505:INFO:create_model() successfully completed......................................
2023-04-24 21:37:03,603:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:03,603:INFO:Creating metrics dataframe
2023-04-24 21:37:03,610:INFO:Initializing Lasso Least Angle Regression
2023-04-24 21:37:03,610:INFO:Total runtime is 0.068793253103892 minutes
2023-04-24 21:37:03,612:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:03,613:INFO:Initializing create_model()
2023-04-24 21:37:03,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:03,613:INFO:Checking exceptions
2023-04-24 21:37:03,613:INFO:Importing libraries
2023-04-24 21:37:03,613:INFO:Copying training dataset
2023-04-24 21:37:03,619:INFO:Defining folds
2023-04-24 21:37:03,619:INFO:Declaring metric variables
2023-04-24 21:37:03,622:INFO:Importing untrained model
2023-04-24 21:37:03,629:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 21:37:03,637:INFO:Starting cross validation
2023-04-24 21:37:03,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:03,680:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,686:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,703:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,705:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,717:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,725:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,732:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,743:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,872:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:03,881:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:37:04,302:INFO:Calculating mean and std
2023-04-24 21:37:04,304:INFO:Creating metrics dataframe
2023-04-24 21:37:04,379:INFO:Uploading results into container
2023-04-24 21:37:04,380:INFO:Uploading model into container now
2023-04-24 21:37:04,380:INFO:_master_model_container: 6
2023-04-24 21:37:04,380:INFO:_display_container: 2
2023-04-24 21:37:04,380:INFO:LassoLars(random_state=3041)
2023-04-24 21:37:04,380:INFO:create_model() successfully completed......................................
2023-04-24 21:37:04,482:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:04,482:INFO:Creating metrics dataframe
2023-04-24 21:37:04,490:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 21:37:04,490:INFO:Total runtime is 0.08345317045847575 minutes
2023-04-24 21:37:04,493:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:04,493:INFO:Initializing create_model()
2023-04-24 21:37:04,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:04,494:INFO:Checking exceptions
2023-04-24 21:37:04,494:INFO:Importing libraries
2023-04-24 21:37:04,494:INFO:Copying training dataset
2023-04-24 21:37:04,501:INFO:Defining folds
2023-04-24 21:37:04,501:INFO:Declaring metric variables
2023-04-24 21:37:04,505:INFO:Importing untrained model
2023-04-24 21:37:04,511:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 21:37:04,519:INFO:Starting cross validation
2023-04-24 21:37:04,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:04,569:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,570:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,578:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,587:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,602:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,612:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,613:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,626:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,761:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:04,764:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:37:05,140:INFO:Calculating mean and std
2023-04-24 21:37:05,142:INFO:Creating metrics dataframe
2023-04-24 21:37:05,221:INFO:Uploading results into container
2023-04-24 21:37:05,222:INFO:Uploading model into container now
2023-04-24 21:37:05,222:INFO:_master_model_container: 7
2023-04-24 21:37:05,222:INFO:_display_container: 2
2023-04-24 21:37:05,223:INFO:OrthogonalMatchingPursuit()
2023-04-24 21:37:05,223:INFO:create_model() successfully completed......................................
2023-04-24 21:37:05,325:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:05,325:INFO:Creating metrics dataframe
2023-04-24 21:37:05,334:INFO:Initializing Bayesian Ridge
2023-04-24 21:37:05,334:INFO:Total runtime is 0.09753382603327433 minutes
2023-04-24 21:37:05,338:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:05,338:INFO:Initializing create_model()
2023-04-24 21:37:05,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:05,339:INFO:Checking exceptions
2023-04-24 21:37:05,339:INFO:Importing libraries
2023-04-24 21:37:05,339:INFO:Copying training dataset
2023-04-24 21:37:05,343:INFO:Defining folds
2023-04-24 21:37:05,343:INFO:Declaring metric variables
2023-04-24 21:37:05,347:INFO:Importing untrained model
2023-04-24 21:37:05,354:INFO:Bayesian Ridge Imported successfully
2023-04-24 21:37:05,359:INFO:Starting cross validation
2023-04-24 21:37:05,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:05,988:INFO:Calculating mean and std
2023-04-24 21:37:05,989:INFO:Creating metrics dataframe
2023-04-24 21:37:06,066:INFO:Uploading results into container
2023-04-24 21:37:06,068:INFO:Uploading model into container now
2023-04-24 21:37:06,068:INFO:_master_model_container: 8
2023-04-24 21:37:06,069:INFO:_display_container: 2
2023-04-24 21:37:06,070:INFO:BayesianRidge()
2023-04-24 21:37:06,070:INFO:create_model() successfully completed......................................
2023-04-24 21:37:06,167:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:06,167:INFO:Creating metrics dataframe
2023-04-24 21:37:06,175:INFO:Initializing Passive Aggressive Regressor
2023-04-24 21:37:06,175:INFO:Total runtime is 0.11154871781667074 minutes
2023-04-24 21:37:06,178:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:06,178:INFO:Initializing create_model()
2023-04-24 21:37:06,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:06,179:INFO:Checking exceptions
2023-04-24 21:37:06,179:INFO:Importing libraries
2023-04-24 21:37:06,179:INFO:Copying training dataset
2023-04-24 21:37:06,183:INFO:Defining folds
2023-04-24 21:37:06,183:INFO:Declaring metric variables
2023-04-24 21:37:06,186:INFO:Importing untrained model
2023-04-24 21:37:06,194:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 21:37:06,203:INFO:Starting cross validation
2023-04-24 21:37:06,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:06,822:INFO:Calculating mean and std
2023-04-24 21:37:06,825:INFO:Creating metrics dataframe
2023-04-24 21:37:06,901:INFO:Uploading results into container
2023-04-24 21:37:06,901:INFO:Uploading model into container now
2023-04-24 21:37:06,901:INFO:_master_model_container: 9
2023-04-24 21:37:06,902:INFO:_display_container: 2
2023-04-24 21:37:06,902:INFO:PassiveAggressiveRegressor(random_state=3041)
2023-04-24 21:37:06,902:INFO:create_model() successfully completed......................................
2023-04-24 21:37:06,997:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:06,997:INFO:Creating metrics dataframe
2023-04-24 21:37:07,007:INFO:Initializing Huber Regressor
2023-04-24 21:37:07,007:INFO:Total runtime is 0.1254153331120809 minutes
2023-04-24 21:37:07,009:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:07,010:INFO:Initializing create_model()
2023-04-24 21:37:07,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:07,010:INFO:Checking exceptions
2023-04-24 21:37:07,010:INFO:Importing libraries
2023-04-24 21:37:07,010:INFO:Copying training dataset
2023-04-24 21:37:07,014:INFO:Defining folds
2023-04-24 21:37:07,014:INFO:Declaring metric variables
2023-04-24 21:37:07,018:INFO:Importing untrained model
2023-04-24 21:37:07,022:INFO:Huber Regressor Imported successfully
2023-04-24 21:37:07,030:INFO:Starting cross validation
2023-04-24 21:37:07,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:07,626:INFO:Calculating mean and std
2023-04-24 21:37:07,627:INFO:Creating metrics dataframe
2023-04-24 21:37:07,701:INFO:Uploading results into container
2023-04-24 21:37:07,702:INFO:Uploading model into container now
2023-04-24 21:37:07,702:INFO:_master_model_container: 10
2023-04-24 21:37:07,702:INFO:_display_container: 2
2023-04-24 21:37:07,702:INFO:HuberRegressor()
2023-04-24 21:37:07,702:INFO:create_model() successfully completed......................................
2023-04-24 21:37:07,801:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:07,801:INFO:Creating metrics dataframe
2023-04-24 21:37:07,809:INFO:Initializing K Neighbors Regressor
2023-04-24 21:37:07,809:INFO:Total runtime is 0.13876885573069253 minutes
2023-04-24 21:37:07,813:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:07,813:INFO:Initializing create_model()
2023-04-24 21:37:07,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:07,813:INFO:Checking exceptions
2023-04-24 21:37:07,813:INFO:Importing libraries
2023-04-24 21:37:07,813:INFO:Copying training dataset
2023-04-24 21:37:07,817:INFO:Defining folds
2023-04-24 21:37:07,817:INFO:Declaring metric variables
2023-04-24 21:37:07,823:INFO:Importing untrained model
2023-04-24 21:37:07,827:INFO:K Neighbors Regressor Imported successfully
2023-04-24 21:37:07,833:INFO:Starting cross validation
2023-04-24 21:37:07,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:08,441:INFO:Calculating mean and std
2023-04-24 21:37:08,442:INFO:Creating metrics dataframe
2023-04-24 21:37:08,519:INFO:Uploading results into container
2023-04-24 21:37:08,519:INFO:Uploading model into container now
2023-04-24 21:37:08,520:INFO:_master_model_container: 11
2023-04-24 21:37:08,520:INFO:_display_container: 2
2023-04-24 21:37:08,520:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 21:37:08,520:INFO:create_model() successfully completed......................................
2023-04-24 21:37:08,618:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:08,618:INFO:Creating metrics dataframe
2023-04-24 21:37:08,628:INFO:Initializing Decision Tree Regressor
2023-04-24 21:37:08,628:INFO:Total runtime is 0.15242467323939005 minutes
2023-04-24 21:37:08,631:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:08,631:INFO:Initializing create_model()
2023-04-24 21:37:08,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:08,631:INFO:Checking exceptions
2023-04-24 21:37:08,631:INFO:Importing libraries
2023-04-24 21:37:08,631:INFO:Copying training dataset
2023-04-24 21:37:08,637:INFO:Defining folds
2023-04-24 21:37:08,637:INFO:Declaring metric variables
2023-04-24 21:37:08,640:INFO:Importing untrained model
2023-04-24 21:37:08,644:INFO:Decision Tree Regressor Imported successfully
2023-04-24 21:37:08,651:INFO:Starting cross validation
2023-04-24 21:37:08,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:09,242:INFO:Calculating mean and std
2023-04-24 21:37:09,242:INFO:Creating metrics dataframe
2023-04-24 21:37:09,313:INFO:Uploading results into container
2023-04-24 21:37:09,313:INFO:Uploading model into container now
2023-04-24 21:37:09,314:INFO:_master_model_container: 12
2023-04-24 21:37:09,314:INFO:_display_container: 2
2023-04-24 21:37:09,314:INFO:DecisionTreeRegressor(random_state=3041)
2023-04-24 21:37:09,314:INFO:create_model() successfully completed......................................
2023-04-24 21:37:09,410:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:09,410:INFO:Creating metrics dataframe
2023-04-24 21:37:09,420:INFO:Initializing Random Forest Regressor
2023-04-24 21:37:09,421:INFO:Total runtime is 0.16564358870188395 minutes
2023-04-24 21:37:09,423:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:09,423:INFO:Initializing create_model()
2023-04-24 21:37:09,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:09,423:INFO:Checking exceptions
2023-04-24 21:37:09,423:INFO:Importing libraries
2023-04-24 21:37:09,423:INFO:Copying training dataset
2023-04-24 21:37:09,427:INFO:Defining folds
2023-04-24 21:37:09,428:INFO:Declaring metric variables
2023-04-24 21:37:09,431:INFO:Importing untrained model
2023-04-24 21:37:09,434:INFO:Random Forest Regressor Imported successfully
2023-04-24 21:37:09,445:INFO:Starting cross validation
2023-04-24 21:37:09,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:10,667:INFO:Calculating mean and std
2023-04-24 21:37:10,668:INFO:Creating metrics dataframe
2023-04-24 21:37:10,742:INFO:Uploading results into container
2023-04-24 21:37:10,743:INFO:Uploading model into container now
2023-04-24 21:37:10,744:INFO:_master_model_container: 13
2023-04-24 21:37:10,744:INFO:_display_container: 2
2023-04-24 21:37:10,745:INFO:RandomForestRegressor(n_jobs=-1, random_state=3041)
2023-04-24 21:37:10,745:INFO:create_model() successfully completed......................................
2023-04-24 21:37:10,842:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:10,842:INFO:Creating metrics dataframe
2023-04-24 21:37:10,850:INFO:Initializing Extra Trees Regressor
2023-04-24 21:37:10,850:INFO:Total runtime is 0.18946038087209066 minutes
2023-04-24 21:37:10,852:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:10,853:INFO:Initializing create_model()
2023-04-24 21:37:10,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:10,853:INFO:Checking exceptions
2023-04-24 21:37:10,853:INFO:Importing libraries
2023-04-24 21:37:10,853:INFO:Copying training dataset
2023-04-24 21:37:10,858:INFO:Defining folds
2023-04-24 21:37:10,858:INFO:Declaring metric variables
2023-04-24 21:37:10,861:INFO:Importing untrained model
2023-04-24 21:37:10,866:INFO:Extra Trees Regressor Imported successfully
2023-04-24 21:37:10,874:INFO:Starting cross validation
2023-04-24 21:37:10,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:12,110:INFO:Calculating mean and std
2023-04-24 21:37:12,111:INFO:Creating metrics dataframe
2023-04-24 21:37:12,189:INFO:Uploading results into container
2023-04-24 21:37:12,190:INFO:Uploading model into container now
2023-04-24 21:37:12,190:INFO:_master_model_container: 14
2023-04-24 21:37:12,190:INFO:_display_container: 2
2023-04-24 21:37:12,190:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3041)
2023-04-24 21:37:12,190:INFO:create_model() successfully completed......................................
2023-04-24 21:37:12,286:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:12,287:INFO:Creating metrics dataframe
2023-04-24 21:37:12,296:INFO:Initializing AdaBoost Regressor
2023-04-24 21:37:12,296:INFO:Total runtime is 0.21356123685836792 minutes
2023-04-24 21:37:12,300:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:12,300:INFO:Initializing create_model()
2023-04-24 21:37:12,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:12,300:INFO:Checking exceptions
2023-04-24 21:37:12,300:INFO:Importing libraries
2023-04-24 21:37:12,300:INFO:Copying training dataset
2023-04-24 21:37:12,304:INFO:Defining folds
2023-04-24 21:37:12,304:INFO:Declaring metric variables
2023-04-24 21:37:12,307:INFO:Importing untrained model
2023-04-24 21:37:12,312:INFO:AdaBoost Regressor Imported successfully
2023-04-24 21:37:12,321:INFO:Starting cross validation
2023-04-24 21:37:12,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:12,972:INFO:Calculating mean and std
2023-04-24 21:37:12,975:INFO:Creating metrics dataframe
2023-04-24 21:37:13,054:INFO:Uploading results into container
2023-04-24 21:37:13,054:INFO:Uploading model into container now
2023-04-24 21:37:13,054:INFO:_master_model_container: 15
2023-04-24 21:37:13,055:INFO:_display_container: 2
2023-04-24 21:37:13,055:INFO:AdaBoostRegressor(random_state=3041)
2023-04-24 21:37:13,055:INFO:create_model() successfully completed......................................
2023-04-24 21:37:13,152:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:13,152:INFO:Creating metrics dataframe
2023-04-24 21:37:13,162:INFO:Initializing Gradient Boosting Regressor
2023-04-24 21:37:13,162:INFO:Total runtime is 0.22799475193023683 minutes
2023-04-24 21:37:13,165:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:13,165:INFO:Initializing create_model()
2023-04-24 21:37:13,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:13,165:INFO:Checking exceptions
2023-04-24 21:37:13,166:INFO:Importing libraries
2023-04-24 21:37:13,166:INFO:Copying training dataset
2023-04-24 21:37:13,170:INFO:Defining folds
2023-04-24 21:37:13,170:INFO:Declaring metric variables
2023-04-24 21:37:13,172:INFO:Importing untrained model
2023-04-24 21:37:13,176:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:13,185:INFO:Starting cross validation
2023-04-24 21:37:13,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:13,981:INFO:Calculating mean and std
2023-04-24 21:37:13,983:INFO:Creating metrics dataframe
2023-04-24 21:37:14,066:INFO:Uploading results into container
2023-04-24 21:37:14,066:INFO:Uploading model into container now
2023-04-24 21:37:14,066:INFO:_master_model_container: 16
2023-04-24 21:37:14,066:INFO:_display_container: 2
2023-04-24 21:37:14,067:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:14,067:INFO:create_model() successfully completed......................................
2023-04-24 21:37:14,183:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:14,183:INFO:Creating metrics dataframe
2023-04-24 21:37:14,194:INFO:Initializing Extreme Gradient Boosting
2023-04-24 21:37:14,195:INFO:Total runtime is 0.24520248969395958 minutes
2023-04-24 21:37:14,197:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:14,198:INFO:Initializing create_model()
2023-04-24 21:37:14,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:14,198:INFO:Checking exceptions
2023-04-24 21:37:14,198:INFO:Importing libraries
2023-04-24 21:37:14,198:INFO:Copying training dataset
2023-04-24 21:37:14,207:INFO:Defining folds
2023-04-24 21:37:14,208:INFO:Declaring metric variables
2023-04-24 21:37:14,217:INFO:Importing untrained model
2023-04-24 21:37:14,226:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 21:37:14,234:INFO:Starting cross validation
2023-04-24 21:37:14,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:15,170:INFO:Calculating mean and std
2023-04-24 21:37:15,171:INFO:Creating metrics dataframe
2023-04-24 21:37:15,267:INFO:Uploading results into container
2023-04-24 21:37:15,267:INFO:Uploading model into container now
2023-04-24 21:37:15,268:INFO:_master_model_container: 17
2023-04-24 21:37:15,268:INFO:_display_container: 2
2023-04-24 21:37:15,269:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3041, ...)
2023-04-24 21:37:15,269:INFO:create_model() successfully completed......................................
2023-04-24 21:37:15,388:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:15,389:INFO:Creating metrics dataframe
2023-04-24 21:37:15,399:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 21:37:15,399:INFO:Total runtime is 0.265280822912852 minutes
2023-04-24 21:37:15,402:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:15,402:INFO:Initializing create_model()
2023-04-24 21:37:15,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:15,402:INFO:Checking exceptions
2023-04-24 21:37:15,402:INFO:Importing libraries
2023-04-24 21:37:15,402:INFO:Copying training dataset
2023-04-24 21:37:15,406:INFO:Defining folds
2023-04-24 21:37:15,406:INFO:Declaring metric variables
2023-04-24 21:37:15,409:INFO:Importing untrained model
2023-04-24 21:37:15,412:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 21:37:15,420:INFO:Starting cross validation
2023-04-24 21:37:15,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:16,198:INFO:Calculating mean and std
2023-04-24 21:37:16,201:INFO:Creating metrics dataframe
2023-04-24 21:37:16,300:INFO:Uploading results into container
2023-04-24 21:37:16,301:INFO:Uploading model into container now
2023-04-24 21:37:16,301:INFO:_master_model_container: 18
2023-04-24 21:37:16,301:INFO:_display_container: 2
2023-04-24 21:37:16,302:INFO:LGBMRegressor(random_state=3041)
2023-04-24 21:37:16,302:INFO:create_model() successfully completed......................................
2023-04-24 21:37:16,409:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:16,409:INFO:Creating metrics dataframe
2023-04-24 21:37:16,418:INFO:Initializing Dummy Regressor
2023-04-24 21:37:16,418:INFO:Total runtime is 0.2822669863700867 minutes
2023-04-24 21:37:16,421:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:16,421:INFO:Initializing create_model()
2023-04-24 21:37:16,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CCA650>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:16,421:INFO:Checking exceptions
2023-04-24 21:37:16,421:INFO:Importing libraries
2023-04-24 21:37:16,422:INFO:Copying training dataset
2023-04-24 21:37:16,427:INFO:Defining folds
2023-04-24 21:37:16,427:INFO:Declaring metric variables
2023-04-24 21:37:16,430:INFO:Importing untrained model
2023-04-24 21:37:16,435:INFO:Dummy Regressor Imported successfully
2023-04-24 21:37:16,445:INFO:Starting cross validation
2023-04-24 21:37:16,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:17,133:INFO:Calculating mean and std
2023-04-24 21:37:17,134:INFO:Creating metrics dataframe
2023-04-24 21:37:17,224:INFO:Uploading results into container
2023-04-24 21:37:17,225:INFO:Uploading model into container now
2023-04-24 21:37:17,225:INFO:_master_model_container: 19
2023-04-24 21:37:17,225:INFO:_display_container: 2
2023-04-24 21:37:17,225:INFO:DummyRegressor()
2023-04-24 21:37:17,225:INFO:create_model() successfully completed......................................
2023-04-24 21:37:17,337:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:17,337:INFO:Creating metrics dataframe
2023-04-24 21:37:17,362:INFO:Initializing create_model()
2023-04-24 21:37:17,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:17,362:INFO:Checking exceptions
2023-04-24 21:37:17,364:INFO:Importing libraries
2023-04-24 21:37:17,364:INFO:Copying training dataset
2023-04-24 21:37:17,366:INFO:Defining folds
2023-04-24 21:37:17,366:INFO:Declaring metric variables
2023-04-24 21:37:17,367:INFO:Importing untrained model
2023-04-24 21:37:17,367:INFO:Declaring custom model
2023-04-24 21:37:17,367:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:17,368:INFO:Cross validation set to False
2023-04-24 21:37:17,368:INFO:Fitting Model
2023-04-24 21:37:17,515:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:17,515:INFO:create_model() successfully completed......................................
2023-04-24 21:37:17,618:INFO:Creating Dashboard logs
2023-04-24 21:37:17,622:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:37:17,665:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:17,747:INFO:Initializing predict_model()
2023-04-24 21:37:17,748:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562E94AF0>)
2023-04-24 21:37:17,748:INFO:Checking exceptions
2023-04-24 21:37:17,748:INFO:Preloading libraries
2023-04-24 21:37:18,130:INFO:Creating Dashboard logs
2023-04-24 21:37:18,133:INFO:Model: Light Gradient Boosting Machine
2023-04-24 21:37:18,181:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 21:37:18,459:INFO:Creating Dashboard logs
2023-04-24 21:37:18,462:INFO:Model: Random Forest Regressor
2023-04-24 21:37:18,521:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:18,786:INFO:Creating Dashboard logs
2023-04-24 21:37:18,789:INFO:Model: K Neighbors Regressor
2023-04-24 21:37:18,831:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 21:37:19,132:INFO:Creating Dashboard logs
2023-04-24 21:37:19,137:INFO:Model: AdaBoost Regressor
2023-04-24 21:37:19,181:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 3041}
2023-04-24 21:37:19,443:INFO:Creating Dashboard logs
2023-04-24 21:37:19,446:INFO:Model: Extra Trees Regressor
2023-04-24 21:37:19,494:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:19,760:INFO:Creating Dashboard logs
2023-04-24 21:37:19,762:INFO:Model: Extreme Gradient Boosting
2023-04-24 21:37:19,807:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 3041, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-24 21:37:20,098:INFO:Creating Dashboard logs
2023-04-24 21:37:20,101:INFO:Model: Lasso Least Angle Regression
2023-04-24 21:37:20,149:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 3041, 'verbose': False}
2023-04-24 21:37:20,448:INFO:Creating Dashboard logs
2023-04-24 21:37:20,451:INFO:Model: Bayesian Ridge
2023-04-24 21:37:20,494:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 21:37:20,811:INFO:Creating Dashboard logs
2023-04-24 21:37:20,814:INFO:Model: Ridge Regression
2023-04-24 21:37:20,858:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 3041, 'solver': 'auto', 'tol': 0.001}
2023-04-24 21:37:21,115:INFO:Creating Dashboard logs
2023-04-24 21:37:21,117:INFO:Model: Least Angle Regression
2023-04-24 21:37:21,159:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 3041, 'verbose': False}
2023-04-24 21:37:21,420:INFO:Creating Dashboard logs
2023-04-24 21:37:21,423:INFO:Model: Linear Regression
2023-04-24 21:37:21,468:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 21:37:21,762:INFO:Creating Dashboard logs
2023-04-24 21:37:21,765:INFO:Model: Lasso Regression
2023-04-24 21:37:21,822:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 3041, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 21:37:22,087:INFO:Creating Dashboard logs
2023-04-24 21:37:22,090:INFO:Model: Elastic Net
2023-04-24 21:37:22,134:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 3041, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 21:37:22,439:INFO:Creating Dashboard logs
2023-04-24 21:37:22,441:INFO:Model: Decision Tree Regressor
2023-04-24 21:37:22,487:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 3041, 'splitter': 'best'}
2023-04-24 21:37:22,748:INFO:Creating Dashboard logs
2023-04-24 21:37:22,750:INFO:Model: Huber Regressor
2023-04-24 21:37:22,794:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 21:37:23,057:INFO:Creating Dashboard logs
2023-04-24 21:37:23,061:INFO:Model: Passive Aggressive Regressor
2023-04-24 21:37:23,106:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 3041, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:23,406:INFO:Creating Dashboard logs
2023-04-24 21:37:23,409:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 21:37:23,455:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 21:37:23,705:INFO:Creating Dashboard logs
2023-04-24 21:37:23,708:INFO:Model: Dummy Regressor
2023-04-24 21:37:23,751:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 21:37:24,009:INFO:_master_model_container: 19
2023-04-24 21:37:24,009:INFO:_display_container: 2
2023-04-24 21:37:24,009:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:24,009:INFO:compare_models() successfully completed......................................
2023-04-24 21:37:24,023:INFO:Initializing create_model()
2023-04-24 21:37:24,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:24,023:INFO:Checking exceptions
2023-04-24 21:37:24,050:INFO:Importing libraries
2023-04-24 21:37:24,050:INFO:Copying training dataset
2023-04-24 21:37:24,054:INFO:Defining folds
2023-04-24 21:37:24,054:INFO:Declaring metric variables
2023-04-24 21:37:24,062:INFO:Importing untrained model
2023-04-24 21:37:24,065:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:24,073:INFO:Starting cross validation
2023-04-24 21:37:24,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:24,917:INFO:Calculating mean and std
2023-04-24 21:37:24,917:INFO:Creating metrics dataframe
2023-04-24 21:37:24,921:INFO:Finalizing model
2023-04-24 21:37:25,081:INFO:Creating Dashboard logs
2023-04-24 21:37:25,084:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:37:25,132:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:25,228:INFO:Initializing predict_model()
2023-04-24 21:37:25,228:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562E95120>)
2023-04-24 21:37:25,229:INFO:Checking exceptions
2023-04-24 21:37:25,229:INFO:Preloading libraries
2023-04-24 21:37:25,554:INFO:Uploading results into container
2023-04-24 21:37:25,555:INFO:Uploading model into container now
2023-04-24 21:37:25,565:INFO:_master_model_container: 20
2023-04-24 21:37:25,565:INFO:_display_container: 3
2023-04-24 21:37:25,566:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:25,566:INFO:create_model() successfully completed......................................
2023-04-24 21:37:25,704:INFO:Initializing create_model()
2023-04-24 21:37:25,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:25,704:INFO:Checking exceptions
2023-04-24 21:37:25,738:INFO:Importing libraries
2023-04-24 21:37:25,738:INFO:Copying training dataset
2023-04-24 21:37:25,742:INFO:Defining folds
2023-04-24 21:37:25,742:INFO:Declaring metric variables
2023-04-24 21:37:25,745:INFO:Importing untrained model
2023-04-24 21:37:25,750:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:25,758:INFO:Starting cross validation
2023-04-24 21:37:25,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:26,603:INFO:Calculating mean and std
2023-04-24 21:37:26,604:INFO:Creating metrics dataframe
2023-04-24 21:37:26,610:INFO:Finalizing model
2023-04-24 21:37:26,758:INFO:Creating Dashboard logs
2023-04-24 21:37:26,761:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:37:26,804:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:26,876:INFO:Initializing predict_model()
2023-04-24 21:37:26,876:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562E95360>)
2023-04-24 21:37:26,876:INFO:Checking exceptions
2023-04-24 21:37:26,876:INFO:Preloading libraries
2023-04-24 21:37:27,198:INFO:Uploading results into container
2023-04-24 21:37:27,200:INFO:Uploading model into container now
2023-04-24 21:37:27,207:INFO:_master_model_container: 21
2023-04-24 21:37:27,209:INFO:_display_container: 4
2023-04-24 21:37:27,209:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:27,209:INFO:create_model() successfully completed......................................
2023-04-24 21:37:27,346:INFO:Initializing tune_model()
2023-04-24 21:37:27,346:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=3041), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>)
2023-04-24 21:37:27,346:INFO:Checking exceptions
2023-04-24 21:37:27,373:INFO:Copying training dataset
2023-04-24 21:37:27,378:INFO:Checking base model
2023-04-24 21:37:27,378:INFO:Base model : Gradient Boosting Regressor
2023-04-24 21:37:27,382:INFO:Declaring metric variables
2023-04-24 21:37:27,385:INFO:Defining Hyperparameters
2023-04-24 21:37:27,487:INFO:Tuning with n_jobs=-1
2023-04-24 21:37:27,487:INFO:Initializing RandomizedSearchCV
2023-04-24 21:37:36,820:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.2}
2023-04-24 21:37:36,821:INFO:Hyperparameter search completed
2023-04-24 21:37:36,821:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:36,822:INFO:Initializing create_model()
2023-04-24 21:37:36,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56072C4F0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 20, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'log2', 'max_depth': 11, 'learning_rate': 0.2})
2023-04-24 21:37:36,822:INFO:Checking exceptions
2023-04-24 21:37:36,822:INFO:Importing libraries
2023-04-24 21:37:36,822:INFO:Copying training dataset
2023-04-24 21:37:36,825:INFO:Defining folds
2023-04-24 21:37:36,825:INFO:Declaring metric variables
2023-04-24 21:37:36,827:INFO:Importing untrained model
2023-04-24 21:37:36,828:INFO:Declaring custom model
2023-04-24 21:37:36,830:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:36,835:INFO:Starting cross validation
2023-04-24 21:37:36,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:37,663:INFO:Calculating mean and std
2023-04-24 21:37:37,664:INFO:Creating metrics dataframe
2023-04-24 21:37:37,669:INFO:Finalizing model
2023-04-24 21:37:37,792:INFO:Uploading results into container
2023-04-24 21:37:37,793:INFO:Uploading model into container now
2023-04-24 21:37:37,794:INFO:_master_model_container: 22
2023-04-24 21:37:37,794:INFO:_display_container: 5
2023-04-24 21:37:37,795:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=11, max_features='log2',
                          min_impurity_decrease=0.3, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=20,
                          random_state=3041, subsample=0.35)
2023-04-24 21:37:37,795:INFO:create_model() successfully completed......................................
2023-04-24 21:37:37,897:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:37,897:INFO:choose_better activated
2023-04-24 21:37:37,900:INFO:SubProcess create_model() called ==================================
2023-04-24 21:37:37,902:INFO:Initializing create_model()
2023-04-24 21:37:37,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:37:37,902:INFO:Checking exceptions
2023-04-24 21:37:37,903:INFO:Importing libraries
2023-04-24 21:37:37,903:INFO:Copying training dataset
2023-04-24 21:37:37,906:INFO:Defining folds
2023-04-24 21:37:37,906:INFO:Declaring metric variables
2023-04-24 21:37:37,906:INFO:Importing untrained model
2023-04-24 21:37:37,906:INFO:Declaring custom model
2023-04-24 21:37:37,907:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:37,907:INFO:Starting cross validation
2023-04-24 21:37:37,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:37:38,885:INFO:Calculating mean and std
2023-04-24 21:37:38,885:INFO:Creating metrics dataframe
2023-04-24 21:37:38,887:INFO:Finalizing model
2023-04-24 21:37:39,043:INFO:Uploading results into container
2023-04-24 21:37:39,044:INFO:Uploading model into container now
2023-04-24 21:37:39,044:INFO:_master_model_container: 23
2023-04-24 21:37:39,044:INFO:_display_container: 6
2023-04-24 21:37:39,045:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:39,045:INFO:create_model() successfully completed......................................
2023-04-24 21:37:39,165:INFO:SubProcess create_model() end ==================================
2023-04-24 21:37:39,166:INFO:GradientBoostingRegressor(random_state=3041) result for R2 is 0.8053
2023-04-24 21:37:39,166:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=11, max_features='log2',
                          min_impurity_decrease=0.3, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=20,
                          random_state=3041, subsample=0.35) result for R2 is 0.7864
2023-04-24 21:37:39,166:INFO:GradientBoostingRegressor(random_state=3041) is best model
2023-04-24 21:37:39,166:INFO:choose_better completed
2023-04-24 21:37:39,166:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 21:37:39,167:INFO:Creating Dashboard logs
2023-04-24 21:37:39,171:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:37:39,217:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:39,327:INFO:Initializing predict_model()
2023-04-24 21:37:39,327:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562E97010>)
2023-04-24 21:37:39,327:INFO:Checking exceptions
2023-04-24 21:37:39,327:INFO:Preloading libraries
2023-04-24 21:37:39,664:INFO:_master_model_container: 23
2023-04-24 21:37:39,664:INFO:_display_container: 5
2023-04-24 21:37:39,664:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:39,664:INFO:tune_model() successfully completed......................................
2023-04-24 21:37:39,862:INFO:Initializing plot_model()
2023-04-24 21:37:39,862:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:37:39,862:INFO:Checking exceptions
2023-04-24 21:37:39,866:INFO:Preloading libraries
2023-04-24 21:37:39,873:INFO:Copying training dataset
2023-04-24 21:37:39,873:INFO:Plot type: error
2023-04-24 21:37:39,940:INFO:Fitting Model
2023-04-24 21:37:39,940:INFO:Scoring test/hold-out set
2023-04-24 21:37:40,102:INFO:Visual Rendered Successfully
2023-04-24 21:37:40,199:INFO:plot_model() successfully completed......................................
2023-04-24 21:37:40,223:INFO:Initializing plot_model()
2023-04-24 21:37:40,223:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:37:40,223:INFO:Checking exceptions
2023-04-24 21:37:40,229:INFO:Preloading libraries
2023-04-24 21:37:40,235:INFO:Copying training dataset
2023-04-24 21:37:40,236:INFO:Plot type: feature
2023-04-24 21:37:40,236:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 21:37:40,372:INFO:Visual Rendered Successfully
2023-04-24 21:37:40,469:INFO:plot_model() successfully completed......................................
2023-04-24 21:37:40,491:INFO:Initializing predict_model()
2023-04-24 21:37:40,492:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56224A3B0>)
2023-04-24 21:37:40,492:INFO:Checking exceptions
2023-04-24 21:37:40,492:INFO:Preloading libraries
2023-04-24 21:37:40,645:INFO:Initializing finalize_model()
2023-04-24 21:37:40,646:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-24 21:37:40,646:INFO:Finalizing GradientBoostingRegressor(random_state=3041)
2023-04-24 21:37:40,650:INFO:Initializing create_model()
2023-04-24 21:37:40,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-24 21:37:40,652:INFO:Checking exceptions
2023-04-24 21:37:40,654:INFO:Importing libraries
2023-04-24 21:37:40,654:INFO:Copying training dataset
2023-04-24 21:37:40,654:INFO:Defining folds
2023-04-24 21:37:40,654:INFO:Declaring metric variables
2023-04-24 21:37:40,655:INFO:Importing untrained model
2023-04-24 21:37:40,655:INFO:Declaring custom model
2023-04-24 21:37:40,655:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:37:40,656:INFO:Cross validation set to False
2023-04-24 21:37:40,656:INFO:Fitting Model
2023-04-24 21:37:40,760:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=3041))])
2023-04-24 21:37:40,760:INFO:create_model() successfully completed......................................
2023-04-24 21:37:40,856:INFO:Creating Dashboard logs
2023-04-24 21:37:40,856:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:37:40,893:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:37:41,122:INFO:_master_model_container: 23
2023-04-24 21:37:41,122:INFO:_display_container: 6
2023-04-24 21:37:41,126:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=3041))])
2023-04-24 21:37:41,126:INFO:finalize_model() successfully completed......................................
2023-04-24 21:37:41,305:INFO:Initializing predict_model()
2023-04-24 21:37:41,305:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=3041))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56224B910>)
2023-04-24 21:37:41,305:INFO:Checking exceptions
2023-04-24 21:37:41,305:INFO:Preloading libraries
2023-04-24 21:37:41,306:INFO:Set up data.
2023-04-24 21:37:41,311:INFO:Set up index.
2023-04-24 21:39:36,025:INFO:Initializing evaluate_model()
2023-04-24 21:39:36,025:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-24 21:39:36,039:INFO:Initializing plot_model()
2023-04-24 21:39:36,039:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:39:36,039:INFO:Checking exceptions
2023-04-24 21:39:36,044:INFO:Preloading libraries
2023-04-24 21:39:36,053:INFO:Copying training dataset
2023-04-24 21:39:36,053:INFO:Plot type: pipeline
2023-04-24 21:39:44,148:INFO:Initializing plot_model()
2023-04-24 21:39:44,148:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:39:44,148:INFO:Checking exceptions
2023-04-24 21:39:44,151:INFO:Preloading libraries
2023-04-24 21:39:44,156:INFO:Copying training dataset
2023-04-24 21:39:44,156:INFO:Plot type: parameter
2023-04-24 21:39:44,163:INFO:Visual Rendered Successfully
2023-04-24 21:39:44,268:INFO:plot_model() successfully completed......................................
2023-04-24 21:39:46,424:INFO:Initializing plot_model()
2023-04-24 21:39:46,424:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:39:46,424:INFO:Checking exceptions
2023-04-24 21:39:46,425:INFO:Preloading libraries
2023-04-24 21:39:46,430:INFO:Copying training dataset
2023-04-24 21:39:46,430:INFO:Plot type: vc
2023-04-24 21:39:46,431:INFO:Determining param_name
2023-04-24 21:39:46,431:INFO:param_name: alpha
2023-04-24 21:39:46,565:INFO:Fitting Model
2023-04-24 21:39:47,875:INFO:Visual Rendered Successfully
2023-04-24 21:39:47,977:INFO:plot_model() successfully completed......................................
2023-04-24 21:39:47,994:INFO:Initializing plot_model()
2023-04-24 21:39:47,995:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:39:47,995:INFO:Checking exceptions
2023-04-24 21:39:47,997:INFO:Preloading libraries
2023-04-24 21:39:48,002:INFO:Copying training dataset
2023-04-24 21:39:48,002:INFO:Plot type: residuals
2023-04-24 21:39:48,066:INFO:Fitting Model
2023-04-24 21:39:48,099:INFO:Scoring test/hold-out set
2023-04-24 21:39:48,465:INFO:Visual Rendered Successfully
2023-04-24 21:39:48,594:INFO:plot_model() successfully completed......................................
2023-04-24 21:39:55,975:INFO:Initializing plot_model()
2023-04-24 21:39:55,975:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:39:55,975:INFO:Checking exceptions
2023-04-24 21:39:55,977:INFO:Preloading libraries
2023-04-24 21:39:55,982:INFO:Copying training dataset
2023-04-24 21:39:55,982:INFO:Plot type: parameter
2023-04-24 21:39:55,988:INFO:Visual Rendered Successfully
2023-04-24 21:39:56,085:INFO:plot_model() successfully completed......................................
2023-04-24 21:39:58,439:INFO:Initializing plot_model()
2023-04-24 21:39:58,439:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:39:58,439:INFO:Checking exceptions
2023-04-24 21:39:58,441:INFO:Preloading libraries
2023-04-24 21:39:58,446:INFO:Copying training dataset
2023-04-24 21:39:58,446:INFO:Plot type: error
2023-04-24 21:39:58,504:INFO:Fitting Model
2023-04-24 21:39:58,504:INFO:Scoring test/hold-out set
2023-04-24 21:39:58,662:INFO:Visual Rendered Successfully
2023-04-24 21:39:58,767:INFO:plot_model() successfully completed......................................
2023-04-24 21:40:00,400:INFO:Initializing plot_model()
2023-04-24 21:40:00,400:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:40:00,400:INFO:Checking exceptions
2023-04-24 21:40:00,403:INFO:Preloading libraries
2023-04-24 21:40:00,409:INFO:Copying training dataset
2023-04-24 21:40:00,410:INFO:Plot type: cooks
2023-04-24 21:40:00,479:INFO:Fitting Model
2023-04-24 21:40:00,672:INFO:Visual Rendered Successfully
2023-04-24 21:40:00,774:INFO:plot_model() successfully completed......................................
2023-04-24 21:40:02,392:INFO:Initializing plot_model()
2023-04-24 21:40:02,392:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:40:02,392:INFO:Checking exceptions
2023-04-24 21:40:02,395:INFO:Preloading libraries
2023-04-24 21:40:02,400:INFO:Copying training dataset
2023-04-24 21:40:02,400:INFO:Plot type: rfe
2023-04-24 21:40:02,459:INFO:Fitting Model
2023-04-24 21:40:14,187:INFO:Visual Rendered Successfully
2023-04-24 21:40:14,281:INFO:plot_model() successfully completed......................................
2023-04-24 21:40:14,314:INFO:Initializing plot_model()
2023-04-24 21:40:14,314:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 21:40:14,314:INFO:Checking exceptions
2023-04-24 21:40:14,316:INFO:Preloading libraries
2023-04-24 21:40:14,320:INFO:Copying training dataset
2023-04-24 21:40:14,320:INFO:Plot type: residuals_interactive
2023-04-24 21:40:14,453:INFO:Calculated model residuals
2023-04-24 21:40:18,959:INFO:Calculated Tunkey-Anscombe Plot
2023-04-24 21:40:19,123:INFO:Calculated Normal QQ Plot
2023-04-24 21:40:19,315:INFO:Calculated Scale-Location Plot
2023-04-24 21:40:19,585:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2023-04-24 21:40:19,757:INFO:Visual Rendered Successfully
2023-04-24 21:40:19,860:INFO:plot_model() successfully completed......................................
2023-04-24 21:49:11,162:INFO:Initializing compare_models()
2023-04-24 21:49:11,162:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 21:49:11,163:INFO:Checking exceptions
2023-04-24 21:49:11,166:INFO:Preparing display monitor
2023-04-24 21:49:11,204:INFO:Initializing Linear Regression
2023-04-24 21:49:11,204:INFO:Total runtime is 0.0 minutes
2023-04-24 21:49:11,210:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:11,211:INFO:Initializing create_model()
2023-04-24 21:49:11,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:11,211:INFO:Checking exceptions
2023-04-24 21:49:11,211:INFO:Importing libraries
2023-04-24 21:49:11,211:INFO:Copying training dataset
2023-04-24 21:49:11,220:INFO:Defining folds
2023-04-24 21:49:11,220:INFO:Declaring metric variables
2023-04-24 21:49:11,227:INFO:Importing untrained model
2023-04-24 21:49:11,232:INFO:Linear Regression Imported successfully
2023-04-24 21:49:11,238:INFO:Starting cross validation
2023-04-24 21:49:11,240:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:15,634:INFO:Calculating mean and std
2023-04-24 21:49:15,635:INFO:Creating metrics dataframe
2023-04-24 21:49:15,734:INFO:Uploading results into container
2023-04-24 21:49:15,736:INFO:Uploading model into container now
2023-04-24 21:49:15,736:INFO:_master_model_container: 24
2023-04-24 21:49:15,736:INFO:_display_container: 8
2023-04-24 21:49:15,737:INFO:LinearRegression(n_jobs=-1)
2023-04-24 21:49:15,737:INFO:create_model() successfully completed......................................
2023-04-24 21:49:15,862:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:15,862:INFO:Creating metrics dataframe
2023-04-24 21:49:15,868:INFO:Initializing Lasso Regression
2023-04-24 21:49:15,868:INFO:Total runtime is 0.07772742907206218 minutes
2023-04-24 21:49:15,871:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:15,871:INFO:Initializing create_model()
2023-04-24 21:49:15,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:15,871:INFO:Checking exceptions
2023-04-24 21:49:15,871:INFO:Importing libraries
2023-04-24 21:49:15,871:INFO:Copying training dataset
2023-04-24 21:49:15,875:INFO:Defining folds
2023-04-24 21:49:15,875:INFO:Declaring metric variables
2023-04-24 21:49:15,878:INFO:Importing untrained model
2023-04-24 21:49:15,881:INFO:Lasso Regression Imported successfully
2023-04-24 21:49:15,886:INFO:Starting cross validation
2023-04-24 21:49:15,887:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:17,576:INFO:Calculating mean and std
2023-04-24 21:49:17,578:INFO:Creating metrics dataframe
2023-04-24 21:49:17,684:INFO:Uploading results into container
2023-04-24 21:49:17,685:INFO:Uploading model into container now
2023-04-24 21:49:17,686:INFO:_master_model_container: 25
2023-04-24 21:49:17,686:INFO:_display_container: 8
2023-04-24 21:49:17,686:INFO:Lasso(random_state=3041)
2023-04-24 21:49:17,686:INFO:create_model() successfully completed......................................
2023-04-24 21:49:17,809:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:17,809:INFO:Creating metrics dataframe
2023-04-24 21:49:17,816:INFO:Initializing Ridge Regression
2023-04-24 21:49:17,816:INFO:Total runtime is 0.1101935108502706 minutes
2023-04-24 21:49:17,819:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:17,819:INFO:Initializing create_model()
2023-04-24 21:49:17,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:17,819:INFO:Checking exceptions
2023-04-24 21:49:17,819:INFO:Importing libraries
2023-04-24 21:49:17,819:INFO:Copying training dataset
2023-04-24 21:49:17,823:INFO:Defining folds
2023-04-24 21:49:17,823:INFO:Declaring metric variables
2023-04-24 21:49:17,825:INFO:Importing untrained model
2023-04-24 21:49:17,830:INFO:Ridge Regression Imported successfully
2023-04-24 21:49:17,836:INFO:Starting cross validation
2023-04-24 21:49:17,837:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:18,199:INFO:Calculating mean and std
2023-04-24 21:49:18,201:INFO:Creating metrics dataframe
2023-04-24 21:49:18,289:INFO:Uploading results into container
2023-04-24 21:49:18,289:INFO:Uploading model into container now
2023-04-24 21:49:18,290:INFO:_master_model_container: 26
2023-04-24 21:49:18,290:INFO:_display_container: 8
2023-04-24 21:49:18,290:INFO:Ridge(random_state=3041)
2023-04-24 21:49:18,290:INFO:create_model() successfully completed......................................
2023-04-24 21:49:18,392:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:18,392:INFO:Creating metrics dataframe
2023-04-24 21:49:18,400:INFO:Initializing Elastic Net
2023-04-24 21:49:18,400:INFO:Total runtime is 0.1199272394180298 minutes
2023-04-24 21:49:18,403:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:18,403:INFO:Initializing create_model()
2023-04-24 21:49:18,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:18,403:INFO:Checking exceptions
2023-04-24 21:49:18,403:INFO:Importing libraries
2023-04-24 21:49:18,403:INFO:Copying training dataset
2023-04-24 21:49:18,408:INFO:Defining folds
2023-04-24 21:49:18,408:INFO:Declaring metric variables
2023-04-24 21:49:18,412:INFO:Importing untrained model
2023-04-24 21:49:18,416:INFO:Elastic Net Imported successfully
2023-04-24 21:49:18,421:INFO:Starting cross validation
2023-04-24 21:49:18,422:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:18,787:INFO:Calculating mean and std
2023-04-24 21:49:18,789:INFO:Creating metrics dataframe
2023-04-24 21:49:18,884:INFO:Uploading results into container
2023-04-24 21:49:18,886:INFO:Uploading model into container now
2023-04-24 21:49:18,886:INFO:_master_model_container: 27
2023-04-24 21:49:18,887:INFO:_display_container: 8
2023-04-24 21:49:18,887:INFO:ElasticNet(random_state=3041)
2023-04-24 21:49:18,887:INFO:create_model() successfully completed......................................
2023-04-24 21:49:19,004:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:19,004:INFO:Creating metrics dataframe
2023-04-24 21:49:19,012:INFO:Initializing Least Angle Regression
2023-04-24 21:49:19,012:INFO:Total runtime is 0.13012900749842327 minutes
2023-04-24 21:49:19,014:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:19,014:INFO:Initializing create_model()
2023-04-24 21:49:19,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:19,014:INFO:Checking exceptions
2023-04-24 21:49:19,014:INFO:Importing libraries
2023-04-24 21:49:19,014:INFO:Copying training dataset
2023-04-24 21:49:19,019:INFO:Defining folds
2023-04-24 21:49:19,019:INFO:Declaring metric variables
2023-04-24 21:49:19,022:INFO:Importing untrained model
2023-04-24 21:49:19,025:INFO:Least Angle Regression Imported successfully
2023-04-24 21:49:19,030:INFO:Starting cross validation
2023-04-24 21:49:19,031:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:19,068:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:19,071:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:19,081:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:19,088:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:19,090:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:19,382:INFO:Calculating mean and std
2023-04-24 21:49:19,383:INFO:Creating metrics dataframe
2023-04-24 21:49:19,481:INFO:Uploading results into container
2023-04-24 21:49:19,482:INFO:Uploading model into container now
2023-04-24 21:49:19,482:INFO:_master_model_container: 28
2023-04-24 21:49:19,482:INFO:_display_container: 8
2023-04-24 21:49:19,482:INFO:Lars(random_state=3041)
2023-04-24 21:49:19,482:INFO:create_model() successfully completed......................................
2023-04-24 21:49:19,588:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:19,589:INFO:Creating metrics dataframe
2023-04-24 21:49:19,597:INFO:Initializing Lasso Least Angle Regression
2023-04-24 21:49:19,597:INFO:Total runtime is 0.13987730741500856 minutes
2023-04-24 21:49:19,600:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:19,600:INFO:Initializing create_model()
2023-04-24 21:49:19,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:19,601:INFO:Checking exceptions
2023-04-24 21:49:19,601:INFO:Importing libraries
2023-04-24 21:49:19,601:INFO:Copying training dataset
2023-04-24 21:49:19,604:INFO:Defining folds
2023-04-24 21:49:19,604:INFO:Declaring metric variables
2023-04-24 21:49:19,606:INFO:Importing untrained model
2023-04-24 21:49:19,610:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 21:49:19,616:INFO:Starting cross validation
2023-04-24 21:49:19,617:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:19,654:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:49:19,662:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:49:19,668:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:49:19,671:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:49:19,674:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 21:49:19,967:INFO:Calculating mean and std
2023-04-24 21:49:19,968:INFO:Creating metrics dataframe
2023-04-24 21:49:20,061:INFO:Uploading results into container
2023-04-24 21:49:20,062:INFO:Uploading model into container now
2023-04-24 21:49:20,062:INFO:_master_model_container: 29
2023-04-24 21:49:20,062:INFO:_display_container: 8
2023-04-24 21:49:20,062:INFO:LassoLars(random_state=3041)
2023-04-24 21:49:20,062:INFO:create_model() successfully completed......................................
2023-04-24 21:49:20,171:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:20,172:INFO:Creating metrics dataframe
2023-04-24 21:49:20,180:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 21:49:20,180:INFO:Total runtime is 0.14959837198257447 minutes
2023-04-24 21:49:20,182:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:20,182:INFO:Initializing create_model()
2023-04-24 21:49:20,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:20,182:INFO:Checking exceptions
2023-04-24 21:49:20,182:INFO:Importing libraries
2023-04-24 21:49:20,182:INFO:Copying training dataset
2023-04-24 21:49:20,186:INFO:Defining folds
2023-04-24 21:49:20,186:INFO:Declaring metric variables
2023-04-24 21:49:20,189:INFO:Importing untrained model
2023-04-24 21:49:20,193:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 21:49:20,199:INFO:Starting cross validation
2023-04-24 21:49:20,200:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:20,234:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:20,239:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:20,239:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:20,255:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:20,260:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 21:49:20,545:INFO:Calculating mean and std
2023-04-24 21:49:20,546:INFO:Creating metrics dataframe
2023-04-24 21:49:20,644:INFO:Uploading results into container
2023-04-24 21:49:20,645:INFO:Uploading model into container now
2023-04-24 21:49:20,645:INFO:_master_model_container: 30
2023-04-24 21:49:20,645:INFO:_display_container: 8
2023-04-24 21:49:20,645:INFO:OrthogonalMatchingPursuit()
2023-04-24 21:49:20,645:INFO:create_model() successfully completed......................................
2023-04-24 21:49:20,762:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:20,762:INFO:Creating metrics dataframe
2023-04-24 21:49:20,770:INFO:Initializing Bayesian Ridge
2023-04-24 21:49:20,770:INFO:Total runtime is 0.1594356934229533 minutes
2023-04-24 21:49:20,774:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:20,774:INFO:Initializing create_model()
2023-04-24 21:49:20,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:20,774:INFO:Checking exceptions
2023-04-24 21:49:20,774:INFO:Importing libraries
2023-04-24 21:49:20,774:INFO:Copying training dataset
2023-04-24 21:49:20,781:INFO:Defining folds
2023-04-24 21:49:20,781:INFO:Declaring metric variables
2023-04-24 21:49:20,784:INFO:Importing untrained model
2023-04-24 21:49:20,788:INFO:Bayesian Ridge Imported successfully
2023-04-24 21:49:20,799:INFO:Starting cross validation
2023-04-24 21:49:20,801:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:21,185:INFO:Calculating mean and std
2023-04-24 21:49:21,186:INFO:Creating metrics dataframe
2023-04-24 21:49:21,293:INFO:Uploading results into container
2023-04-24 21:49:21,293:INFO:Uploading model into container now
2023-04-24 21:49:21,293:INFO:_master_model_container: 31
2023-04-24 21:49:21,293:INFO:_display_container: 8
2023-04-24 21:49:21,294:INFO:BayesianRidge()
2023-04-24 21:49:21,294:INFO:create_model() successfully completed......................................
2023-04-24 21:49:21,406:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:21,406:INFO:Creating metrics dataframe
2023-04-24 21:49:21,416:INFO:Initializing Passive Aggressive Regressor
2023-04-24 21:49:21,416:INFO:Total runtime is 0.17019289334615073 minutes
2023-04-24 21:49:21,419:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:21,420:INFO:Initializing create_model()
2023-04-24 21:49:21,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:21,420:INFO:Checking exceptions
2023-04-24 21:49:21,420:INFO:Importing libraries
2023-04-24 21:49:21,421:INFO:Copying training dataset
2023-04-24 21:49:21,424:INFO:Defining folds
2023-04-24 21:49:21,424:INFO:Declaring metric variables
2023-04-24 21:49:21,427:INFO:Importing untrained model
2023-04-24 21:49:21,430:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 21:49:21,439:INFO:Starting cross validation
2023-04-24 21:49:21,441:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:21,796:INFO:Calculating mean and std
2023-04-24 21:49:21,797:INFO:Creating metrics dataframe
2023-04-24 21:49:21,901:INFO:Uploading results into container
2023-04-24 21:49:21,903:INFO:Uploading model into container now
2023-04-24 21:49:21,905:INFO:_master_model_container: 32
2023-04-24 21:49:21,906:INFO:_display_container: 8
2023-04-24 21:49:21,906:INFO:PassiveAggressiveRegressor(random_state=3041)
2023-04-24 21:49:21,907:INFO:create_model() successfully completed......................................
2023-04-24 21:49:22,016:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:22,016:INFO:Creating metrics dataframe
2023-04-24 21:49:22,024:INFO:Initializing Huber Regressor
2023-04-24 21:49:22,024:INFO:Total runtime is 0.1803324341773987 minutes
2023-04-24 21:49:22,028:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:22,028:INFO:Initializing create_model()
2023-04-24 21:49:22,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:22,028:INFO:Checking exceptions
2023-04-24 21:49:22,028:INFO:Importing libraries
2023-04-24 21:49:22,028:INFO:Copying training dataset
2023-04-24 21:49:22,032:INFO:Defining folds
2023-04-24 21:49:22,032:INFO:Declaring metric variables
2023-04-24 21:49:22,034:INFO:Importing untrained model
2023-04-24 21:49:22,038:INFO:Huber Regressor Imported successfully
2023-04-24 21:49:22,044:INFO:Starting cross validation
2023-04-24 21:49:22,044:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:22,437:INFO:Calculating mean and std
2023-04-24 21:49:22,439:INFO:Creating metrics dataframe
2023-04-24 21:49:22,535:INFO:Uploading results into container
2023-04-24 21:49:22,536:INFO:Uploading model into container now
2023-04-24 21:49:22,536:INFO:_master_model_container: 33
2023-04-24 21:49:22,536:INFO:_display_container: 8
2023-04-24 21:49:22,537:INFO:HuberRegressor()
2023-04-24 21:49:22,537:INFO:create_model() successfully completed......................................
2023-04-24 21:49:22,642:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:22,642:INFO:Creating metrics dataframe
2023-04-24 21:49:22,650:INFO:Initializing K Neighbors Regressor
2023-04-24 21:49:22,650:INFO:Total runtime is 0.19076933066050214 minutes
2023-04-24 21:49:22,653:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:22,653:INFO:Initializing create_model()
2023-04-24 21:49:22,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:22,653:INFO:Checking exceptions
2023-04-24 21:49:22,653:INFO:Importing libraries
2023-04-24 21:49:22,653:INFO:Copying training dataset
2023-04-24 21:49:22,658:INFO:Defining folds
2023-04-24 21:49:22,658:INFO:Declaring metric variables
2023-04-24 21:49:22,661:INFO:Importing untrained model
2023-04-24 21:49:22,665:INFO:K Neighbors Regressor Imported successfully
2023-04-24 21:49:22,670:INFO:Starting cross validation
2023-04-24 21:49:22,671:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:23,052:INFO:Calculating mean and std
2023-04-24 21:49:23,054:INFO:Creating metrics dataframe
2023-04-24 21:49:23,165:INFO:Uploading results into container
2023-04-24 21:49:23,165:INFO:Uploading model into container now
2023-04-24 21:49:23,167:INFO:_master_model_container: 34
2023-04-24 21:49:23,167:INFO:_display_container: 8
2023-04-24 21:49:23,167:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 21:49:23,168:INFO:create_model() successfully completed......................................
2023-04-24 21:49:23,323:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:23,324:INFO:Creating metrics dataframe
2023-04-24 21:49:23,334:INFO:Initializing Decision Tree Regressor
2023-04-24 21:49:23,334:INFO:Total runtime is 0.20216159820556642 minutes
2023-04-24 21:49:23,336:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:23,337:INFO:Initializing create_model()
2023-04-24 21:49:23,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:23,337:INFO:Checking exceptions
2023-04-24 21:49:23,337:INFO:Importing libraries
2023-04-24 21:49:23,337:INFO:Copying training dataset
2023-04-24 21:49:23,340:INFO:Defining folds
2023-04-24 21:49:23,340:INFO:Declaring metric variables
2023-04-24 21:49:23,344:INFO:Importing untrained model
2023-04-24 21:49:23,346:INFO:Decision Tree Regressor Imported successfully
2023-04-24 21:49:23,353:INFO:Starting cross validation
2023-04-24 21:49:23,355:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:23,750:INFO:Calculating mean and std
2023-04-24 21:49:23,752:INFO:Creating metrics dataframe
2023-04-24 21:49:23,861:INFO:Uploading results into container
2023-04-24 21:49:23,862:INFO:Uploading model into container now
2023-04-24 21:49:23,862:INFO:_master_model_container: 35
2023-04-24 21:49:23,862:INFO:_display_container: 8
2023-04-24 21:49:23,862:INFO:DecisionTreeRegressor(random_state=3041)
2023-04-24 21:49:23,863:INFO:create_model() successfully completed......................................
2023-04-24 21:49:23,986:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:23,987:INFO:Creating metrics dataframe
2023-04-24 21:49:23,996:INFO:Initializing Random Forest Regressor
2023-04-24 21:49:23,997:INFO:Total runtime is 0.21320875088373822 minutes
2023-04-24 21:49:24,003:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:24,003:INFO:Initializing create_model()
2023-04-24 21:49:24,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:24,003:INFO:Checking exceptions
2023-04-24 21:49:24,004:INFO:Importing libraries
2023-04-24 21:49:24,004:INFO:Copying training dataset
2023-04-24 21:49:24,007:INFO:Defining folds
2023-04-24 21:49:24,007:INFO:Declaring metric variables
2023-04-24 21:49:24,010:INFO:Importing untrained model
2023-04-24 21:49:24,016:INFO:Random Forest Regressor Imported successfully
2023-04-24 21:49:24,022:INFO:Starting cross validation
2023-04-24 21:49:24,023:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:24,887:INFO:Calculating mean and std
2023-04-24 21:49:24,889:INFO:Creating metrics dataframe
2023-04-24 21:49:24,988:INFO:Uploading results into container
2023-04-24 21:49:24,989:INFO:Uploading model into container now
2023-04-24 21:49:24,989:INFO:_master_model_container: 36
2023-04-24 21:49:24,989:INFO:_display_container: 8
2023-04-24 21:49:24,989:INFO:RandomForestRegressor(n_jobs=-1, random_state=3041)
2023-04-24 21:49:24,989:INFO:create_model() successfully completed......................................
2023-04-24 21:49:25,104:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:25,104:INFO:Creating metrics dataframe
2023-04-24 21:49:25,112:INFO:Initializing Extra Trees Regressor
2023-04-24 21:49:25,112:INFO:Total runtime is 0.23180278142293298 minutes
2023-04-24 21:49:25,118:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:25,119:INFO:Initializing create_model()
2023-04-24 21:49:25,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:25,119:INFO:Checking exceptions
2023-04-24 21:49:25,119:INFO:Importing libraries
2023-04-24 21:49:25,119:INFO:Copying training dataset
2023-04-24 21:49:25,124:INFO:Defining folds
2023-04-24 21:49:25,124:INFO:Declaring metric variables
2023-04-24 21:49:25,127:INFO:Importing untrained model
2023-04-24 21:49:25,131:INFO:Extra Trees Regressor Imported successfully
2023-04-24 21:49:25,136:INFO:Starting cross validation
2023-04-24 21:49:25,137:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:25,919:INFO:Calculating mean and std
2023-04-24 21:49:25,920:INFO:Creating metrics dataframe
2023-04-24 21:49:26,072:INFO:Uploading results into container
2023-04-24 21:49:26,073:INFO:Uploading model into container now
2023-04-24 21:49:26,073:INFO:_master_model_container: 37
2023-04-24 21:49:26,074:INFO:_display_container: 8
2023-04-24 21:49:26,074:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3041)
2023-04-24 21:49:26,074:INFO:create_model() successfully completed......................................
2023-04-24 21:49:26,212:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:26,212:INFO:Creating metrics dataframe
2023-04-24 21:49:26,222:INFO:Initializing AdaBoost Regressor
2023-04-24 21:49:26,222:INFO:Total runtime is 0.2502911925315857 minutes
2023-04-24 21:49:26,225:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:26,225:INFO:Initializing create_model()
2023-04-24 21:49:26,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:26,225:INFO:Checking exceptions
2023-04-24 21:49:26,225:INFO:Importing libraries
2023-04-24 21:49:26,225:INFO:Copying training dataset
2023-04-24 21:49:26,228:INFO:Defining folds
2023-04-24 21:49:26,228:INFO:Declaring metric variables
2023-04-24 21:49:26,232:INFO:Importing untrained model
2023-04-24 21:49:26,237:INFO:AdaBoost Regressor Imported successfully
2023-04-24 21:49:26,244:INFO:Starting cross validation
2023-04-24 21:49:26,246:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:26,674:INFO:Calculating mean and std
2023-04-24 21:49:26,677:INFO:Creating metrics dataframe
2023-04-24 21:49:26,784:INFO:Uploading results into container
2023-04-24 21:49:26,785:INFO:Uploading model into container now
2023-04-24 21:49:26,785:INFO:_master_model_container: 38
2023-04-24 21:49:26,785:INFO:_display_container: 8
2023-04-24 21:49:26,785:INFO:AdaBoostRegressor(random_state=3041)
2023-04-24 21:49:26,785:INFO:create_model() successfully completed......................................
2023-04-24 21:49:26,918:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:26,919:INFO:Creating metrics dataframe
2023-04-24 21:49:26,932:INFO:Initializing Gradient Boosting Regressor
2023-04-24 21:49:26,934:INFO:Total runtime is 0.2621570666631063 minutes
2023-04-24 21:49:26,936:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:26,937:INFO:Initializing create_model()
2023-04-24 21:49:26,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:26,937:INFO:Checking exceptions
2023-04-24 21:49:26,937:INFO:Importing libraries
2023-04-24 21:49:26,937:INFO:Copying training dataset
2023-04-24 21:49:26,941:INFO:Defining folds
2023-04-24 21:49:26,941:INFO:Declaring metric variables
2023-04-24 21:49:26,944:INFO:Importing untrained model
2023-04-24 21:49:26,949:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:49:26,957:INFO:Starting cross validation
2023-04-24 21:49:26,958:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:27,467:INFO:Calculating mean and std
2023-04-24 21:49:27,468:INFO:Creating metrics dataframe
2023-04-24 21:49:27,581:INFO:Uploading results into container
2023-04-24 21:49:27,582:INFO:Uploading model into container now
2023-04-24 21:49:27,582:INFO:_master_model_container: 39
2023-04-24 21:49:27,582:INFO:_display_container: 8
2023-04-24 21:49:27,582:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:49:27,582:INFO:create_model() successfully completed......................................
2023-04-24 21:49:27,693:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:27,694:INFO:Creating metrics dataframe
2023-04-24 21:49:27,704:INFO:Initializing Extreme Gradient Boosting
2023-04-24 21:49:27,704:INFO:Total runtime is 0.2749905864397685 minutes
2023-04-24 21:49:27,708:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:27,708:INFO:Initializing create_model()
2023-04-24 21:49:27,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:27,708:INFO:Checking exceptions
2023-04-24 21:49:27,708:INFO:Importing libraries
2023-04-24 21:49:27,709:INFO:Copying training dataset
2023-04-24 21:49:27,713:INFO:Defining folds
2023-04-24 21:49:27,713:INFO:Declaring metric variables
2023-04-24 21:49:27,716:INFO:Importing untrained model
2023-04-24 21:49:27,736:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 21:49:27,743:INFO:Starting cross validation
2023-04-24 21:49:27,744:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:29,366:INFO:Calculating mean and std
2023-04-24 21:49:29,367:INFO:Creating metrics dataframe
2023-04-24 21:49:29,470:INFO:Uploading results into container
2023-04-24 21:49:29,471:INFO:Uploading model into container now
2023-04-24 21:49:29,471:INFO:_master_model_container: 40
2023-04-24 21:49:29,471:INFO:_display_container: 8
2023-04-24 21:49:29,472:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3041, ...)
2023-04-24 21:49:29,472:INFO:create_model() successfully completed......................................
2023-04-24 21:49:29,581:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:29,581:INFO:Creating metrics dataframe
2023-04-24 21:49:29,592:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 21:49:29,592:INFO:Total runtime is 0.306464684009552 minutes
2023-04-24 21:49:29,596:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:29,596:INFO:Initializing create_model()
2023-04-24 21:49:29,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:29,596:INFO:Checking exceptions
2023-04-24 21:49:29,596:INFO:Importing libraries
2023-04-24 21:49:29,596:INFO:Copying training dataset
2023-04-24 21:49:29,603:INFO:Defining folds
2023-04-24 21:49:29,603:INFO:Declaring metric variables
2023-04-24 21:49:29,606:INFO:Importing untrained model
2023-04-24 21:49:29,609:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 21:49:29,616:INFO:Starting cross validation
2023-04-24 21:49:29,616:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:30,069:INFO:Calculating mean and std
2023-04-24 21:49:30,070:INFO:Creating metrics dataframe
2023-04-24 21:49:30,172:INFO:Uploading results into container
2023-04-24 21:49:30,172:INFO:Uploading model into container now
2023-04-24 21:49:30,172:INFO:_master_model_container: 41
2023-04-24 21:49:30,173:INFO:_display_container: 8
2023-04-24 21:49:30,173:INFO:LGBMRegressor(random_state=3041)
2023-04-24 21:49:30,173:INFO:create_model() successfully completed......................................
2023-04-24 21:49:30,283:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:30,284:INFO:Creating metrics dataframe
2023-04-24 21:49:30,295:INFO:Initializing Dummy Regressor
2023-04-24 21:49:30,295:INFO:Total runtime is 0.3181881626447042 minutes
2023-04-24 21:49:30,300:INFO:SubProcess create_model() called ==================================
2023-04-24 21:49:30,301:INFO:Initializing create_model()
2023-04-24 21:49:30,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D13F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:30,301:INFO:Checking exceptions
2023-04-24 21:49:30,301:INFO:Importing libraries
2023-04-24 21:49:30,301:INFO:Copying training dataset
2023-04-24 21:49:30,305:INFO:Defining folds
2023-04-24 21:49:30,305:INFO:Declaring metric variables
2023-04-24 21:49:30,308:INFO:Importing untrained model
2023-04-24 21:49:30,312:INFO:Dummy Regressor Imported successfully
2023-04-24 21:49:30,322:INFO:Starting cross validation
2023-04-24 21:49:30,323:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:49:30,681:INFO:Calculating mean and std
2023-04-24 21:49:30,682:INFO:Creating metrics dataframe
2023-04-24 21:49:30,780:INFO:Uploading results into container
2023-04-24 21:49:30,781:INFO:Uploading model into container now
2023-04-24 21:49:30,781:INFO:_master_model_container: 42
2023-04-24 21:49:30,781:INFO:_display_container: 8
2023-04-24 21:49:30,781:INFO:DummyRegressor()
2023-04-24 21:49:30,781:INFO:create_model() successfully completed......................................
2023-04-24 21:49:30,882:INFO:SubProcess create_model() end ==================================
2023-04-24 21:49:30,883:INFO:Creating metrics dataframe
2023-04-24 21:49:30,900:INFO:Initializing create_model()
2023-04-24 21:49:30,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:49:30,900:INFO:Checking exceptions
2023-04-24 21:49:30,902:INFO:Importing libraries
2023-04-24 21:49:30,902:INFO:Copying training dataset
2023-04-24 21:49:30,905:INFO:Defining folds
2023-04-24 21:49:30,905:INFO:Declaring metric variables
2023-04-24 21:49:30,905:INFO:Importing untrained model
2023-04-24 21:49:30,905:INFO:Declaring custom model
2023-04-24 21:49:30,906:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:49:30,906:INFO:Cross validation set to False
2023-04-24 21:49:30,906:INFO:Fitting Model
2023-04-24 21:49:31,042:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:49:31,042:INFO:create_model() successfully completed......................................
2023-04-24 21:49:31,171:INFO:Creating Dashboard logs
2023-04-24 21:49:31,175:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:49:31,249:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:49:31,339:INFO:Initializing predict_model()
2023-04-24 21:49:31,339:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562B17C70>)
2023-04-24 21:49:31,339:INFO:Checking exceptions
2023-04-24 21:49:31,339:INFO:Preloading libraries
2023-04-24 21:49:31,704:INFO:Creating Dashboard logs
2023-04-24 21:49:31,706:INFO:Model: Light Gradient Boosting Machine
2023-04-24 21:49:31,746:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 21:49:32,010:INFO:Creating Dashboard logs
2023-04-24 21:49:32,013:INFO:Model: Random Forest Regressor
2023-04-24 21:49:32,052:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-24 21:49:32,335:INFO:Creating Dashboard logs
2023-04-24 21:49:32,337:INFO:Model: K Neighbors Regressor
2023-04-24 21:49:32,379:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 21:49:32,643:INFO:Creating Dashboard logs
2023-04-24 21:49:32,646:INFO:Model: Extra Trees Regressor
2023-04-24 21:49:32,697:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-24 21:49:32,997:INFO:Creating Dashboard logs
2023-04-24 21:49:33,000:INFO:Model: Extreme Gradient Boosting
2023-04-24 21:49:33,044:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 3041, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-24 21:49:33,349:INFO:Creating Dashboard logs
2023-04-24 21:49:33,352:INFO:Model: AdaBoost Regressor
2023-04-24 21:49:33,393:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 3041}
2023-04-24 21:49:33,709:INFO:Creating Dashboard logs
2023-04-24 21:49:33,712:INFO:Model: Lasso Least Angle Regression
2023-04-24 21:49:33,753:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 3041, 'verbose': False}
2023-04-24 21:49:34,014:INFO:Creating Dashboard logs
2023-04-24 21:49:34,018:INFO:Model: Bayesian Ridge
2023-04-24 21:49:34,063:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 21:49:34,340:INFO:Creating Dashboard logs
2023-04-24 21:49:34,343:INFO:Model: Ridge Regression
2023-04-24 21:49:34,394:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 3041, 'solver': 'auto', 'tol': 0.001}
2023-04-24 21:49:34,678:INFO:Creating Dashboard logs
2023-04-24 21:49:34,681:INFO:Model: Least Angle Regression
2023-04-24 21:49:34,729:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 3041, 'verbose': False}
2023-04-24 21:49:34,998:INFO:Creating Dashboard logs
2023-04-24 21:49:35,001:INFO:Model: Linear Regression
2023-04-24 21:49:35,043:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 21:49:35,305:INFO:Creating Dashboard logs
2023-04-24 21:49:35,307:INFO:Model: Lasso Regression
2023-04-24 21:49:35,356:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 3041, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 21:49:35,644:INFO:Creating Dashboard logs
2023-04-24 21:49:35,648:INFO:Model: Decision Tree Regressor
2023-04-24 21:49:35,697:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 3041, 'splitter': 'best'}
2023-04-24 21:49:35,975:INFO:Creating Dashboard logs
2023-04-24 21:49:35,978:INFO:Model: Elastic Net
2023-04-24 21:49:36,026:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 3041, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 21:49:36,306:INFO:Creating Dashboard logs
2023-04-24 21:49:36,309:INFO:Model: Passive Aggressive Regressor
2023-04-24 21:49:36,375:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 3041, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:49:36,680:INFO:Creating Dashboard logs
2023-04-24 21:49:36,682:INFO:Model: Huber Regressor
2023-04-24 21:49:36,729:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 21:49:37,048:INFO:Creating Dashboard logs
2023-04-24 21:49:37,051:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 21:49:37,097:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 21:49:37,379:INFO:Creating Dashboard logs
2023-04-24 21:49:37,381:INFO:Model: Dummy Regressor
2023-04-24 21:49:37,420:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 21:49:37,757:INFO:_master_model_container: 42
2023-04-24 21:49:37,757:INFO:_display_container: 8
2023-04-24 21:49:37,758:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:49:37,758:INFO:compare_models() successfully completed......................................
2023-04-24 21:52:13,650:INFO:Initializing create_model()
2023-04-24 21:52:13,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:52:13,650:INFO:Checking exceptions
2023-04-24 21:52:13,677:INFO:Importing libraries
2023-04-24 21:52:13,678:INFO:Copying training dataset
2023-04-24 21:52:13,686:INFO:Defining folds
2023-04-24 21:52:13,686:INFO:Declaring metric variables
2023-04-24 21:52:13,691:INFO:Importing untrained model
2023-04-24 21:52:13,696:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:52:13,707:INFO:Starting cross validation
2023-04-24 21:52:13,710:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:52:14,220:INFO:Calculating mean and std
2023-04-24 21:52:14,221:INFO:Creating metrics dataframe
2023-04-24 21:52:14,225:INFO:Finalizing model
2023-04-24 21:52:14,390:INFO:Creating Dashboard logs
2023-04-24 21:52:14,393:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:52:14,440:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:52:14,521:INFO:Initializing predict_model()
2023-04-24 21:52:14,521:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562B15000>)
2023-04-24 21:52:14,521:INFO:Checking exceptions
2023-04-24 21:52:14,521:INFO:Preloading libraries
2023-04-24 21:52:14,910:INFO:Uploading results into container
2023-04-24 21:52:14,911:INFO:Uploading model into container now
2023-04-24 21:52:14,922:INFO:_master_model_container: 43
2023-04-24 21:52:14,922:INFO:_display_container: 9
2023-04-24 21:52:14,922:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:52:14,922:INFO:create_model() successfully completed......................................
2023-04-24 21:56:12,046:INFO:Initializing tune_model()
2023-04-24 21:56:12,047:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=3041), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>)
2023-04-24 21:56:12,047:INFO:Checking exceptions
2023-04-24 21:56:12,071:INFO:Copying training dataset
2023-04-24 21:56:12,078:INFO:Checking base model
2023-04-24 21:56:12,079:INFO:Base model : Gradient Boosting Regressor
2023-04-24 21:56:12,083:INFO:Declaring metric variables
2023-04-24 21:56:12,090:INFO:Defining Hyperparameters
2023-04-24 21:56:12,227:INFO:Tuning with n_jobs=-1
2023-04-24 21:56:12,227:INFO:Initializing RandomizedSearchCV
2023-04-24 21:56:23,721:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.2}
2023-04-24 21:56:23,723:INFO:Hyperparameter search completed
2023-04-24 21:56:23,724:INFO:SubProcess create_model() called ==================================
2023-04-24 21:56:23,725:INFO:Initializing create_model()
2023-04-24 21:56:23,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560FEEF80>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 20, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'log2', 'max_depth': 11, 'learning_rate': 0.2})
2023-04-24 21:56:23,725:INFO:Checking exceptions
2023-04-24 21:56:23,725:INFO:Importing libraries
2023-04-24 21:56:23,725:INFO:Copying training dataset
2023-04-24 21:56:23,728:INFO:Defining folds
2023-04-24 21:56:23,729:INFO:Declaring metric variables
2023-04-24 21:56:23,731:INFO:Importing untrained model
2023-04-24 21:56:23,731:INFO:Declaring custom model
2023-04-24 21:56:23,737:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:56:23,746:INFO:Starting cross validation
2023-04-24 21:56:23,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:56:24,672:INFO:Calculating mean and std
2023-04-24 21:56:24,673:INFO:Creating metrics dataframe
2023-04-24 21:56:24,676:INFO:Finalizing model
2023-04-24 21:56:24,824:INFO:Uploading results into container
2023-04-24 21:56:24,825:INFO:Uploading model into container now
2023-04-24 21:56:24,825:INFO:_master_model_container: 44
2023-04-24 21:56:24,825:INFO:_display_container: 10
2023-04-24 21:56:24,826:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=11, max_features='log2',
                          min_impurity_decrease=0.3, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=20,
                          random_state=3041, subsample=0.35)
2023-04-24 21:56:24,826:INFO:create_model() successfully completed......................................
2023-04-24 21:56:24,957:INFO:SubProcess create_model() end ==================================
2023-04-24 21:56:24,957:INFO:choose_better activated
2023-04-24 21:56:24,960:INFO:SubProcess create_model() called ==================================
2023-04-24 21:56:24,960:INFO:Initializing create_model()
2023-04-24 21:56:24,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:56:24,960:INFO:Checking exceptions
2023-04-24 21:56:24,961:INFO:Importing libraries
2023-04-24 21:56:24,961:INFO:Copying training dataset
2023-04-24 21:56:24,964:INFO:Defining folds
2023-04-24 21:56:24,965:INFO:Declaring metric variables
2023-04-24 21:56:24,965:INFO:Importing untrained model
2023-04-24 21:56:24,965:INFO:Declaring custom model
2023-04-24 21:56:24,965:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:56:24,965:INFO:Starting cross validation
2023-04-24 21:56:24,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:56:25,968:INFO:Calculating mean and std
2023-04-24 21:56:25,969:INFO:Creating metrics dataframe
2023-04-24 21:56:25,970:INFO:Finalizing model
2023-04-24 21:56:26,164:INFO:Uploading results into container
2023-04-24 21:56:26,165:INFO:Uploading model into container now
2023-04-24 21:56:26,165:INFO:_master_model_container: 45
2023-04-24 21:56:26,165:INFO:_display_container: 11
2023-04-24 21:56:26,165:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:56:26,165:INFO:create_model() successfully completed......................................
2023-04-24 21:56:26,293:INFO:SubProcess create_model() end ==================================
2023-04-24 21:56:26,294:INFO:GradientBoostingRegressor(random_state=3041) result for R2 is 0.8053
2023-04-24 21:56:26,294:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=11, max_features='log2',
                          min_impurity_decrease=0.3, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=20,
                          random_state=3041, subsample=0.35) result for R2 is 0.7864
2023-04-24 21:56:26,294:INFO:GradientBoostingRegressor(random_state=3041) is best model
2023-04-24 21:56:26,294:INFO:choose_better completed
2023-04-24 21:56:26,295:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 21:56:26,295:INFO:Creating Dashboard logs
2023-04-24 21:56:26,298:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:56:26,338:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:56:26,425:INFO:Initializing predict_model()
2023-04-24 21:56:26,425:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562BE5FC0>)
2023-04-24 21:56:26,425:INFO:Checking exceptions
2023-04-24 21:56:26,425:INFO:Preloading libraries
2023-04-24 21:56:26,804:INFO:_master_model_container: 45
2023-04-24 21:56:26,804:INFO:_display_container: 10
2023-04-24 21:56:26,805:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:56:26,805:INFO:tune_model() successfully completed......................................
2023-04-24 21:57:46,459:INFO:Initializing tune_model()
2023-04-24 21:57:46,459:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=3041), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>)
2023-04-24 21:57:46,459:INFO:Checking exceptions
2023-04-24 21:57:46,485:INFO:Copying training dataset
2023-04-24 21:57:46,490:INFO:Checking base model
2023-04-24 21:57:46,491:INFO:Base model : Gradient Boosting Regressor
2023-04-24 21:57:46,497:INFO:Declaring metric variables
2023-04-24 21:57:46,502:INFO:Defining Hyperparameters
2023-04-24 21:57:46,637:INFO:Tuning with n_jobs=-1
2023-04-24 21:57:46,637:INFO:Initializing RandomizedSearchCV
2023-04-24 21:57:51,718:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.2}
2023-04-24 21:57:51,719:INFO:Hyperparameter search completed
2023-04-24 21:57:51,719:INFO:SubProcess create_model() called ==================================
2023-04-24 21:57:51,719:INFO:Initializing create_model()
2023-04-24 21:57:51,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5607CEF50>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 20, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'log2', 'max_depth': 11, 'learning_rate': 0.2})
2023-04-24 21:57:51,719:INFO:Checking exceptions
2023-04-24 21:57:51,721:INFO:Importing libraries
2023-04-24 21:57:51,721:INFO:Copying training dataset
2023-04-24 21:57:51,724:INFO:Defining folds
2023-04-24 21:57:51,725:INFO:Declaring metric variables
2023-04-24 21:57:51,727:INFO:Importing untrained model
2023-04-24 21:57:51,727:INFO:Declaring custom model
2023-04-24 21:57:51,733:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:57:51,739:INFO:Starting cross validation
2023-04-24 21:57:51,740:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:57:52,186:INFO:Calculating mean and std
2023-04-24 21:57:52,187:INFO:Creating metrics dataframe
2023-04-24 21:57:52,192:INFO:Finalizing model
2023-04-24 21:57:52,331:INFO:Uploading results into container
2023-04-24 21:57:52,332:INFO:Uploading model into container now
2023-04-24 21:57:52,332:INFO:_master_model_container: 46
2023-04-24 21:57:52,334:INFO:_display_container: 11
2023-04-24 21:57:52,334:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=11, max_features='log2',
                          min_impurity_decrease=0.3, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=20,
                          random_state=3041, subsample=0.35)
2023-04-24 21:57:52,334:INFO:create_model() successfully completed......................................
2023-04-24 21:57:52,442:INFO:SubProcess create_model() end ==================================
2023-04-24 21:57:52,442:INFO:choose_better activated
2023-04-24 21:57:52,445:INFO:SubProcess create_model() called ==================================
2023-04-24 21:57:52,446:INFO:Initializing create_model()
2023-04-24 21:57:52,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:57:52,446:INFO:Checking exceptions
2023-04-24 21:57:52,447:INFO:Importing libraries
2023-04-24 21:57:52,447:INFO:Copying training dataset
2023-04-24 21:57:52,450:INFO:Defining folds
2023-04-24 21:57:52,450:INFO:Declaring metric variables
2023-04-24 21:57:52,450:INFO:Importing untrained model
2023-04-24 21:57:52,450:INFO:Declaring custom model
2023-04-24 21:57:52,451:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 21:57:52,451:INFO:Starting cross validation
2023-04-24 21:57:52,451:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:57:52,922:INFO:Calculating mean and std
2023-04-24 21:57:52,922:INFO:Creating metrics dataframe
2023-04-24 21:57:52,924:INFO:Finalizing model
2023-04-24 21:57:53,085:INFO:Uploading results into container
2023-04-24 21:57:53,086:INFO:Uploading model into container now
2023-04-24 21:57:53,086:INFO:_master_model_container: 47
2023-04-24 21:57:53,086:INFO:_display_container: 12
2023-04-24 21:57:53,087:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:57:53,087:INFO:create_model() successfully completed......................................
2023-04-24 21:57:53,193:INFO:SubProcess create_model() end ==================================
2023-04-24 21:57:53,195:INFO:GradientBoostingRegressor(random_state=3041) result for R2 is 0.8141
2023-04-24 21:57:53,195:INFO:GradientBoostingRegressor(learning_rate=0.2, max_depth=11, max_features='log2',
                          min_impurity_decrease=0.3, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=20,
                          random_state=3041, subsample=0.35) result for R2 is 0.7897
2023-04-24 21:57:53,196:INFO:GradientBoostingRegressor(random_state=3041) is best model
2023-04-24 21:57:53,196:INFO:choose_better completed
2023-04-24 21:57:53,196:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 21:57:53,196:INFO:Creating Dashboard logs
2023-04-24 21:57:53,199:INFO:Model: Gradient Boosting Regressor
2023-04-24 21:57:53,242:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 21:57:53,318:INFO:Initializing predict_model()
2023-04-24 21:57:53,318:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562BE4940>)
2023-04-24 21:57:53,318:INFO:Checking exceptions
2023-04-24 21:57:53,318:INFO:Preloading libraries
2023-04-24 21:57:53,746:INFO:_master_model_container: 47
2023-04-24 21:57:53,746:INFO:_display_container: 11
2023-04-24 21:57:53,746:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-24 21:57:53,746:INFO:tune_model() successfully completed......................................
2023-04-24 21:59:51,581:INFO:Initializing create_model()
2023-04-24 21:59:51,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 21:59:51,581:INFO:Checking exceptions
2023-04-24 21:59:51,610:INFO:Importing libraries
2023-04-24 21:59:51,610:INFO:Copying training dataset
2023-04-24 21:59:51,615:INFO:Defining folds
2023-04-24 21:59:51,615:INFO:Declaring metric variables
2023-04-24 21:59:51,623:INFO:Importing untrained model
2023-04-24 21:59:51,628:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 21:59:51,640:INFO:Starting cross validation
2023-04-24 21:59:51,641:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 21:59:52,154:INFO:Calculating mean and std
2023-04-24 21:59:52,155:INFO:Creating metrics dataframe
2023-04-24 21:59:52,158:INFO:Finalizing model
2023-04-24 21:59:52,373:INFO:Creating Dashboard logs
2023-04-24 21:59:52,375:INFO:Model: Light Gradient Boosting Machine
2023-04-24 21:59:52,417:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 21:59:52,495:INFO:Initializing predict_model()
2023-04-24 21:59:52,495:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562BE4D30>)
2023-04-24 21:59:52,495:INFO:Checking exceptions
2023-04-24 21:59:52,495:INFO:Preloading libraries
2023-04-24 21:59:52,908:INFO:Uploading results into container
2023-04-24 21:59:52,909:INFO:Uploading model into container now
2023-04-24 21:59:52,916:INFO:_master_model_container: 48
2023-04-24 21:59:52,916:INFO:_display_container: 12
2023-04-24 21:59:52,916:INFO:LGBMRegressor(random_state=3041)
2023-04-24 21:59:52,916:INFO:create_model() successfully completed......................................
2023-04-24 22:00:21,606:INFO:Initializing create_model()
2023-04-24 22:00:21,606:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:00:21,606:INFO:Checking exceptions
2023-04-24 22:00:21,630:INFO:Importing libraries
2023-04-24 22:00:21,630:INFO:Copying training dataset
2023-04-24 22:00:21,636:INFO:Defining folds
2023-04-24 22:00:21,636:INFO:Declaring metric variables
2023-04-24 22:00:21,642:INFO:Importing untrained model
2023-04-24 22:00:21,647:INFO:Random Forest Regressor Imported successfully
2023-04-24 22:00:21,657:INFO:Starting cross validation
2023-04-24 22:00:21,658:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:00:22,191:INFO:Calculating mean and std
2023-04-24 22:00:22,192:INFO:Creating metrics dataframe
2023-04-24 22:00:22,196:INFO:Finalizing model
2023-04-24 22:00:22,499:INFO:Creating Dashboard logs
2023-04-24 22:00:22,502:INFO:Model: Random Forest Regressor
2023-04-24 22:00:22,541:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-24 22:00:22,615:INFO:Initializing predict_model()
2023-04-24 22:00:22,615:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(n_jobs=-1, random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562BE7D00>)
2023-04-24 22:00:22,615:INFO:Checking exceptions
2023-04-24 22:00:22,615:INFO:Preloading libraries
2023-04-24 22:00:23,007:INFO:Uploading results into container
2023-04-24 22:00:23,008:INFO:Uploading model into container now
2023-04-24 22:00:23,017:INFO:_master_model_container: 49
2023-04-24 22:00:23,017:INFO:_display_container: 13
2023-04-24 22:00:23,017:INFO:RandomForestRegressor(n_jobs=-1, random_state=3041)
2023-04-24 22:00:23,017:INFO:create_model() successfully completed......................................
2023-04-24 22:01:19,507:INFO:Initializing tune_model()
2023-04-24 22:01:19,507:INFO:tune_model(estimator=LGBMRegressor(random_state=3041), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>)
2023-04-24 22:01:19,507:INFO:Checking exceptions
2023-04-24 22:01:19,532:INFO:Copying training dataset
2023-04-24 22:01:19,537:INFO:Checking base model
2023-04-24 22:01:19,537:INFO:Base model : Light Gradient Boosting Machine
2023-04-24 22:01:19,543:INFO:Declaring metric variables
2023-04-24 22:01:19,550:INFO:Defining Hyperparameters
2023-04-24 22:01:19,668:INFO:Tuning with n_jobs=-1
2023-04-24 22:01:19,669:INFO:Initializing RandomizedSearchCV
2023-04-24 22:01:25,309:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2023-04-24 22:01:25,310:INFO:Hyperparameter search completed
2023-04-24 22:01:25,310:INFO:SubProcess create_model() called ==================================
2023-04-24 22:01:25,310:INFO:Initializing create_model()
2023-04-24 22:01:25,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562116CE0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.0005, 'num_leaves': 50, 'n_estimators': 80, 'min_split_gain': 0.5, 'min_child_samples': 21, 'learning_rate': 0.15, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2023-04-24 22:01:25,310:INFO:Checking exceptions
2023-04-24 22:01:25,310:INFO:Importing libraries
2023-04-24 22:01:25,310:INFO:Copying training dataset
2023-04-24 22:01:25,313:INFO:Defining folds
2023-04-24 22:01:25,313:INFO:Declaring metric variables
2023-04-24 22:01:25,316:INFO:Importing untrained model
2023-04-24 22:01:25,316:INFO:Declaring custom model
2023-04-24 22:01:25,320:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 22:01:25,326:INFO:Starting cross validation
2023-04-24 22:01:25,326:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:01:25,807:INFO:Calculating mean and std
2023-04-24 22:01:25,809:INFO:Creating metrics dataframe
2023-04-24 22:01:25,813:INFO:Finalizing model
2023-04-24 22:01:25,838:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-04-24 22:01:25,838:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2023-04-24 22:01:25,838:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-04-24 22:01:26,018:INFO:Uploading results into container
2023-04-24 22:01:26,019:INFO:Uploading model into container now
2023-04-24 22:01:26,019:INFO:_master_model_container: 50
2023-04-24 22:01:26,019:INFO:_display_container: 14
2023-04-24 22:01:26,020:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, feature_fraction=0.9,
              learning_rate=0.15, min_child_samples=21, min_split_gain=0.5,
              n_estimators=80, num_leaves=50, random_state=3041,
              reg_alpha=0.0005, reg_lambda=0.01)
2023-04-24 22:01:26,020:INFO:create_model() successfully completed......................................
2023-04-24 22:01:26,151:INFO:SubProcess create_model() end ==================================
2023-04-24 22:01:26,151:INFO:choose_better activated
2023-04-24 22:01:26,154:INFO:SubProcess create_model() called ==================================
2023-04-24 22:01:26,154:INFO:Initializing create_model()
2023-04-24 22:01:26,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:01:26,154:INFO:Checking exceptions
2023-04-24 22:01:26,156:INFO:Importing libraries
2023-04-24 22:01:26,156:INFO:Copying training dataset
2023-04-24 22:01:26,158:INFO:Defining folds
2023-04-24 22:01:26,159:INFO:Declaring metric variables
2023-04-24 22:01:26,159:INFO:Importing untrained model
2023-04-24 22:01:26,159:INFO:Declaring custom model
2023-04-24 22:01:26,160:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 22:01:26,160:INFO:Starting cross validation
2023-04-24 22:01:26,160:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:01:26,610:INFO:Calculating mean and std
2023-04-24 22:01:26,611:INFO:Creating metrics dataframe
2023-04-24 22:01:26,612:INFO:Finalizing model
2023-04-24 22:01:26,818:INFO:Uploading results into container
2023-04-24 22:01:26,819:INFO:Uploading model into container now
2023-04-24 22:01:26,819:INFO:_master_model_container: 51
2023-04-24 22:01:26,819:INFO:_display_container: 15
2023-04-24 22:01:26,819:INFO:LGBMRegressor(random_state=3041)
2023-04-24 22:01:26,819:INFO:create_model() successfully completed......................................
2023-04-24 22:01:26,928:INFO:SubProcess create_model() end ==================================
2023-04-24 22:01:26,929:INFO:LGBMRegressor(random_state=3041) result for R2 is 0.8056
2023-04-24 22:01:26,929:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, feature_fraction=0.9,
              learning_rate=0.15, min_child_samples=21, min_split_gain=0.5,
              n_estimators=80, num_leaves=50, random_state=3041,
              reg_alpha=0.0005, reg_lambda=0.01) result for R2 is 0.802
2023-04-24 22:01:26,929:INFO:LGBMRegressor(random_state=3041) is best model
2023-04-24 22:01:26,929:INFO:choose_better completed
2023-04-24 22:01:26,929:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 22:01:26,930:INFO:Creating Dashboard logs
2023-04-24 22:01:26,933:INFO:Model: Light Gradient Boosting Machine
2023-04-24 22:01:26,981:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 22:01:27,053:INFO:Initializing predict_model()
2023-04-24 22:01:27,053:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562BE5480>)
2023-04-24 22:01:27,053:INFO:Checking exceptions
2023-04-24 22:01:27,053:INFO:Preloading libraries
2023-04-24 22:01:27,470:INFO:_master_model_container: 51
2023-04-24 22:01:27,471:INFO:_display_container: 14
2023-04-24 22:01:27,472:INFO:LGBMRegressor(random_state=3041)
2023-04-24 22:01:27,472:INFO:tune_model() successfully completed......................................
2023-04-24 22:01:27,679:INFO:Initializing tune_model()
2023-04-24 22:01:27,679:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=3041), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>)
2023-04-24 22:01:27,679:INFO:Checking exceptions
2023-04-24 22:01:27,710:INFO:Copying training dataset
2023-04-24 22:01:27,715:INFO:Checking base model
2023-04-24 22:01:27,716:INFO:Base model : Random Forest Regressor
2023-04-24 22:01:27,722:INFO:Declaring metric variables
2023-04-24 22:01:27,725:INFO:Defining Hyperparameters
2023-04-24 22:01:27,838:INFO:Tuning with n_jobs=-1
2023-04-24 22:01:27,838:INFO:Initializing RandomizedSearchCV
2023-04-24 22:01:32,121:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 22:01:33,508:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 22:01:37,721:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2023-04-24 22:01:37,723:INFO:Hyperparameter search completed
2023-04-24 22:01:37,723:INFO:SubProcess create_model() called ==================================
2023-04-24 22:01:37,723:INFO:Initializing create_model()
2023-04-24 22:01:37,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(n_jobs=-1, random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56200E290>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'absolute_error', 'bootstrap': False})
2023-04-24 22:01:37,723:INFO:Checking exceptions
2023-04-24 22:01:37,723:INFO:Importing libraries
2023-04-24 22:01:37,724:INFO:Copying training dataset
2023-04-24 22:01:37,727:INFO:Defining folds
2023-04-24 22:01:37,727:INFO:Declaring metric variables
2023-04-24 22:01:37,730:INFO:Importing untrained model
2023-04-24 22:01:37,730:INFO:Declaring custom model
2023-04-24 22:01:37,735:INFO:Random Forest Regressor Imported successfully
2023-04-24 22:01:37,740:INFO:Starting cross validation
2023-04-24 22:01:37,741:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:01:38,429:INFO:Calculating mean and std
2023-04-24 22:01:38,431:INFO:Creating metrics dataframe
2023-04-24 22:01:38,436:INFO:Finalizing model
2023-04-24 22:01:39,316:INFO:Uploading results into container
2023-04-24 22:01:39,318:INFO:Uploading model into container now
2023-04-24 22:01:39,332:INFO:_master_model_container: 52
2023-04-24 22:01:39,332:INFO:_display_container: 15
2023-04-24 22:01:39,333:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-24 22:01:39,333:INFO:create_model() successfully completed......................................
2023-04-24 22:01:39,453:INFO:SubProcess create_model() end ==================================
2023-04-24 22:01:39,453:INFO:choose_better activated
2023-04-24 22:01:39,455:INFO:SubProcess create_model() called ==================================
2023-04-24 22:01:39,456:INFO:Initializing create_model()
2023-04-24 22:01:39,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(n_jobs=-1, random_state=3041), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:01:39,456:INFO:Checking exceptions
2023-04-24 22:01:39,457:INFO:Importing libraries
2023-04-24 22:01:39,457:INFO:Copying training dataset
2023-04-24 22:01:39,459:INFO:Defining folds
2023-04-24 22:01:39,459:INFO:Declaring metric variables
2023-04-24 22:01:39,459:INFO:Importing untrained model
2023-04-24 22:01:39,459:INFO:Declaring custom model
2023-04-24 22:01:39,460:INFO:Random Forest Regressor Imported successfully
2023-04-24 22:01:39,460:INFO:Starting cross validation
2023-04-24 22:01:39,460:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:01:40,023:INFO:Calculating mean and std
2023-04-24 22:01:40,024:INFO:Creating metrics dataframe
2023-04-24 22:01:40,026:INFO:Finalizing model
2023-04-24 22:01:40,213:INFO:Uploading results into container
2023-04-24 22:01:40,213:INFO:Uploading model into container now
2023-04-24 22:01:40,213:INFO:_master_model_container: 53
2023-04-24 22:01:40,213:INFO:_display_container: 16
2023-04-24 22:01:40,213:INFO:RandomForestRegressor(n_jobs=-1, random_state=3041)
2023-04-24 22:01:40,213:INFO:create_model() successfully completed......................................
2023-04-24 22:01:40,330:INFO:SubProcess create_model() end ==================================
2023-04-24 22:01:40,331:INFO:RandomForestRegressor(n_jobs=-1, random_state=3041) result for R2 is 0.8016
2023-04-24 22:01:40,331:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041) result for R2 is 0.8141
2023-04-24 22:01:40,331:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041) is best model
2023-04-24 22:01:40,332:INFO:choose_better completed
2023-04-24 22:01:40,332:INFO:Creating Dashboard logs
2023-04-24 22:01:40,336:INFO:Model: Random Forest Regressor
2023-04-24 22:01:40,377:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-24 22:01:40,485:INFO:Initializing predict_model()
2023-04-24 22:01:40,485:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562BE7490>)
2023-04-24 22:01:40,485:INFO:Checking exceptions
2023-04-24 22:01:40,485:INFO:Preloading libraries
2023-04-24 22:01:40,922:INFO:_master_model_container: 53
2023-04-24 22:01:40,922:INFO:_display_container: 15
2023-04-24 22:01:40,923:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-24 22:01:40,923:INFO:tune_model() successfully completed......................................
2023-04-24 22:02:03,526:INFO:Initializing plot_model()
2023-04-24 22:02:03,526:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 22:02:03,526:INFO:Checking exceptions
2023-04-24 22:02:03,530:INFO:Preloading libraries
2023-04-24 22:02:03,538:INFO:Copying training dataset
2023-04-24 22:02:03,538:INFO:Plot type: error
2023-04-24 22:02:03,619:INFO:Fitting Model
2023-04-24 22:02:03,619:INFO:Scoring test/hold-out set
2023-04-24 22:02:03,829:INFO:Visual Rendered Successfully
2023-04-24 22:02:03,940:INFO:plot_model() successfully completed......................................
2023-04-24 22:02:14,478:INFO:Initializing plot_model()
2023-04-24 22:02:14,479:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-24 22:02:14,479:INFO:Checking exceptions
2023-04-24 22:02:14,513:INFO:Preloading libraries
2023-04-24 22:02:14,531:INFO:Copying training dataset
2023-04-24 22:02:14,531:INFO:Plot type: error
2023-04-24 22:02:14,589:INFO:Fitting Model
2023-04-24 22:02:14,589:INFO:Scoring test/hold-out set
2023-04-24 22:02:14,792:INFO:Visual Rendered Successfully
2023-04-24 22:02:14,917:INFO:plot_model() successfully completed......................................
2023-04-25 07:46:10,417:INFO:Initializing plot_model()
2023-04-25 07:46:10,420:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:46:10,420:INFO:Checking exceptions
2023-04-25 07:46:10,493:INFO:Preloading libraries
2023-04-25 07:46:10,509:INFO:Copying training dataset
2023-04-25 07:46:10,509:INFO:Plot type: error
2023-04-25 07:46:10,614:INFO:Fitting Model
2023-04-25 07:46:10,615:INFO:Scoring test/hold-out set
2023-04-25 07:46:10,834:INFO:Visual Rendered Successfully
2023-04-25 07:46:11,144:INFO:plot_model() successfully completed......................................
2023-04-25 07:46:11,144:INFO:Initializing plot_model()
2023-04-25 07:46:11,145:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:46:11,145:INFO:Checking exceptions
2023-04-25 07:46:11,150:INFO:Preloading libraries
2023-04-25 07:46:11,160:INFO:Copying training dataset
2023-04-25 07:46:11,160:INFO:Plot type: error
2023-04-25 07:46:11,244:INFO:Fitting Model
2023-04-25 07:46:11,244:INFO:Scoring test/hold-out set
2023-04-25 07:46:11,440:INFO:Visual Rendered Successfully
2023-04-25 07:46:11,544:INFO:plot_model() successfully completed......................................
2023-04-25 07:46:11,545:INFO:Initializing plot_model()
2023-04-25 07:46:11,545:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:46:11,545:INFO:Checking exceptions
2023-04-25 07:46:11,579:INFO:Preloading libraries
2023-04-25 07:46:11,604:INFO:Copying training dataset
2023-04-25 07:46:11,604:INFO:Plot type: error
2023-04-25 07:46:11,659:INFO:Fitting Model
2023-04-25 07:46:11,659:INFO:Scoring test/hold-out set
2023-04-25 07:46:11,837:INFO:Visual Rendered Successfully
2023-04-25 07:46:11,940:INFO:plot_model() successfully completed......................................
2023-04-25 07:46:53,926:INFO:Initializing compare_models()
2023-04-25 07:46:53,926:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, include=[GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, 'include': [GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 07:46:53,926:INFO:Checking exceptions
2023-04-25 07:46:53,928:INFO:Preparing display monitor
2023-04-25 07:46:53,967:INFO:Initializing custom model Gradient Boosting Regressor
2023-04-25 07:46:53,967:INFO:Total runtime is 0.0 minutes
2023-04-25 07:46:53,971:INFO:SubProcess create_model() called ==================================
2023-04-25 07:46:53,971:INFO:Initializing create_model()
2023-04-25 07:46:53,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D1990>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:46:53,972:INFO:Checking exceptions
2023-04-25 07:46:53,972:INFO:Importing libraries
2023-04-25 07:46:53,972:INFO:Copying training dataset
2023-04-25 07:46:53,980:INFO:Defining folds
2023-04-25 07:46:53,980:INFO:Declaring metric variables
2023-04-25 07:46:53,983:INFO:Importing untrained model
2023-04-25 07:46:53,984:INFO:Declaring custom model
2023-04-25 07:46:53,987:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 07:46:54,006:INFO:Starting cross validation
2023-04-25 07:46:54,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:47:14,474:INFO:Calculating mean and std
2023-04-25 07:47:14,476:INFO:Creating metrics dataframe
2023-04-25 07:47:14,603:INFO:Uploading results into container
2023-04-25 07:47:14,605:INFO:Uploading model into container now
2023-04-25 07:47:14,605:INFO:_master_model_container: 54
2023-04-25 07:47:14,606:INFO:_display_container: 16
2023-04-25 07:47:14,606:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-25 07:47:14,606:INFO:create_model() successfully completed......................................
2023-04-25 07:47:14,742:INFO:SubProcess create_model() end ==================================
2023-04-25 07:47:14,742:INFO:Creating metrics dataframe
2023-04-25 07:47:14,757:INFO:Initializing custom model Light Gradient Boosting Machine
2023-04-25 07:47:14,758:INFO:Total runtime is 0.34651434421539307 minutes
2023-04-25 07:47:14,761:INFO:SubProcess create_model() called ==================================
2023-04-25 07:47:14,762:INFO:Initializing create_model()
2023-04-25 07:47:14,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D1990>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:47:14,762:INFO:Checking exceptions
2023-04-25 07:47:14,763:INFO:Importing libraries
2023-04-25 07:47:14,763:INFO:Copying training dataset
2023-04-25 07:47:14,766:INFO:Defining folds
2023-04-25 07:47:14,766:INFO:Declaring metric variables
2023-04-25 07:47:14,769:INFO:Importing untrained model
2023-04-25 07:47:14,769:INFO:Declaring custom model
2023-04-25 07:47:14,774:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 07:47:14,780:INFO:Starting cross validation
2023-04-25 07:47:14,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:47:16,068:INFO:Calculating mean and std
2023-04-25 07:47:16,069:INFO:Creating metrics dataframe
2023-04-25 07:47:16,190:INFO:Uploading results into container
2023-04-25 07:47:16,191:INFO:Uploading model into container now
2023-04-25 07:47:16,192:INFO:_master_model_container: 55
2023-04-25 07:47:16,192:INFO:_display_container: 16
2023-04-25 07:47:16,192:INFO:LGBMRegressor(random_state=3041)
2023-04-25 07:47:16,192:INFO:create_model() successfully completed......................................
2023-04-25 07:47:16,298:INFO:SubProcess create_model() end ==================================
2023-04-25 07:47:16,298:INFO:Creating metrics dataframe
2023-04-25 07:47:16,305:INFO:Initializing custom model Random Forest Regressor
2023-04-25 07:47:16,305:INFO:Total runtime is 0.37230521043141684 minutes
2023-04-25 07:47:16,308:INFO:SubProcess create_model() called ==================================
2023-04-25 07:47:16,309:INFO:Initializing create_model()
2023-04-25 07:47:16,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5625D1990>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:47:16,310:INFO:Checking exceptions
2023-04-25 07:47:16,310:INFO:Importing libraries
2023-04-25 07:47:16,310:INFO:Copying training dataset
2023-04-25 07:47:16,314:INFO:Defining folds
2023-04-25 07:47:16,314:INFO:Declaring metric variables
2023-04-25 07:47:16,317:INFO:Importing untrained model
2023-04-25 07:47:16,317:INFO:Declaring custom model
2023-04-25 07:47:16,320:INFO:Random Forest Regressor Imported successfully
2023-04-25 07:47:16,329:INFO:Starting cross validation
2023-04-25 07:47:16,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:47:18,679:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 07:47:20,375:INFO:Calculating mean and std
2023-04-25 07:47:20,376:INFO:Creating metrics dataframe
2023-04-25 07:47:20,497:INFO:Uploading results into container
2023-04-25 07:47:20,497:INFO:Uploading model into container now
2023-04-25 07:47:20,498:INFO:_master_model_container: 56
2023-04-25 07:47:20,498:INFO:_display_container: 16
2023-04-25 07:47:20,498:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:47:20,498:INFO:create_model() successfully completed......................................
2023-04-25 07:47:20,597:INFO:SubProcess create_model() end ==================================
2023-04-25 07:47:20,598:INFO:Creating metrics dataframe
2023-04-25 07:47:20,613:INFO:Initializing create_model()
2023-04-25 07:47:20,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:47:20,614:INFO:Checking exceptions
2023-04-25 07:47:20,615:INFO:Importing libraries
2023-04-25 07:47:20,615:INFO:Copying training dataset
2023-04-25 07:47:20,619:INFO:Defining folds
2023-04-25 07:47:20,619:INFO:Declaring metric variables
2023-04-25 07:47:20,619:INFO:Importing untrained model
2023-04-25 07:47:20,619:INFO:Declaring custom model
2023-04-25 07:47:20,620:INFO:Random Forest Regressor Imported successfully
2023-04-25 07:47:20,620:INFO:Cross validation set to False
2023-04-25 07:47:20,620:INFO:Fitting Model
2023-04-25 07:47:20,764:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:47:20,764:INFO:create_model() successfully completed......................................
2023-04-25 07:47:20,865:INFO:Creating Dashboard logs
2023-04-25 07:47:20,869:INFO:Model: Random Forest Regressor
2023-04-25 07:47:20,941:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-25 07:47:21,023:INFO:Initializing predict_model()
2023-04-25 07:47:21,024:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562DFC550>)
2023-04-25 07:47:21,024:INFO:Checking exceptions
2023-04-25 07:47:21,024:INFO:Preloading libraries
2023-04-25 07:47:21,448:INFO:Creating Dashboard logs
2023-04-25 07:47:21,451:INFO:Model: Gradient Boosting Regressor
2023-04-25 07:47:21,496:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 07:47:21,806:INFO:Creating Dashboard logs
2023-04-25 07:47:21,809:INFO:Model: Light Gradient Boosting Machine
2023-04-25 07:47:21,851:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 07:47:22,162:INFO:_master_model_container: 56
2023-04-25 07:47:22,162:INFO:_display_container: 16
2023-04-25 07:47:22,163:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:47:22,163:INFO:compare_models() successfully completed......................................
2023-04-25 07:49:25,469:INFO:Initializing compare_models()
2023-04-25 07:49:25,469:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, include=[GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, 'include': [GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 07:49:25,469:INFO:Checking exceptions
2023-04-25 07:49:25,471:INFO:Preparing display monitor
2023-04-25 07:49:25,502:INFO:Initializing custom model Gradient Boosting Regressor
2023-04-25 07:49:25,503:INFO:Total runtime is 1.6542275746663413e-05 minutes
2023-04-25 07:49:25,507:INFO:SubProcess create_model() called ==================================
2023-04-25 07:49:25,508:INFO:Initializing create_model()
2023-04-25 07:49:25,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CA5BA0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:49:25,509:INFO:Checking exceptions
2023-04-25 07:49:25,509:INFO:Importing libraries
2023-04-25 07:49:25,510:INFO:Copying training dataset
2023-04-25 07:49:25,515:INFO:Defining folds
2023-04-25 07:49:25,516:INFO:Declaring metric variables
2023-04-25 07:49:25,520:INFO:Importing untrained model
2023-04-25 07:49:25,520:INFO:Declaring custom model
2023-04-25 07:49:25,524:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 07:49:25,532:INFO:Starting cross validation
2023-04-25 07:49:25,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:49:26,660:INFO:Calculating mean and std
2023-04-25 07:49:26,662:INFO:Creating metrics dataframe
2023-04-25 07:49:26,783:INFO:Uploading results into container
2023-04-25 07:49:26,783:INFO:Uploading model into container now
2023-04-25 07:49:26,784:INFO:_master_model_container: 57
2023-04-25 07:49:26,784:INFO:_display_container: 17
2023-04-25 07:49:26,784:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-25 07:49:26,784:INFO:create_model() successfully completed......................................
2023-04-25 07:49:26,887:INFO:SubProcess create_model() end ==================================
2023-04-25 07:49:26,887:INFO:Creating metrics dataframe
2023-04-25 07:49:26,892:INFO:Initializing custom model Light Gradient Boosting Machine
2023-04-25 07:49:26,893:INFO:Total runtime is 0.023186377684275308 minutes
2023-04-25 07:49:26,896:INFO:SubProcess create_model() called ==================================
2023-04-25 07:49:26,897:INFO:Initializing create_model()
2023-04-25 07:49:26,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CA5BA0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:49:26,897:INFO:Checking exceptions
2023-04-25 07:49:26,897:INFO:Importing libraries
2023-04-25 07:49:26,897:INFO:Copying training dataset
2023-04-25 07:49:26,901:INFO:Defining folds
2023-04-25 07:49:26,901:INFO:Declaring metric variables
2023-04-25 07:49:26,904:INFO:Importing untrained model
2023-04-25 07:49:26,904:INFO:Declaring custom model
2023-04-25 07:49:26,908:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 07:49:26,913:INFO:Starting cross validation
2023-04-25 07:49:26,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:49:27,981:INFO:Calculating mean and std
2023-04-25 07:49:27,983:INFO:Creating metrics dataframe
2023-04-25 07:49:28,105:INFO:Uploading results into container
2023-04-25 07:49:28,106:INFO:Uploading model into container now
2023-04-25 07:49:28,106:INFO:_master_model_container: 58
2023-04-25 07:49:28,106:INFO:_display_container: 17
2023-04-25 07:49:28,107:INFO:LGBMRegressor(random_state=3041)
2023-04-25 07:49:28,107:INFO:create_model() successfully completed......................................
2023-04-25 07:49:28,208:INFO:SubProcess create_model() end ==================================
2023-04-25 07:49:28,208:INFO:Creating metrics dataframe
2023-04-25 07:49:28,218:INFO:Initializing custom model Random Forest Regressor
2023-04-25 07:49:28,218:INFO:Total runtime is 0.04527166684468587 minutes
2023-04-25 07:49:28,221:INFO:SubProcess create_model() called ==================================
2023-04-25 07:49:28,222:INFO:Initializing create_model()
2023-04-25 07:49:28,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D560CA5BA0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:49:28,223:INFO:Checking exceptions
2023-04-25 07:49:28,223:INFO:Importing libraries
2023-04-25 07:49:28,223:INFO:Copying training dataset
2023-04-25 07:49:28,229:INFO:Defining folds
2023-04-25 07:49:28,229:INFO:Declaring metric variables
2023-04-25 07:49:28,232:INFO:Importing untrained model
2023-04-25 07:49:28,232:INFO:Declaring custom model
2023-04-25 07:49:28,235:INFO:Random Forest Regressor Imported successfully
2023-04-25 07:49:28,242:INFO:Starting cross validation
2023-04-25 07:49:28,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:49:29,408:INFO:Calculating mean and std
2023-04-25 07:49:29,409:INFO:Creating metrics dataframe
2023-04-25 07:49:29,531:INFO:Uploading results into container
2023-04-25 07:49:29,531:INFO:Uploading model into container now
2023-04-25 07:49:29,531:INFO:_master_model_container: 59
2023-04-25 07:49:29,531:INFO:_display_container: 17
2023-04-25 07:49:29,532:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:49:29,532:INFO:create_model() successfully completed......................................
2023-04-25 07:49:29,632:INFO:SubProcess create_model() end ==================================
2023-04-25 07:49:29,632:INFO:Creating metrics dataframe
2023-04-25 07:49:29,650:INFO:Initializing create_model()
2023-04-25 07:49:29,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:49:29,650:INFO:Checking exceptions
2023-04-25 07:49:29,652:INFO:Importing libraries
2023-04-25 07:49:29,652:INFO:Copying training dataset
2023-04-25 07:49:29,655:INFO:Defining folds
2023-04-25 07:49:29,655:INFO:Declaring metric variables
2023-04-25 07:49:29,655:INFO:Importing untrained model
2023-04-25 07:49:29,655:INFO:Declaring custom model
2023-04-25 07:49:29,656:INFO:Random Forest Regressor Imported successfully
2023-04-25 07:49:29,657:INFO:Cross validation set to False
2023-04-25 07:49:29,657:INFO:Fitting Model
2023-04-25 07:49:29,794:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:49:29,794:INFO:create_model() successfully completed......................................
2023-04-25 07:49:29,898:INFO:Creating Dashboard logs
2023-04-25 07:49:29,901:INFO:Model: Random Forest Regressor
2023-04-25 07:49:29,951:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-25 07:49:30,023:INFO:Initializing predict_model()
2023-04-25 07:49:30,023:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561FF2D40>)
2023-04-25 07:49:30,023:INFO:Checking exceptions
2023-04-25 07:49:30,023:INFO:Preloading libraries
2023-04-25 07:49:30,406:INFO:Creating Dashboard logs
2023-04-25 07:49:30,409:INFO:Model: Gradient Boosting Regressor
2023-04-25 07:49:30,453:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 07:49:30,736:INFO:Creating Dashboard logs
2023-04-25 07:49:30,739:INFO:Model: Light Gradient Boosting Machine
2023-04-25 07:49:30,783:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 07:49:31,071:INFO:_master_model_container: 59
2023-04-25 07:49:31,071:INFO:_display_container: 17
2023-04-25 07:49:31,071:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:49:31,071:INFO:compare_models() successfully completed......................................
2023-04-25 07:49:31,073:INFO:Initializing plot_model()
2023-04-25 07:49:31,073:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=[GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:49:31,073:INFO:Checking exceptions
2023-04-25 07:50:11,179:INFO:Initializing compare_models()
2023-04-25 07:50:11,179:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, include=[GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, 'include': [GradientBoostingRegressor(random_state=3041), LGBMRegressor(random_state=3041), RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 07:50:11,180:INFO:Checking exceptions
2023-04-25 07:50:11,182:INFO:Preparing display monitor
2023-04-25 07:50:11,218:INFO:Initializing custom model Gradient Boosting Regressor
2023-04-25 07:50:11,218:INFO:Total runtime is 1.6617774963378907e-05 minutes
2023-04-25 07:50:11,225:INFO:SubProcess create_model() called ==================================
2023-04-25 07:50:11,226:INFO:Initializing create_model()
2023-04-25 07:50:11,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=GradientBoostingRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562114A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:50:11,226:INFO:Checking exceptions
2023-04-25 07:50:11,226:INFO:Importing libraries
2023-04-25 07:50:11,226:INFO:Copying training dataset
2023-04-25 07:50:11,230:INFO:Defining folds
2023-04-25 07:50:11,231:INFO:Declaring metric variables
2023-04-25 07:50:11,234:INFO:Importing untrained model
2023-04-25 07:50:11,234:INFO:Declaring custom model
2023-04-25 07:50:11,241:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 07:50:11,248:INFO:Starting cross validation
2023-04-25 07:50:11,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:50:12,325:INFO:Calculating mean and std
2023-04-25 07:50:12,327:INFO:Creating metrics dataframe
2023-04-25 07:50:12,450:INFO:Uploading results into container
2023-04-25 07:50:12,450:INFO:Uploading model into container now
2023-04-25 07:50:12,450:INFO:_master_model_container: 60
2023-04-25 07:50:12,451:INFO:_display_container: 18
2023-04-25 07:50:12,451:INFO:GradientBoostingRegressor(random_state=3041)
2023-04-25 07:50:12,451:INFO:create_model() successfully completed......................................
2023-04-25 07:50:12,560:INFO:SubProcess create_model() end ==================================
2023-04-25 07:50:12,560:INFO:Creating metrics dataframe
2023-04-25 07:50:12,566:INFO:Initializing custom model Light Gradient Boosting Machine
2023-04-25 07:50:12,566:INFO:Total runtime is 0.022482983271280923 minutes
2023-04-25 07:50:12,569:INFO:SubProcess create_model() called ==================================
2023-04-25 07:50:12,570:INFO:Initializing create_model()
2023-04-25 07:50:12,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=LGBMRegressor(random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562114A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:50:12,571:INFO:Checking exceptions
2023-04-25 07:50:12,571:INFO:Importing libraries
2023-04-25 07:50:12,571:INFO:Copying training dataset
2023-04-25 07:50:12,576:INFO:Defining folds
2023-04-25 07:50:12,576:INFO:Declaring metric variables
2023-04-25 07:50:12,580:INFO:Importing untrained model
2023-04-25 07:50:12,580:INFO:Declaring custom model
2023-04-25 07:50:12,584:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 07:50:12,590:INFO:Starting cross validation
2023-04-25 07:50:12,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:50:13,615:INFO:Calculating mean and std
2023-04-25 07:50:13,616:INFO:Creating metrics dataframe
2023-04-25 07:50:13,742:INFO:Uploading results into container
2023-04-25 07:50:13,742:INFO:Uploading model into container now
2023-04-25 07:50:13,743:INFO:_master_model_container: 61
2023-04-25 07:50:13,743:INFO:_display_container: 18
2023-04-25 07:50:13,743:INFO:LGBMRegressor(random_state=3041)
2023-04-25 07:50:13,743:INFO:create_model() successfully completed......................................
2023-04-25 07:50:13,852:INFO:SubProcess create_model() end ==================================
2023-04-25 07:50:13,853:INFO:Creating metrics dataframe
2023-04-25 07:50:13,862:INFO:Initializing custom model Random Forest Regressor
2023-04-25 07:50:13,862:INFO:Total runtime is 0.044080030918121335 minutes
2023-04-25 07:50:13,866:INFO:SubProcess create_model() called ==================================
2023-04-25 07:50:13,866:INFO:Initializing create_model()
2023-04-25 07:50:13,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562114A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:50:13,868:INFO:Checking exceptions
2023-04-25 07:50:13,868:INFO:Importing libraries
2023-04-25 07:50:13,868:INFO:Copying training dataset
2023-04-25 07:50:13,873:INFO:Defining folds
2023-04-25 07:50:13,873:INFO:Declaring metric variables
2023-04-25 07:50:13,876:INFO:Importing untrained model
2023-04-25 07:50:13,876:INFO:Declaring custom model
2023-04-25 07:50:13,879:INFO:Random Forest Regressor Imported successfully
2023-04-25 07:50:13,886:INFO:Starting cross validation
2023-04-25 07:50:13,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 07:50:15,101:INFO:Calculating mean and std
2023-04-25 07:50:15,102:INFO:Creating metrics dataframe
2023-04-25 07:50:15,256:INFO:Uploading results into container
2023-04-25 07:50:15,257:INFO:Uploading model into container now
2023-04-25 07:50:15,257:INFO:_master_model_container: 62
2023-04-25 07:50:15,257:INFO:_display_container: 18
2023-04-25 07:50:15,258:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:50:15,258:INFO:create_model() successfully completed......................................
2023-04-25 07:50:15,380:INFO:SubProcess create_model() end ==================================
2023-04-25 07:50:15,380:INFO:Creating metrics dataframe
2023-04-25 07:50:15,394:INFO:Initializing create_model()
2023-04-25 07:50:15,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 07:50:15,394:INFO:Checking exceptions
2023-04-25 07:50:15,396:INFO:Importing libraries
2023-04-25 07:50:15,396:INFO:Copying training dataset
2023-04-25 07:50:15,398:INFO:Defining folds
2023-04-25 07:50:15,398:INFO:Declaring metric variables
2023-04-25 07:50:15,399:INFO:Importing untrained model
2023-04-25 07:50:15,399:INFO:Declaring custom model
2023-04-25 07:50:15,400:INFO:Random Forest Regressor Imported successfully
2023-04-25 07:50:15,401:INFO:Cross validation set to False
2023-04-25 07:50:15,401:INFO:Fitting Model
2023-04-25 07:50:15,542:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:50:15,542:INFO:create_model() successfully completed......................................
2023-04-25 07:50:15,654:INFO:Creating Dashboard logs
2023-04-25 07:50:15,658:INFO:Model: Random Forest Regressor
2023-04-25 07:50:15,709:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 3041, 'verbose': 0, 'warm_start': False}
2023-04-25 07:50:15,799:INFO:Initializing predict_model()
2023-04-25 07:50:15,799:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D569BC1AB0>)
2023-04-25 07:50:15,799:INFO:Checking exceptions
2023-04-25 07:50:15,799:INFO:Preloading libraries
2023-04-25 07:50:16,233:INFO:Creating Dashboard logs
2023-04-25 07:50:16,237:INFO:Model: Gradient Boosting Regressor
2023-04-25 07:50:16,296:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3041, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 07:50:16,595:INFO:Creating Dashboard logs
2023-04-25 07:50:16,597:INFO:Model: Light Gradient Boosting Machine
2023-04-25 07:50:16,653:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3041, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 07:50:16,939:INFO:_master_model_container: 62
2023-04-25 07:50:16,939:INFO:_display_container: 18
2023-04-25 07:50:16,940:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041)
2023-04-25 07:50:16,940:INFO:compare_models() successfully completed......................................
2023-04-25 07:51:15,331:INFO:Initializing plot_model()
2023-04-25 07:51:15,331:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:51:15,331:INFO:Checking exceptions
2023-04-25 07:51:15,335:INFO:Preloading libraries
2023-04-25 07:51:15,341:INFO:Copying training dataset
2023-04-25 07:51:15,341:INFO:Plot type: error
2023-04-25 07:51:15,406:INFO:Fitting Model
2023-04-25 07:51:15,406:INFO:Scoring test/hold-out set
2023-04-25 07:51:15,562:INFO:Visual Rendered Successfully
2023-04-25 07:51:15,676:INFO:plot_model() successfully completed......................................
2023-04-25 07:51:15,688:INFO:Initializing plot_model()
2023-04-25 07:51:15,688:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:51:15,688:INFO:Checking exceptions
2023-04-25 07:51:15,691:INFO:Preloading libraries
2023-04-25 07:51:15,699:INFO:Copying training dataset
2023-04-25 07:51:15,699:INFO:Plot type: error
2023-04-25 07:51:15,769:INFO:Fitting Model
2023-04-25 07:51:15,769:INFO:Scoring test/hold-out set
2023-04-25 07:51:15,980:INFO:Visual Rendered Successfully
2023-04-25 07:51:16,086:INFO:plot_model() successfully completed......................................
2023-04-25 07:51:16,103:INFO:Initializing plot_model()
2023-04-25 07:51:16,104:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:51:16,104:INFO:Checking exceptions
2023-04-25 07:51:16,126:INFO:Preloading libraries
2023-04-25 07:51:16,139:INFO:Copying training dataset
2023-04-25 07:51:16,139:INFO:Plot type: error
2023-04-25 07:51:16,190:INFO:Fitting Model
2023-04-25 07:51:16,191:INFO:Scoring test/hold-out set
2023-04-25 07:51:16,399:INFO:Visual Rendered Successfully
2023-04-25 07:51:16,514:INFO:plot_model() successfully completed......................................
2023-04-25 07:54:46,891:INFO:Initializing plot_model()
2023-04-25 07:54:46,891:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:54:46,891:INFO:Checking exceptions
2023-04-25 07:54:46,895:INFO:Preloading libraries
2023-04-25 07:54:46,901:INFO:Copying training dataset
2023-04-25 07:54:46,901:INFO:Plot type: error
2023-04-25 07:54:46,967:INFO:Fitting Model
2023-04-25 07:54:46,967:INFO:Scoring test/hold-out set
2023-04-25 07:54:47,125:INFO:Visual Rendered Successfully
2023-04-25 07:54:47,238:INFO:plot_model() successfully completed......................................
2023-04-25 07:54:47,252:INFO:Initializing plot_model()
2023-04-25 07:54:47,252:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:54:47,252:INFO:Checking exceptions
2023-04-25 07:54:47,255:INFO:Preloading libraries
2023-04-25 07:54:47,261:INFO:Copying training dataset
2023-04-25 07:54:47,261:INFO:Plot type: error
2023-04-25 07:54:47,334:INFO:Fitting Model
2023-04-25 07:54:47,334:INFO:Scoring test/hold-out set
2023-04-25 07:54:47,534:INFO:Visual Rendered Successfully
2023-04-25 07:54:47,643:INFO:plot_model() successfully completed......................................
2023-04-25 07:54:47,660:INFO:Initializing plot_model()
2023-04-25 07:54:47,660:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:54:47,660:INFO:Checking exceptions
2023-04-25 07:54:47,681:INFO:Preloading libraries
2023-04-25 07:54:47,695:INFO:Copying training dataset
2023-04-25 07:54:47,695:INFO:Plot type: error
2023-04-25 07:54:47,749:INFO:Fitting Model
2023-04-25 07:54:47,749:INFO:Scoring test/hold-out set
2023-04-25 07:54:47,960:INFO:Visual Rendered Successfully
2023-04-25 07:54:48,079:INFO:plot_model() successfully completed......................................
2023-04-25 07:54:57,370:INFO:Initializing plot_model()
2023-04-25 07:54:57,370:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:54:57,370:INFO:Checking exceptions
2023-04-25 07:54:57,374:INFO:Preloading libraries
2023-04-25 07:54:57,379:INFO:Copying training dataset
2023-04-25 07:54:57,379:INFO:Plot type: error
2023-04-25 07:54:57,440:INFO:Fitting Model
2023-04-25 07:54:57,440:INFO:Scoring test/hold-out set
2023-04-25 07:54:57,596:INFO:Visual Rendered Successfully
2023-04-25 07:54:57,716:INFO:plot_model() successfully completed......................................
2023-04-25 07:54:57,731:INFO:Initializing plot_model()
2023-04-25 07:54:57,731:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:54:57,731:INFO:Checking exceptions
2023-04-25 07:54:57,734:INFO:Preloading libraries
2023-04-25 07:54:57,741:INFO:Copying training dataset
2023-04-25 07:54:57,741:INFO:Plot type: error
2023-04-25 07:54:57,806:INFO:Fitting Model
2023-04-25 07:54:57,806:INFO:Scoring test/hold-out set
2023-04-25 07:54:57,994:INFO:Visual Rendered Successfully
2023-04-25 07:54:58,105:INFO:plot_model() successfully completed......................................
2023-04-25 07:54:58,118:INFO:Initializing plot_model()
2023-04-25 07:54:58,118:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:54:58,118:INFO:Checking exceptions
2023-04-25 07:54:58,139:INFO:Preloading libraries
2023-04-25 07:54:58,154:INFO:Copying training dataset
2023-04-25 07:54:58,154:INFO:Plot type: error
2023-04-25 07:54:58,203:INFO:Fitting Model
2023-04-25 07:54:58,203:INFO:Scoring test/hold-out set
2023-04-25 07:54:58,402:INFO:Visual Rendered Successfully
2023-04-25 07:54:58,543:INFO:plot_model() successfully completed......................................
2023-04-25 07:55:15,493:INFO:Initializing plot_model()
2023-04-25 07:55:15,493:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:55:15,493:INFO:Checking exceptions
2023-04-25 07:55:15,497:INFO:Preloading libraries
2023-04-25 07:55:15,504:INFO:Copying training dataset
2023-04-25 07:55:15,504:INFO:Plot type: error
2023-04-25 07:55:15,592:INFO:Fitting Model
2023-04-25 07:55:15,593:INFO:Scoring test/hold-out set
2023-04-25 07:55:15,784:INFO:Visual Rendered Successfully
2023-04-25 07:55:15,918:INFO:plot_model() successfully completed......................................
2023-04-25 07:55:15,926:INFO:Initializing plot_model()
2023-04-25 07:55:15,926:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:55:15,926:INFO:Checking exceptions
2023-04-25 07:55:15,929:INFO:Preloading libraries
2023-04-25 07:55:15,936:INFO:Copying training dataset
2023-04-25 07:55:15,936:INFO:Plot type: error
2023-04-25 07:55:16,014:INFO:Fitting Model
2023-04-25 07:55:16,014:INFO:Scoring test/hold-out set
2023-04-25 07:55:16,219:INFO:Visual Rendered Successfully
2023-04-25 07:55:16,428:INFO:plot_model() successfully completed......................................
2023-04-25 07:55:16,439:INFO:Initializing plot_model()
2023-04-25 07:55:16,439:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:55:16,439:INFO:Checking exceptions
2023-04-25 07:55:16,466:INFO:Preloading libraries
2023-04-25 07:55:16,484:INFO:Copying training dataset
2023-04-25 07:55:16,484:INFO:Plot type: error
2023-04-25 07:55:16,545:INFO:Fitting Model
2023-04-25 07:55:16,545:INFO:Scoring test/hold-out set
2023-04-25 07:55:16,751:INFO:Visual Rendered Successfully
2023-04-25 07:55:16,881:INFO:plot_model() successfully completed......................................
2023-04-25 07:59:59,650:INFO:Initializing plot_model()
2023-04-25 07:59:59,650:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:59:59,650:INFO:Checking exceptions
2023-04-25 07:59:59,654:INFO:Preloading libraries
2023-04-25 07:59:59,660:INFO:Copying training dataset
2023-04-25 07:59:59,660:INFO:Plot type: feature
2023-04-25 07:59:59,661:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 07:59:59,808:INFO:Visual Rendered Successfully
2023-04-25 07:59:59,922:INFO:plot_model() successfully completed......................................
2023-04-25 07:59:59,929:INFO:Initializing plot_model()
2023-04-25 07:59:59,929:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 07:59:59,930:INFO:Checking exceptions
2023-04-25 07:59:59,933:INFO:Preloading libraries
2023-04-25 07:59:59,939:INFO:Copying training dataset
2023-04-25 07:59:59,939:INFO:Plot type: feature
2023-04-25 07:59:59,940:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:00:00,102:INFO:Visual Rendered Successfully
2023-04-25 08:00:00,237:INFO:plot_model() successfully completed......................................
2023-04-25 08:00:00,243:INFO:Initializing plot_model()
2023-04-25 08:00:00,243:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:00:00,244:INFO:Checking exceptions
2023-04-25 08:00:00,270:INFO:Preloading libraries
2023-04-25 08:00:00,282:INFO:Copying training dataset
2023-04-25 08:00:00,283:INFO:Plot type: feature
2023-04-25 08:00:00,283:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:00:00,426:INFO:Visual Rendered Successfully
2023-04-25 08:00:00,551:INFO:plot_model() successfully completed......................................
2023-04-25 08:01:14,432:INFO:Initializing plot_model()
2023-04-25 08:01:14,432:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:01:14,434:INFO:Checking exceptions
2023-04-25 08:01:14,437:INFO:Preloading libraries
2023-04-25 08:01:14,442:INFO:Copying training dataset
2023-04-25 08:01:14,442:INFO:Plot type: feature
2023-04-25 08:01:14,443:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:01:14,606:INFO:Visual Rendered Successfully
2023-04-25 08:01:14,722:INFO:plot_model() successfully completed......................................
2023-04-25 08:01:14,736:INFO:Initializing plot_model()
2023-04-25 08:01:14,737:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:01:14,737:INFO:Checking exceptions
2023-04-25 08:01:14,740:INFO:Preloading libraries
2023-04-25 08:01:14,747:INFO:Copying training dataset
2023-04-25 08:01:14,747:INFO:Plot type: feature
2023-04-25 08:01:14,747:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:01:14,897:INFO:Visual Rendered Successfully
2023-04-25 08:01:15,009:INFO:plot_model() successfully completed......................................
2023-04-25 08:01:15,029:INFO:Initializing plot_model()
2023-04-25 08:01:15,029:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:01:15,029:INFO:Checking exceptions
2023-04-25 08:01:15,050:INFO:Preloading libraries
2023-04-25 08:01:15,064:INFO:Copying training dataset
2023-04-25 08:01:15,065:INFO:Plot type: feature
2023-04-25 08:01:15,065:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:01:15,193:INFO:Visual Rendered Successfully
2023-04-25 08:01:15,311:INFO:plot_model() successfully completed......................................
2023-04-25 08:02:45,624:INFO:Initializing plot_model()
2023-04-25 08:02:45,625:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:02:45,625:INFO:Checking exceptions
2023-04-25 08:02:45,628:INFO:Preloading libraries
2023-04-25 08:02:45,634:INFO:Copying training dataset
2023-04-25 08:02:45,634:INFO:Plot type: feature
2023-04-25 08:02:45,634:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:02:45,786:INFO:Visual Rendered Successfully
2023-04-25 08:02:45,901:INFO:plot_model() successfully completed......................................
2023-04-25 08:02:45,916:INFO:Initializing plot_model()
2023-04-25 08:02:45,916:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:02:45,916:INFO:Checking exceptions
2023-04-25 08:02:45,919:INFO:Preloading libraries
2023-04-25 08:02:45,926:INFO:Copying training dataset
2023-04-25 08:02:45,926:INFO:Plot type: feature
2023-04-25 08:02:45,926:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:02:46,100:INFO:Visual Rendered Successfully
2023-04-25 08:02:46,216:INFO:plot_model() successfully completed......................................
2023-04-25 08:02:46,228:INFO:Initializing plot_model()
2023-04-25 08:02:46,228:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:02:46,228:INFO:Checking exceptions
2023-04-25 08:02:46,249:INFO:Preloading libraries
2023-04-25 08:02:46,263:INFO:Copying training dataset
2023-04-25 08:02:46,263:INFO:Plot type: feature
2023-04-25 08:02:46,264:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:02:46,397:INFO:Visual Rendered Successfully
2023-04-25 08:02:46,540:INFO:plot_model() successfully completed......................................
2023-04-25 08:03:12,658:INFO:Initializing plot_model()
2023-04-25 08:03:12,659:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:03:12,659:INFO:Checking exceptions
2023-04-25 08:03:12,662:INFO:Preloading libraries
2023-04-25 08:03:12,668:INFO:Copying training dataset
2023-04-25 08:03:12,668:INFO:Plot type: feature
2023-04-25 08:03:12,668:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:03:12,813:INFO:Visual Rendered Successfully
2023-04-25 08:03:12,926:INFO:plot_model() successfully completed......................................
2023-04-25 08:03:12,940:INFO:Initializing plot_model()
2023-04-25 08:03:12,940:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:03:12,941:INFO:Checking exceptions
2023-04-25 08:03:12,944:INFO:Preloading libraries
2023-04-25 08:03:12,950:INFO:Copying training dataset
2023-04-25 08:03:12,950:INFO:Plot type: feature
2023-04-25 08:03:12,950:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:03:13,117:INFO:Visual Rendered Successfully
2023-04-25 08:03:13,259:INFO:plot_model() successfully completed......................................
2023-04-25 08:03:13,273:INFO:Initializing plot_model()
2023-04-25 08:03:13,273:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:03:13,273:INFO:Checking exceptions
2023-04-25 08:03:13,296:INFO:Preloading libraries
2023-04-25 08:03:13,310:INFO:Copying training dataset
2023-04-25 08:03:13,311:INFO:Plot type: feature
2023-04-25 08:03:13,311:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:03:13,438:INFO:Visual Rendered Successfully
2023-04-25 08:03:13,551:INFO:plot_model() successfully completed......................................
2023-04-25 08:06:55,504:INFO:Initializing plot_model()
2023-04-25 08:06:55,505:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:06:55,505:INFO:Checking exceptions
2023-04-25 08:06:55,511:INFO:Preloading libraries
2023-04-25 08:06:55,517:INFO:Copying training dataset
2023-04-25 08:06:55,517:INFO:Plot type: feature
2023-04-25 08:06:55,518:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:06:55,655:INFO:Visual Rendered Successfully
2023-04-25 08:06:55,785:INFO:plot_model() successfully completed......................................
2023-04-25 08:06:55,785:INFO:Initializing plot_model()
2023-04-25 08:06:55,785:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:06:55,785:INFO:Checking exceptions
2023-04-25 08:06:55,787:INFO:Preloading libraries
2023-04-25 08:06:55,796:INFO:Copying training dataset
2023-04-25 08:06:55,796:INFO:Plot type: feature
2023-04-25 08:06:55,796:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:06:55,942:INFO:Visual Rendered Successfully
2023-04-25 08:06:56,060:INFO:plot_model() successfully completed......................................
2023-04-25 08:06:56,060:INFO:Initializing plot_model()
2023-04-25 08:06:56,061:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:06:56,061:INFO:Checking exceptions
2023-04-25 08:06:56,084:INFO:Preloading libraries
2023-04-25 08:06:56,099:INFO:Copying training dataset
2023-04-25 08:06:56,099:INFO:Plot type: feature
2023-04-25 08:06:56,100:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:06:56,238:INFO:Visual Rendered Successfully
2023-04-25 08:06:56,384:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:08,347:INFO:Initializing plot_model()
2023-04-25 08:07:08,347:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:08,347:INFO:Checking exceptions
2023-04-25 08:07:08,351:INFO:Preloading libraries
2023-04-25 08:07:08,356:INFO:Copying training dataset
2023-04-25 08:07:08,356:INFO:Plot type: feature
2023-04-25 08:07:08,356:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:08,491:INFO:Visual Rendered Successfully
2023-04-25 08:07:08,609:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:08,609:INFO:Initializing plot_model()
2023-04-25 08:07:08,609:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:08,610:INFO:Checking exceptions
2023-04-25 08:07:08,613:INFO:Preloading libraries
2023-04-25 08:07:08,619:INFO:Copying training dataset
2023-04-25 08:07:08,619:INFO:Plot type: feature
2023-04-25 08:07:08,620:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:08,775:INFO:Visual Rendered Successfully
2023-04-25 08:07:08,887:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:08,889:INFO:Initializing plot_model()
2023-04-25 08:07:08,890:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:08,890:INFO:Checking exceptions
2023-04-25 08:07:08,913:INFO:Preloading libraries
2023-04-25 08:07:08,928:INFO:Copying training dataset
2023-04-25 08:07:08,928:INFO:Plot type: feature
2023-04-25 08:07:08,928:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:09,053:INFO:Visual Rendered Successfully
2023-04-25 08:07:09,178:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:31,763:INFO:Initializing plot_model()
2023-04-25 08:07:31,764:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:31,764:INFO:Checking exceptions
2023-04-25 08:07:31,770:INFO:Preloading libraries
2023-04-25 08:07:31,776:INFO:Copying training dataset
2023-04-25 08:07:31,776:INFO:Plot type: feature
2023-04-25 08:07:31,776:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:31,913:INFO:Visual Rendered Successfully
2023-04-25 08:07:32,031:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:45,394:INFO:Initializing plot_model()
2023-04-25 08:07:45,394:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:45,394:INFO:Checking exceptions
2023-04-25 08:07:45,400:INFO:Preloading libraries
2023-04-25 08:07:45,407:INFO:Copying training dataset
2023-04-25 08:07:45,407:INFO:Plot type: feature
2023-04-25 08:07:45,407:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:45,544:INFO:Visual Rendered Successfully
2023-04-25 08:07:45,661:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:45,662:INFO:Initializing plot_model()
2023-04-25 08:07:45,662:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:45,662:INFO:Checking exceptions
2023-04-25 08:07:45,668:INFO:Preloading libraries
2023-04-25 08:07:45,675:INFO:Copying training dataset
2023-04-25 08:07:45,675:INFO:Plot type: feature
2023-04-25 08:07:45,675:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:45,847:INFO:Visual Rendered Successfully
2023-04-25 08:07:45,972:INFO:plot_model() successfully completed......................................
2023-04-25 08:07:45,973:INFO:Initializing plot_model()
2023-04-25 08:07:45,973:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=10,
                      max_features='log2', min_impurity_decrease=0,
                      min_samples_leaf=2, n_estimators=200, n_jobs=-1,
                      random_state=3041), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D561EE8730>, system=True)
2023-04-25 08:07:45,973:INFO:Checking exceptions
2023-04-25 08:07:45,998:INFO:Preloading libraries
2023-04-25 08:07:46,011:INFO:Copying training dataset
2023-04-25 08:07:46,011:INFO:Plot type: feature
2023-04-25 08:07:46,013:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:07:46,141:INFO:Visual Rendered Successfully
2023-04-25 08:07:46,257:INFO:plot_model() successfully completed......................................
2023-04-25 08:10:51,085:INFO:PyCaret RegressionExperiment
2023-04-25 08:10:51,085:INFO:Logging name: charges
2023-04-25 08:10:51,085:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 08:10:51,085:INFO:version 3.0.0
2023-04-25 08:10:51,085:INFO:Initializing setup()
2023-04-25 08:10:51,085:INFO:self.USI: 4db1
2023-04-25 08:10:51,086:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-25 08:10:51,086:INFO:Checking environment
2023-04-25 08:10:51,086:INFO:python_version: 3.10.11
2023-04-25 08:10:51,086:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-25 08:10:51,086:INFO:machine: AMD64
2023-04-25 08:10:51,086:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 08:10:51,086:INFO:Memory: svmem(total=8362713088, available=998428672, percent=88.1, used=7364284416, free=998428672)
2023-04-25 08:10:51,087:INFO:Physical Core: 4
2023-04-25 08:10:51,087:INFO:Logical Core: 8
2023-04-25 08:10:51,087:INFO:Checking libraries
2023-04-25 08:10:51,087:INFO:System:
2023-04-25 08:10:51,087:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-25 08:10:51,087:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-25 08:10:51,087:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 08:10:51,087:INFO:PyCaret required dependencies:
2023-04-25 08:10:51,087:INFO:                 pip: 23.0.1
2023-04-25 08:10:51,087:INFO:          setuptools: 65.5.0
2023-04-25 08:10:51,087:INFO:             pycaret: 3.0.0
2023-04-25 08:10:51,087:INFO:             IPython: 8.5.0
2023-04-25 08:10:51,087:INFO:          ipywidgets: 8.0.2
2023-04-25 08:10:51,087:INFO:                tqdm: 4.65.0
2023-04-25 08:10:51,087:INFO:               numpy: 1.23.3
2023-04-25 08:10:51,088:INFO:              pandas: 1.5.0
2023-04-25 08:10:51,088:INFO:              jinja2: 3.1.2
2023-04-25 08:10:51,088:INFO:               scipy: 1.9.1
2023-04-25 08:10:51,088:INFO:              joblib: 1.2.0
2023-04-25 08:10:51,088:INFO:             sklearn: 1.1.2
2023-04-25 08:10:51,088:INFO:                pyod: 1.0.9
2023-04-25 08:10:51,088:INFO:            imblearn: 0.10.1
2023-04-25 08:10:51,088:INFO:   category_encoders: 2.6.0
2023-04-25 08:10:51,088:INFO:            lightgbm: 3.3.5
2023-04-25 08:10:51,088:INFO:               numba: 0.56.4
2023-04-25 08:10:51,088:INFO:            requests: 2.28.1
2023-04-25 08:10:51,088:INFO:          matplotlib: 3.6.0
2023-04-25 08:10:51,088:INFO:          scikitplot: 0.3.7
2023-04-25 08:10:51,088:INFO:         yellowbrick: 1.5
2023-04-25 08:10:51,088:INFO:              plotly: 5.10.0
2023-04-25 08:10:51,088:INFO:             kaleido: 0.2.1
2023-04-25 08:10:51,088:INFO:         statsmodels: 0.13.5
2023-04-25 08:10:51,088:INFO:              sktime: 0.17.1
2023-04-25 08:10:51,088:INFO:               tbats: 1.1.3
2023-04-25 08:10:51,088:INFO:            pmdarima: 2.0.3
2023-04-25 08:10:51,088:INFO:              psutil: 5.9.2
2023-04-25 08:10:51,088:INFO:PyCaret optional dependencies:
2023-04-25 08:10:51,088:INFO:                shap: Not installed
2023-04-25 08:10:51,088:INFO:           interpret: Not installed
2023-04-25 08:10:51,088:INFO:                umap: Not installed
2023-04-25 08:10:51,088:INFO:    pandas_profiling: Not installed
2023-04-25 08:10:51,088:INFO:  explainerdashboard: Not installed
2023-04-25 08:10:51,088:INFO:             autoviz: Not installed
2023-04-25 08:10:51,088:INFO:           fairlearn: Not installed
2023-04-25 08:10:51,088:INFO:             xgboost: 1.7.5
2023-04-25 08:10:51,088:INFO:            catboost: Not installed
2023-04-25 08:10:51,088:INFO:              kmodes: Not installed
2023-04-25 08:10:51,088:INFO:             mlxtend: Not installed
2023-04-25 08:10:51,088:INFO:       statsforecast: Not installed
2023-04-25 08:10:51,088:INFO:        tune_sklearn: Not installed
2023-04-25 08:10:51,088:INFO:                 ray: Not installed
2023-04-25 08:10:51,088:INFO:            hyperopt: Not installed
2023-04-25 08:10:51,088:INFO:              optuna: Not installed
2023-04-25 08:10:51,089:INFO:               skopt: Not installed
2023-04-25 08:10:51,089:INFO:              mlflow: 2.3.0
2023-04-25 08:10:51,089:INFO:              gradio: Not installed
2023-04-25 08:10:51,089:INFO:             fastapi: Not installed
2023-04-25 08:10:51,089:INFO:             uvicorn: Not installed
2023-04-25 08:10:51,089:INFO:              m2cgen: Not installed
2023-04-25 08:10:51,089:INFO:           evidently: Not installed
2023-04-25 08:10:51,089:INFO:               fugue: Not installed
2023-04-25 08:10:51,089:INFO:           streamlit: Not installed
2023-04-25 08:10:51,089:INFO:             prophet: Not installed
2023-04-25 08:10:51,089:INFO:None
2023-04-25 08:10:51,089:INFO:Set up data.
2023-04-25 08:10:51,094:INFO:Set up train/test split.
2023-04-25 08:10:51,095:INFO:Set up index.
2023-04-25 08:10:51,095:INFO:Set up folding strategy.
2023-04-25 08:10:51,095:INFO:Assigning column types.
2023-04-25 08:10:51,098:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 08:10:51,098:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,100:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,104:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,180:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,183:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,186:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,270:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,272:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 08:10:51,276:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,280:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,362:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,362:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,414:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,446:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,449:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 08:10:51,456:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,533:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,542:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,620:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,622:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 08:10:51,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,705:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,792:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,796:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 08:10:51,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,884:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:10:51,971:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:51,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:51,973:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 08:10:52,055:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:52,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:52,142:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:52,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:52,145:INFO:Preparing preprocessing pipeline...
2023-04-25 08:10:52,145:INFO:Set up simple imputation.
2023-04-25 08:10:52,145:INFO:Set up feature normalization.
2023-04-25 08:10:52,160:INFO:Finished creating preprocessing pipeline.
2023-04-25 08:10:52,163:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-25 08:10:52,163:INFO:Creating final display dataframe.
2023-04-25 08:10:52,216:INFO:Setup _display_container:                     Description         Value
0                    Session id          1307
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1204, 8)
4        Transformed data shape     (1204, 8)
5   Transformed train set shape      (842, 8)
6    Transformed test set shape      (362, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          4db1
2023-04-25 08:10:52,309:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:52,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:52,394:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:10:52,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:10:52,397:INFO:Logging experiment in loggers
2023-04-25 08:10:52,466:INFO:SubProcess save_model() called ==================================
2023-04-25 08:10:52,473:INFO:Initializing save_model()
2023-04-25 08:10:52,473:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmpwt7ntnby\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 08:10:52,473:INFO:Adding model into prep_pipe
2023-04-25 08:10:52,473:WARNING:Only Model saved as it was a pipeline.
2023-04-25 08:10:52,475:INFO:C:\Users\danie\AppData\Local\Temp\tmpwt7ntnby\Transformation Pipeline.pkl saved in current working directory
2023-04-25 08:10:52,478:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-25 08:10:52,478:INFO:save_model() successfully completed......................................
2023-04-25 08:10:52,743:INFO:SubProcess save_model() end ==================================
2023-04-25 08:10:52,797:INFO:setup() successfully completed in 1.4s...............
2023-04-25 08:10:52,803:INFO:Initializing compare_models()
2023-04-25 08:10:52,804:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 08:10:52,804:INFO:Checking exceptions
2023-04-25 08:10:52,808:INFO:Preparing display monitor
2023-04-25 08:10:52,835:INFO:Initializing Linear Regression
2023-04-25 08:10:52,835:INFO:Total runtime is 0.0 minutes
2023-04-25 08:10:52,838:INFO:SubProcess create_model() called ==================================
2023-04-25 08:10:52,839:INFO:Initializing create_model()
2023-04-25 08:10:52,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:10:52,839:INFO:Checking exceptions
2023-04-25 08:10:52,839:INFO:Importing libraries
2023-04-25 08:10:52,839:INFO:Copying training dataset
2023-04-25 08:10:52,843:INFO:Defining folds
2023-04-25 08:10:52,843:INFO:Declaring metric variables
2023-04-25 08:10:52,847:INFO:Importing untrained model
2023-04-25 08:10:52,851:INFO:Linear Regression Imported successfully
2023-04-25 08:10:52,857:INFO:Starting cross validation
2023-04-25 08:10:52,859:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:10:57,202:INFO:Calculating mean and std
2023-04-25 08:10:57,204:INFO:Creating metrics dataframe
2023-04-25 08:10:57,335:INFO:Uploading results into container
2023-04-25 08:10:57,335:INFO:Uploading model into container now
2023-04-25 08:10:57,336:INFO:_master_model_container: 1
2023-04-25 08:10:57,336:INFO:_display_container: 2
2023-04-25 08:10:57,336:INFO:LinearRegression(n_jobs=-1)
2023-04-25 08:10:57,336:INFO:create_model() successfully completed......................................
2023-04-25 08:10:57,477:INFO:SubProcess create_model() end ==================================
2023-04-25 08:10:57,477:INFO:Creating metrics dataframe
2023-04-25 08:10:57,484:INFO:Initializing Lasso Regression
2023-04-25 08:10:57,484:INFO:Total runtime is 0.07748481432596842 minutes
2023-04-25 08:10:57,487:INFO:SubProcess create_model() called ==================================
2023-04-25 08:10:57,487:INFO:Initializing create_model()
2023-04-25 08:10:57,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:10:57,487:INFO:Checking exceptions
2023-04-25 08:10:57,488:INFO:Importing libraries
2023-04-25 08:10:57,488:INFO:Copying training dataset
2023-04-25 08:10:57,494:INFO:Defining folds
2023-04-25 08:10:57,494:INFO:Declaring metric variables
2023-04-25 08:10:57,497:INFO:Importing untrained model
2023-04-25 08:10:57,500:INFO:Lasso Regression Imported successfully
2023-04-25 08:10:57,506:INFO:Starting cross validation
2023-04-25 08:10:57,507:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:10:59,256:INFO:Calculating mean and std
2023-04-25 08:10:59,258:INFO:Creating metrics dataframe
2023-04-25 08:10:59,389:INFO:Uploading results into container
2023-04-25 08:10:59,389:INFO:Uploading model into container now
2023-04-25 08:10:59,390:INFO:_master_model_container: 2
2023-04-25 08:10:59,390:INFO:_display_container: 2
2023-04-25 08:10:59,390:INFO:Lasso(random_state=1307)
2023-04-25 08:10:59,390:INFO:create_model() successfully completed......................................
2023-04-25 08:10:59,535:INFO:SubProcess create_model() end ==================================
2023-04-25 08:10:59,535:INFO:Creating metrics dataframe
2023-04-25 08:10:59,546:INFO:Initializing Ridge Regression
2023-04-25 08:10:59,546:INFO:Total runtime is 0.11185071070988972 minutes
2023-04-25 08:10:59,550:INFO:SubProcess create_model() called ==================================
2023-04-25 08:10:59,550:INFO:Initializing create_model()
2023-04-25 08:10:59,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:10:59,550:INFO:Checking exceptions
2023-04-25 08:10:59,550:INFO:Importing libraries
2023-04-25 08:10:59,550:INFO:Copying training dataset
2023-04-25 08:10:59,554:INFO:Defining folds
2023-04-25 08:10:59,554:INFO:Declaring metric variables
2023-04-25 08:10:59,556:INFO:Importing untrained model
2023-04-25 08:10:59,561:INFO:Ridge Regression Imported successfully
2023-04-25 08:10:59,567:INFO:Starting cross validation
2023-04-25 08:10:59,567:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:00,038:INFO:Calculating mean and std
2023-04-25 08:11:00,039:INFO:Creating metrics dataframe
2023-04-25 08:11:00,180:INFO:Uploading results into container
2023-04-25 08:11:00,182:INFO:Uploading model into container now
2023-04-25 08:11:00,183:INFO:_master_model_container: 3
2023-04-25 08:11:00,183:INFO:_display_container: 2
2023-04-25 08:11:00,183:INFO:Ridge(random_state=1307)
2023-04-25 08:11:00,183:INFO:create_model() successfully completed......................................
2023-04-25 08:11:00,318:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:00,319:INFO:Creating metrics dataframe
2023-04-25 08:11:00,329:INFO:Initializing Elastic Net
2023-04-25 08:11:00,329:INFO:Total runtime is 0.12490625381469726 minutes
2023-04-25 08:11:00,332:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:00,333:INFO:Initializing create_model()
2023-04-25 08:11:00,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:00,333:INFO:Checking exceptions
2023-04-25 08:11:00,333:INFO:Importing libraries
2023-04-25 08:11:00,333:INFO:Copying training dataset
2023-04-25 08:11:00,336:INFO:Defining folds
2023-04-25 08:11:00,337:INFO:Declaring metric variables
2023-04-25 08:11:00,340:INFO:Importing untrained model
2023-04-25 08:11:00,346:INFO:Elastic Net Imported successfully
2023-04-25 08:11:00,352:INFO:Starting cross validation
2023-04-25 08:11:00,353:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:00,823:INFO:Calculating mean and std
2023-04-25 08:11:00,824:INFO:Creating metrics dataframe
2023-04-25 08:11:00,946:INFO:Uploading results into container
2023-04-25 08:11:00,947:INFO:Uploading model into container now
2023-04-25 08:11:00,947:INFO:_master_model_container: 4
2023-04-25 08:11:00,947:INFO:_display_container: 2
2023-04-25 08:11:00,947:INFO:ElasticNet(random_state=1307)
2023-04-25 08:11:00,947:INFO:create_model() successfully completed......................................
2023-04-25 08:11:01,062:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:01,062:INFO:Creating metrics dataframe
2023-04-25 08:11:01,069:INFO:Initializing Least Angle Regression
2023-04-25 08:11:01,069:INFO:Total runtime is 0.13723471562067668 minutes
2023-04-25 08:11:01,072:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:01,073:INFO:Initializing create_model()
2023-04-25 08:11:01,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:01,073:INFO:Checking exceptions
2023-04-25 08:11:01,073:INFO:Importing libraries
2023-04-25 08:11:01,073:INFO:Copying training dataset
2023-04-25 08:11:01,079:INFO:Defining folds
2023-04-25 08:11:01,079:INFO:Declaring metric variables
2023-04-25 08:11:01,083:INFO:Importing untrained model
2023-04-25 08:11:01,087:INFO:Least Angle Regression Imported successfully
2023-04-25 08:11:01,094:INFO:Starting cross validation
2023-04-25 08:11:01,095:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:01,152:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:01,156:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:01,164:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:01,568:INFO:Calculating mean and std
2023-04-25 08:11:01,569:INFO:Creating metrics dataframe
2023-04-25 08:11:01,701:INFO:Uploading results into container
2023-04-25 08:11:01,701:INFO:Uploading model into container now
2023-04-25 08:11:01,702:INFO:_master_model_container: 5
2023-04-25 08:11:01,702:INFO:_display_container: 2
2023-04-25 08:11:01,704:INFO:Lars(random_state=1307)
2023-04-25 08:11:01,704:INFO:create_model() successfully completed......................................
2023-04-25 08:11:01,826:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:01,827:INFO:Creating metrics dataframe
2023-04-25 08:11:01,837:INFO:Initializing Lasso Least Angle Regression
2023-04-25 08:11:01,837:INFO:Total runtime is 0.15003399054209393 minutes
2023-04-25 08:11:01,839:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:01,839:INFO:Initializing create_model()
2023-04-25 08:11:01,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:01,840:INFO:Checking exceptions
2023-04-25 08:11:01,840:INFO:Importing libraries
2023-04-25 08:11:01,840:INFO:Copying training dataset
2023-04-25 08:11:01,845:INFO:Defining folds
2023-04-25 08:11:01,845:INFO:Declaring metric variables
2023-04-25 08:11:01,849:INFO:Importing untrained model
2023-04-25 08:11:01,852:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 08:11:01,857:INFO:Starting cross validation
2023-04-25 08:11:01,858:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:01,910:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:11:01,921:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:11:01,929:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:11:01,935:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:11:01,941:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:11:02,349:INFO:Calculating mean and std
2023-04-25 08:11:02,350:INFO:Creating metrics dataframe
2023-04-25 08:11:02,471:INFO:Uploading results into container
2023-04-25 08:11:02,471:INFO:Uploading model into container now
2023-04-25 08:11:02,472:INFO:_master_model_container: 6
2023-04-25 08:11:02,472:INFO:_display_container: 2
2023-04-25 08:11:02,472:INFO:LassoLars(random_state=1307)
2023-04-25 08:11:02,472:INFO:create_model() successfully completed......................................
2023-04-25 08:11:02,585:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:02,585:INFO:Creating metrics dataframe
2023-04-25 08:11:02,593:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 08:11:02,593:INFO:Total runtime is 0.162632159392039 minutes
2023-04-25 08:11:02,596:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:02,596:INFO:Initializing create_model()
2023-04-25 08:11:02,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:02,596:INFO:Checking exceptions
2023-04-25 08:11:02,596:INFO:Importing libraries
2023-04-25 08:11:02,597:INFO:Copying training dataset
2023-04-25 08:11:02,601:INFO:Defining folds
2023-04-25 08:11:02,602:INFO:Declaring metric variables
2023-04-25 08:11:02,605:INFO:Importing untrained model
2023-04-25 08:11:02,608:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 08:11:02,614:INFO:Starting cross validation
2023-04-25 08:11:02,615:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:02,650:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:02,655:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:02,661:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:02,665:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:02,679:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:11:03,069:INFO:Calculating mean and std
2023-04-25 08:11:03,070:INFO:Creating metrics dataframe
2023-04-25 08:11:03,200:INFO:Uploading results into container
2023-04-25 08:11:03,201:INFO:Uploading model into container now
2023-04-25 08:11:03,201:INFO:_master_model_container: 7
2023-04-25 08:11:03,201:INFO:_display_container: 2
2023-04-25 08:11:03,201:INFO:OrthogonalMatchingPursuit()
2023-04-25 08:11:03,201:INFO:create_model() successfully completed......................................
2023-04-25 08:11:03,319:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:03,319:INFO:Creating metrics dataframe
2023-04-25 08:11:03,328:INFO:Initializing Bayesian Ridge
2023-04-25 08:11:03,328:INFO:Total runtime is 0.17489585479100547 minutes
2023-04-25 08:11:03,332:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:03,332:INFO:Initializing create_model()
2023-04-25 08:11:03,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:03,332:INFO:Checking exceptions
2023-04-25 08:11:03,332:INFO:Importing libraries
2023-04-25 08:11:03,332:INFO:Copying training dataset
2023-04-25 08:11:03,336:INFO:Defining folds
2023-04-25 08:11:03,337:INFO:Declaring metric variables
2023-04-25 08:11:03,340:INFO:Importing untrained model
2023-04-25 08:11:03,343:INFO:Bayesian Ridge Imported successfully
2023-04-25 08:11:03,353:INFO:Starting cross validation
2023-04-25 08:11:03,354:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:03,806:INFO:Calculating mean and std
2023-04-25 08:11:03,807:INFO:Creating metrics dataframe
2023-04-25 08:11:03,930:INFO:Uploading results into container
2023-04-25 08:11:03,930:INFO:Uploading model into container now
2023-04-25 08:11:03,930:INFO:_master_model_container: 8
2023-04-25 08:11:03,930:INFO:_display_container: 2
2023-04-25 08:11:03,931:INFO:BayesianRidge()
2023-04-25 08:11:03,931:INFO:create_model() successfully completed......................................
2023-04-25 08:11:04,044:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:04,044:INFO:Creating metrics dataframe
2023-04-25 08:11:04,054:INFO:Initializing Passive Aggressive Regressor
2023-04-25 08:11:04,055:INFO:Total runtime is 0.18700993855794273 minutes
2023-04-25 08:11:04,058:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:04,058:INFO:Initializing create_model()
2023-04-25 08:11:04,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:04,058:INFO:Checking exceptions
2023-04-25 08:11:04,058:INFO:Importing libraries
2023-04-25 08:11:04,058:INFO:Copying training dataset
2023-04-25 08:11:04,063:INFO:Defining folds
2023-04-25 08:11:04,063:INFO:Declaring metric variables
2023-04-25 08:11:04,066:INFO:Importing untrained model
2023-04-25 08:11:04,069:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 08:11:04,074:INFO:Starting cross validation
2023-04-25 08:11:04,075:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:04,529:INFO:Calculating mean and std
2023-04-25 08:11:04,530:INFO:Creating metrics dataframe
2023-04-25 08:11:04,654:INFO:Uploading results into container
2023-04-25 08:11:04,654:INFO:Uploading model into container now
2023-04-25 08:11:04,655:INFO:_master_model_container: 9
2023-04-25 08:11:04,655:INFO:_display_container: 2
2023-04-25 08:11:04,655:INFO:PassiveAggressiveRegressor(random_state=1307)
2023-04-25 08:11:04,655:INFO:create_model() successfully completed......................................
2023-04-25 08:11:04,768:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:04,769:INFO:Creating metrics dataframe
2023-04-25 08:11:04,776:INFO:Initializing Huber Regressor
2023-04-25 08:11:04,776:INFO:Total runtime is 0.19901717503865562 minutes
2023-04-25 08:11:04,779:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:04,779:INFO:Initializing create_model()
2023-04-25 08:11:04,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:04,779:INFO:Checking exceptions
2023-04-25 08:11:04,779:INFO:Importing libraries
2023-04-25 08:11:04,780:INFO:Copying training dataset
2023-04-25 08:11:04,784:INFO:Defining folds
2023-04-25 08:11:04,785:INFO:Declaring metric variables
2023-04-25 08:11:04,789:INFO:Importing untrained model
2023-04-25 08:11:04,792:INFO:Huber Regressor Imported successfully
2023-04-25 08:11:04,797:INFO:Starting cross validation
2023-04-25 08:11:04,798:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:05,250:INFO:Calculating mean and std
2023-04-25 08:11:05,251:INFO:Creating metrics dataframe
2023-04-25 08:11:05,372:INFO:Uploading results into container
2023-04-25 08:11:05,373:INFO:Uploading model into container now
2023-04-25 08:11:05,373:INFO:_master_model_container: 10
2023-04-25 08:11:05,373:INFO:_display_container: 2
2023-04-25 08:11:05,373:INFO:HuberRegressor()
2023-04-25 08:11:05,373:INFO:create_model() successfully completed......................................
2023-04-25 08:11:05,490:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:05,490:INFO:Creating metrics dataframe
2023-04-25 08:11:05,501:INFO:Initializing K Neighbors Regressor
2023-04-25 08:11:05,501:INFO:Total runtime is 0.21110051075617475 minutes
2023-04-25 08:11:05,504:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:05,504:INFO:Initializing create_model()
2023-04-25 08:11:05,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:05,504:INFO:Checking exceptions
2023-04-25 08:11:05,504:INFO:Importing libraries
2023-04-25 08:11:05,504:INFO:Copying training dataset
2023-04-25 08:11:05,509:INFO:Defining folds
2023-04-25 08:11:05,509:INFO:Declaring metric variables
2023-04-25 08:11:05,513:INFO:Importing untrained model
2023-04-25 08:11:05,516:INFO:K Neighbors Regressor Imported successfully
2023-04-25 08:11:05,522:INFO:Starting cross validation
2023-04-25 08:11:05,523:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:05,981:INFO:Calculating mean and std
2023-04-25 08:11:05,982:INFO:Creating metrics dataframe
2023-04-25 08:11:06,105:INFO:Uploading results into container
2023-04-25 08:11:06,105:INFO:Uploading model into container now
2023-04-25 08:11:06,106:INFO:_master_model_container: 11
2023-04-25 08:11:06,106:INFO:_display_container: 2
2023-04-25 08:11:06,106:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 08:11:06,106:INFO:create_model() successfully completed......................................
2023-04-25 08:11:06,220:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:06,220:INFO:Creating metrics dataframe
2023-04-25 08:11:06,230:INFO:Initializing Decision Tree Regressor
2023-04-25 08:11:06,230:INFO:Total runtime is 0.22325856685638432 minutes
2023-04-25 08:11:06,234:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:06,234:INFO:Initializing create_model()
2023-04-25 08:11:06,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:06,234:INFO:Checking exceptions
2023-04-25 08:11:06,234:INFO:Importing libraries
2023-04-25 08:11:06,234:INFO:Copying training dataset
2023-04-25 08:11:06,239:INFO:Defining folds
2023-04-25 08:11:06,239:INFO:Declaring metric variables
2023-04-25 08:11:06,241:INFO:Importing untrained model
2023-04-25 08:11:06,245:INFO:Decision Tree Regressor Imported successfully
2023-04-25 08:11:06,250:INFO:Starting cross validation
2023-04-25 08:11:06,251:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:06,699:INFO:Calculating mean and std
2023-04-25 08:11:06,700:INFO:Creating metrics dataframe
2023-04-25 08:11:06,824:INFO:Uploading results into container
2023-04-25 08:11:06,825:INFO:Uploading model into container now
2023-04-25 08:11:06,826:INFO:_master_model_container: 12
2023-04-25 08:11:06,826:INFO:_display_container: 2
2023-04-25 08:11:06,826:INFO:DecisionTreeRegressor(random_state=1307)
2023-04-25 08:11:06,826:INFO:create_model() successfully completed......................................
2023-04-25 08:11:06,941:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:06,941:INFO:Creating metrics dataframe
2023-04-25 08:11:06,950:INFO:Initializing Random Forest Regressor
2023-04-25 08:11:06,950:INFO:Total runtime is 0.23525634209314986 minutes
2023-04-25 08:11:06,953:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:06,954:INFO:Initializing create_model()
2023-04-25 08:11:06,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:06,954:INFO:Checking exceptions
2023-04-25 08:11:06,955:INFO:Importing libraries
2023-04-25 08:11:06,955:INFO:Copying training dataset
2023-04-25 08:11:06,959:INFO:Defining folds
2023-04-25 08:11:06,959:INFO:Declaring metric variables
2023-04-25 08:11:06,962:INFO:Importing untrained model
2023-04-25 08:11:06,965:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:11:06,972:INFO:Starting cross validation
2023-04-25 08:11:06,974:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:07,729:INFO:Calculating mean and std
2023-04-25 08:11:07,730:INFO:Creating metrics dataframe
2023-04-25 08:11:07,854:INFO:Uploading results into container
2023-04-25 08:11:07,854:INFO:Uploading model into container now
2023-04-25 08:11:07,854:INFO:_master_model_container: 13
2023-04-25 08:11:07,855:INFO:_display_container: 2
2023-04-25 08:11:07,855:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:11:07,855:INFO:create_model() successfully completed......................................
2023-04-25 08:11:07,969:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:07,969:INFO:Creating metrics dataframe
2023-04-25 08:11:07,981:INFO:Initializing Extra Trees Regressor
2023-04-25 08:11:07,981:INFO:Total runtime is 0.2524475971857707 minutes
2023-04-25 08:11:07,985:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:07,985:INFO:Initializing create_model()
2023-04-25 08:11:07,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:07,985:INFO:Checking exceptions
2023-04-25 08:11:07,985:INFO:Importing libraries
2023-04-25 08:11:07,985:INFO:Copying training dataset
2023-04-25 08:11:07,990:INFO:Defining folds
2023-04-25 08:11:07,991:INFO:Declaring metric variables
2023-04-25 08:11:07,994:INFO:Importing untrained model
2023-04-25 08:11:07,997:INFO:Extra Trees Regressor Imported successfully
2023-04-25 08:11:08,005:INFO:Starting cross validation
2023-04-25 08:11:08,007:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:08,773:INFO:Calculating mean and std
2023-04-25 08:11:08,774:INFO:Creating metrics dataframe
2023-04-25 08:11:08,901:INFO:Uploading results into container
2023-04-25 08:11:08,901:INFO:Uploading model into container now
2023-04-25 08:11:08,902:INFO:_master_model_container: 14
2023-04-25 08:11:08,902:INFO:_display_container: 2
2023-04-25 08:11:08,902:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:11:08,902:INFO:create_model() successfully completed......................................
2023-04-25 08:11:09,015:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:09,015:INFO:Creating metrics dataframe
2023-04-25 08:11:09,026:INFO:Initializing AdaBoost Regressor
2023-04-25 08:11:09,027:INFO:Total runtime is 0.26987200180689497 minutes
2023-04-25 08:11:09,030:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:09,030:INFO:Initializing create_model()
2023-04-25 08:11:09,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:09,030:INFO:Checking exceptions
2023-04-25 08:11:09,030:INFO:Importing libraries
2023-04-25 08:11:09,030:INFO:Copying training dataset
2023-04-25 08:11:09,035:INFO:Defining folds
2023-04-25 08:11:09,035:INFO:Declaring metric variables
2023-04-25 08:11:09,038:INFO:Importing untrained model
2023-04-25 08:11:09,041:INFO:AdaBoost Regressor Imported successfully
2023-04-25 08:11:09,047:INFO:Starting cross validation
2023-04-25 08:11:09,048:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:09,551:INFO:Calculating mean and std
2023-04-25 08:11:09,552:INFO:Creating metrics dataframe
2023-04-25 08:11:09,679:INFO:Uploading results into container
2023-04-25 08:11:09,680:INFO:Uploading model into container now
2023-04-25 08:11:09,680:INFO:_master_model_container: 15
2023-04-25 08:11:09,680:INFO:_display_container: 2
2023-04-25 08:11:09,681:INFO:AdaBoostRegressor(random_state=1307)
2023-04-25 08:11:09,681:INFO:create_model() successfully completed......................................
2023-04-25 08:11:09,794:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:09,794:INFO:Creating metrics dataframe
2023-04-25 08:11:09,806:INFO:Initializing Gradient Boosting Regressor
2023-04-25 08:11:09,806:INFO:Total runtime is 0.28286280632019045 minutes
2023-04-25 08:11:09,810:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:09,811:INFO:Initializing create_model()
2023-04-25 08:11:09,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:09,811:INFO:Checking exceptions
2023-04-25 08:11:09,811:INFO:Importing libraries
2023-04-25 08:11:09,811:INFO:Copying training dataset
2023-04-25 08:11:09,818:INFO:Defining folds
2023-04-25 08:11:09,818:INFO:Declaring metric variables
2023-04-25 08:11:09,823:INFO:Importing untrained model
2023-04-25 08:11:09,826:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:11:09,834:INFO:Starting cross validation
2023-04-25 08:11:09,837:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:10,377:INFO:Calculating mean and std
2023-04-25 08:11:10,379:INFO:Creating metrics dataframe
2023-04-25 08:11:10,511:INFO:Uploading results into container
2023-04-25 08:11:10,511:INFO:Uploading model into container now
2023-04-25 08:11:10,512:INFO:_master_model_container: 16
2023-04-25 08:11:10,512:INFO:_display_container: 2
2023-04-25 08:11:10,512:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:11:10,512:INFO:create_model() successfully completed......................................
2023-04-25 08:11:10,627:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:10,628:INFO:Creating metrics dataframe
2023-04-25 08:11:10,638:INFO:Initializing Extreme Gradient Boosting
2023-04-25 08:11:10,638:INFO:Total runtime is 0.2967211206754049 minutes
2023-04-25 08:11:10,641:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:10,642:INFO:Initializing create_model()
2023-04-25 08:11:10,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:10,642:INFO:Checking exceptions
2023-04-25 08:11:10,642:INFO:Importing libraries
2023-04-25 08:11:10,642:INFO:Copying training dataset
2023-04-25 08:11:10,647:INFO:Defining folds
2023-04-25 08:11:10,647:INFO:Declaring metric variables
2023-04-25 08:11:10,649:INFO:Importing untrained model
2023-04-25 08:11:10,653:INFO:Extreme Gradient Boosting Imported successfully
2023-04-25 08:11:10,658:INFO:Starting cross validation
2023-04-25 08:11:10,659:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:12,619:INFO:Calculating mean and std
2023-04-25 08:11:12,620:INFO:Creating metrics dataframe
2023-04-25 08:11:12,749:INFO:Uploading results into container
2023-04-25 08:11:12,750:INFO:Uploading model into container now
2023-04-25 08:11:12,750:INFO:_master_model_container: 17
2023-04-25 08:11:12,750:INFO:_display_container: 2
2023-04-25 08:11:12,751:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1307, ...)
2023-04-25 08:11:12,751:INFO:create_model() successfully completed......................................
2023-04-25 08:11:12,867:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:12,867:INFO:Creating metrics dataframe
2023-04-25 08:11:12,878:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 08:11:12,878:INFO:Total runtime is 0.3340590238571167 minutes
2023-04-25 08:11:12,880:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:12,881:INFO:Initializing create_model()
2023-04-25 08:11:12,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:12,881:INFO:Checking exceptions
2023-04-25 08:11:12,881:INFO:Importing libraries
2023-04-25 08:11:12,882:INFO:Copying training dataset
2023-04-25 08:11:12,887:INFO:Defining folds
2023-04-25 08:11:12,887:INFO:Declaring metric variables
2023-04-25 08:11:12,889:INFO:Importing untrained model
2023-04-25 08:11:12,892:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:11:12,898:INFO:Starting cross validation
2023-04-25 08:11:12,899:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:13,460:INFO:Calculating mean and std
2023-04-25 08:11:13,461:INFO:Creating metrics dataframe
2023-04-25 08:11:13,591:INFO:Uploading results into container
2023-04-25 08:11:13,591:INFO:Uploading model into container now
2023-04-25 08:11:13,591:INFO:_master_model_container: 18
2023-04-25 08:11:13,591:INFO:_display_container: 2
2023-04-25 08:11:13,593:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:11:13,593:INFO:create_model() successfully completed......................................
2023-04-25 08:11:13,706:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:13,706:INFO:Creating metrics dataframe
2023-04-25 08:11:13,716:INFO:Initializing Dummy Regressor
2023-04-25 08:11:13,716:INFO:Total runtime is 0.34801560640335083 minutes
2023-04-25 08:11:13,718:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:13,720:INFO:Initializing create_model()
2023-04-25 08:11:13,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AD9AFE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:13,720:INFO:Checking exceptions
2023-04-25 08:11:13,720:INFO:Importing libraries
2023-04-25 08:11:13,720:INFO:Copying training dataset
2023-04-25 08:11:13,725:INFO:Defining folds
2023-04-25 08:11:13,726:INFO:Declaring metric variables
2023-04-25 08:11:13,730:INFO:Importing untrained model
2023-04-25 08:11:13,733:INFO:Dummy Regressor Imported successfully
2023-04-25 08:11:13,741:INFO:Starting cross validation
2023-04-25 08:11:13,742:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:14,205:INFO:Calculating mean and std
2023-04-25 08:11:14,206:INFO:Creating metrics dataframe
2023-04-25 08:11:14,338:INFO:Uploading results into container
2023-04-25 08:11:14,338:INFO:Uploading model into container now
2023-04-25 08:11:14,339:INFO:_master_model_container: 19
2023-04-25 08:11:14,339:INFO:_display_container: 2
2023-04-25 08:11:14,340:INFO:DummyRegressor()
2023-04-25 08:11:14,340:INFO:create_model() successfully completed......................................
2023-04-25 08:11:14,454:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:14,455:INFO:Creating metrics dataframe
2023-04-25 08:11:14,474:INFO:Initializing create_model()
2023-04-25 08:11:14,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:14,474:INFO:Checking exceptions
2023-04-25 08:11:14,476:INFO:Importing libraries
2023-04-25 08:11:14,476:INFO:Copying training dataset
2023-04-25 08:11:14,478:INFO:Defining folds
2023-04-25 08:11:14,479:INFO:Declaring metric variables
2023-04-25 08:11:14,479:INFO:Importing untrained model
2023-04-25 08:11:14,479:INFO:Declaring custom model
2023-04-25 08:11:14,479:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:11:14,480:INFO:Cross validation set to False
2023-04-25 08:11:14,480:INFO:Fitting Model
2023-04-25 08:11:14,638:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:11:14,638:INFO:create_model() successfully completed......................................
2023-04-25 08:11:14,756:INFO:Creating Dashboard logs
2023-04-25 08:11:14,760:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:11:14,806:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:14,883:INFO:Initializing predict_model()
2023-04-25 08:11:14,883:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BD630>)
2023-04-25 08:11:14,883:INFO:Checking exceptions
2023-04-25 08:11:14,884:INFO:Preloading libraries
2023-04-25 08:11:15,270:INFO:Creating Dashboard logs
2023-04-25 08:11:15,273:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:11:15,312:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:11:15,611:INFO:Creating Dashboard logs
2023-04-25 08:11:15,614:INFO:Model: Random Forest Regressor
2023-04-25 08:11:15,652:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:15,951:INFO:Creating Dashboard logs
2023-04-25 08:11:15,953:INFO:Model: AdaBoost Regressor
2023-04-25 08:11:15,994:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1307}
2023-04-25 08:11:16,291:INFO:Creating Dashboard logs
2023-04-25 08:11:16,294:INFO:Model: Extra Trees Regressor
2023-04-25 08:11:16,340:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:16,667:INFO:Creating Dashboard logs
2023-04-25 08:11:16,670:INFO:Model: K Neighbors Regressor
2023-04-25 08:11:16,719:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-25 08:11:17,027:INFO:Creating Dashboard logs
2023-04-25 08:11:17,030:INFO:Model: Extreme Gradient Boosting
2023-04-25 08:11:17,074:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 1307, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-25 08:11:17,412:INFO:Creating Dashboard logs
2023-04-25 08:11:17,415:INFO:Model: Lasso Least Angle Regression
2023-04-25 08:11:17,462:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 1307, 'verbose': False}
2023-04-25 08:11:17,770:INFO:Creating Dashboard logs
2023-04-25 08:11:17,772:INFO:Model: Bayesian Ridge
2023-04-25 08:11:17,817:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-25 08:11:18,140:INFO:Creating Dashboard logs
2023-04-25 08:11:18,143:INFO:Model: Ridge Regression
2023-04-25 08:11:18,186:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 1307, 'solver': 'auto', 'tol': 0.001}
2023-04-25 08:11:18,515:INFO:Creating Dashboard logs
2023-04-25 08:11:18,520:INFO:Model: Lasso Regression
2023-04-25 08:11:18,572:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 1307, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:11:18,908:INFO:Creating Dashboard logs
2023-04-25 08:11:18,910:INFO:Model: Linear Regression
2023-04-25 08:11:18,954:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-25 08:11:19,267:INFO:Creating Dashboard logs
2023-04-25 08:11:19,270:INFO:Model: Least Angle Regression
2023-04-25 08:11:19,323:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 1307, 'verbose': False}
2023-04-25 08:11:19,622:INFO:Creating Dashboard logs
2023-04-25 08:11:19,625:INFO:Model: Decision Tree Regressor
2023-04-25 08:11:19,673:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1307, 'splitter': 'best'}
2023-04-25 08:11:19,972:INFO:Creating Dashboard logs
2023-04-25 08:11:19,974:INFO:Model: Huber Regressor
2023-04-25 08:11:20,018:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-25 08:11:20,312:INFO:Creating Dashboard logs
2023-04-25 08:11:20,315:INFO:Model: Passive Aggressive Regressor
2023-04-25 08:11:20,360:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 1307, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:20,662:INFO:Creating Dashboard logs
2023-04-25 08:11:20,665:INFO:Model: Elastic Net
2023-04-25 08:11:20,709:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 1307, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:11:21,006:INFO:Creating Dashboard logs
2023-04-25 08:11:21,008:INFO:Model: Orthogonal Matching Pursuit
2023-04-25 08:11:21,052:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-25 08:11:21,340:INFO:Creating Dashboard logs
2023-04-25 08:11:21,343:INFO:Model: Dummy Regressor
2023-04-25 08:11:21,384:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-25 08:11:21,690:INFO:_master_model_container: 19
2023-04-25 08:11:21,690:INFO:_display_container: 2
2023-04-25 08:11:21,690:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:11:21,690:INFO:compare_models() successfully completed......................................
2023-04-25 08:11:21,715:INFO:Initializing create_model()
2023-04-25 08:11:21,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:21,715:INFO:Checking exceptions
2023-04-25 08:11:21,739:INFO:Importing libraries
2023-04-25 08:11:21,739:INFO:Copying training dataset
2023-04-25 08:11:21,743:INFO:Defining folds
2023-04-25 08:11:21,743:INFO:Declaring metric variables
2023-04-25 08:11:21,749:INFO:Importing untrained model
2023-04-25 08:11:21,753:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:11:21,759:INFO:Starting cross validation
2023-04-25 08:11:21,760:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:22,314:INFO:Calculating mean and std
2023-04-25 08:11:22,314:INFO:Creating metrics dataframe
2023-04-25 08:11:22,318:INFO:Finalizing model
2023-04-25 08:11:22,501:INFO:Creating Dashboard logs
2023-04-25 08:11:22,503:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:11:22,544:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:22,615:INFO:Initializing predict_model()
2023-04-25 08:11:22,615:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BC3A0>)
2023-04-25 08:11:22,615:INFO:Checking exceptions
2023-04-25 08:11:22,615:INFO:Preloading libraries
2023-04-25 08:11:22,998:INFO:Uploading results into container
2023-04-25 08:11:22,999:INFO:Uploading model into container now
2023-04-25 08:11:23,006:INFO:_master_model_container: 20
2023-04-25 08:11:23,006:INFO:_display_container: 3
2023-04-25 08:11:23,006:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:11:23,006:INFO:create_model() successfully completed......................................
2023-04-25 08:11:23,154:INFO:Initializing create_model()
2023-04-25 08:11:23,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:23,155:INFO:Checking exceptions
2023-04-25 08:11:23,179:INFO:Importing libraries
2023-04-25 08:11:23,179:INFO:Copying training dataset
2023-04-25 08:11:23,184:INFO:Defining folds
2023-04-25 08:11:23,184:INFO:Declaring metric variables
2023-04-25 08:11:23,189:INFO:Importing untrained model
2023-04-25 08:11:23,193:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:11:23,200:INFO:Starting cross validation
2023-04-25 08:11:23,202:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:23,743:INFO:Calculating mean and std
2023-04-25 08:11:23,744:INFO:Creating metrics dataframe
2023-04-25 08:11:23,747:INFO:Finalizing model
2023-04-25 08:11:23,967:INFO:Creating Dashboard logs
2023-04-25 08:11:23,969:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:11:24,011:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:11:24,089:INFO:Initializing predict_model()
2023-04-25 08:11:24,089:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BCF70>)
2023-04-25 08:11:24,089:INFO:Checking exceptions
2023-04-25 08:11:24,089:INFO:Preloading libraries
2023-04-25 08:11:24,541:INFO:Uploading results into container
2023-04-25 08:11:24,541:INFO:Uploading model into container now
2023-04-25 08:11:24,551:INFO:_master_model_container: 21
2023-04-25 08:11:24,552:INFO:_display_container: 4
2023-04-25 08:11:24,552:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:11:24,553:INFO:create_model() successfully completed......................................
2023-04-25 08:11:24,711:INFO:Initializing create_model()
2023-04-25 08:11:24,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:24,711:INFO:Checking exceptions
2023-04-25 08:11:24,736:INFO:Importing libraries
2023-04-25 08:11:24,736:INFO:Copying training dataset
2023-04-25 08:11:24,741:INFO:Defining folds
2023-04-25 08:11:24,741:INFO:Declaring metric variables
2023-04-25 08:11:24,743:INFO:Importing untrained model
2023-04-25 08:11:24,746:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:11:24,753:INFO:Starting cross validation
2023-04-25 08:11:24,754:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:25,347:INFO:Calculating mean and std
2023-04-25 08:11:25,347:INFO:Creating metrics dataframe
2023-04-25 08:11:25,352:INFO:Finalizing model
2023-04-25 08:11:25,692:INFO:Creating Dashboard logs
2023-04-25 08:11:25,694:INFO:Model: Random Forest Regressor
2023-04-25 08:11:25,735:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:25,804:INFO:Initializing predict_model()
2023-04-25 08:11:25,804:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BDA20>)
2023-04-25 08:11:25,804:INFO:Checking exceptions
2023-04-25 08:11:25,804:INFO:Preloading libraries
2023-04-25 08:11:26,274:INFO:Uploading results into container
2023-04-25 08:11:26,275:INFO:Uploading model into container now
2023-04-25 08:11:26,281:INFO:_master_model_container: 22
2023-04-25 08:11:26,282:INFO:_display_container: 5
2023-04-25 08:11:26,282:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:11:26,282:INFO:create_model() successfully completed......................................
2023-04-25 08:11:26,437:INFO:Initializing tune_model()
2023-04-25 08:11:26,437:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:11:26,437:INFO:Checking exceptions
2023-04-25 08:11:26,458:INFO:Copying training dataset
2023-04-25 08:11:26,460:INFO:Checking base model
2023-04-25 08:11:26,460:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:11:26,463:INFO:Declaring metric variables
2023-04-25 08:11:26,466:INFO:Defining Hyperparameters
2023-04-25 08:11:26,591:INFO:Tuning with n_jobs=-1
2023-04-25 08:11:26,591:INFO:Initializing RandomizedSearchCV
2023-04-25 08:11:33,753:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.05}
2023-04-25 08:11:33,755:INFO:Hyperparameter search completed
2023-04-25 08:11:33,755:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:33,755:INFO:Initializing create_model()
2023-04-25 08:11:33,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A8EDC30>, model_only=True, return_train_score=False, kwargs={'subsample': 1.0, 'n_estimators': 280, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.05})
2023-04-25 08:11:33,755:INFO:Checking exceptions
2023-04-25 08:11:33,756:INFO:Importing libraries
2023-04-25 08:11:33,756:INFO:Copying training dataset
2023-04-25 08:11:33,762:INFO:Defining folds
2023-04-25 08:11:33,762:INFO:Declaring metric variables
2023-04-25 08:11:33,764:INFO:Importing untrained model
2023-04-25 08:11:33,764:INFO:Declaring custom model
2023-04-25 08:11:33,769:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:11:33,776:INFO:Starting cross validation
2023-04-25 08:11:33,778:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:34,415:INFO:Calculating mean and std
2023-04-25 08:11:34,416:INFO:Creating metrics dataframe
2023-04-25 08:11:34,420:INFO:Finalizing model
2023-04-25 08:11:34,900:INFO:Uploading results into container
2023-04-25 08:11:34,900:INFO:Uploading model into container now
2023-04-25 08:11:34,901:INFO:_master_model_container: 23
2023-04-25 08:11:34,901:INFO:_display_container: 6
2023-04-25 08:11:34,901:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307)
2023-04-25 08:11:34,901:INFO:create_model() successfully completed......................................
2023-04-25 08:11:35,021:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:35,021:INFO:choose_better activated
2023-04-25 08:11:35,024:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:35,024:INFO:Initializing create_model()
2023-04-25 08:11:35,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:35,025:INFO:Checking exceptions
2023-04-25 08:11:35,026:INFO:Importing libraries
2023-04-25 08:11:35,026:INFO:Copying training dataset
2023-04-25 08:11:35,028:INFO:Defining folds
2023-04-25 08:11:35,029:INFO:Declaring metric variables
2023-04-25 08:11:35,029:INFO:Importing untrained model
2023-04-25 08:11:35,029:INFO:Declaring custom model
2023-04-25 08:11:35,029:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:11:35,029:INFO:Starting cross validation
2023-04-25 08:11:35,030:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:35,590:INFO:Calculating mean and std
2023-04-25 08:11:35,591:INFO:Creating metrics dataframe
2023-04-25 08:11:35,592:INFO:Finalizing model
2023-04-25 08:11:35,783:INFO:Uploading results into container
2023-04-25 08:11:35,784:INFO:Uploading model into container now
2023-04-25 08:11:35,784:INFO:_master_model_container: 24
2023-04-25 08:11:35,784:INFO:_display_container: 7
2023-04-25 08:11:35,785:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:11:35,785:INFO:create_model() successfully completed......................................
2023-04-25 08:11:35,902:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:35,902:INFO:GradientBoostingRegressor(random_state=1307) result for R2 is 0.8603
2023-04-25 08:11:35,903:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307) result for R2 is 0.8253
2023-04-25 08:11:35,903:INFO:GradientBoostingRegressor(random_state=1307) is best model
2023-04-25 08:11:35,903:INFO:choose_better completed
2023-04-25 08:11:35,903:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:11:35,903:INFO:Creating Dashboard logs
2023-04-25 08:11:35,907:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:11:35,953:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:36,033:INFO:Initializing predict_model()
2023-04-25 08:11:36,033:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BCE50>)
2023-04-25 08:11:36,033:INFO:Checking exceptions
2023-04-25 08:11:36,034:INFO:Preloading libraries
2023-04-25 08:11:36,441:INFO:_master_model_container: 24
2023-04-25 08:11:36,441:INFO:_display_container: 6
2023-04-25 08:11:36,442:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:11:36,443:INFO:tune_model() successfully completed......................................
2023-04-25 08:11:36,671:INFO:Initializing tune_model()
2023-04-25 08:11:36,671:INFO:tune_model(estimator=LGBMRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:11:36,671:INFO:Checking exceptions
2023-04-25 08:11:36,700:INFO:Copying training dataset
2023-04-25 08:11:36,705:INFO:Checking base model
2023-04-25 08:11:36,706:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:11:36,710:INFO:Declaring metric variables
2023-04-25 08:11:36,714:INFO:Defining Hyperparameters
2023-04-25 08:11:36,839:INFO:Tuning with n_jobs=-1
2023-04-25 08:11:36,839:INFO:Initializing RandomizedSearchCV
2023-04-25 08:11:42,867:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2023-04-25 08:11:42,869:INFO:Hyperparameter search completed
2023-04-25 08:11:42,869:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:42,869:INFO:Initializing create_model()
2023-04-25 08:11:42,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC0E260>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 0.001, 'num_leaves': 50, 'n_estimators': 150, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2023-04-25 08:11:42,869:INFO:Checking exceptions
2023-04-25 08:11:42,869:INFO:Importing libraries
2023-04-25 08:11:42,869:INFO:Copying training dataset
2023-04-25 08:11:42,872:INFO:Defining folds
2023-04-25 08:11:42,872:INFO:Declaring metric variables
2023-04-25 08:11:42,876:INFO:Importing untrained model
2023-04-25 08:11:42,876:INFO:Declaring custom model
2023-04-25 08:11:42,882:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:11:42,888:INFO:Starting cross validation
2023-04-25 08:11:42,888:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:43,414:INFO:Calculating mean and std
2023-04-25 08:11:43,415:INFO:Creating metrics dataframe
2023-04-25 08:11:43,419:INFO:Finalizing model
2023-04-25 08:11:43,444:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:11:43,444:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:11:43,445:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-04-25 08:11:43,639:INFO:Uploading results into container
2023-04-25 08:11:43,640:INFO:Uploading model into container now
2023-04-25 08:11:43,641:INFO:_master_model_container: 25
2023-04-25 08:11:43,641:INFO:_display_container: 7
2023-04-25 08:11:43,641:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:11:43,641:INFO:create_model() successfully completed......................................
2023-04-25 08:11:43,768:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:43,768:INFO:choose_better activated
2023-04-25 08:11:43,770:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:43,771:INFO:Initializing create_model()
2023-04-25 08:11:43,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:43,771:INFO:Checking exceptions
2023-04-25 08:11:43,773:INFO:Importing libraries
2023-04-25 08:11:43,773:INFO:Copying training dataset
2023-04-25 08:11:43,776:INFO:Defining folds
2023-04-25 08:11:43,776:INFO:Declaring metric variables
2023-04-25 08:11:43,776:INFO:Importing untrained model
2023-04-25 08:11:43,776:INFO:Declaring custom model
2023-04-25 08:11:43,777:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:11:43,778:INFO:Starting cross validation
2023-04-25 08:11:43,778:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:44,312:INFO:Calculating mean and std
2023-04-25 08:11:44,313:INFO:Creating metrics dataframe
2023-04-25 08:11:44,314:INFO:Finalizing model
2023-04-25 08:11:44,526:INFO:Uploading results into container
2023-04-25 08:11:44,527:INFO:Uploading model into container now
2023-04-25 08:11:44,527:INFO:_master_model_container: 26
2023-04-25 08:11:44,527:INFO:_display_container: 8
2023-04-25 08:11:44,527:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:11:44,528:INFO:create_model() successfully completed......................................
2023-04-25 08:11:44,641:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:44,641:INFO:LGBMRegressor(random_state=1307) result for R2 is 0.852
2023-04-25 08:11:44,642:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) result for R2 is 0.8618
2023-04-25 08:11:44,642:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) is best model
2023-04-25 08:11:44,642:INFO:choose_better completed
2023-04-25 08:11:44,642:INFO:Creating Dashboard logs
2023-04-25 08:11:44,645:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:11:44,685:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 150, 'n_jobs': -1, 'num_leaves': 50, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.001, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0}
2023-04-25 08:11:44,761:INFO:Initializing predict_model()
2023-04-25 08:11:44,762:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BE440>)
2023-04-25 08:11:44,762:INFO:Checking exceptions
2023-04-25 08:11:44,762:INFO:Preloading libraries
2023-04-25 08:11:45,226:INFO:_master_model_container: 26
2023-04-25 08:11:45,227:INFO:_display_container: 7
2023-04-25 08:11:45,227:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:11:45,227:INFO:tune_model() successfully completed......................................
2023-04-25 08:11:45,460:INFO:Initializing tune_model()
2023-04-25 08:11:45,460:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:11:45,460:INFO:Checking exceptions
2023-04-25 08:11:45,485:INFO:Copying training dataset
2023-04-25 08:11:45,487:INFO:Checking base model
2023-04-25 08:11:45,487:INFO:Base model : Random Forest Regressor
2023-04-25 08:11:45,491:INFO:Declaring metric variables
2023-04-25 08:11:45,494:INFO:Defining Hyperparameters
2023-04-25 08:11:45,620:INFO:Tuning with n_jobs=-1
2023-04-25 08:11:45,620:INFO:Initializing RandomizedSearchCV
2023-04-25 08:11:54,505:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': True}
2023-04-25 08:11:54,506:INFO:Hyperparameter search completed
2023-04-25 08:11:54,506:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:54,506:INFO:Initializing create_model()
2023-04-25 08:11:54,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A72F3D0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 70, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'absolute_error', 'bootstrap': True})
2023-04-25 08:11:54,506:INFO:Checking exceptions
2023-04-25 08:11:54,507:INFO:Importing libraries
2023-04-25 08:11:54,507:INFO:Copying training dataset
2023-04-25 08:11:54,510:INFO:Defining folds
2023-04-25 08:11:54,510:INFO:Declaring metric variables
2023-04-25 08:11:54,513:INFO:Importing untrained model
2023-04-25 08:11:54,513:INFO:Declaring custom model
2023-04-25 08:11:54,518:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:11:54,524:INFO:Starting cross validation
2023-04-25 08:11:54,525:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:55,105:INFO:Calculating mean and std
2023-04-25 08:11:55,107:INFO:Creating metrics dataframe
2023-04-25 08:11:55,112:INFO:Finalizing model
2023-04-25 08:11:55,483:INFO:Uploading results into container
2023-04-25 08:11:55,484:INFO:Uploading model into container now
2023-04-25 08:11:55,484:INFO:_master_model_container: 27
2023-04-25 08:11:55,484:INFO:_display_container: 8
2023-04-25 08:11:55,485:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:11:55,485:INFO:create_model() successfully completed......................................
2023-04-25 08:11:55,607:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:55,607:INFO:choose_better activated
2023-04-25 08:11:55,610:INFO:SubProcess create_model() called ==================================
2023-04-25 08:11:55,611:INFO:Initializing create_model()
2023-04-25 08:11:55,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:11:55,611:INFO:Checking exceptions
2023-04-25 08:11:55,613:INFO:Importing libraries
2023-04-25 08:11:55,613:INFO:Copying training dataset
2023-04-25 08:11:55,619:INFO:Defining folds
2023-04-25 08:11:55,619:INFO:Declaring metric variables
2023-04-25 08:11:55,619:INFO:Importing untrained model
2023-04-25 08:11:55,619:INFO:Declaring custom model
2023-04-25 08:11:55,619:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:11:55,619:INFO:Starting cross validation
2023-04-25 08:11:55,620:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:11:56,240:INFO:Calculating mean and std
2023-04-25 08:11:56,240:INFO:Creating metrics dataframe
2023-04-25 08:11:56,241:INFO:Finalizing model
2023-04-25 08:11:56,433:INFO:Uploading results into container
2023-04-25 08:11:56,434:INFO:Uploading model into container now
2023-04-25 08:11:56,434:INFO:_master_model_container: 28
2023-04-25 08:11:56,434:INFO:_display_container: 9
2023-04-25 08:11:56,434:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:11:56,434:INFO:create_model() successfully completed......................................
2023-04-25 08:11:56,555:INFO:SubProcess create_model() end ==================================
2023-04-25 08:11:56,556:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307) result for R2 is 0.8456
2023-04-25 08:11:56,556:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) result for R2 is 0.87
2023-04-25 08:11:56,556:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) is best model
2023-04-25 08:11:56,556:INFO:choose_better completed
2023-04-25 08:11:56,556:INFO:Creating Dashboard logs
2023-04-25 08:11:56,558:INFO:Model: Random Forest Regressor
2023-04-25 08:11:56,602:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:11:56,672:INFO:Initializing predict_model()
2023-04-25 08:11:56,672:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BEB90>)
2023-04-25 08:11:56,672:INFO:Checking exceptions
2023-04-25 08:11:56,672:INFO:Preloading libraries
2023-04-25 08:11:57,106:INFO:_master_model_container: 28
2023-04-25 08:11:57,106:INFO:_display_container: 8
2023-04-25 08:11:57,106:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:11:57,107:INFO:tune_model() successfully completed......................................
2023-04-25 08:11:57,362:INFO:Initializing plot_model()
2023-04-25 08:11:57,362:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:11:57,362:INFO:Checking exceptions
2023-04-25 08:11:57,366:INFO:Preloading libraries
2023-04-25 08:11:57,371:INFO:Copying training dataset
2023-04-25 08:11:57,371:INFO:Plot type: error
2023-04-25 08:11:57,421:INFO:Fitting Model
2023-04-25 08:11:57,422:INFO:Scoring test/hold-out set
2023-04-25 08:11:57,595:INFO:Visual Rendered Successfully
2023-04-25 08:11:57,719:INFO:plot_model() successfully completed......................................
2023-04-25 08:11:57,745:INFO:Initializing plot_model()
2023-04-25 08:11:57,746:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:11:57,746:INFO:Checking exceptions
2023-04-25 08:11:57,748:INFO:Preloading libraries
2023-04-25 08:11:57,757:INFO:Copying training dataset
2023-04-25 08:11:57,757:INFO:Plot type: error
2023-04-25 08:11:57,826:INFO:Fitting Model
2023-04-25 08:11:57,826:INFO:Scoring test/hold-out set
2023-04-25 08:11:58,015:INFO:Visual Rendered Successfully
2023-04-25 08:11:58,135:INFO:plot_model() successfully completed......................................
2023-04-25 08:11:58,142:INFO:Initializing plot_model()
2023-04-25 08:11:58,142:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:11:58,143:INFO:Checking exceptions
2023-04-25 08:11:58,156:INFO:Preloading libraries
2023-04-25 08:11:58,160:INFO:Copying training dataset
2023-04-25 08:11:58,160:INFO:Plot type: error
2023-04-25 08:11:58,214:INFO:Fitting Model
2023-04-25 08:11:58,214:INFO:Scoring test/hold-out set
2023-04-25 08:11:58,408:INFO:Visual Rendered Successfully
2023-04-25 08:11:58,534:INFO:plot_model() successfully completed......................................
2023-04-25 08:11:58,572:INFO:Initializing plot_model()
2023-04-25 08:11:58,572:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:11:58,572:INFO:Checking exceptions
2023-04-25 08:11:58,575:INFO:Preloading libraries
2023-04-25 08:11:58,581:INFO:Copying training dataset
2023-04-25 08:11:58,581:INFO:Plot type: feature
2023-04-25 08:11:58,581:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:11:58,709:INFO:Visual Rendered Successfully
2023-04-25 08:11:58,830:INFO:plot_model() successfully completed......................................
2023-04-25 08:11:58,830:INFO:Initializing plot_model()
2023-04-25 08:11:58,831:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:11:58,831:INFO:Checking exceptions
2023-04-25 08:11:58,834:INFO:Preloading libraries
2023-04-25 08:11:58,840:INFO:Copying training dataset
2023-04-25 08:11:58,840:INFO:Plot type: feature
2023-04-25 08:11:58,841:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:11:58,993:INFO:Visual Rendered Successfully
2023-04-25 08:11:59,114:INFO:plot_model() successfully completed......................................
2023-04-25 08:11:59,115:INFO:Initializing plot_model()
2023-04-25 08:11:59,115:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:11:59,115:INFO:Checking exceptions
2023-04-25 08:11:59,128:INFO:Preloading libraries
2023-04-25 08:11:59,132:INFO:Copying training dataset
2023-04-25 08:11:59,132:INFO:Plot type: feature
2023-04-25 08:11:59,132:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:11:59,271:INFO:Visual Rendered Successfully
2023-04-25 08:11:59,390:INFO:plot_model() successfully completed......................................
2023-04-25 08:12:38,738:INFO:Initializing tune_model()
2023-04-25 08:12:38,738:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:12:38,738:INFO:Checking exceptions
2023-04-25 08:12:38,763:INFO:Copying training dataset
2023-04-25 08:12:38,766:INFO:Checking base model
2023-04-25 08:12:38,767:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:12:38,771:INFO:Declaring metric variables
2023-04-25 08:12:38,779:INFO:Defining Hyperparameters
2023-04-25 08:12:38,913:INFO:Tuning with n_jobs=-1
2023-04-25 08:12:38,913:INFO:Initializing RandomizedSearchCV
2023-04-25 08:12:45,639:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.05}
2023-04-25 08:12:45,641:INFO:Hyperparameter search completed
2023-04-25 08:12:45,641:INFO:SubProcess create_model() called ==================================
2023-04-25 08:12:45,641:INFO:Initializing create_model()
2023-04-25 08:12:45,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A87E800>, model_only=True, return_train_score=False, kwargs={'subsample': 1.0, 'n_estimators': 280, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.05})
2023-04-25 08:12:45,641:INFO:Checking exceptions
2023-04-25 08:12:45,642:INFO:Importing libraries
2023-04-25 08:12:45,642:INFO:Copying training dataset
2023-04-25 08:12:45,644:INFO:Defining folds
2023-04-25 08:12:45,644:INFO:Declaring metric variables
2023-04-25 08:12:45,647:INFO:Importing untrained model
2023-04-25 08:12:45,647:INFO:Declaring custom model
2023-04-25 08:12:45,650:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:12:45,655:INFO:Starting cross validation
2023-04-25 08:12:45,656:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:12:46,370:INFO:Calculating mean and std
2023-04-25 08:12:46,371:INFO:Creating metrics dataframe
2023-04-25 08:12:46,375:INFO:Finalizing model
2023-04-25 08:12:46,565:INFO:Uploading results into container
2023-04-25 08:12:46,566:INFO:Uploading model into container now
2023-04-25 08:12:46,567:INFO:_master_model_container: 29
2023-04-25 08:12:46,567:INFO:_display_container: 9
2023-04-25 08:12:46,568:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307)
2023-04-25 08:12:46,568:INFO:create_model() successfully completed......................................
2023-04-25 08:12:46,719:INFO:SubProcess create_model() end ==================================
2023-04-25 08:12:46,719:INFO:choose_better activated
2023-04-25 08:12:46,722:INFO:SubProcess create_model() called ==================================
2023-04-25 08:12:46,724:INFO:Initializing create_model()
2023-04-25 08:12:46,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:12:46,724:INFO:Checking exceptions
2023-04-25 08:12:46,726:INFO:Importing libraries
2023-04-25 08:12:46,726:INFO:Copying training dataset
2023-04-25 08:12:46,728:INFO:Defining folds
2023-04-25 08:12:46,728:INFO:Declaring metric variables
2023-04-25 08:12:46,729:INFO:Importing untrained model
2023-04-25 08:12:46,729:INFO:Declaring custom model
2023-04-25 08:12:46,729:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:12:46,729:INFO:Starting cross validation
2023-04-25 08:12:46,730:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:12:47,354:INFO:Calculating mean and std
2023-04-25 08:12:47,354:INFO:Creating metrics dataframe
2023-04-25 08:12:47,356:INFO:Finalizing model
2023-04-25 08:12:47,561:INFO:Uploading results into container
2023-04-25 08:12:47,561:INFO:Uploading model into container now
2023-04-25 08:12:47,562:INFO:_master_model_container: 30
2023-04-25 08:12:47,562:INFO:_display_container: 10
2023-04-25 08:12:47,562:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:12:47,562:INFO:create_model() successfully completed......................................
2023-04-25 08:12:47,678:INFO:SubProcess create_model() end ==================================
2023-04-25 08:12:47,678:INFO:GradientBoostingRegressor(random_state=1307) result for RMSE is 4618.0896
2023-04-25 08:12:47,679:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307) result for RMSE is 5174.4955
2023-04-25 08:12:47,679:INFO:GradientBoostingRegressor(random_state=1307) is best model
2023-04-25 08:12:47,679:INFO:choose_better completed
2023-04-25 08:12:47,679:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:12:47,679:INFO:Creating Dashboard logs
2023-04-25 08:12:47,682:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:12:47,725:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:12:47,795:INFO:Initializing predict_model()
2023-04-25 08:12:47,795:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB3AF80>)
2023-04-25 08:12:47,795:INFO:Checking exceptions
2023-04-25 08:12:47,795:INFO:Preloading libraries
2023-04-25 08:12:48,220:INFO:_master_model_container: 30
2023-04-25 08:12:48,220:INFO:_display_container: 9
2023-04-25 08:12:48,221:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:12:48,221:INFO:tune_model() successfully completed......................................
2023-04-25 08:12:48,457:INFO:Initializing tune_model()
2023-04-25 08:12:48,458:INFO:tune_model(estimator=LGBMRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:12:48,458:INFO:Checking exceptions
2023-04-25 08:12:48,482:INFO:Copying training dataset
2023-04-25 08:12:48,485:INFO:Checking base model
2023-04-25 08:12:48,485:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:12:48,488:INFO:Declaring metric variables
2023-04-25 08:12:48,494:INFO:Defining Hyperparameters
2023-04-25 08:12:48,621:INFO:Tuning with n_jobs=-1
2023-04-25 08:12:48,621:INFO:Initializing RandomizedSearchCV
2023-04-25 08:12:55,162:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2023-04-25 08:12:55,163:INFO:Hyperparameter search completed
2023-04-25 08:12:55,163:INFO:SubProcess create_model() called ==================================
2023-04-25 08:12:55,163:INFO:Initializing create_model()
2023-04-25 08:12:55,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5622F85B0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 0.001, 'num_leaves': 50, 'n_estimators': 150, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2023-04-25 08:12:55,164:INFO:Checking exceptions
2023-04-25 08:12:55,164:INFO:Importing libraries
2023-04-25 08:12:55,164:INFO:Copying training dataset
2023-04-25 08:12:55,167:INFO:Defining folds
2023-04-25 08:12:55,168:INFO:Declaring metric variables
2023-04-25 08:12:55,170:INFO:Importing untrained model
2023-04-25 08:12:55,170:INFO:Declaring custom model
2023-04-25 08:12:55,173:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:12:55,178:INFO:Starting cross validation
2023-04-25 08:12:55,179:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:12:55,768:INFO:Calculating mean and std
2023-04-25 08:12:55,769:INFO:Creating metrics dataframe
2023-04-25 08:12:55,773:INFO:Finalizing model
2023-04-25 08:12:55,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:12:55,795:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:12:55,795:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-04-25 08:12:56,009:INFO:Uploading results into container
2023-04-25 08:12:56,010:INFO:Uploading model into container now
2023-04-25 08:12:56,011:INFO:_master_model_container: 31
2023-04-25 08:12:56,011:INFO:_display_container: 10
2023-04-25 08:12:56,012:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:12:56,012:INFO:create_model() successfully completed......................................
2023-04-25 08:12:56,137:INFO:SubProcess create_model() end ==================================
2023-04-25 08:12:56,137:INFO:choose_better activated
2023-04-25 08:12:56,139:INFO:SubProcess create_model() called ==================================
2023-04-25 08:12:56,139:INFO:Initializing create_model()
2023-04-25 08:12:56,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:12:56,139:INFO:Checking exceptions
2023-04-25 08:12:56,141:INFO:Importing libraries
2023-04-25 08:12:56,141:INFO:Copying training dataset
2023-04-25 08:12:56,143:INFO:Defining folds
2023-04-25 08:12:56,143:INFO:Declaring metric variables
2023-04-25 08:12:56,143:INFO:Importing untrained model
2023-04-25 08:12:56,143:INFO:Declaring custom model
2023-04-25 08:12:56,144:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:12:56,144:INFO:Starting cross validation
2023-04-25 08:12:56,145:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:12:56,713:INFO:Calculating mean and std
2023-04-25 08:12:56,713:INFO:Creating metrics dataframe
2023-04-25 08:12:56,715:INFO:Finalizing model
2023-04-25 08:12:56,951:INFO:Uploading results into container
2023-04-25 08:12:56,951:INFO:Uploading model into container now
2023-04-25 08:12:56,952:INFO:_master_model_container: 32
2023-04-25 08:12:56,952:INFO:_display_container: 11
2023-04-25 08:12:56,952:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:12:56,952:INFO:create_model() successfully completed......................................
2023-04-25 08:12:57,065:INFO:SubProcess create_model() end ==================================
2023-04-25 08:12:57,066:INFO:LGBMRegressor(random_state=1307) result for RMSE is 4768.6841
2023-04-25 08:12:57,066:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) result for RMSE is 4589.6796
2023-04-25 08:12:57,067:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) is best model
2023-04-25 08:12:57,067:INFO:choose_better completed
2023-04-25 08:12:57,067:INFO:Creating Dashboard logs
2023-04-25 08:12:57,070:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:12:57,110:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 150, 'n_jobs': -1, 'num_leaves': 50, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.001, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0}
2023-04-25 08:12:57,180:INFO:Initializing predict_model()
2023-04-25 08:12:57,180:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB38700>)
2023-04-25 08:12:57,180:INFO:Checking exceptions
2023-04-25 08:12:57,181:INFO:Preloading libraries
2023-04-25 08:12:57,654:INFO:_master_model_container: 32
2023-04-25 08:12:57,654:INFO:_display_container: 10
2023-04-25 08:12:57,655:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:12:57,655:INFO:tune_model() successfully completed......................................
2023-04-25 08:12:57,898:INFO:Initializing tune_model()
2023-04-25 08:12:57,898:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:12:57,898:INFO:Checking exceptions
2023-04-25 08:12:57,921:INFO:Copying training dataset
2023-04-25 08:12:57,923:INFO:Checking base model
2023-04-25 08:12:57,924:INFO:Base model : Random Forest Regressor
2023-04-25 08:12:57,927:INFO:Declaring metric variables
2023-04-25 08:12:57,930:INFO:Defining Hyperparameters
2023-04-25 08:12:58,060:INFO:Tuning with n_jobs=-1
2023-04-25 08:12:58,061:INFO:Initializing RandomizedSearchCV
2023-04-25 08:13:04,979:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': True}
2023-04-25 08:13:04,981:INFO:Hyperparameter search completed
2023-04-25 08:13:04,981:INFO:SubProcess create_model() called ==================================
2023-04-25 08:13:04,981:INFO:Initializing create_model()
2023-04-25 08:13:04,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A8EDB40>, model_only=True, return_train_score=False, kwargs={'n_estimators': 70, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'absolute_error', 'bootstrap': True})
2023-04-25 08:13:04,981:INFO:Checking exceptions
2023-04-25 08:13:04,981:INFO:Importing libraries
2023-04-25 08:13:04,981:INFO:Copying training dataset
2023-04-25 08:13:04,984:INFO:Defining folds
2023-04-25 08:13:04,985:INFO:Declaring metric variables
2023-04-25 08:13:04,987:INFO:Importing untrained model
2023-04-25 08:13:04,987:INFO:Declaring custom model
2023-04-25 08:13:04,991:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:13:04,996:INFO:Starting cross validation
2023-04-25 08:13:04,997:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:13:05,586:INFO:Calculating mean and std
2023-04-25 08:13:05,587:INFO:Creating metrics dataframe
2023-04-25 08:13:05,592:INFO:Finalizing model
2023-04-25 08:13:05,779:INFO:Uploading results into container
2023-04-25 08:13:05,780:INFO:Uploading model into container now
2023-04-25 08:13:05,780:INFO:_master_model_container: 33
2023-04-25 08:13:05,780:INFO:_display_container: 11
2023-04-25 08:13:05,781:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:13:05,781:INFO:create_model() successfully completed......................................
2023-04-25 08:13:05,902:INFO:SubProcess create_model() end ==================================
2023-04-25 08:13:05,902:INFO:choose_better activated
2023-04-25 08:13:05,904:INFO:SubProcess create_model() called ==================================
2023-04-25 08:13:05,905:INFO:Initializing create_model()
2023-04-25 08:13:05,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:13:05,905:INFO:Checking exceptions
2023-04-25 08:13:05,906:INFO:Importing libraries
2023-04-25 08:13:05,906:INFO:Copying training dataset
2023-04-25 08:13:05,909:INFO:Defining folds
2023-04-25 08:13:05,909:INFO:Declaring metric variables
2023-04-25 08:13:05,909:INFO:Importing untrained model
2023-04-25 08:13:05,909:INFO:Declaring custom model
2023-04-25 08:13:05,909:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:13:05,910:INFO:Starting cross validation
2023-04-25 08:13:05,910:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:13:06,607:INFO:Calculating mean and std
2023-04-25 08:13:06,608:INFO:Creating metrics dataframe
2023-04-25 08:13:06,609:INFO:Finalizing model
2023-04-25 08:13:06,798:INFO:Uploading results into container
2023-04-25 08:13:06,799:INFO:Uploading model into container now
2023-04-25 08:13:06,799:INFO:_master_model_container: 34
2023-04-25 08:13:06,799:INFO:_display_container: 12
2023-04-25 08:13:06,799:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:13:06,799:INFO:create_model() successfully completed......................................
2023-04-25 08:13:06,927:INFO:SubProcess create_model() end ==================================
2023-04-25 08:13:06,927:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307) result for RMSE is 4873.5316
2023-04-25 08:13:06,928:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) result for RMSE is 4432.3432
2023-04-25 08:13:06,929:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) is best model
2023-04-25 08:13:06,929:INFO:choose_better completed
2023-04-25 08:13:06,929:INFO:Creating Dashboard logs
2023-04-25 08:13:06,932:INFO:Model: Random Forest Regressor
2023-04-25 08:13:06,979:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:13:07,064:INFO:Initializing predict_model()
2023-04-25 08:13:07,064:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB3A560>)
2023-04-25 08:13:07,064:INFO:Checking exceptions
2023-04-25 08:13:07,064:INFO:Preloading libraries
2023-04-25 08:13:07,499:INFO:_master_model_container: 34
2023-04-25 08:13:07,499:INFO:_display_container: 11
2023-04-25 08:13:07,500:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:13:07,500:INFO:tune_model() successfully completed......................................
2023-04-25 08:14:43,336:INFO:Initializing plot_model()
2023-04-25 08:14:43,336:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:14:43,336:INFO:Checking exceptions
2023-04-25 08:14:43,340:INFO:Preloading libraries
2023-04-25 08:14:43,348:INFO:Copying training dataset
2023-04-25 08:14:43,348:INFO:Plot type: error
2023-04-25 08:14:43,408:INFO:Fitting Model
2023-04-25 08:14:43,408:INFO:Scoring test/hold-out set
2023-04-25 08:14:43,573:INFO:Visual Rendered Successfully
2023-04-25 08:14:43,701:INFO:plot_model() successfully completed......................................
2023-04-25 08:14:43,711:INFO:Initializing plot_model()
2023-04-25 08:14:43,711:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:14:43,711:INFO:Checking exceptions
2023-04-25 08:14:43,714:INFO:Preloading libraries
2023-04-25 08:14:43,721:INFO:Copying training dataset
2023-04-25 08:14:43,721:INFO:Plot type: error
2023-04-25 08:14:43,789:INFO:Fitting Model
2023-04-25 08:14:43,790:INFO:Scoring test/hold-out set
2023-04-25 08:14:43,976:INFO:Visual Rendered Successfully
2023-04-25 08:14:44,094:INFO:plot_model() successfully completed......................................
2023-04-25 08:14:44,103:INFO:Initializing plot_model()
2023-04-25 08:14:44,103:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:14:44,103:INFO:Checking exceptions
2023-04-25 08:14:44,117:INFO:Preloading libraries
2023-04-25 08:14:44,121:INFO:Copying training dataset
2023-04-25 08:14:44,121:INFO:Plot type: error
2023-04-25 08:14:44,173:INFO:Fitting Model
2023-04-25 08:14:44,173:INFO:Scoring test/hold-out set
2023-04-25 08:14:44,351:INFO:Visual Rendered Successfully
2023-04-25 08:14:44,475:INFO:plot_model() successfully completed......................................
2023-04-25 08:15:14,555:INFO:Initializing plot_model()
2023-04-25 08:15:14,556:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:15:14,556:INFO:Checking exceptions
2023-04-25 08:15:14,559:INFO:Preloading libraries
2023-04-25 08:15:14,564:INFO:Copying training dataset
2023-04-25 08:15:14,564:INFO:Plot type: feature
2023-04-25 08:15:14,564:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:15:14,696:INFO:Visual Rendered Successfully
2023-04-25 08:15:14,819:INFO:plot_model() successfully completed......................................
2023-04-25 08:15:14,820:INFO:Initializing plot_model()
2023-04-25 08:15:14,820:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:15:14,820:INFO:Checking exceptions
2023-04-25 08:15:14,823:INFO:Preloading libraries
2023-04-25 08:15:14,830:INFO:Copying training dataset
2023-04-25 08:15:14,830:INFO:Plot type: feature
2023-04-25 08:15:14,831:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:15:14,989:INFO:Visual Rendered Successfully
2023-04-25 08:15:15,105:INFO:plot_model() successfully completed......................................
2023-04-25 08:15:15,106:INFO:Initializing plot_model()
2023-04-25 08:15:15,106:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:15:15,106:INFO:Checking exceptions
2023-04-25 08:15:15,122:INFO:Preloading libraries
2023-04-25 08:15:15,127:INFO:Copying training dataset
2023-04-25 08:15:15,127:INFO:Plot type: feature
2023-04-25 08:15:15,128:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:15:15,249:INFO:Visual Rendered Successfully
2023-04-25 08:15:15,404:INFO:plot_model() successfully completed......................................
2023-04-25 08:15:29,895:INFO:Initializing predict_model()
2023-04-25 08:15:29,895:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59D510>)
2023-04-25 08:15:29,895:INFO:Checking exceptions
2023-04-25 08:15:29,895:INFO:Preloading libraries
2023-04-25 08:17:31,156:INFO:Initializing predict_model()
2023-04-25 08:17:31,156:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0B2F80>)
2023-04-25 08:17:31,156:INFO:Checking exceptions
2023-04-25 08:17:31,156:INFO:Preloading libraries
2023-04-25 08:19:27,169:INFO:Initializing predict_model()
2023-04-25 08:19:27,169:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0B2EF0>)
2023-04-25 08:19:27,169:INFO:Checking exceptions
2023-04-25 08:19:27,169:INFO:Preloading libraries
2023-04-25 08:22:48,169:INFO:Initializing tune_model()
2023-04-25 08:22:48,169:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:22:48,169:INFO:Checking exceptions
2023-04-25 08:22:48,195:INFO:Copying training dataset
2023-04-25 08:22:48,199:INFO:Checking base model
2023-04-25 08:22:48,199:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:22:48,207:INFO:Declaring metric variables
2023-04-25 08:22:48,211:INFO:Defining Hyperparameters
2023-04-25 08:22:48,346:INFO:Tuning with n_jobs=-1
2023-04-25 08:22:48,346:INFO:Initializing RandomizedSearchCV
2023-04-25 08:22:58,762:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.05}
2023-04-25 08:22:58,763:INFO:Hyperparameter search completed
2023-04-25 08:22:58,764:INFO:SubProcess create_model() called ==================================
2023-04-25 08:22:58,764:INFO:Initializing create_model()
2023-04-25 08:22:58,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5697E8B20>, model_only=True, return_train_score=False, kwargs={'subsample': 1.0, 'n_estimators': 280, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.05})
2023-04-25 08:22:58,764:INFO:Checking exceptions
2023-04-25 08:22:58,764:INFO:Importing libraries
2023-04-25 08:22:58,765:INFO:Copying training dataset
2023-04-25 08:22:58,768:INFO:Defining folds
2023-04-25 08:22:58,768:INFO:Declaring metric variables
2023-04-25 08:22:58,771:INFO:Importing untrained model
2023-04-25 08:22:58,771:INFO:Declaring custom model
2023-04-25 08:22:58,774:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:22:58,779:INFO:Starting cross validation
2023-04-25 08:22:58,780:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:22:59,440:INFO:Calculating mean and std
2023-04-25 08:22:59,441:INFO:Creating metrics dataframe
2023-04-25 08:22:59,446:INFO:Finalizing model
2023-04-25 08:22:59,662:INFO:Uploading results into container
2023-04-25 08:22:59,662:INFO:Uploading model into container now
2023-04-25 08:22:59,663:INFO:_master_model_container: 35
2023-04-25 08:22:59,663:INFO:_display_container: 15
2023-04-25 08:22:59,664:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307)
2023-04-25 08:22:59,664:INFO:create_model() successfully completed......................................
2023-04-25 08:22:59,804:INFO:SubProcess create_model() end ==================================
2023-04-25 08:22:59,805:INFO:choose_better activated
2023-04-25 08:22:59,807:INFO:SubProcess create_model() called ==================================
2023-04-25 08:22:59,807:INFO:Initializing create_model()
2023-04-25 08:22:59,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:22:59,807:INFO:Checking exceptions
2023-04-25 08:22:59,808:INFO:Importing libraries
2023-04-25 08:22:59,808:INFO:Copying training dataset
2023-04-25 08:22:59,810:INFO:Defining folds
2023-04-25 08:22:59,810:INFO:Declaring metric variables
2023-04-25 08:22:59,811:INFO:Importing untrained model
2023-04-25 08:22:59,811:INFO:Declaring custom model
2023-04-25 08:22:59,811:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:22:59,811:INFO:Starting cross validation
2023-04-25 08:22:59,812:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:23:00,415:INFO:Calculating mean and std
2023-04-25 08:23:00,415:INFO:Creating metrics dataframe
2023-04-25 08:23:00,417:INFO:Finalizing model
2023-04-25 08:23:00,617:INFO:Uploading results into container
2023-04-25 08:23:00,617:INFO:Uploading model into container now
2023-04-25 08:23:00,618:INFO:_master_model_container: 36
2023-04-25 08:23:00,618:INFO:_display_container: 16
2023-04-25 08:23:00,618:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:23:00,618:INFO:create_model() successfully completed......................................
2023-04-25 08:23:00,732:INFO:SubProcess create_model() end ==================================
2023-04-25 08:23:00,733:INFO:GradientBoostingRegressor(random_state=1307) result for R2 is 0.8603
2023-04-25 08:23:00,733:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307) result for R2 is 0.8253
2023-04-25 08:23:00,734:INFO:GradientBoostingRegressor(random_state=1307) is best model
2023-04-25 08:23:00,734:INFO:choose_better completed
2023-04-25 08:23:00,734:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:23:00,734:INFO:Creating Dashboard logs
2023-04-25 08:23:00,737:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:23:00,783:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:23:00,855:INFO:Initializing predict_model()
2023-04-25 08:23:00,855:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BEB00>)
2023-04-25 08:23:00,855:INFO:Checking exceptions
2023-04-25 08:23:00,855:INFO:Preloading libraries
2023-04-25 08:23:01,272:INFO:_master_model_container: 36
2023-04-25 08:23:01,273:INFO:_display_container: 15
2023-04-25 08:23:01,273:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:23:01,273:INFO:tune_model() successfully completed......................................
2023-04-25 08:23:01,516:INFO:Initializing tune_model()
2023-04-25 08:23:01,517:INFO:tune_model(estimator=LGBMRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:23:01,517:INFO:Checking exceptions
2023-04-25 08:23:01,541:INFO:Copying training dataset
2023-04-25 08:23:01,544:INFO:Checking base model
2023-04-25 08:23:01,544:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:23:01,548:INFO:Declaring metric variables
2023-04-25 08:23:01,553:INFO:Defining Hyperparameters
2023-04-25 08:23:01,699:INFO:Tuning with n_jobs=-1
2023-04-25 08:23:01,699:INFO:Initializing RandomizedSearchCV
2023-04-25 08:23:08,097:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2023-04-25 08:23:08,099:INFO:Hyperparameter search completed
2023-04-25 08:23:08,100:INFO:SubProcess create_model() called ==================================
2023-04-25 08:23:08,100:INFO:Initializing create_model()
2023-04-25 08:23:08,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562D7B130>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 0.001, 'num_leaves': 50, 'n_estimators': 150, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2023-04-25 08:23:08,100:INFO:Checking exceptions
2023-04-25 08:23:08,100:INFO:Importing libraries
2023-04-25 08:23:08,100:INFO:Copying training dataset
2023-04-25 08:23:08,104:INFO:Defining folds
2023-04-25 08:23:08,104:INFO:Declaring metric variables
2023-04-25 08:23:08,107:INFO:Importing untrained model
2023-04-25 08:23:08,107:INFO:Declaring custom model
2023-04-25 08:23:08,110:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:23:08,116:INFO:Starting cross validation
2023-04-25 08:23:08,117:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:23:08,692:INFO:Calculating mean and std
2023-04-25 08:23:08,693:INFO:Creating metrics dataframe
2023-04-25 08:23:08,698:INFO:Finalizing model
2023-04-25 08:23:08,721:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:23:08,721:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:23:08,721:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-04-25 08:23:08,927:INFO:Uploading results into container
2023-04-25 08:23:08,927:INFO:Uploading model into container now
2023-04-25 08:23:08,928:INFO:_master_model_container: 37
2023-04-25 08:23:08,928:INFO:_display_container: 16
2023-04-25 08:23:08,929:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:23:08,929:INFO:create_model() successfully completed......................................
2023-04-25 08:23:09,050:INFO:SubProcess create_model() end ==================================
2023-04-25 08:23:09,050:INFO:choose_better activated
2023-04-25 08:23:09,052:INFO:SubProcess create_model() called ==================================
2023-04-25 08:23:09,053:INFO:Initializing create_model()
2023-04-25 08:23:09,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:23:09,053:INFO:Checking exceptions
2023-04-25 08:23:09,054:INFO:Importing libraries
2023-04-25 08:23:09,054:INFO:Copying training dataset
2023-04-25 08:23:09,057:INFO:Defining folds
2023-04-25 08:23:09,057:INFO:Declaring metric variables
2023-04-25 08:23:09,057:INFO:Importing untrained model
2023-04-25 08:23:09,057:INFO:Declaring custom model
2023-04-25 08:23:09,058:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:23:09,058:INFO:Starting cross validation
2023-04-25 08:23:09,058:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:23:09,628:INFO:Calculating mean and std
2023-04-25 08:23:09,629:INFO:Creating metrics dataframe
2023-04-25 08:23:09,630:INFO:Finalizing model
2023-04-25 08:23:09,852:INFO:Uploading results into container
2023-04-25 08:23:09,852:INFO:Uploading model into container now
2023-04-25 08:23:09,853:INFO:_master_model_container: 38
2023-04-25 08:23:09,853:INFO:_display_container: 17
2023-04-25 08:23:09,853:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:23:09,853:INFO:create_model() successfully completed......................................
2023-04-25 08:23:09,968:INFO:SubProcess create_model() end ==================================
2023-04-25 08:23:09,970:INFO:LGBMRegressor(random_state=1307) result for R2 is 0.852
2023-04-25 08:23:09,971:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) result for R2 is 0.8618
2023-04-25 08:23:09,971:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) is best model
2023-04-25 08:23:09,971:INFO:choose_better completed
2023-04-25 08:23:09,971:INFO:Creating Dashboard logs
2023-04-25 08:23:09,974:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:23:10,013:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 150, 'n_jobs': -1, 'num_leaves': 50, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.001, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0}
2023-04-25 08:23:10,087:INFO:Initializing predict_model()
2023-04-25 08:23:10,087:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BC790>)
2023-04-25 08:23:10,087:INFO:Checking exceptions
2023-04-25 08:23:10,087:INFO:Preloading libraries
2023-04-25 08:23:10,558:INFO:_master_model_container: 38
2023-04-25 08:23:10,558:INFO:_display_container: 16
2023-04-25 08:23:10,561:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:23:10,561:INFO:tune_model() successfully completed......................................
2023-04-25 08:23:10,800:INFO:Initializing tune_model()
2023-04-25 08:23:10,801:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:23:10,801:INFO:Checking exceptions
2023-04-25 08:23:10,829:INFO:Copying training dataset
2023-04-25 08:23:10,832:INFO:Checking base model
2023-04-25 08:23:10,832:INFO:Base model : Random Forest Regressor
2023-04-25 08:23:10,839:INFO:Declaring metric variables
2023-04-25 08:23:10,842:INFO:Defining Hyperparameters
2023-04-25 08:23:10,966:INFO:Tuning with n_jobs=-1
2023-04-25 08:23:10,966:INFO:Initializing RandomizedSearchCV
2023-04-25 08:23:17,555:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': True}
2023-04-25 08:23:17,556:INFO:Hyperparameter search completed
2023-04-25 08:23:17,556:INFO:SubProcess create_model() called ==================================
2023-04-25 08:23:17,556:INFO:Initializing create_model()
2023-04-25 08:23:17,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A7C4790>, model_only=True, return_train_score=False, kwargs={'n_estimators': 70, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'absolute_error', 'bootstrap': True})
2023-04-25 08:23:17,557:INFO:Checking exceptions
2023-04-25 08:23:17,557:INFO:Importing libraries
2023-04-25 08:23:17,557:INFO:Copying training dataset
2023-04-25 08:23:17,561:INFO:Defining folds
2023-04-25 08:23:17,561:INFO:Declaring metric variables
2023-04-25 08:23:17,566:INFO:Importing untrained model
2023-04-25 08:23:17,566:INFO:Declaring custom model
2023-04-25 08:23:17,571:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:23:17,577:INFO:Starting cross validation
2023-04-25 08:23:17,578:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:23:18,195:INFO:Calculating mean and std
2023-04-25 08:23:18,196:INFO:Creating metrics dataframe
2023-04-25 08:23:18,200:INFO:Finalizing model
2023-04-25 08:23:18,421:INFO:Uploading results into container
2023-04-25 08:23:18,422:INFO:Uploading model into container now
2023-04-25 08:23:18,422:INFO:_master_model_container: 39
2023-04-25 08:23:18,422:INFO:_display_container: 17
2023-04-25 08:23:18,423:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:23:18,423:INFO:create_model() successfully completed......................................
2023-04-25 08:23:18,553:INFO:SubProcess create_model() end ==================================
2023-04-25 08:23:18,553:INFO:choose_better activated
2023-04-25 08:23:18,556:INFO:SubProcess create_model() called ==================================
2023-04-25 08:23:18,556:INFO:Initializing create_model()
2023-04-25 08:23:18,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:23:18,556:INFO:Checking exceptions
2023-04-25 08:23:18,557:INFO:Importing libraries
2023-04-25 08:23:18,558:INFO:Copying training dataset
2023-04-25 08:23:18,561:INFO:Defining folds
2023-04-25 08:23:18,561:INFO:Declaring metric variables
2023-04-25 08:23:18,561:INFO:Importing untrained model
2023-04-25 08:23:18,561:INFO:Declaring custom model
2023-04-25 08:23:18,562:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:23:18,562:INFO:Starting cross validation
2023-04-25 08:23:18,563:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:23:19,169:INFO:Calculating mean and std
2023-04-25 08:23:19,169:INFO:Creating metrics dataframe
2023-04-25 08:23:19,170:INFO:Finalizing model
2023-04-25 08:23:19,356:INFO:Uploading results into container
2023-04-25 08:23:19,356:INFO:Uploading model into container now
2023-04-25 08:23:19,357:INFO:_master_model_container: 40
2023-04-25 08:23:19,357:INFO:_display_container: 18
2023-04-25 08:23:19,357:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:23:19,357:INFO:create_model() successfully completed......................................
2023-04-25 08:23:19,473:INFO:SubProcess create_model() end ==================================
2023-04-25 08:23:19,473:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307) result for R2 is 0.8456
2023-04-25 08:23:19,474:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) result for R2 is 0.87
2023-04-25 08:23:19,474:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) is best model
2023-04-25 08:23:19,474:INFO:choose_better completed
2023-04-25 08:23:19,474:INFO:Creating Dashboard logs
2023-04-25 08:23:19,477:INFO:Model: Random Forest Regressor
2023-04-25 08:23:19,517:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:23:19,587:INFO:Initializing predict_model()
2023-04-25 08:23:19,587:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BF400>)
2023-04-25 08:23:19,587:INFO:Checking exceptions
2023-04-25 08:23:19,587:INFO:Preloading libraries
2023-04-25 08:23:20,051:INFO:_master_model_container: 40
2023-04-25 08:23:20,051:INFO:_display_container: 17
2023-04-25 08:23:20,052:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:23:20,052:INFO:tune_model() successfully completed......................................
2023-04-25 08:24:18,014:INFO:Initializing predict_model()
2023-04-25 08:24:18,014:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59D510>)
2023-04-25 08:24:18,015:INFO:Checking exceptions
2023-04-25 08:24:18,015:INFO:Preloading libraries
2023-04-25 08:24:22,422:INFO:Initializing predict_model()
2023-04-25 08:24:22,422:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59DE10>)
2023-04-25 08:24:22,422:INFO:Checking exceptions
2023-04-25 08:24:22,423:INFO:Preloading libraries
2023-04-25 08:24:28,166:INFO:Initializing predict_model()
2023-04-25 08:24:28,166:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59F1C0>)
2023-04-25 08:24:28,166:INFO:Checking exceptions
2023-04-25 08:24:28,167:INFO:Preloading libraries
2023-04-25 08:24:47,479:INFO:Initializing create_model()
2023-04-25 08:24:47,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:24:47,479:INFO:Checking exceptions
2023-04-25 08:24:47,500:INFO:Importing libraries
2023-04-25 08:24:47,500:INFO:Copying training dataset
2023-04-25 08:24:47,503:INFO:Defining folds
2023-04-25 08:24:47,503:INFO:Declaring metric variables
2023-04-25 08:24:47,507:INFO:Importing untrained model
2023-04-25 08:24:47,514:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:24:47,521:INFO:Starting cross validation
2023-04-25 08:24:47,522:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:24:48,142:INFO:Calculating mean and std
2023-04-25 08:24:48,142:INFO:Creating metrics dataframe
2023-04-25 08:24:48,146:INFO:Finalizing model
2023-04-25 08:24:48,350:INFO:Creating Dashboard logs
2023-04-25 08:24:48,354:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:24:48,395:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:24:48,464:INFO:Initializing predict_model()
2023-04-25 08:24:48,464:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BC550>)
2023-04-25 08:24:48,464:INFO:Checking exceptions
2023-04-25 08:24:48,464:INFO:Preloading libraries
2023-04-25 08:24:48,873:INFO:Uploading results into container
2023-04-25 08:24:48,874:INFO:Uploading model into container now
2023-04-25 08:24:48,885:INFO:_master_model_container: 41
2023-04-25 08:24:48,885:INFO:_display_container: 21
2023-04-25 08:24:48,885:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:24:48,885:INFO:create_model() successfully completed......................................
2023-04-25 08:24:59,270:INFO:Initializing create_model()
2023-04-25 08:24:59,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=gbr, fold=10, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:24:59,270:INFO:Checking exceptions
2023-04-25 08:24:59,290:INFO:Importing libraries
2023-04-25 08:24:59,290:INFO:Copying training dataset
2023-04-25 08:24:59,293:INFO:Defining folds
2023-04-25 08:24:59,293:INFO:Declaring metric variables
2023-04-25 08:24:59,297:INFO:Importing untrained model
2023-04-25 08:24:59,304:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:24:59,312:INFO:Starting cross validation
2023-04-25 08:24:59,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:25:00,611:INFO:Calculating mean and std
2023-04-25 08:25:00,612:INFO:Creating metrics dataframe
2023-04-25 08:25:00,618:INFO:Finalizing model
2023-04-25 08:25:00,826:INFO:Creating Dashboard logs
2023-04-25 08:25:00,829:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:25:00,867:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:25:00,943:INFO:Initializing predict_model()
2023-04-25 08:25:00,943:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BF1C0>)
2023-04-25 08:25:00,943:INFO:Checking exceptions
2023-04-25 08:25:00,943:INFO:Preloading libraries
2023-04-25 08:25:01,343:INFO:Uploading results into container
2023-04-25 08:25:01,344:INFO:Uploading model into container now
2023-04-25 08:25:01,354:INFO:_master_model_container: 42
2023-04-25 08:25:01,354:INFO:_display_container: 22
2023-04-25 08:25:01,354:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:25:01,354:INFO:create_model() successfully completed......................................
2023-04-25 08:25:04,926:INFO:Initializing create_model()
2023-04-25 08:25:04,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:25:04,926:INFO:Checking exceptions
2023-04-25 08:25:04,945:INFO:Importing libraries
2023-04-25 08:25:04,945:INFO:Copying training dataset
2023-04-25 08:25:04,949:INFO:Defining folds
2023-04-25 08:25:04,949:INFO:Declaring metric variables
2023-04-25 08:25:04,952:INFO:Importing untrained model
2023-04-25 08:25:04,956:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:25:04,965:INFO:Starting cross validation
2023-04-25 08:25:04,966:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:25:05,593:INFO:Calculating mean and std
2023-04-25 08:25:05,593:INFO:Creating metrics dataframe
2023-04-25 08:25:05,597:INFO:Finalizing model
2023-04-25 08:25:05,800:INFO:Creating Dashboard logs
2023-04-25 08:25:05,802:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:25:05,842:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:25:05,911:INFO:Initializing predict_model()
2023-04-25 08:25:05,911:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BD510>)
2023-04-25 08:25:05,911:INFO:Checking exceptions
2023-04-25 08:25:05,911:INFO:Preloading libraries
2023-04-25 08:25:06,325:INFO:Uploading results into container
2023-04-25 08:25:06,326:INFO:Uploading model into container now
2023-04-25 08:25:06,334:INFO:_master_model_container: 43
2023-04-25 08:25:06,334:INFO:_display_container: 23
2023-04-25 08:25:06,334:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:25:06,334:INFO:create_model() successfully completed......................................
2023-04-25 08:27:21,672:INFO:Initializing create_model()
2023-04-25 08:27:21,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:27:21,673:INFO:Checking exceptions
2023-04-25 08:27:21,692:INFO:Importing libraries
2023-04-25 08:27:21,693:INFO:Copying training dataset
2023-04-25 08:27:21,696:INFO:Defining folds
2023-04-25 08:27:21,696:INFO:Declaring metric variables
2023-04-25 08:27:21,701:INFO:Importing untrained model
2023-04-25 08:27:21,709:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:27:21,717:INFO:Starting cross validation
2023-04-25 08:27:21,720:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:22,340:INFO:Calculating mean and std
2023-04-25 08:27:22,340:INFO:Creating metrics dataframe
2023-04-25 08:27:22,344:INFO:Finalizing model
2023-04-25 08:27:22,551:INFO:Creating Dashboard logs
2023-04-25 08:27:22,554:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:27:22,604:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:27:22,680:INFO:Initializing predict_model()
2023-04-25 08:27:22,680:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BD6C0>)
2023-04-25 08:27:22,680:INFO:Checking exceptions
2023-04-25 08:27:22,680:INFO:Preloading libraries
2023-04-25 08:27:23,128:INFO:Uploading results into container
2023-04-25 08:27:23,129:INFO:Uploading model into container now
2023-04-25 08:27:23,138:INFO:_master_model_container: 44
2023-04-25 08:27:23,138:INFO:_display_container: 24
2023-04-25 08:27:23,138:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:27:23,138:INFO:create_model() successfully completed......................................
2023-04-25 08:27:29,494:INFO:Initializing create_model()
2023-04-25 08:27:29,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:27:29,494:INFO:Checking exceptions
2023-04-25 08:27:29,515:INFO:Importing libraries
2023-04-25 08:27:29,515:INFO:Copying training dataset
2023-04-25 08:27:29,518:INFO:Defining folds
2023-04-25 08:27:29,519:INFO:Declaring metric variables
2023-04-25 08:27:29,522:INFO:Importing untrained model
2023-04-25 08:27:29,529:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:27:29,539:INFO:Starting cross validation
2023-04-25 08:27:29,540:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:30,184:INFO:Calculating mean and std
2023-04-25 08:27:30,184:INFO:Creating metrics dataframe
2023-04-25 08:27:30,189:INFO:Finalizing model
2023-04-25 08:27:30,443:INFO:Creating Dashboard logs
2023-04-25 08:27:30,446:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:27:30,487:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:27:30,564:INFO:Initializing predict_model()
2023-04-25 08:27:30,564:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BC280>)
2023-04-25 08:27:30,564:INFO:Checking exceptions
2023-04-25 08:27:30,564:INFO:Preloading libraries
2023-04-25 08:27:31,056:INFO:Uploading results into container
2023-04-25 08:27:31,057:INFO:Uploading model into container now
2023-04-25 08:27:31,064:INFO:_master_model_container: 45
2023-04-25 08:27:31,064:INFO:_display_container: 25
2023-04-25 08:27:31,065:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:27:31,065:INFO:create_model() successfully completed......................................
2023-04-25 08:27:31,267:INFO:Initializing create_model()
2023-04-25 08:27:31,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:27:31,267:INFO:Checking exceptions
2023-04-25 08:27:31,292:INFO:Importing libraries
2023-04-25 08:27:31,292:INFO:Copying training dataset
2023-04-25 08:27:31,298:INFO:Defining folds
2023-04-25 08:27:31,298:INFO:Declaring metric variables
2023-04-25 08:27:31,301:INFO:Importing untrained model
2023-04-25 08:27:31,304:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:27:31,313:INFO:Starting cross validation
2023-04-25 08:27:31,314:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:31,986:INFO:Calculating mean and std
2023-04-25 08:27:31,986:INFO:Creating metrics dataframe
2023-04-25 08:27:31,990:INFO:Finalizing model
2023-04-25 08:27:32,226:INFO:Creating Dashboard logs
2023-04-25 08:27:32,230:INFO:Model: Random Forest Regressor
2023-04-25 08:27:32,269:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:27:32,348:INFO:Initializing predict_model()
2023-04-25 08:27:32,348:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0B52D0>)
2023-04-25 08:27:32,348:INFO:Checking exceptions
2023-04-25 08:27:32,348:INFO:Preloading libraries
2023-04-25 08:27:32,842:INFO:Uploading results into container
2023-04-25 08:27:32,843:INFO:Uploading model into container now
2023-04-25 08:27:32,853:INFO:_master_model_container: 46
2023-04-25 08:27:32,853:INFO:_display_container: 26
2023-04-25 08:27:32,853:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:27:32,853:INFO:create_model() successfully completed......................................
2023-04-25 08:27:33,020:INFO:Initializing tune_model()
2023-04-25 08:27:33,020:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:27:33,020:INFO:Checking exceptions
2023-04-25 08:27:33,048:INFO:Copying training dataset
2023-04-25 08:27:33,051:INFO:Checking base model
2023-04-25 08:27:33,051:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:27:33,055:INFO:Declaring metric variables
2023-04-25 08:27:33,058:INFO:Defining Hyperparameters
2023-04-25 08:27:33,195:INFO:Tuning with n_jobs=-1
2023-04-25 08:27:33,195:INFO:Initializing RandomizedSearchCV
2023-04-25 08:27:39,906:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.05}
2023-04-25 08:27:39,907:INFO:Hyperparameter search completed
2023-04-25 08:27:39,908:INFO:SubProcess create_model() called ==================================
2023-04-25 08:27:39,908:INFO:Initializing create_model()
2023-04-25 08:27:39,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A511480>, model_only=True, return_train_score=False, kwargs={'subsample': 1.0, 'n_estimators': 280, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.05})
2023-04-25 08:27:39,908:INFO:Checking exceptions
2023-04-25 08:27:39,908:INFO:Importing libraries
2023-04-25 08:27:39,908:INFO:Copying training dataset
2023-04-25 08:27:39,910:INFO:Defining folds
2023-04-25 08:27:39,910:INFO:Declaring metric variables
2023-04-25 08:27:39,914:INFO:Importing untrained model
2023-04-25 08:27:39,914:INFO:Declaring custom model
2023-04-25 08:27:39,916:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:27:39,922:INFO:Starting cross validation
2023-04-25 08:27:39,923:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:40,547:INFO:Calculating mean and std
2023-04-25 08:27:40,547:INFO:Creating metrics dataframe
2023-04-25 08:27:40,552:INFO:Finalizing model
2023-04-25 08:27:40,733:INFO:Uploading results into container
2023-04-25 08:27:40,734:INFO:Uploading model into container now
2023-04-25 08:27:40,734:INFO:_master_model_container: 47
2023-04-25 08:27:40,734:INFO:_display_container: 27
2023-04-25 08:27:40,735:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307)
2023-04-25 08:27:40,735:INFO:create_model() successfully completed......................................
2023-04-25 08:27:40,856:INFO:SubProcess create_model() end ==================================
2023-04-25 08:27:40,856:INFO:choose_better activated
2023-04-25 08:27:40,859:INFO:SubProcess create_model() called ==================================
2023-04-25 08:27:40,859:INFO:Initializing create_model()
2023-04-25 08:27:40,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:27:40,859:INFO:Checking exceptions
2023-04-25 08:27:40,861:INFO:Importing libraries
2023-04-25 08:27:40,861:INFO:Copying training dataset
2023-04-25 08:27:40,862:INFO:Defining folds
2023-04-25 08:27:40,863:INFO:Declaring metric variables
2023-04-25 08:27:40,863:INFO:Importing untrained model
2023-04-25 08:27:40,863:INFO:Declaring custom model
2023-04-25 08:27:40,865:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:27:40,865:INFO:Starting cross validation
2023-04-25 08:27:40,866:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:41,496:INFO:Calculating mean and std
2023-04-25 08:27:41,497:INFO:Creating metrics dataframe
2023-04-25 08:27:41,498:INFO:Finalizing model
2023-04-25 08:27:41,695:INFO:Uploading results into container
2023-04-25 08:27:41,695:INFO:Uploading model into container now
2023-04-25 08:27:41,696:INFO:_master_model_container: 48
2023-04-25 08:27:41,696:INFO:_display_container: 28
2023-04-25 08:27:41,696:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:27:41,696:INFO:create_model() successfully completed......................................
2023-04-25 08:27:41,812:INFO:SubProcess create_model() end ==================================
2023-04-25 08:27:41,812:INFO:GradientBoostingRegressor(random_state=1307) result for R2 is 0.8603
2023-04-25 08:27:41,813:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.0001, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=280,
                          random_state=1307) result for R2 is 0.8253
2023-04-25 08:27:41,813:INFO:GradientBoostingRegressor(random_state=1307) is best model
2023-04-25 08:27:41,813:INFO:choose_better completed
2023-04-25 08:27:41,813:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:27:41,813:INFO:Creating Dashboard logs
2023-04-25 08:27:41,816:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:27:41,862:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:27:41,933:INFO:Initializing predict_model()
2023-04-25 08:27:41,933:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8501F0>)
2023-04-25 08:27:41,933:INFO:Checking exceptions
2023-04-25 08:27:41,933:INFO:Preloading libraries
2023-04-25 08:27:42,357:INFO:_master_model_container: 48
2023-04-25 08:27:42,358:INFO:_display_container: 27
2023-04-25 08:27:42,358:INFO:GradientBoostingRegressor(random_state=1307)
2023-04-25 08:27:42,358:INFO:tune_model() successfully completed......................................
2023-04-25 08:27:42,617:INFO:Initializing tune_model()
2023-04-25 08:27:42,617:INFO:tune_model(estimator=LGBMRegressor(random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:27:42,617:INFO:Checking exceptions
2023-04-25 08:27:42,640:INFO:Copying training dataset
2023-04-25 08:27:42,643:INFO:Checking base model
2023-04-25 08:27:42,644:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:27:42,647:INFO:Declaring metric variables
2023-04-25 08:27:42,651:INFO:Defining Hyperparameters
2023-04-25 08:27:42,776:INFO:Tuning with n_jobs=-1
2023-04-25 08:27:42,776:INFO:Initializing RandomizedSearchCV
2023-04-25 08:27:49,185:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2023-04-25 08:27:49,186:INFO:Hyperparameter search completed
2023-04-25 08:27:49,186:INFO:SubProcess create_model() called ==================================
2023-04-25 08:27:49,187:INFO:Initializing create_model()
2023-04-25 08:27:49,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A7057B0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 0.001, 'num_leaves': 50, 'n_estimators': 150, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2023-04-25 08:27:49,187:INFO:Checking exceptions
2023-04-25 08:27:49,187:INFO:Importing libraries
2023-04-25 08:27:49,187:INFO:Copying training dataset
2023-04-25 08:27:49,190:INFO:Defining folds
2023-04-25 08:27:49,190:INFO:Declaring metric variables
2023-04-25 08:27:49,194:INFO:Importing untrained model
2023-04-25 08:27:49,194:INFO:Declaring custom model
2023-04-25 08:27:49,198:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:27:49,203:INFO:Starting cross validation
2023-04-25 08:27:49,204:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:49,778:INFO:Calculating mean and std
2023-04-25 08:27:49,780:INFO:Creating metrics dataframe
2023-04-25 08:27:49,785:INFO:Finalizing model
2023-04-25 08:27:49,807:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:27:49,807:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:27:49,807:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-04-25 08:27:50,051:INFO:Uploading results into container
2023-04-25 08:27:50,051:INFO:Uploading model into container now
2023-04-25 08:27:50,053:INFO:_master_model_container: 49
2023-04-25 08:27:50,053:INFO:_display_container: 28
2023-04-25 08:27:50,054:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:27:50,054:INFO:create_model() successfully completed......................................
2023-04-25 08:27:50,227:INFO:SubProcess create_model() end ==================================
2023-04-25 08:27:50,228:INFO:choose_better activated
2023-04-25 08:27:50,232:INFO:SubProcess create_model() called ==================================
2023-04-25 08:27:50,233:INFO:Initializing create_model()
2023-04-25 08:27:50,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:27:50,233:INFO:Checking exceptions
2023-04-25 08:27:50,235:INFO:Importing libraries
2023-04-25 08:27:50,235:INFO:Copying training dataset
2023-04-25 08:27:50,237:INFO:Defining folds
2023-04-25 08:27:50,237:INFO:Declaring metric variables
2023-04-25 08:27:50,237:INFO:Importing untrained model
2023-04-25 08:27:50,237:INFO:Declaring custom model
2023-04-25 08:27:50,238:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:27:50,238:INFO:Starting cross validation
2023-04-25 08:27:50,239:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:50,812:INFO:Calculating mean and std
2023-04-25 08:27:50,812:INFO:Creating metrics dataframe
2023-04-25 08:27:50,814:INFO:Finalizing model
2023-04-25 08:27:51,057:INFO:Uploading results into container
2023-04-25 08:27:51,060:INFO:Uploading model into container now
2023-04-25 08:27:51,060:INFO:_master_model_container: 50
2023-04-25 08:27:51,060:INFO:_display_container: 29
2023-04-25 08:27:51,060:INFO:LGBMRegressor(random_state=1307)
2023-04-25 08:27:51,060:INFO:create_model() successfully completed......................................
2023-04-25 08:27:51,211:INFO:SubProcess create_model() end ==================================
2023-04-25 08:27:51,211:INFO:LGBMRegressor(random_state=1307) result for R2 is 0.852
2023-04-25 08:27:51,212:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) result for R2 is 0.8618
2023-04-25 08:27:51,212:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10) is best model
2023-04-25 08:27:51,212:INFO:choose_better completed
2023-04-25 08:27:51,213:INFO:Creating Dashboard logs
2023-04-25 08:27:51,216:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:27:51,259:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 150, 'n_jobs': -1, 'num_leaves': 50, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.001, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0}
2023-04-25 08:27:51,339:INFO:Initializing predict_model()
2023-04-25 08:27:51,339:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A851EA0>)
2023-04-25 08:27:51,339:INFO:Checking exceptions
2023-04-25 08:27:51,339:INFO:Preloading libraries
2023-04-25 08:27:51,840:INFO:_master_model_container: 50
2023-04-25 08:27:51,841:INFO:_display_container: 28
2023-04-25 08:27:51,841:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:27:51,842:INFO:tune_model() successfully completed......................................
2023-04-25 08:27:52,076:INFO:Initializing tune_model()
2023-04-25 08:27:52,076:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>)
2023-04-25 08:27:52,076:INFO:Checking exceptions
2023-04-25 08:27:52,104:INFO:Copying training dataset
2023-04-25 08:27:52,108:INFO:Checking base model
2023-04-25 08:27:52,109:INFO:Base model : Random Forest Regressor
2023-04-25 08:27:52,114:INFO:Declaring metric variables
2023-04-25 08:27:52,117:INFO:Defining Hyperparameters
2023-04-25 08:27:52,246:INFO:Tuning with n_jobs=-1
2023-04-25 08:27:52,246:INFO:Initializing RandomizedSearchCV
2023-04-25 08:27:59,000:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': True}
2023-04-25 08:27:59,001:INFO:Hyperparameter search completed
2023-04-25 08:27:59,001:INFO:SubProcess create_model() called ==================================
2023-04-25 08:27:59,001:INFO:Initializing create_model()
2023-04-25 08:27:59,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562058C40>, model_only=True, return_train_score=False, kwargs={'n_estimators': 70, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'absolute_error', 'bootstrap': True})
2023-04-25 08:27:59,001:INFO:Checking exceptions
2023-04-25 08:27:59,001:INFO:Importing libraries
2023-04-25 08:27:59,001:INFO:Copying training dataset
2023-04-25 08:27:59,004:INFO:Defining folds
2023-04-25 08:27:59,005:INFO:Declaring metric variables
2023-04-25 08:27:59,007:INFO:Importing untrained model
2023-04-25 08:27:59,007:INFO:Declaring custom model
2023-04-25 08:27:59,010:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:27:59,015:INFO:Starting cross validation
2023-04-25 08:27:59,016:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:27:59,625:INFO:Calculating mean and std
2023-04-25 08:27:59,626:INFO:Creating metrics dataframe
2023-04-25 08:27:59,630:INFO:Finalizing model
2023-04-25 08:27:59,810:INFO:Uploading results into container
2023-04-25 08:27:59,811:INFO:Uploading model into container now
2023-04-25 08:27:59,811:INFO:_master_model_container: 51
2023-04-25 08:27:59,812:INFO:_display_container: 29
2023-04-25 08:27:59,812:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:27:59,813:INFO:create_model() successfully completed......................................
2023-04-25 08:27:59,937:INFO:SubProcess create_model() end ==================================
2023-04-25 08:27:59,937:INFO:choose_better activated
2023-04-25 08:27:59,940:INFO:SubProcess create_model() called ==================================
2023-04-25 08:27:59,940:INFO:Initializing create_model()
2023-04-25 08:27:59,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1307), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:27:59,940:INFO:Checking exceptions
2023-04-25 08:27:59,941:INFO:Importing libraries
2023-04-25 08:27:59,941:INFO:Copying training dataset
2023-04-25 08:27:59,943:INFO:Defining folds
2023-04-25 08:27:59,944:INFO:Declaring metric variables
2023-04-25 08:27:59,944:INFO:Importing untrained model
2023-04-25 08:27:59,944:INFO:Declaring custom model
2023-04-25 08:27:59,944:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:27:59,944:INFO:Starting cross validation
2023-04-25 08:27:59,945:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:28:00,585:INFO:Calculating mean and std
2023-04-25 08:28:00,587:INFO:Creating metrics dataframe
2023-04-25 08:28:00,588:INFO:Finalizing model
2023-04-25 08:28:00,813:INFO:Uploading results into container
2023-04-25 08:28:00,813:INFO:Uploading model into container now
2023-04-25 08:28:00,814:INFO:_master_model_container: 52
2023-04-25 08:28:00,814:INFO:_display_container: 30
2023-04-25 08:28:00,814:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307)
2023-04-25 08:28:00,814:INFO:create_model() successfully completed......................................
2023-04-25 08:28:00,935:INFO:SubProcess create_model() end ==================================
2023-04-25 08:28:00,935:INFO:RandomForestRegressor(n_jobs=-1, random_state=1307) result for R2 is 0.8456
2023-04-25 08:28:00,936:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) result for R2 is 0.87
2023-04-25 08:28:00,936:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307) is best model
2023-04-25 08:28:00,936:INFO:choose_better completed
2023-04-25 08:28:00,936:INFO:Creating Dashboard logs
2023-04-25 08:28:00,938:INFO:Model: Random Forest Regressor
2023-04-25 08:28:00,980:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:28:01,048:INFO:Initializing predict_model()
2023-04-25 08:28:01,048:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A852170>)
2023-04-25 08:28:01,048:INFO:Checking exceptions
2023-04-25 08:28:01,048:INFO:Preloading libraries
2023-04-25 08:28:01,527:INFO:_master_model_container: 52
2023-04-25 08:28:01,528:INFO:_display_container: 29
2023-04-25 08:28:01,528:INFO:RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:28:01,528:INFO:tune_model() successfully completed......................................
2023-04-25 08:28:01,779:INFO:Initializing plot_model()
2023-04-25 08:28:01,779:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:28:01,779:INFO:Checking exceptions
2023-04-25 08:28:01,783:INFO:Preloading libraries
2023-04-25 08:28:01,788:INFO:Copying training dataset
2023-04-25 08:28:01,788:INFO:Plot type: error
2023-04-25 08:28:01,842:INFO:Fitting Model
2023-04-25 08:28:01,842:INFO:Scoring test/hold-out set
2023-04-25 08:28:02,000:INFO:Visual Rendered Successfully
2023-04-25 08:28:02,123:INFO:plot_model() successfully completed......................................
2023-04-25 08:28:02,132:INFO:Initializing plot_model()
2023-04-25 08:28:02,132:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:28:02,132:INFO:Checking exceptions
2023-04-25 08:28:02,136:INFO:Preloading libraries
2023-04-25 08:28:02,141:INFO:Copying training dataset
2023-04-25 08:28:02,141:INFO:Plot type: error
2023-04-25 08:28:02,211:INFO:Fitting Model
2023-04-25 08:28:02,211:INFO:Scoring test/hold-out set
2023-04-25 08:28:02,403:INFO:Visual Rendered Successfully
2023-04-25 08:28:02,525:INFO:plot_model() successfully completed......................................
2023-04-25 08:28:02,533:INFO:Initializing plot_model()
2023-04-25 08:28:02,533:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:28:02,533:INFO:Checking exceptions
2023-04-25 08:28:02,546:INFO:Preloading libraries
2023-04-25 08:28:02,552:INFO:Copying training dataset
2023-04-25 08:28:02,552:INFO:Plot type: error
2023-04-25 08:28:02,606:INFO:Fitting Model
2023-04-25 08:28:02,606:INFO:Scoring test/hold-out set
2023-04-25 08:28:02,793:INFO:Visual Rendered Successfully
2023-04-25 08:28:02,920:INFO:plot_model() successfully completed......................................
2023-04-25 08:28:02,957:INFO:Initializing plot_model()
2023-04-25 08:28:02,957:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:28:02,957:INFO:Checking exceptions
2023-04-25 08:28:02,961:INFO:Preloading libraries
2023-04-25 08:28:02,966:INFO:Copying training dataset
2023-04-25 08:28:02,966:INFO:Plot type: feature
2023-04-25 08:28:02,966:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:28:03,111:INFO:Visual Rendered Successfully
2023-04-25 08:28:03,255:INFO:plot_model() successfully completed......................................
2023-04-25 08:28:03,256:INFO:Initializing plot_model()
2023-04-25 08:28:03,256:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:28:03,256:INFO:Checking exceptions
2023-04-25 08:28:03,263:INFO:Preloading libraries
2023-04-25 08:28:03,269:INFO:Copying training dataset
2023-04-25 08:28:03,269:INFO:Plot type: feature
2023-04-25 08:28:03,269:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:28:03,445:INFO:Visual Rendered Successfully
2023-04-25 08:28:03,589:INFO:plot_model() successfully completed......................................
2023-04-25 08:28:03,590:INFO:Initializing plot_model()
2023-04-25 08:28:03,590:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, system=True)
2023-04-25 08:28:03,590:INFO:Checking exceptions
2023-04-25 08:28:03,602:INFO:Preloading libraries
2023-04-25 08:28:03,609:INFO:Copying training dataset
2023-04-25 08:28:03,609:INFO:Plot type: feature
2023-04-25 08:28:03,609:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:28:03,735:INFO:Visual Rendered Successfully
2023-04-25 08:28:03,855:INFO:plot_model() successfully completed......................................
2023-04-25 08:28:03,869:INFO:Initializing predict_model()
2023-04-25 08:28:03,870:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A63FD00>)
2023-04-25 08:28:03,870:INFO:Checking exceptions
2023-04-25 08:28:03,870:INFO:Preloading libraries
2023-04-25 08:30:51,359:INFO:Initializing finalize_model()
2023-04-25 08:30:51,360:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:30:51,360:INFO:Finalizing GradientBoostingRegressor(random_state=1307)
2023-04-25 08:30:51,363:INFO:Initializing create_model()
2023-04-25 08:30:51,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:30:51,363:INFO:Checking exceptions
2023-04-25 08:30:51,364:INFO:Importing libraries
2023-04-25 08:30:51,364:INFO:Copying training dataset
2023-04-25 08:30:51,364:INFO:Defining folds
2023-04-25 08:30:51,364:INFO:Declaring metric variables
2023-04-25 08:30:51,365:INFO:Importing untrained model
2023-04-25 08:30:51,365:INFO:Declaring custom model
2023-04-25 08:30:51,365:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:30:51,366:INFO:Cross validation set to False
2023-04-25 08:30:51,366:INFO:Fitting Model
2023-04-25 08:30:51,461:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1307))])
2023-04-25 08:30:51,461:INFO:create_model() successfully completed......................................
2023-04-25 08:30:51,585:INFO:Creating Dashboard logs
2023-04-25 08:30:51,586:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:30:51,627:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:30:51,934:INFO:_master_model_container: 52
2023-04-25 08:30:51,934:INFO:_display_container: 30
2023-04-25 08:30:51,938:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1307))])
2023-04-25 08:30:51,938:INFO:finalize_model() successfully completed......................................
2023-04-25 08:31:25,648:INFO:Initializing finalize_model()
2023-04-25 08:31:25,649:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:31:25,649:INFO:Finalizing GradientBoostingRegressor(random_state=1307)
2023-04-25 08:31:25,651:INFO:Initializing create_model()
2023-04-25 08:31:25,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=GradientBoostingRegressor(random_state=1307), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:31:25,652:INFO:Checking exceptions
2023-04-25 08:31:25,653:INFO:Importing libraries
2023-04-25 08:31:25,653:INFO:Copying training dataset
2023-04-25 08:31:25,653:INFO:Defining folds
2023-04-25 08:31:25,653:INFO:Declaring metric variables
2023-04-25 08:31:25,653:INFO:Importing untrained model
2023-04-25 08:31:25,653:INFO:Declaring custom model
2023-04-25 08:31:25,654:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:31:25,654:INFO:Cross validation set to False
2023-04-25 08:31:25,655:INFO:Fitting Model
2023-04-25 08:31:25,751:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1307))])
2023-04-25 08:31:25,751:INFO:create_model() successfully completed......................................
2023-04-25 08:31:25,879:INFO:Creating Dashboard logs
2023-04-25 08:31:25,880:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:31:25,924:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1307, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:31:26,233:INFO:_master_model_container: 52
2023-04-25 08:31:26,234:INFO:_display_container: 30
2023-04-25 08:31:26,237:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1307))])
2023-04-25 08:31:26,237:INFO:finalize_model() successfully completed......................................
2023-04-25 08:31:26,459:INFO:Initializing finalize_model()
2023-04-25 08:31:26,459:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:31:26,460:INFO:Finalizing LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10)
2023-04-25 08:31:26,462:INFO:Initializing create_model()
2023-04-25 08:31:26,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=7, feature_fraction=0.5,
              min_child_samples=41, min_split_gain=0.9, n_estimators=150,
              num_leaves=50, random_state=1307, reg_alpha=0.001, reg_lambda=10), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:31:26,462:INFO:Checking exceptions
2023-04-25 08:31:26,464:INFO:Importing libraries
2023-04-25 08:31:26,464:INFO:Copying training dataset
2023-04-25 08:31:26,464:INFO:Defining folds
2023-04-25 08:31:26,465:INFO:Declaring metric variables
2023-04-25 08:31:26,465:INFO:Importing untrained model
2023-04-25 08:31:26,465:INFO:Declaring custom model
2023-04-25 08:31:26,465:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:31:26,466:INFO:Cross validation set to False
2023-04-25 08:31:26,466:INFO:Fitting Model
2023-04-25 08:31:26,485:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:31:26,485:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:31:26,485:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-04-25 08:31:26,530:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=7,
                               feature_fraction=0.5, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=150,
                               num_leaves=50, random_state=1307,
                               reg_alpha=0.001, reg_lambda=10))])
2023-04-25 08:31:26,530:INFO:create_model() successfully completed......................................
2023-04-25 08:31:26,673:INFO:Creating Dashboard logs
2023-04-25 08:31:26,674:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:31:26,718:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 150, 'n_jobs': -1, 'num_leaves': 50, 'objective': None, 'random_state': 1307, 'reg_alpha': 0.001, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 1.0}
2023-04-25 08:31:27,040:INFO:_master_model_container: 52
2023-04-25 08:31:27,040:INFO:_display_container: 30
2023-04-25 08:31:27,044:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=7,
                               feature_fraction=0.5, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=150,
                               num_leaves=50, random_state=1307,
                               reg_alpha=0.001, reg_lambda=10))])
2023-04-25 08:31:27,044:INFO:finalize_model() successfully completed......................................
2023-04-25 08:31:27,160:INFO:Initializing finalize_model()
2023-04-25 08:31:27,160:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:31:27,160:INFO:Finalizing RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307)
2023-04-25 08:31:27,162:INFO:Initializing create_model()
2023-04-25 08:31:27,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=RandomForestRegressor(criterion='absolute_error', max_depth=7,
                      min_impurity_decrease=0.1, min_samples_leaf=4,
                      n_estimators=70, n_jobs=-1, random_state=1307), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:31:27,162:INFO:Checking exceptions
2023-04-25 08:31:27,163:INFO:Importing libraries
2023-04-25 08:31:27,164:INFO:Copying training dataset
2023-04-25 08:31:27,164:INFO:Defining folds
2023-04-25 08:31:27,164:INFO:Declaring metric variables
2023-04-25 08:31:27,164:INFO:Importing untrained model
2023-04-25 08:31:27,164:INFO:Declaring custom model
2023-04-25 08:31:27,164:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:31:27,165:INFO:Cross validation set to False
2023-04-25 08:31:27,165:INFO:Fitting Model
2023-04-25 08:31:27,466:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(criterion='absolute_error', max_depth=7,
                                       min_impurity_decrease=0.1,
                                       min_samples_leaf=4, n_estimators=70,
                                       n_jobs=-1, random_state=1307))])
2023-04-25 08:31:27,466:INFO:create_model() successfully completed......................................
2023-04-25 08:31:27,582:INFO:Creating Dashboard logs
2023-04-25 08:31:27,583:INFO:Model: Random Forest Regressor
2023-04-25 08:31:27,621:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'absolute_error', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_jobs': -1, 'oob_score': False, 'random_state': 1307, 'verbose': 0, 'warm_start': False}
2023-04-25 08:31:27,908:INFO:_master_model_container: 52
2023-04-25 08:31:27,908:INFO:_display_container: 30
2023-04-25 08:31:27,912:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(criterion='absolute_error', max_depth=7,
                                       min_impurity_decrease=0.1,
                                       min_samples_leaf=4, n_estimators=70,
                                       n_jobs=-1, random_state=1307))])
2023-04-25 08:31:27,912:INFO:finalize_model() successfully completed......................................
2023-04-25 08:32:23,650:INFO:Initializing predict_model()
2023-04-25 08:32:23,651:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1307))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561DD2050>)
2023-04-25 08:32:23,651:INFO:Checking exceptions
2023-04-25 08:32:23,651:INFO:Preloading libraries
2023-04-25 08:32:23,653:INFO:Set up data.
2023-04-25 08:32:23,658:INFO:Set up index.
2023-04-25 08:32:44,868:INFO:Initializing predict_model()
2023-04-25 08:32:44,869:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=7,
                               feature_fraction=0.5, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=150,
                               num_leaves=50, random_state=1307,
                               reg_alpha=0.001, reg_lambda=10))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D5693C9D80>)
2023-04-25 08:32:44,869:INFO:Checking exceptions
2023-04-25 08:32:44,869:INFO:Preloading libraries
2023-04-25 08:32:44,871:INFO:Set up data.
2023-04-25 08:32:44,876:INFO:Set up index.
2023-04-25 08:33:34,572:INFO:Initializing predict_model()
2023-04-25 08:33:34,573:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A87CEB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(criterion='absolute_error', max_depth=7,
                                       min_impurity_decrease=0.1,
                                       min_samples_leaf=4, n_estimators=70,
                                       n_jobs=-1, random_state=1307))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A63E320>)
2023-04-25 08:33:34,573:INFO:Checking exceptions
2023-04-25 08:33:34,573:INFO:Preloading libraries
2023-04-25 08:33:34,575:INFO:Set up data.
2023-04-25 08:33:34,579:INFO:Set up index.
2023-04-25 08:34:46,046:INFO:PyCaret RegressionExperiment
2023-04-25 08:34:46,046:INFO:Logging name: charges
2023-04-25 08:34:46,046:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 08:34:46,046:INFO:version 3.0.0
2023-04-25 08:34:46,046:INFO:Initializing setup()
2023-04-25 08:34:46,046:INFO:self.USI: 0d89
2023-04-25 08:34:46,046:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-25 08:34:46,046:INFO:Checking environment
2023-04-25 08:34:46,046:INFO:python_version: 3.10.11
2023-04-25 08:34:46,046:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-25 08:34:46,046:INFO:machine: AMD64
2023-04-25 08:34:46,046:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 08:34:46,046:INFO:Memory: svmem(total=8362713088, available=1867976704, percent=77.7, used=6494736384, free=1867976704)
2023-04-25 08:34:46,047:INFO:Physical Core: 4
2023-04-25 08:34:46,047:INFO:Logical Core: 8
2023-04-25 08:34:46,047:INFO:Checking libraries
2023-04-25 08:34:46,047:INFO:System:
2023-04-25 08:34:46,047:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-25 08:34:46,047:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-25 08:34:46,047:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 08:34:46,047:INFO:PyCaret required dependencies:
2023-04-25 08:34:46,047:INFO:                 pip: 23.0.1
2023-04-25 08:34:46,047:INFO:          setuptools: 65.5.0
2023-04-25 08:34:46,047:INFO:             pycaret: 3.0.0
2023-04-25 08:34:46,047:INFO:             IPython: 8.5.0
2023-04-25 08:34:46,047:INFO:          ipywidgets: 8.0.2
2023-04-25 08:34:46,047:INFO:                tqdm: 4.65.0
2023-04-25 08:34:46,047:INFO:               numpy: 1.23.3
2023-04-25 08:34:46,047:INFO:              pandas: 1.5.0
2023-04-25 08:34:46,047:INFO:              jinja2: 3.1.2
2023-04-25 08:34:46,047:INFO:               scipy: 1.9.1
2023-04-25 08:34:46,047:INFO:              joblib: 1.2.0
2023-04-25 08:34:46,047:INFO:             sklearn: 1.1.2
2023-04-25 08:34:46,047:INFO:                pyod: 1.0.9
2023-04-25 08:34:46,047:INFO:            imblearn: 0.10.1
2023-04-25 08:34:46,047:INFO:   category_encoders: 2.6.0
2023-04-25 08:34:46,047:INFO:            lightgbm: 3.3.5
2023-04-25 08:34:46,047:INFO:               numba: 0.56.4
2023-04-25 08:34:46,047:INFO:            requests: 2.28.1
2023-04-25 08:34:46,047:INFO:          matplotlib: 3.6.0
2023-04-25 08:34:46,047:INFO:          scikitplot: 0.3.7
2023-04-25 08:34:46,047:INFO:         yellowbrick: 1.5
2023-04-25 08:34:46,047:INFO:              plotly: 5.10.0
2023-04-25 08:34:46,047:INFO:             kaleido: 0.2.1
2023-04-25 08:34:46,047:INFO:         statsmodels: 0.13.5
2023-04-25 08:34:46,047:INFO:              sktime: 0.17.1
2023-04-25 08:34:46,047:INFO:               tbats: 1.1.3
2023-04-25 08:34:46,047:INFO:            pmdarima: 2.0.3
2023-04-25 08:34:46,047:INFO:              psutil: 5.9.2
2023-04-25 08:34:46,047:INFO:PyCaret optional dependencies:
2023-04-25 08:34:46,047:INFO:                shap: Not installed
2023-04-25 08:34:46,047:INFO:           interpret: Not installed
2023-04-25 08:34:46,047:INFO:                umap: Not installed
2023-04-25 08:34:46,048:INFO:    pandas_profiling: Not installed
2023-04-25 08:34:46,048:INFO:  explainerdashboard: Not installed
2023-04-25 08:34:46,048:INFO:             autoviz: Not installed
2023-04-25 08:34:46,048:INFO:           fairlearn: Not installed
2023-04-25 08:34:46,048:INFO:             xgboost: 1.7.5
2023-04-25 08:34:46,048:INFO:            catboost: Not installed
2023-04-25 08:34:46,048:INFO:              kmodes: Not installed
2023-04-25 08:34:46,048:INFO:             mlxtend: Not installed
2023-04-25 08:34:46,048:INFO:       statsforecast: Not installed
2023-04-25 08:34:46,048:INFO:        tune_sklearn: Not installed
2023-04-25 08:34:46,048:INFO:                 ray: Not installed
2023-04-25 08:34:46,048:INFO:            hyperopt: Not installed
2023-04-25 08:34:46,048:INFO:              optuna: Not installed
2023-04-25 08:34:46,048:INFO:               skopt: Not installed
2023-04-25 08:34:46,048:INFO:              mlflow: 2.3.0
2023-04-25 08:34:46,048:INFO:              gradio: Not installed
2023-04-25 08:34:46,048:INFO:             fastapi: Not installed
2023-04-25 08:34:46,048:INFO:             uvicorn: Not installed
2023-04-25 08:34:46,048:INFO:              m2cgen: Not installed
2023-04-25 08:34:46,048:INFO:           evidently: Not installed
2023-04-25 08:34:46,048:INFO:               fugue: Not installed
2023-04-25 08:34:46,048:INFO:           streamlit: Not installed
2023-04-25 08:34:46,048:INFO:             prophet: Not installed
2023-04-25 08:34:46,048:INFO:None
2023-04-25 08:34:46,048:INFO:Set up data.
2023-04-25 08:34:46,051:INFO:Set up train/test split.
2023-04-25 08:34:46,053:INFO:Set up index.
2023-04-25 08:34:46,053:INFO:Set up folding strategy.
2023-04-25 08:34:46,053:INFO:Assigning column types.
2023-04-25 08:34:46,055:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 08:34:46,055:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,063:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,110:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,143:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,145:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,149:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,152:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,226:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,228:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 08:34:46,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,311:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,316:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,320:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,393:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,395:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 08:34:46,401:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,474:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,482:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,559:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,561:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 08:34:46,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,641:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,641:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,722:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,724:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 08:34:46,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,804:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:34:46,886:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:46,888:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 08:34:46,969:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:46,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:47,053:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:47,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:47,056:INFO:Preparing preprocessing pipeline...
2023-04-25 08:34:47,056:INFO:Set up simple imputation.
2023-04-25 08:34:47,056:INFO:Set up feature normalization.
2023-04-25 08:34:47,071:INFO:Finished creating preprocessing pipeline.
2023-04-25 08:34:47,074:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-25 08:34:47,074:INFO:Creating final display dataframe.
2023-04-25 08:34:47,124:INFO:Setup _display_container:                     Description         Value
0                    Session id          1754
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1204, 8)
4        Transformed data shape     (1204, 8)
5   Transformed train set shape      (842, 8)
6    Transformed test set shape      (362, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          0d89
2023-04-25 08:34:47,215:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:47,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:47,298:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:34:47,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:34:47,300:INFO:Logging experiment in loggers
2023-04-25 08:34:47,365:INFO:SubProcess save_model() called ==================================
2023-04-25 08:34:47,371:INFO:Initializing save_model()
2023-04-25 08:34:47,371:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmp1wlh357k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 08:34:47,371:INFO:Adding model into prep_pipe
2023-04-25 08:34:47,371:WARNING:Only Model saved as it was a pipeline.
2023-04-25 08:34:47,373:INFO:C:\Users\danie\AppData\Local\Temp\tmp1wlh357k\Transformation Pipeline.pkl saved in current working directory
2023-04-25 08:34:47,376:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-25 08:34:47,376:INFO:save_model() successfully completed......................................
2023-04-25 08:34:47,613:INFO:SubProcess save_model() end ==================================
2023-04-25 08:34:47,648:INFO:setup() successfully completed in 1.36s...............
2023-04-25 08:34:47,767:INFO:Initializing compare_models()
2023-04-25 08:34:47,768:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 08:34:47,768:INFO:Checking exceptions
2023-04-25 08:34:47,769:INFO:Preparing display monitor
2023-04-25 08:34:47,801:INFO:Initializing Linear Regression
2023-04-25 08:34:47,801:INFO:Total runtime is 0.0 minutes
2023-04-25 08:34:47,804:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:47,805:INFO:Initializing create_model()
2023-04-25 08:34:47,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:47,805:INFO:Checking exceptions
2023-04-25 08:34:47,806:INFO:Importing libraries
2023-04-25 08:34:47,806:INFO:Copying training dataset
2023-04-25 08:34:47,812:INFO:Defining folds
2023-04-25 08:34:47,812:INFO:Declaring metric variables
2023-04-25 08:34:47,816:INFO:Importing untrained model
2023-04-25 08:34:47,819:INFO:Linear Regression Imported successfully
2023-04-25 08:34:47,829:INFO:Starting cross validation
2023-04-25 08:34:47,830:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:52,150:INFO:Calculating mean and std
2023-04-25 08:34:52,151:INFO:Creating metrics dataframe
2023-04-25 08:34:52,312:INFO:Uploading results into container
2023-04-25 08:34:52,313:INFO:Uploading model into container now
2023-04-25 08:34:52,313:INFO:_master_model_container: 1
2023-04-25 08:34:52,313:INFO:_display_container: 2
2023-04-25 08:34:52,314:INFO:LinearRegression(n_jobs=-1)
2023-04-25 08:34:52,314:INFO:create_model() successfully completed......................................
2023-04-25 08:34:52,451:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:52,451:INFO:Creating metrics dataframe
2023-04-25 08:34:52,457:INFO:Initializing Lasso Regression
2023-04-25 08:34:52,457:INFO:Total runtime is 0.0776088039080302 minutes
2023-04-25 08:34:52,460:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:52,460:INFO:Initializing create_model()
2023-04-25 08:34:52,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:52,460:INFO:Checking exceptions
2023-04-25 08:34:52,460:INFO:Importing libraries
2023-04-25 08:34:52,461:INFO:Copying training dataset
2023-04-25 08:34:52,465:INFO:Defining folds
2023-04-25 08:34:52,465:INFO:Declaring metric variables
2023-04-25 08:34:52,468:INFO:Importing untrained model
2023-04-25 08:34:52,471:INFO:Lasso Regression Imported successfully
2023-04-25 08:34:52,477:INFO:Starting cross validation
2023-04-25 08:34:52,478:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:54,419:INFO:Calculating mean and std
2023-04-25 08:34:54,423:INFO:Creating metrics dataframe
2023-04-25 08:34:54,589:INFO:Uploading results into container
2023-04-25 08:34:54,591:INFO:Uploading model into container now
2023-04-25 08:34:54,591:INFO:_master_model_container: 2
2023-04-25 08:34:54,591:INFO:_display_container: 2
2023-04-25 08:34:54,591:INFO:Lasso(random_state=1754)
2023-04-25 08:34:54,591:INFO:create_model() successfully completed......................................
2023-04-25 08:34:54,724:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:54,724:INFO:Creating metrics dataframe
2023-04-25 08:34:54,730:INFO:Initializing Ridge Regression
2023-04-25 08:34:54,731:INFO:Total runtime is 0.1155025839805603 minutes
2023-04-25 08:34:54,733:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:54,733:INFO:Initializing create_model()
2023-04-25 08:34:54,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:54,734:INFO:Checking exceptions
2023-04-25 08:34:54,734:INFO:Importing libraries
2023-04-25 08:34:54,734:INFO:Copying training dataset
2023-04-25 08:34:54,737:INFO:Defining folds
2023-04-25 08:34:54,737:INFO:Declaring metric variables
2023-04-25 08:34:54,740:INFO:Importing untrained model
2023-04-25 08:34:54,743:INFO:Ridge Regression Imported successfully
2023-04-25 08:34:54,748:INFO:Starting cross validation
2023-04-25 08:34:54,748:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:55,365:INFO:Calculating mean and std
2023-04-25 08:34:55,367:INFO:Creating metrics dataframe
2023-04-25 08:34:55,560:INFO:Uploading results into container
2023-04-25 08:34:55,561:INFO:Uploading model into container now
2023-04-25 08:34:55,561:INFO:_master_model_container: 3
2023-04-25 08:34:55,561:INFO:_display_container: 2
2023-04-25 08:34:55,562:INFO:Ridge(random_state=1754)
2023-04-25 08:34:55,562:INFO:create_model() successfully completed......................................
2023-04-25 08:34:55,685:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:55,685:INFO:Creating metrics dataframe
2023-04-25 08:34:55,692:INFO:Initializing Elastic Net
2023-04-25 08:34:55,692:INFO:Total runtime is 0.1315184752146403 minutes
2023-04-25 08:34:55,695:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:55,695:INFO:Initializing create_model()
2023-04-25 08:34:55,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:55,695:INFO:Checking exceptions
2023-04-25 08:34:55,696:INFO:Importing libraries
2023-04-25 08:34:55,696:INFO:Copying training dataset
2023-04-25 08:34:55,700:INFO:Defining folds
2023-04-25 08:34:55,700:INFO:Declaring metric variables
2023-04-25 08:34:55,703:INFO:Importing untrained model
2023-04-25 08:34:55,705:INFO:Elastic Net Imported successfully
2023-04-25 08:34:55,710:INFO:Starting cross validation
2023-04-25 08:34:55,711:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:56,249:INFO:Calculating mean and std
2023-04-25 08:34:56,250:INFO:Creating metrics dataframe
2023-04-25 08:34:56,401:INFO:Uploading results into container
2023-04-25 08:34:56,401:INFO:Uploading model into container now
2023-04-25 08:34:56,402:INFO:_master_model_container: 4
2023-04-25 08:34:56,402:INFO:_display_container: 2
2023-04-25 08:34:56,402:INFO:ElasticNet(random_state=1754)
2023-04-25 08:34:56,402:INFO:create_model() successfully completed......................................
2023-04-25 08:34:56,524:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:56,524:INFO:Creating metrics dataframe
2023-04-25 08:34:56,532:INFO:Initializing Least Angle Regression
2023-04-25 08:34:56,532:INFO:Total runtime is 0.14551114638646445 minutes
2023-04-25 08:34:56,534:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:56,534:INFO:Initializing create_model()
2023-04-25 08:34:56,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:56,534:INFO:Checking exceptions
2023-04-25 08:34:56,534:INFO:Importing libraries
2023-04-25 08:34:56,536:INFO:Copying training dataset
2023-04-25 08:34:56,538:INFO:Defining folds
2023-04-25 08:34:56,540:INFO:Declaring metric variables
2023-04-25 08:34:56,541:INFO:Importing untrained model
2023-04-25 08:34:56,543:INFO:Least Angle Regression Imported successfully
2023-04-25 08:34:56,548:INFO:Starting cross validation
2023-04-25 08:34:56,549:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:56,582:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:56,589:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:56,589:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:56,605:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:56,608:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:57,124:INFO:Calculating mean and std
2023-04-25 08:34:57,125:INFO:Creating metrics dataframe
2023-04-25 08:34:57,271:INFO:Uploading results into container
2023-04-25 08:34:57,272:INFO:Uploading model into container now
2023-04-25 08:34:57,273:INFO:_master_model_container: 5
2023-04-25 08:34:57,273:INFO:_display_container: 2
2023-04-25 08:34:57,273:INFO:Lars(random_state=1754)
2023-04-25 08:34:57,273:INFO:create_model() successfully completed......................................
2023-04-25 08:34:57,401:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:57,401:INFO:Creating metrics dataframe
2023-04-25 08:34:57,409:INFO:Initializing Lasso Least Angle Regression
2023-04-25 08:34:57,410:INFO:Total runtime is 0.16014589866002402 minutes
2023-04-25 08:34:57,414:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:57,414:INFO:Initializing create_model()
2023-04-25 08:34:57,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:57,414:INFO:Checking exceptions
2023-04-25 08:34:57,414:INFO:Importing libraries
2023-04-25 08:34:57,414:INFO:Copying training dataset
2023-04-25 08:34:57,417:INFO:Defining folds
2023-04-25 08:34:57,417:INFO:Declaring metric variables
2023-04-25 08:34:57,421:INFO:Importing untrained model
2023-04-25 08:34:57,422:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 08:34:57,428:INFO:Starting cross validation
2023-04-25 08:34:57,430:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:57,471:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:34:57,476:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:34:57,486:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:34:57,496:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:34:57,501:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:34:58,081:INFO:Calculating mean and std
2023-04-25 08:34:58,082:INFO:Creating metrics dataframe
2023-04-25 08:34:58,253:INFO:Uploading results into container
2023-04-25 08:34:58,254:INFO:Uploading model into container now
2023-04-25 08:34:58,254:INFO:_master_model_container: 6
2023-04-25 08:34:58,254:INFO:_display_container: 2
2023-04-25 08:34:58,254:INFO:LassoLars(random_state=1754)
2023-04-25 08:34:58,254:INFO:create_model() successfully completed......................................
2023-04-25 08:34:58,382:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:58,382:INFO:Creating metrics dataframe
2023-04-25 08:34:58,390:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 08:34:58,390:INFO:Total runtime is 0.17649137179056804 minutes
2023-04-25 08:34:58,394:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:58,395:INFO:Initializing create_model()
2023-04-25 08:34:58,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:58,395:INFO:Checking exceptions
2023-04-25 08:34:58,395:INFO:Importing libraries
2023-04-25 08:34:58,395:INFO:Copying training dataset
2023-04-25 08:34:58,399:INFO:Defining folds
2023-04-25 08:34:58,399:INFO:Declaring metric variables
2023-04-25 08:34:58,405:INFO:Importing untrained model
2023-04-25 08:34:58,408:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 08:34:58,414:INFO:Starting cross validation
2023-04-25 08:34:58,415:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:58,455:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:58,465:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:58,469:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:58,480:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:58,484:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:34:58,989:INFO:Calculating mean and std
2023-04-25 08:34:58,992:INFO:Creating metrics dataframe
2023-04-25 08:34:59,162:INFO:Uploading results into container
2023-04-25 08:34:59,163:INFO:Uploading model into container now
2023-04-25 08:34:59,163:INFO:_master_model_container: 7
2023-04-25 08:34:59,163:INFO:_display_container: 2
2023-04-25 08:34:59,164:INFO:OrthogonalMatchingPursuit()
2023-04-25 08:34:59,164:INFO:create_model() successfully completed......................................
2023-04-25 08:34:59,307:INFO:SubProcess create_model() end ==================================
2023-04-25 08:34:59,308:INFO:Creating metrics dataframe
2023-04-25 08:34:59,314:INFO:Initializing Bayesian Ridge
2023-04-25 08:34:59,314:INFO:Total runtime is 0.1918872356414795 minutes
2023-04-25 08:34:59,318:INFO:SubProcess create_model() called ==================================
2023-04-25 08:34:59,318:INFO:Initializing create_model()
2023-04-25 08:34:59,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:34:59,318:INFO:Checking exceptions
2023-04-25 08:34:59,318:INFO:Importing libraries
2023-04-25 08:34:59,318:INFO:Copying training dataset
2023-04-25 08:34:59,323:INFO:Defining folds
2023-04-25 08:34:59,323:INFO:Declaring metric variables
2023-04-25 08:34:59,328:INFO:Importing untrained model
2023-04-25 08:34:59,330:INFO:Bayesian Ridge Imported successfully
2023-04-25 08:34:59,336:INFO:Starting cross validation
2023-04-25 08:34:59,337:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:34:59,907:INFO:Calculating mean and std
2023-04-25 08:34:59,909:INFO:Creating metrics dataframe
2023-04-25 08:35:00,081:INFO:Uploading results into container
2023-04-25 08:35:00,082:INFO:Uploading model into container now
2023-04-25 08:35:00,082:INFO:_master_model_container: 8
2023-04-25 08:35:00,082:INFO:_display_container: 2
2023-04-25 08:35:00,083:INFO:BayesianRidge()
2023-04-25 08:35:00,083:INFO:create_model() successfully completed......................................
2023-04-25 08:35:00,202:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:00,203:INFO:Creating metrics dataframe
2023-04-25 08:35:00,210:INFO:Initializing Passive Aggressive Regressor
2023-04-25 08:35:00,211:INFO:Total runtime is 0.20682897965113323 minutes
2023-04-25 08:35:00,213:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:00,214:INFO:Initializing create_model()
2023-04-25 08:35:00,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:00,214:INFO:Checking exceptions
2023-04-25 08:35:00,214:INFO:Importing libraries
2023-04-25 08:35:00,214:INFO:Copying training dataset
2023-04-25 08:35:00,218:INFO:Defining folds
2023-04-25 08:35:00,218:INFO:Declaring metric variables
2023-04-25 08:35:00,221:INFO:Importing untrained model
2023-04-25 08:35:00,225:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 08:35:00,233:INFO:Starting cross validation
2023-04-25 08:35:00,234:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:00,806:INFO:Calculating mean and std
2023-04-25 08:35:00,807:INFO:Creating metrics dataframe
2023-04-25 08:35:00,961:INFO:Uploading results into container
2023-04-25 08:35:00,961:INFO:Uploading model into container now
2023-04-25 08:35:00,961:INFO:_master_model_container: 9
2023-04-25 08:35:00,961:INFO:_display_container: 2
2023-04-25 08:35:00,962:INFO:PassiveAggressiveRegressor(random_state=1754)
2023-04-25 08:35:00,962:INFO:create_model() successfully completed......................................
2023-04-25 08:35:01,093:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:01,093:INFO:Creating metrics dataframe
2023-04-25 08:35:01,103:INFO:Initializing Huber Regressor
2023-04-25 08:35:01,103:INFO:Total runtime is 0.22169586022694907 minutes
2023-04-25 08:35:01,106:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:01,106:INFO:Initializing create_model()
2023-04-25 08:35:01,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:01,106:INFO:Checking exceptions
2023-04-25 08:35:01,106:INFO:Importing libraries
2023-04-25 08:35:01,106:INFO:Copying training dataset
2023-04-25 08:35:01,125:INFO:Defining folds
2023-04-25 08:35:01,125:INFO:Declaring metric variables
2023-04-25 08:35:01,130:INFO:Importing untrained model
2023-04-25 08:35:01,136:INFO:Huber Regressor Imported successfully
2023-04-25 08:35:01,143:INFO:Starting cross validation
2023-04-25 08:35:01,145:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:01,708:INFO:Calculating mean and std
2023-04-25 08:35:01,709:INFO:Creating metrics dataframe
2023-04-25 08:35:01,875:INFO:Uploading results into container
2023-04-25 08:35:01,876:INFO:Uploading model into container now
2023-04-25 08:35:01,876:INFO:_master_model_container: 10
2023-04-25 08:35:01,876:INFO:_display_container: 2
2023-04-25 08:35:01,877:INFO:HuberRegressor()
2023-04-25 08:35:01,877:INFO:create_model() successfully completed......................................
2023-04-25 08:35:02,009:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:02,009:INFO:Creating metrics dataframe
2023-04-25 08:35:02,017:INFO:Initializing K Neighbors Regressor
2023-04-25 08:35:02,017:INFO:Total runtime is 0.23693358500798545 minutes
2023-04-25 08:35:02,021:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:02,021:INFO:Initializing create_model()
2023-04-25 08:35:02,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:02,022:INFO:Checking exceptions
2023-04-25 08:35:02,022:INFO:Importing libraries
2023-04-25 08:35:02,022:INFO:Copying training dataset
2023-04-25 08:35:02,025:INFO:Defining folds
2023-04-25 08:35:02,025:INFO:Declaring metric variables
2023-04-25 08:35:02,028:INFO:Importing untrained model
2023-04-25 08:35:02,031:INFO:K Neighbors Regressor Imported successfully
2023-04-25 08:35:02,038:INFO:Starting cross validation
2023-04-25 08:35:02,039:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:02,593:INFO:Calculating mean and std
2023-04-25 08:35:02,594:INFO:Creating metrics dataframe
2023-04-25 08:35:02,749:INFO:Uploading results into container
2023-04-25 08:35:02,749:INFO:Uploading model into container now
2023-04-25 08:35:02,750:INFO:_master_model_container: 11
2023-04-25 08:35:02,750:INFO:_display_container: 2
2023-04-25 08:35:02,750:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 08:35:02,750:INFO:create_model() successfully completed......................................
2023-04-25 08:35:02,870:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:02,871:INFO:Creating metrics dataframe
2023-04-25 08:35:02,878:INFO:Initializing Decision Tree Regressor
2023-04-25 08:35:02,878:INFO:Total runtime is 0.25129197438557943 minutes
2023-04-25 08:35:02,881:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:02,882:INFO:Initializing create_model()
2023-04-25 08:35:02,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:02,882:INFO:Checking exceptions
2023-04-25 08:35:02,882:INFO:Importing libraries
2023-04-25 08:35:02,882:INFO:Copying training dataset
2023-04-25 08:35:02,886:INFO:Defining folds
2023-04-25 08:35:02,886:INFO:Declaring metric variables
2023-04-25 08:35:02,889:INFO:Importing untrained model
2023-04-25 08:35:02,893:INFO:Decision Tree Regressor Imported successfully
2023-04-25 08:35:02,901:INFO:Starting cross validation
2023-04-25 08:35:02,901:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:03,484:INFO:Calculating mean and std
2023-04-25 08:35:03,485:INFO:Creating metrics dataframe
2023-04-25 08:35:03,638:INFO:Uploading results into container
2023-04-25 08:35:03,639:INFO:Uploading model into container now
2023-04-25 08:35:03,639:INFO:_master_model_container: 12
2023-04-25 08:35:03,639:INFO:_display_container: 2
2023-04-25 08:35:03,639:INFO:DecisionTreeRegressor(random_state=1754)
2023-04-25 08:35:03,640:INFO:create_model() successfully completed......................................
2023-04-25 08:35:03,766:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:03,767:INFO:Creating metrics dataframe
2023-04-25 08:35:03,776:INFO:Initializing Random Forest Regressor
2023-04-25 08:35:03,776:INFO:Total runtime is 0.266250209013621 minutes
2023-04-25 08:35:03,779:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:03,779:INFO:Initializing create_model()
2023-04-25 08:35:03,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:03,779:INFO:Checking exceptions
2023-04-25 08:35:03,779:INFO:Importing libraries
2023-04-25 08:35:03,779:INFO:Copying training dataset
2023-04-25 08:35:03,784:INFO:Defining folds
2023-04-25 08:35:03,784:INFO:Declaring metric variables
2023-04-25 08:35:03,787:INFO:Importing untrained model
2023-04-25 08:35:03,790:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:35:03,796:INFO:Starting cross validation
2023-04-25 08:35:03,797:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:04,648:INFO:Calculating mean and std
2023-04-25 08:35:04,649:INFO:Creating metrics dataframe
2023-04-25 08:35:04,819:INFO:Uploading results into container
2023-04-25 08:35:04,820:INFO:Uploading model into container now
2023-04-25 08:35:04,820:INFO:_master_model_container: 13
2023-04-25 08:35:04,821:INFO:_display_container: 2
2023-04-25 08:35:04,821:INFO:RandomForestRegressor(n_jobs=-1, random_state=1754)
2023-04-25 08:35:04,821:INFO:create_model() successfully completed......................................
2023-04-25 08:35:04,955:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:04,956:INFO:Creating metrics dataframe
2023-04-25 08:35:04,965:INFO:Initializing Extra Trees Regressor
2023-04-25 08:35:04,965:INFO:Total runtime is 0.28607205549875897 minutes
2023-04-25 08:35:04,969:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:04,969:INFO:Initializing create_model()
2023-04-25 08:35:04,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:04,969:INFO:Checking exceptions
2023-04-25 08:35:04,969:INFO:Importing libraries
2023-04-25 08:35:04,969:INFO:Copying training dataset
2023-04-25 08:35:04,973:INFO:Defining folds
2023-04-25 08:35:04,973:INFO:Declaring metric variables
2023-04-25 08:35:04,976:INFO:Importing untrained model
2023-04-25 08:35:04,979:INFO:Extra Trees Regressor Imported successfully
2023-04-25 08:35:04,989:INFO:Starting cross validation
2023-04-25 08:35:04,990:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:05,878:INFO:Calculating mean and std
2023-04-25 08:35:05,879:INFO:Creating metrics dataframe
2023-04-25 08:35:06,039:INFO:Uploading results into container
2023-04-25 08:35:06,040:INFO:Uploading model into container now
2023-04-25 08:35:06,040:INFO:_master_model_container: 14
2023-04-25 08:35:06,040:INFO:_display_container: 2
2023-04-25 08:35:06,041:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1754)
2023-04-25 08:35:06,041:INFO:create_model() successfully completed......................................
2023-04-25 08:35:06,171:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:06,171:INFO:Creating metrics dataframe
2023-04-25 08:35:06,179:INFO:Initializing AdaBoost Regressor
2023-04-25 08:35:06,179:INFO:Total runtime is 0.3063083370526632 minutes
2023-04-25 08:35:06,182:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:06,183:INFO:Initializing create_model()
2023-04-25 08:35:06,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:06,183:INFO:Checking exceptions
2023-04-25 08:35:06,183:INFO:Importing libraries
2023-04-25 08:35:06,183:INFO:Copying training dataset
2023-04-25 08:35:06,187:INFO:Defining folds
2023-04-25 08:35:06,187:INFO:Declaring metric variables
2023-04-25 08:35:06,190:INFO:Importing untrained model
2023-04-25 08:35:06,193:INFO:AdaBoost Regressor Imported successfully
2023-04-25 08:35:06,199:INFO:Starting cross validation
2023-04-25 08:35:06,200:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:06,809:INFO:Calculating mean and std
2023-04-25 08:35:06,810:INFO:Creating metrics dataframe
2023-04-25 08:35:06,974:INFO:Uploading results into container
2023-04-25 08:35:06,975:INFO:Uploading model into container now
2023-04-25 08:35:06,975:INFO:_master_model_container: 15
2023-04-25 08:35:06,975:INFO:_display_container: 2
2023-04-25 08:35:06,975:INFO:AdaBoostRegressor(random_state=1754)
2023-04-25 08:35:06,975:INFO:create_model() successfully completed......................................
2023-04-25 08:35:07,093:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:07,093:INFO:Creating metrics dataframe
2023-04-25 08:35:07,105:INFO:Initializing Gradient Boosting Regressor
2023-04-25 08:35:07,105:INFO:Total runtime is 0.3217361450195313 minutes
2023-04-25 08:35:07,108:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:07,108:INFO:Initializing create_model()
2023-04-25 08:35:07,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:07,108:INFO:Checking exceptions
2023-04-25 08:35:07,108:INFO:Importing libraries
2023-04-25 08:35:07,109:INFO:Copying training dataset
2023-04-25 08:35:07,112:INFO:Defining folds
2023-04-25 08:35:07,113:INFO:Declaring metric variables
2023-04-25 08:35:07,116:INFO:Importing untrained model
2023-04-25 08:35:07,119:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:35:07,125:INFO:Starting cross validation
2023-04-25 08:35:07,126:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:07,796:INFO:Calculating mean and std
2023-04-25 08:35:07,798:INFO:Creating metrics dataframe
2023-04-25 08:35:07,975:INFO:Uploading results into container
2023-04-25 08:35:07,976:INFO:Uploading model into container now
2023-04-25 08:35:07,976:INFO:_master_model_container: 16
2023-04-25 08:35:07,976:INFO:_display_container: 2
2023-04-25 08:35:07,976:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:35:07,976:INFO:create_model() successfully completed......................................
2023-04-25 08:35:08,098:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:08,098:INFO:Creating metrics dataframe
2023-04-25 08:35:08,108:INFO:Initializing Extreme Gradient Boosting
2023-04-25 08:35:08,108:INFO:Total runtime is 0.33845137755076093 minutes
2023-04-25 08:35:08,111:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:08,111:INFO:Initializing create_model()
2023-04-25 08:35:08,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:08,111:INFO:Checking exceptions
2023-04-25 08:35:08,112:INFO:Importing libraries
2023-04-25 08:35:08,112:INFO:Copying training dataset
2023-04-25 08:35:08,116:INFO:Defining folds
2023-04-25 08:35:08,116:INFO:Declaring metric variables
2023-04-25 08:35:08,118:INFO:Importing untrained model
2023-04-25 08:35:08,122:INFO:Extreme Gradient Boosting Imported successfully
2023-04-25 08:35:08,128:INFO:Starting cross validation
2023-04-25 08:35:08,129:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:10,028:INFO:Calculating mean and std
2023-04-25 08:35:10,030:INFO:Creating metrics dataframe
2023-04-25 08:35:10,185:INFO:Uploading results into container
2023-04-25 08:35:10,186:INFO:Uploading model into container now
2023-04-25 08:35:10,186:INFO:_master_model_container: 17
2023-04-25 08:35:10,186:INFO:_display_container: 2
2023-04-25 08:35:10,187:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1754, ...)
2023-04-25 08:35:10,187:INFO:create_model() successfully completed......................................
2023-04-25 08:35:10,306:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:10,306:INFO:Creating metrics dataframe
2023-04-25 08:35:10,316:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 08:35:10,316:INFO:Total runtime is 0.37524980306625366 minutes
2023-04-25 08:35:10,319:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:10,320:INFO:Initializing create_model()
2023-04-25 08:35:10,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:10,320:INFO:Checking exceptions
2023-04-25 08:35:10,320:INFO:Importing libraries
2023-04-25 08:35:10,320:INFO:Copying training dataset
2023-04-25 08:35:10,324:INFO:Defining folds
2023-04-25 08:35:10,324:INFO:Declaring metric variables
2023-04-25 08:35:10,327:INFO:Importing untrained model
2023-04-25 08:35:10,332:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:35:10,341:INFO:Starting cross validation
2023-04-25 08:35:10,342:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:10,995:INFO:Calculating mean and std
2023-04-25 08:35:10,996:INFO:Creating metrics dataframe
2023-04-25 08:35:11,151:INFO:Uploading results into container
2023-04-25 08:35:11,152:INFO:Uploading model into container now
2023-04-25 08:35:11,152:INFO:_master_model_container: 18
2023-04-25 08:35:11,153:INFO:_display_container: 2
2023-04-25 08:35:11,153:INFO:LGBMRegressor(random_state=1754)
2023-04-25 08:35:11,153:INFO:create_model() successfully completed......................................
2023-04-25 08:35:11,271:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:11,271:INFO:Creating metrics dataframe
2023-04-25 08:35:11,282:INFO:Initializing Dummy Regressor
2023-04-25 08:35:11,282:INFO:Total runtime is 0.3913469394048055 minutes
2023-04-25 08:35:11,285:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:11,285:INFO:Initializing create_model()
2023-04-25 08:35:11,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4F2140>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:11,285:INFO:Checking exceptions
2023-04-25 08:35:11,285:INFO:Importing libraries
2023-04-25 08:35:11,285:INFO:Copying training dataset
2023-04-25 08:35:11,290:INFO:Defining folds
2023-04-25 08:35:11,290:INFO:Declaring metric variables
2023-04-25 08:35:11,293:INFO:Importing untrained model
2023-04-25 08:35:11,296:INFO:Dummy Regressor Imported successfully
2023-04-25 08:35:11,301:INFO:Starting cross validation
2023-04-25 08:35:11,302:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:11,853:INFO:Calculating mean and std
2023-04-25 08:35:11,854:INFO:Creating metrics dataframe
2023-04-25 08:35:12,004:INFO:Uploading results into container
2023-04-25 08:35:12,004:INFO:Uploading model into container now
2023-04-25 08:35:12,005:INFO:_master_model_container: 19
2023-04-25 08:35:12,005:INFO:_display_container: 2
2023-04-25 08:35:12,005:INFO:DummyRegressor()
2023-04-25 08:35:12,005:INFO:create_model() successfully completed......................................
2023-04-25 08:35:12,128:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:12,129:INFO:Creating metrics dataframe
2023-04-25 08:35:12,146:INFO:Initializing create_model()
2023-04-25 08:35:12,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:12,146:INFO:Checking exceptions
2023-04-25 08:35:12,148:INFO:Importing libraries
2023-04-25 08:35:12,148:INFO:Copying training dataset
2023-04-25 08:35:12,151:INFO:Defining folds
2023-04-25 08:35:12,151:INFO:Declaring metric variables
2023-04-25 08:35:12,151:INFO:Importing untrained model
2023-04-25 08:35:12,151:INFO:Declaring custom model
2023-04-25 08:35:12,152:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:35:12,152:INFO:Cross validation set to False
2023-04-25 08:35:12,153:INFO:Fitting Model
2023-04-25 08:35:12,333:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:35:12,334:INFO:create_model() successfully completed......................................
2023-04-25 08:35:12,465:INFO:Creating Dashboard logs
2023-04-25 08:35:12,468:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:35:12,512:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1754, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:12,591:INFO:Initializing predict_model()
2023-04-25 08:35:12,591:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4F1C0>)
2023-04-25 08:35:12,591:INFO:Checking exceptions
2023-04-25 08:35:12,591:INFO:Preloading libraries
2023-04-25 08:35:13,030:INFO:Creating Dashboard logs
2023-04-25 08:35:13,033:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:35:13,076:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1754, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:35:13,416:INFO:Creating Dashboard logs
2023-04-25 08:35:13,418:INFO:Model: Random Forest Regressor
2023-04-25 08:35:13,458:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:13,796:INFO:Creating Dashboard logs
2023-04-25 08:35:13,798:INFO:Model: Extra Trees Regressor
2023-04-25 08:35:13,841:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:14,181:INFO:Creating Dashboard logs
2023-04-25 08:35:14,184:INFO:Model: Extreme Gradient Boosting
2023-04-25 08:35:14,234:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 1754, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-25 08:35:14,593:INFO:Creating Dashboard logs
2023-04-25 08:35:14,596:INFO:Model: AdaBoost Regressor
2023-04-25 08:35:14,643:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1754}
2023-04-25 08:35:14,967:INFO:Creating Dashboard logs
2023-04-25 08:35:14,970:INFO:Model: K Neighbors Regressor
2023-04-25 08:35:15,011:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-25 08:35:15,347:INFO:Creating Dashboard logs
2023-04-25 08:35:15,350:INFO:Model: Lasso Least Angle Regression
2023-04-25 08:35:15,394:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 1754, 'verbose': False}
2023-04-25 08:35:15,733:INFO:Creating Dashboard logs
2023-04-25 08:35:15,736:INFO:Model: Bayesian Ridge
2023-04-25 08:35:15,777:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-25 08:35:16,105:INFO:Creating Dashboard logs
2023-04-25 08:35:16,108:INFO:Model: Ridge Regression
2023-04-25 08:35:16,151:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 1754, 'solver': 'auto', 'tol': 0.001}
2023-04-25 08:35:16,476:INFO:Creating Dashboard logs
2023-04-25 08:35:16,478:INFO:Model: Least Angle Regression
2023-04-25 08:35:16,523:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 1754, 'verbose': False}
2023-04-25 08:35:16,844:INFO:Creating Dashboard logs
2023-04-25 08:35:16,846:INFO:Model: Linear Regression
2023-04-25 08:35:16,892:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-25 08:35:17,210:INFO:Creating Dashboard logs
2023-04-25 08:35:17,213:INFO:Model: Lasso Regression
2023-04-25 08:35:17,256:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 1754, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:35:17,580:INFO:Creating Dashboard logs
2023-04-25 08:35:17,583:INFO:Model: Decision Tree Regressor
2023-04-25 08:35:17,627:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1754, 'splitter': 'best'}
2023-04-25 08:35:17,950:INFO:Creating Dashboard logs
2023-04-25 08:35:17,953:INFO:Model: Elastic Net
2023-04-25 08:35:18,001:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 1754, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:35:18,371:INFO:Creating Dashboard logs
2023-04-25 08:35:18,374:INFO:Model: Huber Regressor
2023-04-25 08:35:18,417:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-25 08:35:18,740:INFO:Creating Dashboard logs
2023-04-25 08:35:18,743:INFO:Model: Passive Aggressive Regressor
2023-04-25 08:35:18,794:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 1754, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:19,148:INFO:Creating Dashboard logs
2023-04-25 08:35:19,152:INFO:Model: Orthogonal Matching Pursuit
2023-04-25 08:35:19,204:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-25 08:35:19,563:INFO:Creating Dashboard logs
2023-04-25 08:35:19,565:INFO:Model: Dummy Regressor
2023-04-25 08:35:19,612:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-25 08:35:19,995:INFO:_master_model_container: 19
2023-04-25 08:35:19,995:INFO:_display_container: 2
2023-04-25 08:35:19,995:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:35:19,995:INFO:compare_models() successfully completed......................................
2023-04-25 08:35:20,022:INFO:Initializing create_model()
2023-04-25 08:35:20,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:20,023:INFO:Checking exceptions
2023-04-25 08:35:20,050:INFO:Importing libraries
2023-04-25 08:35:20,051:INFO:Copying training dataset
2023-04-25 08:35:20,054:INFO:Defining folds
2023-04-25 08:35:20,054:INFO:Declaring metric variables
2023-04-25 08:35:20,057:INFO:Importing untrained model
2023-04-25 08:35:20,061:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:35:20,069:INFO:Starting cross validation
2023-04-25 08:35:20,070:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:20,737:INFO:Calculating mean and std
2023-04-25 08:35:20,737:INFO:Creating metrics dataframe
2023-04-25 08:35:20,741:INFO:Finalizing model
2023-04-25 08:35:20,953:INFO:Creating Dashboard logs
2023-04-25 08:35:20,956:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:35:20,996:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1754, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:21,073:INFO:Initializing predict_model()
2023-04-25 08:35:21,073:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4EE60>)
2023-04-25 08:35:21,073:INFO:Checking exceptions
2023-04-25 08:35:21,073:INFO:Preloading libraries
2023-04-25 08:35:21,480:INFO:Uploading results into container
2023-04-25 08:35:21,481:INFO:Uploading model into container now
2023-04-25 08:35:21,489:INFO:_master_model_container: 20
2023-04-25 08:35:21,489:INFO:_display_container: 3
2023-04-25 08:35:21,489:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:35:21,489:INFO:create_model() successfully completed......................................
2023-04-25 08:35:21,641:INFO:Initializing create_model()
2023-04-25 08:35:21,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:21,641:INFO:Checking exceptions
2023-04-25 08:35:21,665:INFO:Importing libraries
2023-04-25 08:35:21,665:INFO:Copying training dataset
2023-04-25 08:35:21,671:INFO:Defining folds
2023-04-25 08:35:21,671:INFO:Declaring metric variables
2023-04-25 08:35:21,675:INFO:Importing untrained model
2023-04-25 08:35:21,678:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:35:21,687:INFO:Starting cross validation
2023-04-25 08:35:21,688:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:22,288:INFO:Calculating mean and std
2023-04-25 08:35:22,288:INFO:Creating metrics dataframe
2023-04-25 08:35:22,292:INFO:Finalizing model
2023-04-25 08:35:22,531:INFO:Creating Dashboard logs
2023-04-25 08:35:22,533:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:35:22,577:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1754, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:35:22,654:INFO:Initializing predict_model()
2023-04-25 08:35:22,655:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4CEE0>)
2023-04-25 08:35:22,655:INFO:Checking exceptions
2023-04-25 08:35:22,655:INFO:Preloading libraries
2023-04-25 08:35:23,114:INFO:Uploading results into container
2023-04-25 08:35:23,115:INFO:Uploading model into container now
2023-04-25 08:35:23,123:INFO:_master_model_container: 21
2023-04-25 08:35:23,123:INFO:_display_container: 4
2023-04-25 08:35:23,123:INFO:LGBMRegressor(random_state=1754)
2023-04-25 08:35:23,124:INFO:create_model() successfully completed......................................
2023-04-25 08:35:23,282:INFO:Initializing create_model()
2023-04-25 08:35:23,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:23,282:INFO:Checking exceptions
2023-04-25 08:35:23,304:INFO:Importing libraries
2023-04-25 08:35:23,304:INFO:Copying training dataset
2023-04-25 08:35:23,310:INFO:Defining folds
2023-04-25 08:35:23,310:INFO:Declaring metric variables
2023-04-25 08:35:23,314:INFO:Importing untrained model
2023-04-25 08:35:23,317:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:35:23,326:INFO:Starting cross validation
2023-04-25 08:35:23,326:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:23,965:INFO:Calculating mean and std
2023-04-25 08:35:23,965:INFO:Creating metrics dataframe
2023-04-25 08:35:23,969:INFO:Finalizing model
2023-04-25 08:35:24,257:INFO:Creating Dashboard logs
2023-04-25 08:35:24,259:INFO:Model: Random Forest Regressor
2023-04-25 08:35:24,303:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:24,370:INFO:Initializing predict_model()
2023-04-25 08:35:24,370:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4E680>)
2023-04-25 08:35:24,370:INFO:Checking exceptions
2023-04-25 08:35:24,370:INFO:Preloading libraries
2023-04-25 08:35:24,815:INFO:Uploading results into container
2023-04-25 08:35:24,816:INFO:Uploading model into container now
2023-04-25 08:35:24,823:INFO:_master_model_container: 22
2023-04-25 08:35:24,823:INFO:_display_container: 5
2023-04-25 08:35:24,824:INFO:RandomForestRegressor(n_jobs=-1, random_state=1754)
2023-04-25 08:35:24,824:INFO:create_model() successfully completed......................................
2023-04-25 08:35:24,972:INFO:Initializing tune_model()
2023-04-25 08:35:24,972:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=1754), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>)
2023-04-25 08:35:24,972:INFO:Checking exceptions
2023-04-25 08:35:24,998:INFO:Copying training dataset
2023-04-25 08:35:25,001:INFO:Checking base model
2023-04-25 08:35:25,001:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:35:25,003:INFO:Declaring metric variables
2023-04-25 08:35:25,006:INFO:Defining Hyperparameters
2023-04-25 08:35:25,136:INFO:Tuning with n_jobs=-1
2023-04-25 08:35:25,136:INFO:Initializing RandomizedSearchCV
2023-04-25 08:35:32,355:INFO:best_params: {'actual_estimator__subsample': 0.25, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.15}
2023-04-25 08:35:32,356:INFO:Hyperparameter search completed
2023-04-25 08:35:32,357:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:32,357:INFO:Initializing create_model()
2023-04-25 08:35:32,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A4D9630>, model_only=True, return_train_score=False, kwargs={'subsample': 0.25, 'n_estimators': 170, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 'log2', 'max_depth': 3, 'learning_rate': 0.15})
2023-04-25 08:35:32,357:INFO:Checking exceptions
2023-04-25 08:35:32,357:INFO:Importing libraries
2023-04-25 08:35:32,357:INFO:Copying training dataset
2023-04-25 08:35:32,361:INFO:Defining folds
2023-04-25 08:35:32,361:INFO:Declaring metric variables
2023-04-25 08:35:32,364:INFO:Importing untrained model
2023-04-25 08:35:32,364:INFO:Declaring custom model
2023-04-25 08:35:32,367:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:35:32,372:INFO:Starting cross validation
2023-04-25 08:35:32,372:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:33,071:INFO:Calculating mean and std
2023-04-25 08:35:33,072:INFO:Creating metrics dataframe
2023-04-25 08:35:33,077:INFO:Finalizing model
2023-04-25 08:35:33,341:INFO:Uploading results into container
2023-04-25 08:35:33,341:INFO:Uploading model into container now
2023-04-25 08:35:33,341:INFO:_master_model_container: 23
2023-04-25 08:35:33,342:INFO:_display_container: 6
2023-04-25 08:35:33,342:INFO:GradientBoostingRegressor(learning_rate=0.15, max_features='log2',
                          min_impurity_decrease=0.1, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=170,
                          random_state=1754, subsample=0.25)
2023-04-25 08:35:33,342:INFO:create_model() successfully completed......................................
2023-04-25 08:35:33,486:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:33,486:INFO:choose_better activated
2023-04-25 08:35:33,488:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:33,489:INFO:Initializing create_model()
2023-04-25 08:35:33,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:33,489:INFO:Checking exceptions
2023-04-25 08:35:33,490:INFO:Importing libraries
2023-04-25 08:35:33,491:INFO:Copying training dataset
2023-04-25 08:35:33,493:INFO:Defining folds
2023-04-25 08:35:33,493:INFO:Declaring metric variables
2023-04-25 08:35:33,493:INFO:Importing untrained model
2023-04-25 08:35:33,493:INFO:Declaring custom model
2023-04-25 08:35:33,494:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:35:33,494:INFO:Starting cross validation
2023-04-25 08:35:33,495:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:34,173:INFO:Calculating mean and std
2023-04-25 08:35:34,173:INFO:Creating metrics dataframe
2023-04-25 08:35:34,174:INFO:Finalizing model
2023-04-25 08:35:34,390:INFO:Uploading results into container
2023-04-25 08:35:34,391:INFO:Uploading model into container now
2023-04-25 08:35:34,391:INFO:_master_model_container: 24
2023-04-25 08:35:34,391:INFO:_display_container: 7
2023-04-25 08:35:34,391:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:35:34,391:INFO:create_model() successfully completed......................................
2023-04-25 08:35:34,509:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:34,509:INFO:GradientBoostingRegressor(random_state=1754) result for RMSE is 4759.1953
2023-04-25 08:35:34,510:INFO:GradientBoostingRegressor(learning_rate=0.15, max_features='log2',
                          min_impurity_decrease=0.1, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=170,
                          random_state=1754, subsample=0.25) result for RMSE is 4948.8446
2023-04-25 08:35:34,510:INFO:GradientBoostingRegressor(random_state=1754) is best model
2023-04-25 08:35:34,510:INFO:choose_better completed
2023-04-25 08:35:34,510:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:35:34,510:INFO:Creating Dashboard logs
2023-04-25 08:35:34,513:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:35:34,562:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1754, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:35:34,645:INFO:Initializing predict_model()
2023-04-25 08:35:34,646:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4CE50>)
2023-04-25 08:35:34,646:INFO:Checking exceptions
2023-04-25 08:35:34,646:INFO:Preloading libraries
2023-04-25 08:35:35,127:INFO:_master_model_container: 24
2023-04-25 08:35:35,127:INFO:_display_container: 6
2023-04-25 08:35:35,128:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:35:35,128:INFO:tune_model() successfully completed......................................
2023-04-25 08:35:35,418:INFO:Initializing tune_model()
2023-04-25 08:35:35,419:INFO:tune_model(estimator=LGBMRegressor(random_state=1754), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>)
2023-04-25 08:35:35,419:INFO:Checking exceptions
2023-04-25 08:35:35,445:INFO:Copying training dataset
2023-04-25 08:35:35,449:INFO:Checking base model
2023-04-25 08:35:35,449:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:35:35,452:INFO:Declaring metric variables
2023-04-25 08:35:35,455:INFO:Defining Hyperparameters
2023-04-25 08:35:35,585:INFO:Tuning with n_jobs=-1
2023-04-25 08:35:35,585:INFO:Initializing RandomizedSearchCV
2023-04-25 08:35:42,601:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.7}
2023-04-25 08:35:42,602:INFO:Hyperparameter search completed
2023-04-25 08:35:42,602:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:42,602:INFO:Initializing create_model()
2023-04-25 08:35:42,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AE2F5E0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 4, 'reg_alpha': 0.3, 'num_leaves': 256, 'n_estimators': 210, 'min_split_gain': 0.5, 'min_child_samples': 36, 'learning_rate': 0.05, 'feature_fraction': 0.7, 'bagging_freq': 1, 'bagging_fraction': 0.7})
2023-04-25 08:35:42,602:INFO:Checking exceptions
2023-04-25 08:35:42,602:INFO:Importing libraries
2023-04-25 08:35:42,602:INFO:Copying training dataset
2023-04-25 08:35:42,605:INFO:Defining folds
2023-04-25 08:35:42,605:INFO:Declaring metric variables
2023-04-25 08:35:42,608:INFO:Importing untrained model
2023-04-25 08:35:42,608:INFO:Declaring custom model
2023-04-25 08:35:42,612:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:35:42,617:INFO:Starting cross validation
2023-04-25 08:35:42,618:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:43,261:INFO:Calculating mean and std
2023-04-25 08:35:43,262:INFO:Creating metrics dataframe
2023-04-25 08:35:43,268:INFO:Finalizing model
2023-04-25 08:35:43,293:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2023-04-25 08:35:43,293:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-04-25 08:35:43,293:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2023-04-25 08:35:43,526:INFO:Uploading results into container
2023-04-25 08:35:43,527:INFO:Uploading model into container now
2023-04-25 08:35:43,527:INFO:_master_model_container: 25
2023-04-25 08:35:43,527:INFO:_display_container: 7
2023-04-25 08:35:43,528:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4)
2023-04-25 08:35:43,528:INFO:create_model() successfully completed......................................
2023-04-25 08:35:43,660:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:43,660:INFO:choose_better activated
2023-04-25 08:35:43,662:INFO:SubProcess create_model() called ==================================
2023-04-25 08:35:43,663:INFO:Initializing create_model()
2023-04-25 08:35:43,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:35:43,663:INFO:Checking exceptions
2023-04-25 08:35:43,665:INFO:Importing libraries
2023-04-25 08:35:43,665:INFO:Copying training dataset
2023-04-25 08:35:43,667:INFO:Defining folds
2023-04-25 08:35:43,667:INFO:Declaring metric variables
2023-04-25 08:35:43,667:INFO:Importing untrained model
2023-04-25 08:35:43,667:INFO:Declaring custom model
2023-04-25 08:35:43,668:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:35:43,668:INFO:Starting cross validation
2023-04-25 08:35:43,668:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:35:44,290:INFO:Calculating mean and std
2023-04-25 08:35:44,290:INFO:Creating metrics dataframe
2023-04-25 08:35:44,291:INFO:Finalizing model
2023-04-25 08:35:44,534:INFO:Uploading results into container
2023-04-25 08:35:44,535:INFO:Uploading model into container now
2023-04-25 08:35:44,535:INFO:_master_model_container: 26
2023-04-25 08:35:44,535:INFO:_display_container: 8
2023-04-25 08:35:44,536:INFO:LGBMRegressor(random_state=1754)
2023-04-25 08:35:44,536:INFO:create_model() successfully completed......................................
2023-04-25 08:35:44,663:INFO:SubProcess create_model() end ==================================
2023-04-25 08:35:44,663:INFO:LGBMRegressor(random_state=1754) result for RMSE is 4873.8506
2023-04-25 08:35:44,664:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4) result for RMSE is 4702.8181
2023-04-25 08:35:44,664:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4) is best model
2023-04-25 08:35:44,664:INFO:choose_better completed
2023-04-25 08:35:44,664:INFO:Creating Dashboard logs
2023-04-25 08:35:44,667:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:35:44,711:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 36, 'min_child_weight': 0.001, 'min_split_gain': 0.5, 'n_estimators': 210, 'n_jobs': -1, 'num_leaves': 256, 'objective': None, 'random_state': 1754, 'reg_alpha': 0.3, 'reg_lambda': 4, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7, 'bagging_freq': 1, 'bagging_fraction': 0.7}
2023-04-25 08:35:44,790:INFO:Initializing predict_model()
2023-04-25 08:35:44,790:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4D2D0>)
2023-04-25 08:35:44,790:INFO:Checking exceptions
2023-04-25 08:35:44,790:INFO:Preloading libraries
2023-04-25 08:35:45,302:INFO:_master_model_container: 26
2023-04-25 08:35:45,302:INFO:_display_container: 7
2023-04-25 08:35:45,302:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4)
2023-04-25 08:35:45,302:INFO:tune_model() successfully completed......................................
2023-04-25 08:35:45,557:INFO:Initializing tune_model()
2023-04-25 08:35:45,557:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=1754), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>)
2023-04-25 08:35:45,557:INFO:Checking exceptions
2023-04-25 08:35:45,588:INFO:Copying training dataset
2023-04-25 08:35:45,590:INFO:Checking base model
2023-04-25 08:35:45,591:INFO:Base model : Random Forest Regressor
2023-04-25 08:35:45,594:INFO:Declaring metric variables
2023-04-25 08:35:45,598:INFO:Defining Hyperparameters
2023-04-25 08:35:45,723:INFO:Tuning with n_jobs=-1
2023-04-25 08:35:45,723:INFO:Initializing RandomizedSearchCV
2023-04-25 08:35:47,803:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:47,944:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:48,585:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:48,679:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:49,099:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:50,833:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:50,880:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:50,952:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:35:56,331:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:36:00,578:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-04-25 08:36:00,580:INFO:Hyperparameter search completed
2023-04-25 08:36:00,580:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:00,580:INFO:Initializing create_model()
2023-04-25 08:36:00,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A958D30>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'squared_error', 'bootstrap': True})
2023-04-25 08:36:00,580:INFO:Checking exceptions
2023-04-25 08:36:00,581:INFO:Importing libraries
2023-04-25 08:36:00,581:INFO:Copying training dataset
2023-04-25 08:36:00,584:INFO:Defining folds
2023-04-25 08:36:00,584:INFO:Declaring metric variables
2023-04-25 08:36:00,587:INFO:Importing untrained model
2023-04-25 08:36:00,587:INFO:Declaring custom model
2023-04-25 08:36:00,590:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:36:00,595:INFO:Starting cross validation
2023-04-25 08:36:00,596:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:01,284:INFO:Calculating mean and std
2023-04-25 08:36:01,285:INFO:Creating metrics dataframe
2023-04-25 08:36:01,290:INFO:Finalizing model
2023-04-25 08:36:01,560:INFO:Uploading results into container
2023-04-25 08:36:01,562:INFO:Uploading model into container now
2023-04-25 08:36:01,563:INFO:_master_model_container: 27
2023-04-25 08:36:01,563:INFO:_display_container: 8
2023-04-25 08:36:01,563:INFO:RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754)
2023-04-25 08:36:01,563:INFO:create_model() successfully completed......................................
2023-04-25 08:36:01,687:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:01,687:INFO:choose_better activated
2023-04-25 08:36:01,691:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:01,691:INFO:Initializing create_model()
2023-04-25 08:36:01,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:01,691:INFO:Checking exceptions
2023-04-25 08:36:01,695:INFO:Importing libraries
2023-04-25 08:36:01,696:INFO:Copying training dataset
2023-04-25 08:36:01,698:INFO:Defining folds
2023-04-25 08:36:01,698:INFO:Declaring metric variables
2023-04-25 08:36:01,698:INFO:Importing untrained model
2023-04-25 08:36:01,699:INFO:Declaring custom model
2023-04-25 08:36:01,699:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:36:01,699:INFO:Starting cross validation
2023-04-25 08:36:01,700:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:02,391:INFO:Calculating mean and std
2023-04-25 08:36:02,391:INFO:Creating metrics dataframe
2023-04-25 08:36:02,393:INFO:Finalizing model
2023-04-25 08:36:02,667:INFO:Uploading results into container
2023-04-25 08:36:02,668:INFO:Uploading model into container now
2023-04-25 08:36:02,668:INFO:_master_model_container: 28
2023-04-25 08:36:02,668:INFO:_display_container: 9
2023-04-25 08:36:02,668:INFO:RandomForestRegressor(n_jobs=-1, random_state=1754)
2023-04-25 08:36:02,668:INFO:create_model() successfully completed......................................
2023-04-25 08:36:02,786:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:02,787:INFO:RandomForestRegressor(n_jobs=-1, random_state=1754) result for RMSE is 4939.5524
2023-04-25 08:36:02,787:INFO:RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754) result for RMSE is 4686.7763
2023-04-25 08:36:02,787:INFO:RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754) is best model
2023-04-25 08:36:02,787:INFO:choose_better completed
2023-04-25 08:36:02,787:INFO:Creating Dashboard logs
2023-04-25 08:36:02,790:INFO:Model: Random Forest Regressor
2023-04-25 08:36:02,834:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0002, 'min_samples_leaf': 5, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:02,919:INFO:Initializing predict_model()
2023-04-25 08:36:02,919:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB4E3B0>)
2023-04-25 08:36:02,919:INFO:Checking exceptions
2023-04-25 08:36:02,920:INFO:Preloading libraries
2023-04-25 08:36:03,437:INFO:_master_model_container: 28
2023-04-25 08:36:03,437:INFO:_display_container: 8
2023-04-25 08:36:03,438:INFO:RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754)
2023-04-25 08:36:03,438:INFO:tune_model() successfully completed......................................
2023-04-25 08:36:03,723:INFO:Initializing plot_model()
2023-04-25 08:36:03,723:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1754), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, system=True)
2023-04-25 08:36:03,723:INFO:Checking exceptions
2023-04-25 08:36:03,728:INFO:Preloading libraries
2023-04-25 08:36:03,734:INFO:Copying training dataset
2023-04-25 08:36:03,734:INFO:Plot type: error
2023-04-25 08:36:03,788:INFO:Fitting Model
2023-04-25 08:36:03,788:INFO:Scoring test/hold-out set
2023-04-25 08:36:03,943:INFO:Visual Rendered Successfully
2023-04-25 08:36:04,077:INFO:plot_model() successfully completed......................................
2023-04-25 08:36:04,084:INFO:Initializing plot_model()
2023-04-25 08:36:04,085:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, system=True)
2023-04-25 08:36:04,085:INFO:Checking exceptions
2023-04-25 08:36:04,087:INFO:Preloading libraries
2023-04-25 08:36:04,094:INFO:Copying training dataset
2023-04-25 08:36:04,095:INFO:Plot type: error
2023-04-25 08:36:04,161:INFO:Fitting Model
2023-04-25 08:36:04,161:INFO:Scoring test/hold-out set
2023-04-25 08:36:04,338:INFO:Visual Rendered Successfully
2023-04-25 08:36:04,474:INFO:plot_model() successfully completed......................................
2023-04-25 08:36:04,482:INFO:Initializing plot_model()
2023-04-25 08:36:04,482:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, system=True)
2023-04-25 08:36:04,482:INFO:Checking exceptions
2023-04-25 08:36:04,496:INFO:Preloading libraries
2023-04-25 08:36:04,502:INFO:Copying training dataset
2023-04-25 08:36:04,502:INFO:Plot type: error
2023-04-25 08:36:04,557:INFO:Fitting Model
2023-04-25 08:36:04,558:INFO:Scoring test/hold-out set
2023-04-25 08:36:04,737:INFO:Visual Rendered Successfully
2023-04-25 08:36:04,863:INFO:plot_model() successfully completed......................................
2023-04-25 08:36:04,905:INFO:Initializing plot_model()
2023-04-25 08:36:04,905:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=1754), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, system=True)
2023-04-25 08:36:04,905:INFO:Checking exceptions
2023-04-25 08:36:04,908:INFO:Preloading libraries
2023-04-25 08:36:04,914:INFO:Copying training dataset
2023-04-25 08:36:04,914:INFO:Plot type: feature
2023-04-25 08:36:04,914:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:36:05,048:INFO:Visual Rendered Successfully
2023-04-25 08:36:05,172:INFO:plot_model() successfully completed......................................
2023-04-25 08:36:05,173:INFO:Initializing plot_model()
2023-04-25 08:36:05,173:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, system=True)
2023-04-25 08:36:05,173:INFO:Checking exceptions
2023-04-25 08:36:05,176:INFO:Preloading libraries
2023-04-25 08:36:05,184:INFO:Copying training dataset
2023-04-25 08:36:05,184:INFO:Plot type: feature
2023-04-25 08:36:05,184:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:36:05,328:INFO:Visual Rendered Successfully
2023-04-25 08:36:05,452:INFO:plot_model() successfully completed......................................
2023-04-25 08:36:05,453:INFO:Initializing plot_model()
2023-04-25 08:36:05,453:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, system=True)
2023-04-25 08:36:05,453:INFO:Checking exceptions
2023-04-25 08:36:05,466:INFO:Preloading libraries
2023-04-25 08:36:05,471:INFO:Copying training dataset
2023-04-25 08:36:05,471:INFO:Plot type: feature
2023-04-25 08:36:05,472:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:36:05,606:INFO:Visual Rendered Successfully
2023-04-25 08:36:05,726:INFO:plot_model() successfully completed......................................
2023-04-25 08:36:05,741:INFO:Initializing predict_model()
2023-04-25 08:36:05,742:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB02200>)
2023-04-25 08:36:05,742:INFO:Checking exceptions
2023-04-25 08:36:05,742:INFO:Preloading libraries
2023-04-25 08:36:05,911:INFO:Initializing predict_model()
2023-04-25 08:36:05,911:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D562DFDBD0>)
2023-04-25 08:36:05,912:INFO:Checking exceptions
2023-04-25 08:36:05,912:INFO:Preloading libraries
2023-04-25 08:36:06,114:INFO:Initializing predict_model()
2023-04-25 08:36:06,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561F2BA30>)
2023-04-25 08:36:06,115:INFO:Checking exceptions
2023-04-25 08:36:06,115:INFO:Preloading libraries
2023-04-25 08:36:06,302:INFO:Initializing finalize_model()
2023-04-25 08:36:06,302:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:36:06,303:INFO:Finalizing GradientBoostingRegressor(random_state=1754)
2023-04-25 08:36:06,306:INFO:Initializing create_model()
2023-04-25 08:36:06,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:36:06,306:INFO:Checking exceptions
2023-04-25 08:36:06,308:INFO:Importing libraries
2023-04-25 08:36:06,308:INFO:Copying training dataset
2023-04-25 08:36:06,308:INFO:Defining folds
2023-04-25 08:36:06,308:INFO:Declaring metric variables
2023-04-25 08:36:06,309:INFO:Importing untrained model
2023-04-25 08:36:06,310:INFO:Declaring custom model
2023-04-25 08:36:06,311:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:36:06,312:INFO:Cross validation set to False
2023-04-25 08:36:06,312:INFO:Fitting Model
2023-04-25 08:36:06,399:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1754))])
2023-04-25 08:36:06,399:INFO:create_model() successfully completed......................................
2023-04-25 08:36:06,516:INFO:Creating Dashboard logs
2023-04-25 08:36:06,517:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:36:06,554:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1754, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:06,885:INFO:_master_model_container: 28
2023-04-25 08:36:06,885:INFO:_display_container: 11
2023-04-25 08:36:06,889:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1754))])
2023-04-25 08:36:06,889:INFO:finalize_model() successfully completed......................................
2023-04-25 08:36:07,132:INFO:Initializing finalize_model()
2023-04-25 08:36:07,132:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:36:07,132:INFO:Finalizing LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4)
2023-04-25 08:36:07,134:INFO:Initializing create_model()
2023-04-25 08:36:07,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=1, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=36, min_split_gain=0.5,
              n_estimators=210, num_leaves=256, random_state=1754,
              reg_alpha=0.3, reg_lambda=4), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:36:07,134:INFO:Checking exceptions
2023-04-25 08:36:07,135:INFO:Importing libraries
2023-04-25 08:36:07,135:INFO:Copying training dataset
2023-04-25 08:36:07,135:INFO:Defining folds
2023-04-25 08:36:07,135:INFO:Declaring metric variables
2023-04-25 08:36:07,136:INFO:Importing untrained model
2023-04-25 08:36:07,136:INFO:Declaring custom model
2023-04-25 08:36:07,136:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:36:07,137:INFO:Cross validation set to False
2023-04-25 08:36:07,137:INFO:Fitting Model
2023-04-25 08:36:07,153:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2023-04-25 08:36:07,153:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-04-25 08:36:07,153:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2023-04-25 08:36:07,218:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=1,
                               feature_fraction=0.7, learning_rate=0.05,
                               min_child_samples=36, min_split_gain=0.5,
                               n_estimators=210, num_leaves=256,
                               random_state=1754, reg_alpha=0.3,
                               reg_lambda=4))])
2023-04-25 08:36:07,218:INFO:create_model() successfully completed......................................
2023-04-25 08:36:07,366:INFO:Creating Dashboard logs
2023-04-25 08:36:07,367:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:36:07,409:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 36, 'min_child_weight': 0.001, 'min_split_gain': 0.5, 'n_estimators': 210, 'n_jobs': -1, 'num_leaves': 256, 'objective': None, 'random_state': 1754, 'reg_alpha': 0.3, 'reg_lambda': 4, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7, 'bagging_freq': 1, 'bagging_fraction': 0.7}
2023-04-25 08:36:07,754:INFO:_master_model_container: 28
2023-04-25 08:36:07,754:INFO:_display_container: 11
2023-04-25 08:36:07,759:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=1,
                               feature_fraction=0.7, learning_rate=0.05,
                               min_child_samples=36, min_split_gain=0.5,
                               n_estimators=210, num_leaves=256,
                               random_state=1754, reg_alpha=0.3,
                               reg_lambda=4))])
2023-04-25 08:36:07,759:INFO:finalize_model() successfully completed......................................
2023-04-25 08:36:07,999:INFO:Initializing finalize_model()
2023-04-25 08:36:07,999:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:36:08,000:INFO:Finalizing RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754)
2023-04-25 08:36:08,002:INFO:Initializing create_model()
2023-04-25 08:36:08,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=RandomForestRegressor(max_depth=10, min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=5, n_jobs=-1,
                      random_state=1754), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:36:08,002:INFO:Checking exceptions
2023-04-25 08:36:08,003:INFO:Importing libraries
2023-04-25 08:36:08,003:INFO:Copying training dataset
2023-04-25 08:36:08,003:INFO:Defining folds
2023-04-25 08:36:08,003:INFO:Declaring metric variables
2023-04-25 08:36:08,003:INFO:Importing untrained model
2023-04-25 08:36:08,003:INFO:Declaring custom model
2023-04-25 08:36:08,004:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:36:08,004:INFO:Cross validation set to False
2023-04-25 08:36:08,004:INFO:Fitting Model
2023-04-25 08:36:08,112:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(max_depth=10,
                                       min_impurity_decrease=0.0002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       n_jobs=-1, random_state=1754))])
2023-04-25 08:36:08,113:INFO:create_model() successfully completed......................................
2023-04-25 08:36:08,236:INFO:Creating Dashboard logs
2023-04-25 08:36:08,236:INFO:Model: Random Forest Regressor
2023-04-25 08:36:08,279:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0002, 'min_samples_leaf': 5, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:08,607:INFO:_master_model_container: 28
2023-04-25 08:36:08,607:INFO:_display_container: 11
2023-04-25 08:36:08,612:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(max_depth=10,
                                       min_impurity_decrease=0.0002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       n_jobs=-1, random_state=1754))])
2023-04-25 08:36:08,612:INFO:finalize_model() successfully completed......................................
2023-04-25 08:36:08,864:INFO:Initializing predict_model()
2023-04-25 08:36:08,864:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=1754))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A8BE320>)
2023-04-25 08:36:08,864:INFO:Checking exceptions
2023-04-25 08:36:08,864:INFO:Preloading libraries
2023-04-25 08:36:08,866:INFO:Set up data.
2023-04-25 08:36:08,870:INFO:Set up index.
2023-04-25 08:36:09,055:INFO:Initializing predict_model()
2023-04-25 08:36:09,055:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=1,
                               feature_fraction=0.7, learning_rate=0.05,
                               min_child_samples=36, min_split_gain=0.5,
                               n_estimators=210, num_leaves=256,
                               random_state=1754, reg_alpha=0.3,
                               reg_lambda=4))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D569D8DD80>)
2023-04-25 08:36:09,056:INFO:Checking exceptions
2023-04-25 08:36:09,056:INFO:Preloading libraries
2023-04-25 08:36:09,057:INFO:Set up data.
2023-04-25 08:36:09,061:INFO:Set up index.
2023-04-25 08:36:09,270:INFO:Initializing predict_model()
2023-04-25 08:36:09,270:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(max_depth=10,
                                       min_impurity_decrease=0.0002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       n_jobs=-1, random_state=1754))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D569D8EEF0>)
2023-04-25 08:36:09,270:INFO:Checking exceptions
2023-04-25 08:36:09,270:INFO:Preloading libraries
2023-04-25 08:36:09,274:INFO:Set up data.
2023-04-25 08:36:09,278:INFO:Set up index.
2023-04-25 08:36:09,473:INFO:Initializing compare_models()
2023-04-25 08:36:09,473:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, include=None, fold=5, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 08:36:09,473:INFO:Checking exceptions
2023-04-25 08:36:09,475:INFO:Preparing display monitor
2023-04-25 08:36:09,504:INFO:Initializing Linear Regression
2023-04-25 08:36:09,505:INFO:Total runtime is 1.66932741800944e-05 minutes
2023-04-25 08:36:09,510:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:09,510:INFO:Initializing create_model()
2023-04-25 08:36:09,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:09,510:INFO:Checking exceptions
2023-04-25 08:36:09,511:INFO:Importing libraries
2023-04-25 08:36:09,511:INFO:Copying training dataset
2023-04-25 08:36:09,514:INFO:Defining folds
2023-04-25 08:36:09,514:INFO:Declaring metric variables
2023-04-25 08:36:09,517:INFO:Importing untrained model
2023-04-25 08:36:09,520:INFO:Linear Regression Imported successfully
2023-04-25 08:36:09,526:INFO:Starting cross validation
2023-04-25 08:36:09,527:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:10,163:INFO:Calculating mean and std
2023-04-25 08:36:10,163:INFO:Creating metrics dataframe
2023-04-25 08:36:10,330:INFO:Uploading results into container
2023-04-25 08:36:10,331:INFO:Uploading model into container now
2023-04-25 08:36:10,331:INFO:_master_model_container: 29
2023-04-25 08:36:10,331:INFO:_display_container: 15
2023-04-25 08:36:10,331:INFO:LinearRegression(n_jobs=-1)
2023-04-25 08:36:10,331:INFO:create_model() successfully completed......................................
2023-04-25 08:36:10,459:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:10,459:INFO:Creating metrics dataframe
2023-04-25 08:36:10,465:INFO:Initializing Lasso Regression
2023-04-25 08:36:10,465:INFO:Total runtime is 0.016003461678822835 minutes
2023-04-25 08:36:10,467:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:10,468:INFO:Initializing create_model()
2023-04-25 08:36:10,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:10,468:INFO:Checking exceptions
2023-04-25 08:36:10,468:INFO:Importing libraries
2023-04-25 08:36:10,468:INFO:Copying training dataset
2023-04-25 08:36:10,471:INFO:Defining folds
2023-04-25 08:36:10,472:INFO:Declaring metric variables
2023-04-25 08:36:10,475:INFO:Importing untrained model
2023-04-25 08:36:10,478:INFO:Lasso Regression Imported successfully
2023-04-25 08:36:10,489:INFO:Starting cross validation
2023-04-25 08:36:10,490:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:11,124:INFO:Calculating mean and std
2023-04-25 08:36:11,125:INFO:Creating metrics dataframe
2023-04-25 08:36:11,302:INFO:Uploading results into container
2023-04-25 08:36:11,303:INFO:Uploading model into container now
2023-04-25 08:36:11,303:INFO:_master_model_container: 30
2023-04-25 08:36:11,304:INFO:_display_container: 15
2023-04-25 08:36:11,304:INFO:Lasso(random_state=1754)
2023-04-25 08:36:11,304:INFO:create_model() successfully completed......................................
2023-04-25 08:36:11,425:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:11,425:INFO:Creating metrics dataframe
2023-04-25 08:36:11,435:INFO:Initializing Ridge Regression
2023-04-25 08:36:11,435:INFO:Total runtime is 0.03218544324239095 minutes
2023-04-25 08:36:11,438:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:11,438:INFO:Initializing create_model()
2023-04-25 08:36:11,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:11,438:INFO:Checking exceptions
2023-04-25 08:36:11,438:INFO:Importing libraries
2023-04-25 08:36:11,438:INFO:Copying training dataset
2023-04-25 08:36:11,443:INFO:Defining folds
2023-04-25 08:36:11,444:INFO:Declaring metric variables
2023-04-25 08:36:11,447:INFO:Importing untrained model
2023-04-25 08:36:11,450:INFO:Ridge Regression Imported successfully
2023-04-25 08:36:11,455:INFO:Starting cross validation
2023-04-25 08:36:11,456:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:12,077:INFO:Calculating mean and std
2023-04-25 08:36:12,078:INFO:Creating metrics dataframe
2023-04-25 08:36:12,254:INFO:Uploading results into container
2023-04-25 08:36:12,255:INFO:Uploading model into container now
2023-04-25 08:36:12,255:INFO:_master_model_container: 31
2023-04-25 08:36:12,255:INFO:_display_container: 15
2023-04-25 08:36:12,255:INFO:Ridge(random_state=1754)
2023-04-25 08:36:12,255:INFO:create_model() successfully completed......................................
2023-04-25 08:36:12,384:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:12,384:INFO:Creating metrics dataframe
2023-04-25 08:36:12,394:INFO:Initializing Elastic Net
2023-04-25 08:36:12,394:INFO:Total runtime is 0.04816259145736694 minutes
2023-04-25 08:36:12,396:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:12,397:INFO:Initializing create_model()
2023-04-25 08:36:12,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:12,397:INFO:Checking exceptions
2023-04-25 08:36:12,397:INFO:Importing libraries
2023-04-25 08:36:12,397:INFO:Copying training dataset
2023-04-25 08:36:12,400:INFO:Defining folds
2023-04-25 08:36:12,400:INFO:Declaring metric variables
2023-04-25 08:36:12,404:INFO:Importing untrained model
2023-04-25 08:36:12,407:INFO:Elastic Net Imported successfully
2023-04-25 08:36:12,414:INFO:Starting cross validation
2023-04-25 08:36:12,415:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:13,038:INFO:Calculating mean and std
2023-04-25 08:36:13,040:INFO:Creating metrics dataframe
2023-04-25 08:36:13,216:INFO:Uploading results into container
2023-04-25 08:36:13,217:INFO:Uploading model into container now
2023-04-25 08:36:13,217:INFO:_master_model_container: 32
2023-04-25 08:36:13,217:INFO:_display_container: 15
2023-04-25 08:36:13,218:INFO:ElasticNet(random_state=1754)
2023-04-25 08:36:13,218:INFO:create_model() successfully completed......................................
2023-04-25 08:36:13,342:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:13,342:INFO:Creating metrics dataframe
2023-04-25 08:36:13,350:INFO:Initializing Least Angle Regression
2023-04-25 08:36:13,350:INFO:Total runtime is 0.06409267981847128 minutes
2023-04-25 08:36:13,354:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:13,354:INFO:Initializing create_model()
2023-04-25 08:36:13,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:13,354:INFO:Checking exceptions
2023-04-25 08:36:13,355:INFO:Importing libraries
2023-04-25 08:36:13,355:INFO:Copying training dataset
2023-04-25 08:36:13,359:INFO:Defining folds
2023-04-25 08:36:13,359:INFO:Declaring metric variables
2023-04-25 08:36:13,362:INFO:Importing untrained model
2023-04-25 08:36:13,365:INFO:Least Angle Regression Imported successfully
2023-04-25 08:36:13,371:INFO:Starting cross validation
2023-04-25 08:36:13,372:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:13,414:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:13,419:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:13,422:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:13,434:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:13,440:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:13,989:INFO:Calculating mean and std
2023-04-25 08:36:13,990:INFO:Creating metrics dataframe
2023-04-25 08:36:14,168:INFO:Uploading results into container
2023-04-25 08:36:14,169:INFO:Uploading model into container now
2023-04-25 08:36:14,169:INFO:_master_model_container: 33
2023-04-25 08:36:14,169:INFO:_display_container: 15
2023-04-25 08:36:14,170:INFO:Lars(random_state=1754)
2023-04-25 08:36:14,170:INFO:create_model() successfully completed......................................
2023-04-25 08:36:14,292:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:14,292:INFO:Creating metrics dataframe
2023-04-25 08:36:14,299:INFO:Initializing Lasso Least Angle Regression
2023-04-25 08:36:14,300:INFO:Total runtime is 0.07992560863494874 minutes
2023-04-25 08:36:14,304:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:14,304:INFO:Initializing create_model()
2023-04-25 08:36:14,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:14,304:INFO:Checking exceptions
2023-04-25 08:36:14,304:INFO:Importing libraries
2023-04-25 08:36:14,304:INFO:Copying training dataset
2023-04-25 08:36:14,310:INFO:Defining folds
2023-04-25 08:36:14,310:INFO:Declaring metric variables
2023-04-25 08:36:14,314:INFO:Importing untrained model
2023-04-25 08:36:14,318:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 08:36:14,324:INFO:Starting cross validation
2023-04-25 08:36:14,325:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:14,366:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:36:14,370:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:36:14,380:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:36:14,382:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:36:14,390:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:36:14,938:INFO:Calculating mean and std
2023-04-25 08:36:14,939:INFO:Creating metrics dataframe
2023-04-25 08:36:15,119:INFO:Uploading results into container
2023-04-25 08:36:15,119:INFO:Uploading model into container now
2023-04-25 08:36:15,120:INFO:_master_model_container: 34
2023-04-25 08:36:15,120:INFO:_display_container: 15
2023-04-25 08:36:15,120:INFO:LassoLars(random_state=1754)
2023-04-25 08:36:15,120:INFO:create_model() successfully completed......................................
2023-04-25 08:36:15,243:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:15,243:INFO:Creating metrics dataframe
2023-04-25 08:36:15,250:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 08:36:15,251:INFO:Total runtime is 0.09577951431274415 minutes
2023-04-25 08:36:15,254:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:15,255:INFO:Initializing create_model()
2023-04-25 08:36:15,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:15,255:INFO:Checking exceptions
2023-04-25 08:36:15,255:INFO:Importing libraries
2023-04-25 08:36:15,255:INFO:Copying training dataset
2023-04-25 08:36:15,261:INFO:Defining folds
2023-04-25 08:36:15,261:INFO:Declaring metric variables
2023-04-25 08:36:15,264:INFO:Importing untrained model
2023-04-25 08:36:15,267:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 08:36:15,274:INFO:Starting cross validation
2023-04-25 08:36:15,277:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:15,314:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:15,326:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:15,327:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:15,340:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:15,341:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:36:15,903:INFO:Calculating mean and std
2023-04-25 08:36:15,904:INFO:Creating metrics dataframe
2023-04-25 08:36:16,084:INFO:Uploading results into container
2023-04-25 08:36:16,084:INFO:Uploading model into container now
2023-04-25 08:36:16,085:INFO:_master_model_container: 35
2023-04-25 08:36:16,085:INFO:_display_container: 15
2023-04-25 08:36:16,085:INFO:OrthogonalMatchingPursuit()
2023-04-25 08:36:16,085:INFO:create_model() successfully completed......................................
2023-04-25 08:36:16,209:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:16,209:INFO:Creating metrics dataframe
2023-04-25 08:36:16,217:INFO:Initializing Bayesian Ridge
2023-04-25 08:36:16,217:INFO:Total runtime is 0.11188400189081829 minutes
2023-04-25 08:36:16,221:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:16,221:INFO:Initializing create_model()
2023-04-25 08:36:16,221:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:16,222:INFO:Checking exceptions
2023-04-25 08:36:16,222:INFO:Importing libraries
2023-04-25 08:36:16,223:INFO:Copying training dataset
2023-04-25 08:36:16,227:INFO:Defining folds
2023-04-25 08:36:16,227:INFO:Declaring metric variables
2023-04-25 08:36:16,230:INFO:Importing untrained model
2023-04-25 08:36:16,234:INFO:Bayesian Ridge Imported successfully
2023-04-25 08:36:16,243:INFO:Starting cross validation
2023-04-25 08:36:16,244:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:16,862:INFO:Calculating mean and std
2023-04-25 08:36:16,863:INFO:Creating metrics dataframe
2023-04-25 08:36:17,037:INFO:Uploading results into container
2023-04-25 08:36:17,038:INFO:Uploading model into container now
2023-04-25 08:36:17,038:INFO:_master_model_container: 36
2023-04-25 08:36:17,038:INFO:_display_container: 15
2023-04-25 08:36:17,038:INFO:BayesianRidge()
2023-04-25 08:36:17,038:INFO:create_model() successfully completed......................................
2023-04-25 08:36:17,163:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:17,163:INFO:Creating metrics dataframe
2023-04-25 08:36:17,174:INFO:Initializing Passive Aggressive Regressor
2023-04-25 08:36:17,174:INFO:Total runtime is 0.12782386541366578 minutes
2023-04-25 08:36:17,177:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:17,177:INFO:Initializing create_model()
2023-04-25 08:36:17,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:17,177:INFO:Checking exceptions
2023-04-25 08:36:17,177:INFO:Importing libraries
2023-04-25 08:36:17,178:INFO:Copying training dataset
2023-04-25 08:36:17,182:INFO:Defining folds
2023-04-25 08:36:17,183:INFO:Declaring metric variables
2023-04-25 08:36:17,185:INFO:Importing untrained model
2023-04-25 08:36:17,188:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 08:36:17,195:INFO:Starting cross validation
2023-04-25 08:36:17,196:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:17,844:INFO:Calculating mean and std
2023-04-25 08:36:17,846:INFO:Creating metrics dataframe
2023-04-25 08:36:18,019:INFO:Uploading results into container
2023-04-25 08:36:18,019:INFO:Uploading model into container now
2023-04-25 08:36:18,019:INFO:_master_model_container: 37
2023-04-25 08:36:18,019:INFO:_display_container: 15
2023-04-25 08:36:18,020:INFO:PassiveAggressiveRegressor(random_state=1754)
2023-04-25 08:36:18,020:INFO:create_model() successfully completed......................................
2023-04-25 08:36:18,138:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:18,138:INFO:Creating metrics dataframe
2023-04-25 08:36:18,146:INFO:Initializing Huber Regressor
2023-04-25 08:36:18,147:INFO:Total runtime is 0.14404023090998333 minutes
2023-04-25 08:36:18,150:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:18,150:INFO:Initializing create_model()
2023-04-25 08:36:18,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:18,150:INFO:Checking exceptions
2023-04-25 08:36:18,150:INFO:Importing libraries
2023-04-25 08:36:18,150:INFO:Copying training dataset
2023-04-25 08:36:18,155:INFO:Defining folds
2023-04-25 08:36:18,155:INFO:Declaring metric variables
2023-04-25 08:36:18,158:INFO:Importing untrained model
2023-04-25 08:36:18,162:INFO:Huber Regressor Imported successfully
2023-04-25 08:36:18,171:INFO:Starting cross validation
2023-04-25 08:36:18,171:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:18,798:INFO:Calculating mean and std
2023-04-25 08:36:18,800:INFO:Creating metrics dataframe
2023-04-25 08:36:18,966:INFO:Uploading results into container
2023-04-25 08:36:18,967:INFO:Uploading model into container now
2023-04-25 08:36:18,967:INFO:_master_model_container: 38
2023-04-25 08:36:18,967:INFO:_display_container: 15
2023-04-25 08:36:18,967:INFO:HuberRegressor()
2023-04-25 08:36:18,968:INFO:create_model() successfully completed......................................
2023-04-25 08:36:19,090:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:19,091:INFO:Creating metrics dataframe
2023-04-25 08:36:19,100:INFO:Initializing K Neighbors Regressor
2023-04-25 08:36:19,100:INFO:Total runtime is 0.15993378559748334 minutes
2023-04-25 08:36:19,103:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:19,104:INFO:Initializing create_model()
2023-04-25 08:36:19,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:19,104:INFO:Checking exceptions
2023-04-25 08:36:19,104:INFO:Importing libraries
2023-04-25 08:36:19,104:INFO:Copying training dataset
2023-04-25 08:36:19,108:INFO:Defining folds
2023-04-25 08:36:19,108:INFO:Declaring metric variables
2023-04-25 08:36:19,111:INFO:Importing untrained model
2023-04-25 08:36:19,114:INFO:K Neighbors Regressor Imported successfully
2023-04-25 08:36:19,119:INFO:Starting cross validation
2023-04-25 08:36:19,120:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:19,747:INFO:Calculating mean and std
2023-04-25 08:36:19,748:INFO:Creating metrics dataframe
2023-04-25 08:36:19,922:INFO:Uploading results into container
2023-04-25 08:36:19,923:INFO:Uploading model into container now
2023-04-25 08:36:19,923:INFO:_master_model_container: 39
2023-04-25 08:36:19,923:INFO:_display_container: 15
2023-04-25 08:36:19,923:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 08:36:19,923:INFO:create_model() successfully completed......................................
2023-04-25 08:36:20,041:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:20,042:INFO:Creating metrics dataframe
2023-04-25 08:36:20,050:INFO:Initializing Decision Tree Regressor
2023-04-25 08:36:20,050:INFO:Total runtime is 0.17576933701833092 minutes
2023-04-25 08:36:20,053:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:20,053:INFO:Initializing create_model()
2023-04-25 08:36:20,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:20,053:INFO:Checking exceptions
2023-04-25 08:36:20,053:INFO:Importing libraries
2023-04-25 08:36:20,053:INFO:Copying training dataset
2023-04-25 08:36:20,057:INFO:Defining folds
2023-04-25 08:36:20,057:INFO:Declaring metric variables
2023-04-25 08:36:20,061:INFO:Importing untrained model
2023-04-25 08:36:20,064:INFO:Decision Tree Regressor Imported successfully
2023-04-25 08:36:20,070:INFO:Starting cross validation
2023-04-25 08:36:20,070:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:20,671:INFO:Calculating mean and std
2023-04-25 08:36:20,673:INFO:Creating metrics dataframe
2023-04-25 08:36:20,840:INFO:Uploading results into container
2023-04-25 08:36:20,840:INFO:Uploading model into container now
2023-04-25 08:36:20,841:INFO:_master_model_container: 40
2023-04-25 08:36:20,841:INFO:_display_container: 15
2023-04-25 08:36:20,841:INFO:DecisionTreeRegressor(random_state=1754)
2023-04-25 08:36:20,841:INFO:create_model() successfully completed......................................
2023-04-25 08:36:20,959:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:20,959:INFO:Creating metrics dataframe
2023-04-25 08:36:20,969:INFO:Initializing Random Forest Regressor
2023-04-25 08:36:20,969:INFO:Total runtime is 0.19107779264450075 minutes
2023-04-25 08:36:20,972:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:20,972:INFO:Initializing create_model()
2023-04-25 08:36:20,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:20,973:INFO:Checking exceptions
2023-04-25 08:36:20,973:INFO:Importing libraries
2023-04-25 08:36:20,973:INFO:Copying training dataset
2023-04-25 08:36:20,978:INFO:Defining folds
2023-04-25 08:36:20,978:INFO:Declaring metric variables
2023-04-25 08:36:20,981:INFO:Importing untrained model
2023-04-25 08:36:20,984:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:36:20,991:INFO:Starting cross validation
2023-04-25 08:36:20,992:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:21,723:INFO:Calculating mean and std
2023-04-25 08:36:21,724:INFO:Creating metrics dataframe
2023-04-25 08:36:21,896:INFO:Uploading results into container
2023-04-25 08:36:21,897:INFO:Uploading model into container now
2023-04-25 08:36:21,897:INFO:_master_model_container: 41
2023-04-25 08:36:21,897:INFO:_display_container: 15
2023-04-25 08:36:21,897:INFO:RandomForestRegressor(n_jobs=-1, random_state=1754)
2023-04-25 08:36:21,897:INFO:create_model() successfully completed......................................
2023-04-25 08:36:22,027:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:22,028:INFO:Creating metrics dataframe
2023-04-25 08:36:22,037:INFO:Initializing Extra Trees Regressor
2023-04-25 08:36:22,037:INFO:Total runtime is 0.20887489318847657 minutes
2023-04-25 08:36:22,040:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:22,040:INFO:Initializing create_model()
2023-04-25 08:36:22,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:22,040:INFO:Checking exceptions
2023-04-25 08:36:22,041:INFO:Importing libraries
2023-04-25 08:36:22,041:INFO:Copying training dataset
2023-04-25 08:36:22,044:INFO:Defining folds
2023-04-25 08:36:22,044:INFO:Declaring metric variables
2023-04-25 08:36:22,047:INFO:Importing untrained model
2023-04-25 08:36:22,051:INFO:Extra Trees Regressor Imported successfully
2023-04-25 08:36:22,057:INFO:Starting cross validation
2023-04-25 08:36:22,059:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:22,787:INFO:Calculating mean and std
2023-04-25 08:36:22,788:INFO:Creating metrics dataframe
2023-04-25 08:36:22,962:INFO:Uploading results into container
2023-04-25 08:36:22,962:INFO:Uploading model into container now
2023-04-25 08:36:22,963:INFO:_master_model_container: 42
2023-04-25 08:36:22,963:INFO:_display_container: 15
2023-04-25 08:36:22,963:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1754)
2023-04-25 08:36:22,963:INFO:create_model() successfully completed......................................
2023-04-25 08:36:23,085:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:23,085:INFO:Creating metrics dataframe
2023-04-25 08:36:23,097:INFO:Initializing AdaBoost Regressor
2023-04-25 08:36:23,097:INFO:Total runtime is 0.22654136021931967 minutes
2023-04-25 08:36:23,099:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:23,100:INFO:Initializing create_model()
2023-04-25 08:36:23,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:23,100:INFO:Checking exceptions
2023-04-25 08:36:23,100:INFO:Importing libraries
2023-04-25 08:36:23,100:INFO:Copying training dataset
2023-04-25 08:36:23,104:INFO:Defining folds
2023-04-25 08:36:23,104:INFO:Declaring metric variables
2023-04-25 08:36:23,107:INFO:Importing untrained model
2023-04-25 08:36:23,111:INFO:AdaBoost Regressor Imported successfully
2023-04-25 08:36:23,116:INFO:Starting cross validation
2023-04-25 08:36:23,117:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:23,752:INFO:Calculating mean and std
2023-04-25 08:36:23,753:INFO:Creating metrics dataframe
2023-04-25 08:36:23,938:INFO:Uploading results into container
2023-04-25 08:36:23,939:INFO:Uploading model into container now
2023-04-25 08:36:23,939:INFO:_master_model_container: 43
2023-04-25 08:36:23,939:INFO:_display_container: 15
2023-04-25 08:36:23,940:INFO:AdaBoostRegressor(random_state=1754)
2023-04-25 08:36:23,940:INFO:create_model() successfully completed......................................
2023-04-25 08:36:24,089:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:24,089:INFO:Creating metrics dataframe
2023-04-25 08:36:24,100:INFO:Initializing Gradient Boosting Regressor
2023-04-25 08:36:24,100:INFO:Total runtime is 0.24325824578603109 minutes
2023-04-25 08:36:24,103:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:24,103:INFO:Initializing create_model()
2023-04-25 08:36:24,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:24,104:INFO:Checking exceptions
2023-04-25 08:36:24,104:INFO:Importing libraries
2023-04-25 08:36:24,104:INFO:Copying training dataset
2023-04-25 08:36:24,109:INFO:Defining folds
2023-04-25 08:36:24,110:INFO:Declaring metric variables
2023-04-25 08:36:24,115:INFO:Importing untrained model
2023-04-25 08:36:24,118:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:36:24,139:INFO:Starting cross validation
2023-04-25 08:36:24,140:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:24,833:INFO:Calculating mean and std
2023-04-25 08:36:24,834:INFO:Creating metrics dataframe
2023-04-25 08:36:25,010:INFO:Uploading results into container
2023-04-25 08:36:25,010:INFO:Uploading model into container now
2023-04-25 08:36:25,011:INFO:_master_model_container: 44
2023-04-25 08:36:25,011:INFO:_display_container: 15
2023-04-25 08:36:25,011:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:36:25,011:INFO:create_model() successfully completed......................................
2023-04-25 08:36:25,129:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:25,129:INFO:Creating metrics dataframe
2023-04-25 08:36:25,142:INFO:Initializing Extreme Gradient Boosting
2023-04-25 08:36:25,142:INFO:Total runtime is 0.26063371499379473 minutes
2023-04-25 08:36:25,145:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:25,145:INFO:Initializing create_model()
2023-04-25 08:36:25,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:25,145:INFO:Checking exceptions
2023-04-25 08:36:25,146:INFO:Importing libraries
2023-04-25 08:36:25,146:INFO:Copying training dataset
2023-04-25 08:36:25,150:INFO:Defining folds
2023-04-25 08:36:25,151:INFO:Declaring metric variables
2023-04-25 08:36:25,155:INFO:Importing untrained model
2023-04-25 08:36:25,159:INFO:Extreme Gradient Boosting Imported successfully
2023-04-25 08:36:25,165:INFO:Starting cross validation
2023-04-25 08:36:25,165:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:25,804:INFO:Calculating mean and std
2023-04-25 08:36:25,805:INFO:Creating metrics dataframe
2023-04-25 08:36:25,976:INFO:Uploading results into container
2023-04-25 08:36:25,977:INFO:Uploading model into container now
2023-04-25 08:36:25,977:INFO:_master_model_container: 45
2023-04-25 08:36:25,977:INFO:_display_container: 15
2023-04-25 08:36:25,979:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1754, ...)
2023-04-25 08:36:25,979:INFO:create_model() successfully completed......................................
2023-04-25 08:36:26,096:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:26,096:INFO:Creating metrics dataframe
2023-04-25 08:36:26,106:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 08:36:26,106:INFO:Total runtime is 0.276688015460968 minutes
2023-04-25 08:36:26,109:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:26,110:INFO:Initializing create_model()
2023-04-25 08:36:26,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:26,110:INFO:Checking exceptions
2023-04-25 08:36:26,110:INFO:Importing libraries
2023-04-25 08:36:26,110:INFO:Copying training dataset
2023-04-25 08:36:26,117:INFO:Defining folds
2023-04-25 08:36:26,117:INFO:Declaring metric variables
2023-04-25 08:36:26,119:INFO:Importing untrained model
2023-04-25 08:36:26,123:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:36:26,128:INFO:Starting cross validation
2023-04-25 08:36:26,129:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:26,768:INFO:Calculating mean and std
2023-04-25 08:36:26,769:INFO:Creating metrics dataframe
2023-04-25 08:36:26,939:INFO:Uploading results into container
2023-04-25 08:36:26,940:INFO:Uploading model into container now
2023-04-25 08:36:26,940:INFO:_master_model_container: 46
2023-04-25 08:36:26,940:INFO:_display_container: 15
2023-04-25 08:36:26,940:INFO:LGBMRegressor(random_state=1754)
2023-04-25 08:36:26,940:INFO:create_model() successfully completed......................................
2023-04-25 08:36:27,059:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:27,060:INFO:Creating metrics dataframe
2023-04-25 08:36:27,069:INFO:Initializing Dummy Regressor
2023-04-25 08:36:27,070:INFO:Total runtime is 0.2927549362182617 minutes
2023-04-25 08:36:27,073:INFO:SubProcess create_model() called ==================================
2023-04-25 08:36:27,073:INFO:Initializing create_model()
2023-04-25 08:36:27,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56F182E00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:27,073:INFO:Checking exceptions
2023-04-25 08:36:27,073:INFO:Importing libraries
2023-04-25 08:36:27,073:INFO:Copying training dataset
2023-04-25 08:36:27,079:INFO:Defining folds
2023-04-25 08:36:27,079:INFO:Declaring metric variables
2023-04-25 08:36:27,082:INFO:Importing untrained model
2023-04-25 08:36:27,085:INFO:Dummy Regressor Imported successfully
2023-04-25 08:36:27,091:INFO:Starting cross validation
2023-04-25 08:36:27,092:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:36:27,708:INFO:Calculating mean and std
2023-04-25 08:36:27,710:INFO:Creating metrics dataframe
2023-04-25 08:36:27,902:INFO:Uploading results into container
2023-04-25 08:36:27,902:INFO:Uploading model into container now
2023-04-25 08:36:27,903:INFO:_master_model_container: 47
2023-04-25 08:36:27,903:INFO:_display_container: 15
2023-04-25 08:36:27,903:INFO:DummyRegressor()
2023-04-25 08:36:27,903:INFO:create_model() successfully completed......................................
2023-04-25 08:36:28,022:INFO:SubProcess create_model() end ==================================
2023-04-25 08:36:28,022:INFO:Creating metrics dataframe
2023-04-25 08:36:28,040:INFO:Initializing create_model()
2023-04-25 08:36:28,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:36:28,041:INFO:Checking exceptions
2023-04-25 08:36:28,043:INFO:Importing libraries
2023-04-25 08:36:28,043:INFO:Copying training dataset
2023-04-25 08:36:28,045:INFO:Defining folds
2023-04-25 08:36:28,045:INFO:Declaring metric variables
2023-04-25 08:36:28,045:INFO:Importing untrained model
2023-04-25 08:36:28,045:INFO:Declaring custom model
2023-04-25 08:36:28,046:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:36:28,046:INFO:Cross validation set to False
2023-04-25 08:36:28,046:INFO:Fitting Model
2023-04-25 08:36:28,236:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:36:28,236:INFO:create_model() successfully completed......................................
2023-04-25 08:36:28,356:INFO:Creating Dashboard logs
2023-04-25 08:36:28,360:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:36:28,407:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1754, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:28,477:INFO:Initializing predict_model()
2023-04-25 08:36:28,477:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56AB18640>, estimator=GradientBoostingRegressor(random_state=1754), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D569D8D000>)
2023-04-25 08:36:28,477:INFO:Checking exceptions
2023-04-25 08:36:28,477:INFO:Preloading libraries
2023-04-25 08:36:28,897:INFO:Creating Dashboard logs
2023-04-25 08:36:28,900:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:36:28,945:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1754, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:36:29,286:INFO:Creating Dashboard logs
2023-04-25 08:36:29,288:INFO:Model: Random Forest Regressor
2023-04-25 08:36:29,332:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:29,670:INFO:Creating Dashboard logs
2023-04-25 08:36:29,673:INFO:Model: Extra Trees Regressor
2023-04-25 08:36:29,718:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1754, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:30,057:INFO:Creating Dashboard logs
2023-04-25 08:36:30,060:INFO:Model: Extreme Gradient Boosting
2023-04-25 08:36:30,112:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 1754, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-25 08:36:30,479:INFO:Creating Dashboard logs
2023-04-25 08:36:30,481:INFO:Model: AdaBoost Regressor
2023-04-25 08:36:30,532:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1754}
2023-04-25 08:36:30,862:INFO:Creating Dashboard logs
2023-04-25 08:36:30,865:INFO:Model: K Neighbors Regressor
2023-04-25 08:36:30,909:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-25 08:36:31,251:INFO:Creating Dashboard logs
2023-04-25 08:36:31,253:INFO:Model: Lasso Least Angle Regression
2023-04-25 08:36:31,299:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 1754, 'verbose': False}
2023-04-25 08:36:31,698:INFO:Creating Dashboard logs
2023-04-25 08:36:31,701:INFO:Model: Ridge Regression
2023-04-25 08:36:31,752:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 1754, 'solver': 'auto', 'tol': 0.001}
2023-04-25 08:36:32,087:INFO:Creating Dashboard logs
2023-04-25 08:36:32,090:INFO:Model: Bayesian Ridge
2023-04-25 08:36:32,134:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-25 08:36:32,488:INFO:Creating Dashboard logs
2023-04-25 08:36:32,491:INFO:Model: Linear Regression
2023-04-25 08:36:32,539:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-25 08:36:32,912:INFO:Creating Dashboard logs
2023-04-25 08:36:32,915:INFO:Model: Least Angle Regression
2023-04-25 08:36:32,964:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 1754, 'verbose': False}
2023-04-25 08:36:33,328:INFO:Creating Dashboard logs
2023-04-25 08:36:33,331:INFO:Model: Lasso Regression
2023-04-25 08:36:33,376:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 1754, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:36:33,798:INFO:Creating Dashboard logs
2023-04-25 08:36:33,802:INFO:Model: Decision Tree Regressor
2023-04-25 08:36:33,845:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1754, 'splitter': 'best'}
2023-04-25 08:36:34,244:INFO:Creating Dashboard logs
2023-04-25 08:36:34,247:INFO:Model: Elastic Net
2023-04-25 08:36:34,292:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 1754, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:36:34,632:INFO:Creating Dashboard logs
2023-04-25 08:36:34,635:INFO:Model: Huber Regressor
2023-04-25 08:36:34,683:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-25 08:36:35,025:INFO:Creating Dashboard logs
2023-04-25 08:36:35,028:INFO:Model: Orthogonal Matching Pursuit
2023-04-25 08:36:35,071:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-25 08:36:35,462:INFO:Creating Dashboard logs
2023-04-25 08:36:35,465:INFO:Model: Passive Aggressive Regressor
2023-04-25 08:36:35,510:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 1754, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:36:35,865:INFO:Creating Dashboard logs
2023-04-25 08:36:35,867:INFO:Model: Dummy Regressor
2023-04-25 08:36:35,913:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-25 08:36:36,268:INFO:_master_model_container: 47
2023-04-25 08:36:36,268:INFO:_display_container: 15
2023-04-25 08:36:36,269:INFO:GradientBoostingRegressor(random_state=1754)
2023-04-25 08:36:36,269:INFO:compare_models() successfully completed......................................
2023-04-25 08:37:08,085:INFO:PyCaret RegressionExperiment
2023-04-25 08:37:08,085:INFO:Logging name: charges
2023-04-25 08:37:08,085:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 08:37:08,085:INFO:version 3.0.0
2023-04-25 08:37:08,085:INFO:Initializing setup()
2023-04-25 08:37:08,085:INFO:self.USI: 6c25
2023-04-25 08:37:08,085:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'fold_generator', 'y_test', 'transform_target_param', 'y_train', 'data', 'fold_shuffle_param', 'USI', 'X_train', 'html_param', 'memory', 'X_test', 'y', 'fold_groups_param', 'X', 'seed', 'logging_param', 'exp_id', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'idx', 'gpu_n_jobs_param'}
2023-04-25 08:37:08,085:INFO:Checking environment
2023-04-25 08:37:08,085:INFO:python_version: 3.10.11
2023-04-25 08:37:08,085:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-04-25 08:37:08,085:INFO:machine: AMD64
2023-04-25 08:37:08,085:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 08:37:08,085:INFO:Memory: svmem(total=8362713088, available=1323900928, percent=84.2, used=7038812160, free=1323900928)
2023-04-25 08:37:08,085:INFO:Physical Core: 4
2023-04-25 08:37:08,085:INFO:Logical Core: 8
2023-04-25 08:37:08,085:INFO:Checking libraries
2023-04-25 08:37:08,085:INFO:System:
2023-04-25 08:37:08,085:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-04-25 08:37:08,085:INFO:executable: C:\Users\danie\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe
2023-04-25 08:37:08,085:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 08:37:08,085:INFO:PyCaret required dependencies:
2023-04-25 08:37:08,085:INFO:                 pip: 23.0.1
2023-04-25 08:37:08,085:INFO:          setuptools: 65.5.0
2023-04-25 08:37:08,085:INFO:             pycaret: 3.0.0
2023-04-25 08:37:08,085:INFO:             IPython: 8.5.0
2023-04-25 08:37:08,085:INFO:          ipywidgets: 8.0.2
2023-04-25 08:37:08,086:INFO:                tqdm: 4.65.0
2023-04-25 08:37:08,086:INFO:               numpy: 1.23.3
2023-04-25 08:37:08,086:INFO:              pandas: 1.5.0
2023-04-25 08:37:08,086:INFO:              jinja2: 3.1.2
2023-04-25 08:37:08,086:INFO:               scipy: 1.9.1
2023-04-25 08:37:08,086:INFO:              joblib: 1.2.0
2023-04-25 08:37:08,086:INFO:             sklearn: 1.1.2
2023-04-25 08:37:08,086:INFO:                pyod: 1.0.9
2023-04-25 08:37:08,086:INFO:            imblearn: 0.10.1
2023-04-25 08:37:08,086:INFO:   category_encoders: 2.6.0
2023-04-25 08:37:08,086:INFO:            lightgbm: 3.3.5
2023-04-25 08:37:08,086:INFO:               numba: 0.56.4
2023-04-25 08:37:08,086:INFO:            requests: 2.28.1
2023-04-25 08:37:08,086:INFO:          matplotlib: 3.6.0
2023-04-25 08:37:08,086:INFO:          scikitplot: 0.3.7
2023-04-25 08:37:08,086:INFO:         yellowbrick: 1.5
2023-04-25 08:37:08,086:INFO:              plotly: 5.10.0
2023-04-25 08:37:08,086:INFO:             kaleido: 0.2.1
2023-04-25 08:37:08,086:INFO:         statsmodels: 0.13.5
2023-04-25 08:37:08,086:INFO:              sktime: 0.17.1
2023-04-25 08:37:08,086:INFO:               tbats: 1.1.3
2023-04-25 08:37:08,086:INFO:            pmdarima: 2.0.3
2023-04-25 08:37:08,086:INFO:              psutil: 5.9.2
2023-04-25 08:37:08,086:INFO:PyCaret optional dependencies:
2023-04-25 08:37:08,086:INFO:                shap: Not installed
2023-04-25 08:37:08,086:INFO:           interpret: Not installed
2023-04-25 08:37:08,086:INFO:                umap: Not installed
2023-04-25 08:37:08,086:INFO:    pandas_profiling: Not installed
2023-04-25 08:37:08,086:INFO:  explainerdashboard: Not installed
2023-04-25 08:37:08,086:INFO:             autoviz: Not installed
2023-04-25 08:37:08,086:INFO:           fairlearn: Not installed
2023-04-25 08:37:08,086:INFO:             xgboost: 1.7.5
2023-04-25 08:37:08,086:INFO:            catboost: Not installed
2023-04-25 08:37:08,087:INFO:              kmodes: Not installed
2023-04-25 08:37:08,087:INFO:             mlxtend: Not installed
2023-04-25 08:37:08,087:INFO:       statsforecast: Not installed
2023-04-25 08:37:08,087:INFO:        tune_sklearn: Not installed
2023-04-25 08:37:08,087:INFO:                 ray: Not installed
2023-04-25 08:37:08,087:INFO:            hyperopt: Not installed
2023-04-25 08:37:08,087:INFO:              optuna: Not installed
2023-04-25 08:37:08,087:INFO:               skopt: Not installed
2023-04-25 08:37:08,087:INFO:              mlflow: 2.3.0
2023-04-25 08:37:08,087:INFO:              gradio: Not installed
2023-04-25 08:37:08,087:INFO:             fastapi: Not installed
2023-04-25 08:37:08,087:INFO:             uvicorn: Not installed
2023-04-25 08:37:08,087:INFO:              m2cgen: Not installed
2023-04-25 08:37:08,087:INFO:           evidently: Not installed
2023-04-25 08:37:08,087:INFO:               fugue: Not installed
2023-04-25 08:37:08,087:INFO:           streamlit: Not installed
2023-04-25 08:37:08,087:INFO:             prophet: Not installed
2023-04-25 08:37:08,087:INFO:None
2023-04-25 08:37:08,087:INFO:Set up data.
2023-04-25 08:37:08,090:INFO:Set up train/test split.
2023-04-25 08:37:08,092:INFO:Set up index.
2023-04-25 08:37:08,092:INFO:Set up folding strategy.
2023-04-25 08:37:08,092:INFO:Assigning column types.
2023-04-25 08:37:08,094:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 08:37:08,094:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,098:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,178:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,180:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,183:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,187:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,261:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,264:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 08:37:08,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,271:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,346:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,352:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,355:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,429:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,429:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,432:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 08:37:08,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,482:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,515:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,524:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,601:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,602:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,605:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 08:37:08,658:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,696:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,787:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 08:37:08,840:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,875:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 08:37:08,960:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:08,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:08,962:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 08:37:09,045:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:09,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:09,128:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:09,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:09,131:INFO:Preparing preprocessing pipeline...
2023-04-25 08:37:09,131:INFO:Set up simple imputation.
2023-04-25 08:37:09,131:INFO:Set up feature normalization.
2023-04-25 08:37:09,148:INFO:Finished creating preprocessing pipeline.
2023-04-25 08:37:09,151:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-25 08:37:09,151:INFO:Creating final display dataframe.
2023-04-25 08:37:09,209:INFO:Setup _display_container:                     Description         Value
0                    Session id          7854
1                        Target       charges
2                   Target type    Regression
3           Original data shape     (1204, 8)
4        Transformed data shape     (1204, 8)
5   Transformed train set shape      (842, 8)
6    Transformed test set shape      (362, 8)
7              Numeric features             7
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12                    Normalize          True
13             Normalize method        zscore
14               Fold Generator         KFold
15                  Fold Number            10
16                     CPU Jobs            -1
17                      Use GPU         False
18               Log Experiment  MlflowLogger
19              Experiment Name       charges
20                          USI          6c25
2023-04-25 08:37:09,308:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:09,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:09,400:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 08:37:09,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 08:37:09,402:INFO:Logging experiment in loggers
2023-04-25 08:37:09,474:INFO:SubProcess save_model() called ==================================
2023-04-25 08:37:09,480:INFO:Initializing save_model()
2023-04-25 08:37:09,480:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\danie\AppData\Local\Temp\tmpkrsohjqc\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 08:37:09,480:INFO:Adding model into prep_pipe
2023-04-25 08:37:09,481:WARNING:Only Model saved as it was a pipeline.
2023-04-25 08:37:09,483:INFO:C:\Users\danie\AppData\Local\Temp\tmpkrsohjqc\Transformation Pipeline.pkl saved in current working directory
2023-04-25 08:37:09,486:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-25 08:37:09,486:INFO:save_model() successfully completed......................................
2023-04-25 08:37:09,761:INFO:SubProcess save_model() end ==================================
2023-04-25 08:37:09,799:INFO:setup() successfully completed in 1.44s...............
2023-04-25 08:37:09,950:INFO:Initializing compare_models()
2023-04-25 08:37:09,950:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, include=None, fold=5, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 08:37:09,950:INFO:Checking exceptions
2023-04-25 08:37:09,952:INFO:Preparing display monitor
2023-04-25 08:37:09,981:INFO:Initializing Linear Regression
2023-04-25 08:37:09,981:INFO:Total runtime is 0.0 minutes
2023-04-25 08:37:09,984:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:09,985:INFO:Initializing create_model()
2023-04-25 08:37:09,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:09,985:INFO:Checking exceptions
2023-04-25 08:37:09,985:INFO:Importing libraries
2023-04-25 08:37:09,985:INFO:Copying training dataset
2023-04-25 08:37:09,988:INFO:Defining folds
2023-04-25 08:37:09,989:INFO:Declaring metric variables
2023-04-25 08:37:09,994:INFO:Importing untrained model
2023-04-25 08:37:09,998:INFO:Linear Regression Imported successfully
2023-04-25 08:37:10,006:INFO:Starting cross validation
2023-04-25 08:37:10,007:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:10,646:INFO:Calculating mean and std
2023-04-25 08:37:10,646:INFO:Creating metrics dataframe
2023-04-25 08:37:10,809:INFO:Uploading results into container
2023-04-25 08:37:10,809:INFO:Uploading model into container now
2023-04-25 08:37:10,809:INFO:_master_model_container: 1
2023-04-25 08:37:10,809:INFO:_display_container: 2
2023-04-25 08:37:10,809:INFO:LinearRegression(n_jobs=-1)
2023-04-25 08:37:10,810:INFO:create_model() successfully completed......................................
2023-04-25 08:37:10,929:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:10,929:INFO:Creating metrics dataframe
2023-04-25 08:37:10,934:INFO:Initializing Lasso Regression
2023-04-25 08:37:10,935:INFO:Total runtime is 0.015897993246714273 minutes
2023-04-25 08:37:10,937:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:10,937:INFO:Initializing create_model()
2023-04-25 08:37:10,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:10,937:INFO:Checking exceptions
2023-04-25 08:37:10,937:INFO:Importing libraries
2023-04-25 08:37:10,937:INFO:Copying training dataset
2023-04-25 08:37:10,940:INFO:Defining folds
2023-04-25 08:37:10,940:INFO:Declaring metric variables
2023-04-25 08:37:10,942:INFO:Importing untrained model
2023-04-25 08:37:10,945:INFO:Lasso Regression Imported successfully
2023-04-25 08:37:10,953:INFO:Starting cross validation
2023-04-25 08:37:10,953:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:11,591:INFO:Calculating mean and std
2023-04-25 08:37:11,591:INFO:Creating metrics dataframe
2023-04-25 08:37:11,761:INFO:Uploading results into container
2023-04-25 08:37:11,761:INFO:Uploading model into container now
2023-04-25 08:37:11,763:INFO:_master_model_container: 2
2023-04-25 08:37:11,763:INFO:_display_container: 2
2023-04-25 08:37:11,763:INFO:Lasso(random_state=7854)
2023-04-25 08:37:11,763:INFO:create_model() successfully completed......................................
2023-04-25 08:37:11,897:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:11,897:INFO:Creating metrics dataframe
2023-04-25 08:37:11,903:INFO:Initializing Ridge Regression
2023-04-25 08:37:11,903:INFO:Total runtime is 0.03203866084416707 minutes
2023-04-25 08:37:11,907:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:11,907:INFO:Initializing create_model()
2023-04-25 08:37:11,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:11,907:INFO:Checking exceptions
2023-04-25 08:37:11,907:INFO:Importing libraries
2023-04-25 08:37:11,907:INFO:Copying training dataset
2023-04-25 08:37:11,913:INFO:Defining folds
2023-04-25 08:37:11,914:INFO:Declaring metric variables
2023-04-25 08:37:11,916:INFO:Importing untrained model
2023-04-25 08:37:11,920:INFO:Ridge Regression Imported successfully
2023-04-25 08:37:11,925:INFO:Starting cross validation
2023-04-25 08:37:11,926:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:12,548:INFO:Calculating mean and std
2023-04-25 08:37:12,548:INFO:Creating metrics dataframe
2023-04-25 08:37:12,730:INFO:Uploading results into container
2023-04-25 08:37:12,731:INFO:Uploading model into container now
2023-04-25 08:37:12,731:INFO:_master_model_container: 3
2023-04-25 08:37:12,731:INFO:_display_container: 2
2023-04-25 08:37:12,732:INFO:Ridge(random_state=7854)
2023-04-25 08:37:12,732:INFO:create_model() successfully completed......................................
2023-04-25 08:37:12,865:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:12,865:INFO:Creating metrics dataframe
2023-04-25 08:37:12,873:INFO:Initializing Elastic Net
2023-04-25 08:37:12,873:INFO:Total runtime is 0.04819790919621786 minutes
2023-04-25 08:37:12,878:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:12,878:INFO:Initializing create_model()
2023-04-25 08:37:12,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:12,878:INFO:Checking exceptions
2023-04-25 08:37:12,879:INFO:Importing libraries
2023-04-25 08:37:12,879:INFO:Copying training dataset
2023-04-25 08:37:12,881:INFO:Defining folds
2023-04-25 08:37:12,881:INFO:Declaring metric variables
2023-04-25 08:37:12,885:INFO:Importing untrained model
2023-04-25 08:37:12,888:INFO:Elastic Net Imported successfully
2023-04-25 08:37:12,896:INFO:Starting cross validation
2023-04-25 08:37:12,897:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:13,543:INFO:Calculating mean and std
2023-04-25 08:37:13,544:INFO:Creating metrics dataframe
2023-04-25 08:37:13,724:INFO:Uploading results into container
2023-04-25 08:37:13,725:INFO:Uploading model into container now
2023-04-25 08:37:13,725:INFO:_master_model_container: 4
2023-04-25 08:37:13,725:INFO:_display_container: 2
2023-04-25 08:37:13,725:INFO:ElasticNet(random_state=7854)
2023-04-25 08:37:13,725:INFO:create_model() successfully completed......................................
2023-04-25 08:37:13,854:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:13,854:INFO:Creating metrics dataframe
2023-04-25 08:37:13,861:INFO:Initializing Least Angle Regression
2023-04-25 08:37:13,861:INFO:Total runtime is 0.0646601676940918 minutes
2023-04-25 08:37:13,864:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:13,865:INFO:Initializing create_model()
2023-04-25 08:37:13,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:13,865:INFO:Checking exceptions
2023-04-25 08:37:13,865:INFO:Importing libraries
2023-04-25 08:37:13,865:INFO:Copying training dataset
2023-04-25 08:37:13,869:INFO:Defining folds
2023-04-25 08:37:13,869:INFO:Declaring metric variables
2023-04-25 08:37:13,872:INFO:Importing untrained model
2023-04-25 08:37:13,876:INFO:Least Angle Regression Imported successfully
2023-04-25 08:37:13,884:INFO:Starting cross validation
2023-04-25 08:37:13,885:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:13,926:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:13,931:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:13,939:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:13,939:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:13,942:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:14,532:INFO:Calculating mean and std
2023-04-25 08:37:14,534:INFO:Creating metrics dataframe
2023-04-25 08:37:14,724:INFO:Uploading results into container
2023-04-25 08:37:14,725:INFO:Uploading model into container now
2023-04-25 08:37:14,725:INFO:_master_model_container: 5
2023-04-25 08:37:14,725:INFO:_display_container: 2
2023-04-25 08:37:14,725:INFO:Lars(random_state=7854)
2023-04-25 08:37:14,725:INFO:create_model() successfully completed......................................
2023-04-25 08:37:14,847:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:14,847:INFO:Creating metrics dataframe
2023-04-25 08:37:14,854:INFO:Initializing Lasso Least Angle Regression
2023-04-25 08:37:14,854:INFO:Total runtime is 0.08122154474258424 minutes
2023-04-25 08:37:14,857:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:14,858:INFO:Initializing create_model()
2023-04-25 08:37:14,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:14,858:INFO:Checking exceptions
2023-04-25 08:37:14,858:INFO:Importing libraries
2023-04-25 08:37:14,858:INFO:Copying training dataset
2023-04-25 08:37:14,862:INFO:Defining folds
2023-04-25 08:37:14,862:INFO:Declaring metric variables
2023-04-25 08:37:14,864:INFO:Importing untrained model
2023-04-25 08:37:14,868:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 08:37:14,874:INFO:Starting cross validation
2023-04-25 08:37:14,875:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:14,913:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:37:14,918:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:37:14,930:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:37:14,934:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:37:14,946:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 08:37:15,538:INFO:Calculating mean and std
2023-04-25 08:37:15,539:INFO:Creating metrics dataframe
2023-04-25 08:37:15,710:INFO:Uploading results into container
2023-04-25 08:37:15,711:INFO:Uploading model into container now
2023-04-25 08:37:15,711:INFO:_master_model_container: 6
2023-04-25 08:37:15,711:INFO:_display_container: 2
2023-04-25 08:37:15,712:INFO:LassoLars(random_state=7854)
2023-04-25 08:37:15,712:INFO:create_model() successfully completed......................................
2023-04-25 08:37:15,831:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:15,831:INFO:Creating metrics dataframe
2023-04-25 08:37:15,839:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 08:37:15,839:INFO:Total runtime is 0.09763635794321697 minutes
2023-04-25 08:37:15,842:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:15,842:INFO:Initializing create_model()
2023-04-25 08:37:15,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:15,843:INFO:Checking exceptions
2023-04-25 08:37:15,843:INFO:Importing libraries
2023-04-25 08:37:15,843:INFO:Copying training dataset
2023-04-25 08:37:15,846:INFO:Defining folds
2023-04-25 08:37:15,846:INFO:Declaring metric variables
2023-04-25 08:37:15,849:INFO:Importing untrained model
2023-04-25 08:37:15,853:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 08:37:15,863:INFO:Starting cross validation
2023-04-25 08:37:15,863:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:15,902:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:15,902:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:15,918:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:15,920:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:15,928:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 08:37:16,474:INFO:Calculating mean and std
2023-04-25 08:37:16,475:INFO:Creating metrics dataframe
2023-04-25 08:37:16,647:INFO:Uploading results into container
2023-04-25 08:37:16,648:INFO:Uploading model into container now
2023-04-25 08:37:16,648:INFO:_master_model_container: 7
2023-04-25 08:37:16,648:INFO:_display_container: 2
2023-04-25 08:37:16,648:INFO:OrthogonalMatchingPursuit()
2023-04-25 08:37:16,648:INFO:create_model() successfully completed......................................
2023-04-25 08:37:16,766:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:16,766:INFO:Creating metrics dataframe
2023-04-25 08:37:16,775:INFO:Initializing Bayesian Ridge
2023-04-25 08:37:16,775:INFO:Total runtime is 0.11323944330215455 minutes
2023-04-25 08:37:16,778:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:16,778:INFO:Initializing create_model()
2023-04-25 08:37:16,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:16,778:INFO:Checking exceptions
2023-04-25 08:37:16,778:INFO:Importing libraries
2023-04-25 08:37:16,778:INFO:Copying training dataset
2023-04-25 08:37:16,783:INFO:Defining folds
2023-04-25 08:37:16,783:INFO:Declaring metric variables
2023-04-25 08:37:16,785:INFO:Importing untrained model
2023-04-25 08:37:16,788:INFO:Bayesian Ridge Imported successfully
2023-04-25 08:37:16,794:INFO:Starting cross validation
2023-04-25 08:37:16,794:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:17,399:INFO:Calculating mean and std
2023-04-25 08:37:17,400:INFO:Creating metrics dataframe
2023-04-25 08:37:17,603:INFO:Uploading results into container
2023-04-25 08:37:17,604:INFO:Uploading model into container now
2023-04-25 08:37:17,604:INFO:_master_model_container: 8
2023-04-25 08:37:17,604:INFO:_display_container: 2
2023-04-25 08:37:17,604:INFO:BayesianRidge()
2023-04-25 08:37:17,604:INFO:create_model() successfully completed......................................
2023-04-25 08:37:17,729:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:17,729:INFO:Creating metrics dataframe
2023-04-25 08:37:17,738:INFO:Initializing Passive Aggressive Regressor
2023-04-25 08:37:17,739:INFO:Total runtime is 0.1292913277943929 minutes
2023-04-25 08:37:17,742:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:17,742:INFO:Initializing create_model()
2023-04-25 08:37:17,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:17,742:INFO:Checking exceptions
2023-04-25 08:37:17,743:INFO:Importing libraries
2023-04-25 08:37:17,743:INFO:Copying training dataset
2023-04-25 08:37:17,747:INFO:Defining folds
2023-04-25 08:37:17,747:INFO:Declaring metric variables
2023-04-25 08:37:17,751:INFO:Importing untrained model
2023-04-25 08:37:17,757:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 08:37:17,767:INFO:Starting cross validation
2023-04-25 08:37:17,768:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:18,396:INFO:Calculating mean and std
2023-04-25 08:37:18,398:INFO:Creating metrics dataframe
2023-04-25 08:37:18,579:INFO:Uploading results into container
2023-04-25 08:37:18,580:INFO:Uploading model into container now
2023-04-25 08:37:18,581:INFO:_master_model_container: 9
2023-04-25 08:37:18,581:INFO:_display_container: 2
2023-04-25 08:37:18,581:INFO:PassiveAggressiveRegressor(random_state=7854)
2023-04-25 08:37:18,581:INFO:create_model() successfully completed......................................
2023-04-25 08:37:18,708:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:18,708:INFO:Creating metrics dataframe
2023-04-25 08:37:18,716:INFO:Initializing Huber Regressor
2023-04-25 08:37:18,716:INFO:Total runtime is 0.14557563066482543 minutes
2023-04-25 08:37:18,719:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:18,720:INFO:Initializing create_model()
2023-04-25 08:37:18,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:18,720:INFO:Checking exceptions
2023-04-25 08:37:18,720:INFO:Importing libraries
2023-04-25 08:37:18,720:INFO:Copying training dataset
2023-04-25 08:37:18,724:INFO:Defining folds
2023-04-25 08:37:18,724:INFO:Declaring metric variables
2023-04-25 08:37:18,726:INFO:Importing untrained model
2023-04-25 08:37:18,729:INFO:Huber Regressor Imported successfully
2023-04-25 08:37:18,735:INFO:Starting cross validation
2023-04-25 08:37:18,735:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:19,375:INFO:Calculating mean and std
2023-04-25 08:37:19,376:INFO:Creating metrics dataframe
2023-04-25 08:37:19,548:INFO:Uploading results into container
2023-04-25 08:37:19,548:INFO:Uploading model into container now
2023-04-25 08:37:19,549:INFO:_master_model_container: 10
2023-04-25 08:37:19,549:INFO:_display_container: 2
2023-04-25 08:37:19,549:INFO:HuberRegressor()
2023-04-25 08:37:19,549:INFO:create_model() successfully completed......................................
2023-04-25 08:37:19,679:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:19,679:INFO:Creating metrics dataframe
2023-04-25 08:37:19,687:INFO:Initializing K Neighbors Regressor
2023-04-25 08:37:19,687:INFO:Total runtime is 0.16176904837290446 minutes
2023-04-25 08:37:19,690:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:19,691:INFO:Initializing create_model()
2023-04-25 08:37:19,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:19,691:INFO:Checking exceptions
2023-04-25 08:37:19,691:INFO:Importing libraries
2023-04-25 08:37:19,691:INFO:Copying training dataset
2023-04-25 08:37:19,696:INFO:Defining folds
2023-04-25 08:37:19,696:INFO:Declaring metric variables
2023-04-25 08:37:19,699:INFO:Importing untrained model
2023-04-25 08:37:19,702:INFO:K Neighbors Regressor Imported successfully
2023-04-25 08:37:19,707:INFO:Starting cross validation
2023-04-25 08:37:19,708:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:20,375:INFO:Calculating mean and std
2023-04-25 08:37:20,376:INFO:Creating metrics dataframe
2023-04-25 08:37:20,573:INFO:Uploading results into container
2023-04-25 08:37:20,573:INFO:Uploading model into container now
2023-04-25 08:37:20,573:INFO:_master_model_container: 11
2023-04-25 08:37:20,573:INFO:_display_container: 2
2023-04-25 08:37:20,574:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 08:37:20,574:INFO:create_model() successfully completed......................................
2023-04-25 08:37:20,693:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:20,693:INFO:Creating metrics dataframe
2023-04-25 08:37:20,701:INFO:Initializing Decision Tree Regressor
2023-04-25 08:37:20,701:INFO:Total runtime is 0.17867303291956582 minutes
2023-04-25 08:37:20,704:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:20,705:INFO:Initializing create_model()
2023-04-25 08:37:20,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:20,705:INFO:Checking exceptions
2023-04-25 08:37:20,705:INFO:Importing libraries
2023-04-25 08:37:20,705:INFO:Copying training dataset
2023-04-25 08:37:20,710:INFO:Defining folds
2023-04-25 08:37:20,710:INFO:Declaring metric variables
2023-04-25 08:37:20,713:INFO:Importing untrained model
2023-04-25 08:37:20,715:INFO:Decision Tree Regressor Imported successfully
2023-04-25 08:37:20,721:INFO:Starting cross validation
2023-04-25 08:37:20,722:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:21,366:INFO:Calculating mean and std
2023-04-25 08:37:21,368:INFO:Creating metrics dataframe
2023-04-25 08:37:21,556:INFO:Uploading results into container
2023-04-25 08:37:21,557:INFO:Uploading model into container now
2023-04-25 08:37:21,557:INFO:_master_model_container: 12
2023-04-25 08:37:21,557:INFO:_display_container: 2
2023-04-25 08:37:21,557:INFO:DecisionTreeRegressor(random_state=7854)
2023-04-25 08:37:21,557:INFO:create_model() successfully completed......................................
2023-04-25 08:37:21,677:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:21,677:INFO:Creating metrics dataframe
2023-04-25 08:37:21,684:INFO:Initializing Random Forest Regressor
2023-04-25 08:37:21,684:INFO:Total runtime is 0.19505104621251423 minutes
2023-04-25 08:37:21,688:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:21,688:INFO:Initializing create_model()
2023-04-25 08:37:21,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:21,689:INFO:Checking exceptions
2023-04-25 08:37:21,689:INFO:Importing libraries
2023-04-25 08:37:21,689:INFO:Copying training dataset
2023-04-25 08:37:21,692:INFO:Defining folds
2023-04-25 08:37:21,692:INFO:Declaring metric variables
2023-04-25 08:37:21,695:INFO:Importing untrained model
2023-04-25 08:37:21,698:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:37:21,703:INFO:Starting cross validation
2023-04-25 08:37:21,704:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:22,691:INFO:Calculating mean and std
2023-04-25 08:37:22,692:INFO:Creating metrics dataframe
2023-04-25 08:37:22,901:INFO:Uploading results into container
2023-04-25 08:37:22,902:INFO:Uploading model into container now
2023-04-25 08:37:22,902:INFO:_master_model_container: 13
2023-04-25 08:37:22,902:INFO:_display_container: 2
2023-04-25 08:37:22,902:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:37:22,902:INFO:create_model() successfully completed......................................
2023-04-25 08:37:23,031:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:23,031:INFO:Creating metrics dataframe
2023-04-25 08:37:23,039:INFO:Initializing Extra Trees Regressor
2023-04-25 08:37:23,040:INFO:Total runtime is 0.21764332056045532 minutes
2023-04-25 08:37:23,043:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:23,043:INFO:Initializing create_model()
2023-04-25 08:37:23,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:23,043:INFO:Checking exceptions
2023-04-25 08:37:23,043:INFO:Importing libraries
2023-04-25 08:37:23,044:INFO:Copying training dataset
2023-04-25 08:37:23,047:INFO:Defining folds
2023-04-25 08:37:23,047:INFO:Declaring metric variables
2023-04-25 08:37:23,050:INFO:Importing untrained model
2023-04-25 08:37:23,053:INFO:Extra Trees Regressor Imported successfully
2023-04-25 08:37:23,058:INFO:Starting cross validation
2023-04-25 08:37:23,059:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:24,013:INFO:Calculating mean and std
2023-04-25 08:37:24,014:INFO:Creating metrics dataframe
2023-04-25 08:37:24,207:INFO:Uploading results into container
2023-04-25 08:37:24,208:INFO:Uploading model into container now
2023-04-25 08:37:24,208:INFO:_master_model_container: 14
2023-04-25 08:37:24,208:INFO:_display_container: 2
2023-04-25 08:37:24,208:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:37:24,208:INFO:create_model() successfully completed......................................
2023-04-25 08:37:24,328:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:24,328:INFO:Creating metrics dataframe
2023-04-25 08:37:24,337:INFO:Initializing AdaBoost Regressor
2023-04-25 08:37:24,338:INFO:Total runtime is 0.2392847498257955 minutes
2023-04-25 08:37:24,341:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:24,341:INFO:Initializing create_model()
2023-04-25 08:37:24,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:24,342:INFO:Checking exceptions
2023-04-25 08:37:24,342:INFO:Importing libraries
2023-04-25 08:37:24,342:INFO:Copying training dataset
2023-04-25 08:37:24,346:INFO:Defining folds
2023-04-25 08:37:24,346:INFO:Declaring metric variables
2023-04-25 08:37:24,349:INFO:Importing untrained model
2023-04-25 08:37:24,351:INFO:AdaBoost Regressor Imported successfully
2023-04-25 08:37:24,357:INFO:Starting cross validation
2023-04-25 08:37:24,358:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:25,030:INFO:Calculating mean and std
2023-04-25 08:37:25,032:INFO:Creating metrics dataframe
2023-04-25 08:37:25,205:INFO:Uploading results into container
2023-04-25 08:37:25,206:INFO:Uploading model into container now
2023-04-25 08:37:25,206:INFO:_master_model_container: 15
2023-04-25 08:37:25,206:INFO:_display_container: 2
2023-04-25 08:37:25,206:INFO:AdaBoostRegressor(random_state=7854)
2023-04-25 08:37:25,206:INFO:create_model() successfully completed......................................
2023-04-25 08:37:25,328:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:25,328:INFO:Creating metrics dataframe
2023-04-25 08:37:25,337:INFO:Initializing Gradient Boosting Regressor
2023-04-25 08:37:25,337:INFO:Total runtime is 0.2559354066848755 minutes
2023-04-25 08:37:25,341:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:25,342:INFO:Initializing create_model()
2023-04-25 08:37:25,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:25,342:INFO:Checking exceptions
2023-04-25 08:37:25,342:INFO:Importing libraries
2023-04-25 08:37:25,342:INFO:Copying training dataset
2023-04-25 08:37:25,345:INFO:Defining folds
2023-04-25 08:37:25,345:INFO:Declaring metric variables
2023-04-25 08:37:25,348:INFO:Importing untrained model
2023-04-25 08:37:25,351:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:37:25,356:INFO:Starting cross validation
2023-04-25 08:37:25,357:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:26,054:INFO:Calculating mean and std
2023-04-25 08:37:26,056:INFO:Creating metrics dataframe
2023-04-25 08:37:26,225:INFO:Uploading results into container
2023-04-25 08:37:26,226:INFO:Uploading model into container now
2023-04-25 08:37:26,226:INFO:_master_model_container: 16
2023-04-25 08:37:26,226:INFO:_display_container: 2
2023-04-25 08:37:26,226:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:37:26,226:INFO:create_model() successfully completed......................................
2023-04-25 08:37:26,346:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:26,346:INFO:Creating metrics dataframe
2023-04-25 08:37:26,356:INFO:Initializing Extreme Gradient Boosting
2023-04-25 08:37:26,356:INFO:Total runtime is 0.2729172984759013 minutes
2023-04-25 08:37:26,359:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:26,359:INFO:Initializing create_model()
2023-04-25 08:37:26,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:26,359:INFO:Checking exceptions
2023-04-25 08:37:26,359:INFO:Importing libraries
2023-04-25 08:37:26,359:INFO:Copying training dataset
2023-04-25 08:37:26,363:INFO:Defining folds
2023-04-25 08:37:26,363:INFO:Declaring metric variables
2023-04-25 08:37:26,365:INFO:Importing untrained model
2023-04-25 08:37:26,369:INFO:Extreme Gradient Boosting Imported successfully
2023-04-25 08:37:26,374:INFO:Starting cross validation
2023-04-25 08:37:26,375:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:27,074:INFO:Calculating mean and std
2023-04-25 08:37:27,075:INFO:Creating metrics dataframe
2023-04-25 08:37:27,247:INFO:Uploading results into container
2023-04-25 08:37:27,248:INFO:Uploading model into container now
2023-04-25 08:37:27,248:INFO:_master_model_container: 17
2023-04-25 08:37:27,248:INFO:_display_container: 2
2023-04-25 08:37:27,249:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=7854, ...)
2023-04-25 08:37:27,249:INFO:create_model() successfully completed......................................
2023-04-25 08:37:27,369:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:27,369:INFO:Creating metrics dataframe
2023-04-25 08:37:27,377:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 08:37:27,377:INFO:Total runtime is 0.289933447043101 minutes
2023-04-25 08:37:27,380:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:27,381:INFO:Initializing create_model()
2023-04-25 08:37:27,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:27,381:INFO:Checking exceptions
2023-04-25 08:37:27,381:INFO:Importing libraries
2023-04-25 08:37:27,381:INFO:Copying training dataset
2023-04-25 08:37:27,385:INFO:Defining folds
2023-04-25 08:37:27,386:INFO:Declaring metric variables
2023-04-25 08:37:27,388:INFO:Importing untrained model
2023-04-25 08:37:27,391:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:37:27,397:INFO:Starting cross validation
2023-04-25 08:37:27,398:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:28,108:INFO:Calculating mean and std
2023-04-25 08:37:28,109:INFO:Creating metrics dataframe
2023-04-25 08:37:28,281:INFO:Uploading results into container
2023-04-25 08:37:28,281:INFO:Uploading model into container now
2023-04-25 08:37:28,282:INFO:_master_model_container: 18
2023-04-25 08:37:28,282:INFO:_display_container: 2
2023-04-25 08:37:28,282:INFO:LGBMRegressor(random_state=7854)
2023-04-25 08:37:28,282:INFO:create_model() successfully completed......................................
2023-04-25 08:37:28,402:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:28,402:INFO:Creating metrics dataframe
2023-04-25 08:37:28,411:INFO:Initializing Dummy Regressor
2023-04-25 08:37:28,411:INFO:Total runtime is 0.3071628212928772 minutes
2023-04-25 08:37:28,414:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:28,415:INFO:Initializing create_model()
2023-04-25 08:37:28,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9E9E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:28,415:INFO:Checking exceptions
2023-04-25 08:37:28,415:INFO:Importing libraries
2023-04-25 08:37:28,415:INFO:Copying training dataset
2023-04-25 08:37:28,418:INFO:Defining folds
2023-04-25 08:37:28,418:INFO:Declaring metric variables
2023-04-25 08:37:28,421:INFO:Importing untrained model
2023-04-25 08:37:28,424:INFO:Dummy Regressor Imported successfully
2023-04-25 08:37:28,430:INFO:Starting cross validation
2023-04-25 08:37:28,431:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:29,045:INFO:Calculating mean and std
2023-04-25 08:37:29,046:INFO:Creating metrics dataframe
2023-04-25 08:37:29,218:INFO:Uploading results into container
2023-04-25 08:37:29,218:INFO:Uploading model into container now
2023-04-25 08:37:29,219:INFO:_master_model_container: 19
2023-04-25 08:37:29,219:INFO:_display_container: 2
2023-04-25 08:37:29,219:INFO:DummyRegressor()
2023-04-25 08:37:29,219:INFO:create_model() successfully completed......................................
2023-04-25 08:37:29,339:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:29,339:INFO:Creating metrics dataframe
2023-04-25 08:37:29,357:INFO:Initializing create_model()
2023-04-25 08:37:29,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:29,357:INFO:Checking exceptions
2023-04-25 08:37:29,359:INFO:Importing libraries
2023-04-25 08:37:29,359:INFO:Copying training dataset
2023-04-25 08:37:29,361:INFO:Defining folds
2023-04-25 08:37:29,361:INFO:Declaring metric variables
2023-04-25 08:37:29,362:INFO:Importing untrained model
2023-04-25 08:37:29,362:INFO:Declaring custom model
2023-04-25 08:37:29,362:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:37:29,362:INFO:Cross validation set to False
2023-04-25 08:37:29,363:INFO:Fitting Model
2023-04-25 08:37:29,553:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:37:29,553:INFO:create_model() successfully completed......................................
2023-04-25 08:37:29,676:INFO:Creating Dashboard logs
2023-04-25 08:37:29,680:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:37:29,725:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7854, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:29,801:INFO:Initializing predict_model()
2023-04-25 08:37:29,801:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB69D80>)
2023-04-25 08:37:29,801:INFO:Checking exceptions
2023-04-25 08:37:29,801:INFO:Preloading libraries
2023-04-25 08:37:30,227:INFO:Creating Dashboard logs
2023-04-25 08:37:30,230:INFO:Model: Random Forest Regressor
2023-04-25 08:37:30,276:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:30,658:INFO:Creating Dashboard logs
2023-04-25 08:37:30,661:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:37:30,708:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 7854, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:37:31,058:INFO:Creating Dashboard logs
2023-04-25 08:37:31,062:INFO:Model: AdaBoost Regressor
2023-04-25 08:37:31,112:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 7854}
2023-04-25 08:37:31,533:INFO:Creating Dashboard logs
2023-04-25 08:37:31,535:INFO:Model: Extra Trees Regressor
2023-04-25 08:37:31,578:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:31,923:INFO:Creating Dashboard logs
2023-04-25 08:37:31,926:INFO:Model: K Neighbors Regressor
2023-04-25 08:37:31,970:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-25 08:37:32,324:INFO:Creating Dashboard logs
2023-04-25 08:37:32,327:INFO:Model: Extreme Gradient Boosting
2023-04-25 08:37:32,370:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 7854, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-04-25 08:37:32,739:INFO:Creating Dashboard logs
2023-04-25 08:37:32,742:INFO:Model: Bayesian Ridge
2023-04-25 08:37:32,792:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-25 08:37:33,162:INFO:Creating Dashboard logs
2023-04-25 08:37:33,164:INFO:Model: Lasso Least Angle Regression
2023-04-25 08:37:33,220:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 7854, 'verbose': False}
2023-04-25 08:37:33,613:INFO:Creating Dashboard logs
2023-04-25 08:37:33,616:INFO:Model: Ridge Regression
2023-04-25 08:37:33,662:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 7854, 'solver': 'auto', 'tol': 0.001}
2023-04-25 08:37:34,001:INFO:Creating Dashboard logs
2023-04-25 08:37:34,004:INFO:Model: Lasso Regression
2023-04-25 08:37:34,046:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 7854, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:37:34,430:INFO:Creating Dashboard logs
2023-04-25 08:37:34,433:INFO:Model: Linear Regression
2023-04-25 08:37:34,481:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-25 08:37:34,818:INFO:Creating Dashboard logs
2023-04-25 08:37:34,821:INFO:Model: Least Angle Regression
2023-04-25 08:37:34,863:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 7854, 'verbose': False}
2023-04-25 08:37:35,207:INFO:Creating Dashboard logs
2023-04-25 08:37:35,209:INFO:Model: Decision Tree Regressor
2023-04-25 08:37:35,252:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 7854, 'splitter': 'best'}
2023-04-25 08:37:35,594:INFO:Creating Dashboard logs
2023-04-25 08:37:35,597:INFO:Model: Huber Regressor
2023-04-25 08:37:35,642:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-25 08:37:35,983:INFO:Creating Dashboard logs
2023-04-25 08:37:35,985:INFO:Model: Passive Aggressive Regressor
2023-04-25 08:37:36,030:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 7854, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:36,380:INFO:Creating Dashboard logs
2023-04-25 08:37:36,383:INFO:Model: Elastic Net
2023-04-25 08:37:36,428:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 7854, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 08:37:36,772:INFO:Creating Dashboard logs
2023-04-25 08:37:36,775:INFO:Model: Orthogonal Matching Pursuit
2023-04-25 08:37:36,817:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-25 08:37:37,156:INFO:Creating Dashboard logs
2023-04-25 08:37:37,159:INFO:Model: Dummy Regressor
2023-04-25 08:37:37,203:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-25 08:37:37,556:INFO:_master_model_container: 19
2023-04-25 08:37:37,557:INFO:_display_container: 2
2023-04-25 08:37:37,557:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:37:37,557:INFO:compare_models() successfully completed......................................
2023-04-25 08:37:37,580:INFO:Initializing create_model()
2023-04-25 08:37:37,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=gbr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:37,580:INFO:Checking exceptions
2023-04-25 08:37:37,603:INFO:Importing libraries
2023-04-25 08:37:37,603:INFO:Copying training dataset
2023-04-25 08:37:37,607:INFO:Defining folds
2023-04-25 08:37:37,607:INFO:Declaring metric variables
2023-04-25 08:37:37,610:INFO:Importing untrained model
2023-04-25 08:37:37,616:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:37:37,622:INFO:Starting cross validation
2023-04-25 08:37:37,623:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:38,319:INFO:Calculating mean and std
2023-04-25 08:37:38,320:INFO:Creating metrics dataframe
2023-04-25 08:37:38,324:INFO:Finalizing model
2023-04-25 08:37:38,547:INFO:Creating Dashboard logs
2023-04-25 08:37:38,549:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:37:38,592:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7854, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:38,672:INFO:Initializing predict_model()
2023-04-25 08:37:38,672:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB6B520>)
2023-04-25 08:37:38,672:INFO:Checking exceptions
2023-04-25 08:37:38,672:INFO:Preloading libraries
2023-04-25 08:37:39,099:INFO:Uploading results into container
2023-04-25 08:37:39,100:INFO:Uploading model into container now
2023-04-25 08:37:39,107:INFO:_master_model_container: 20
2023-04-25 08:37:39,107:INFO:_display_container: 3
2023-04-25 08:37:39,108:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:37:39,108:INFO:create_model() successfully completed......................................
2023-04-25 08:37:39,263:INFO:Initializing create_model()
2023-04-25 08:37:39,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:39,263:INFO:Checking exceptions
2023-04-25 08:37:39,287:INFO:Importing libraries
2023-04-25 08:37:39,288:INFO:Copying training dataset
2023-04-25 08:37:39,294:INFO:Defining folds
2023-04-25 08:37:39,294:INFO:Declaring metric variables
2023-04-25 08:37:39,296:INFO:Importing untrained model
2023-04-25 08:37:39,300:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:37:39,306:INFO:Starting cross validation
2023-04-25 08:37:39,307:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:39,963:INFO:Calculating mean and std
2023-04-25 08:37:39,963:INFO:Creating metrics dataframe
2023-04-25 08:37:39,967:INFO:Finalizing model
2023-04-25 08:37:40,224:INFO:Creating Dashboard logs
2023-04-25 08:37:40,227:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:37:40,270:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 7854, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-25 08:37:40,351:INFO:Initializing predict_model()
2023-04-25 08:37:40,351:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A9D9C60>)
2023-04-25 08:37:40,351:INFO:Checking exceptions
2023-04-25 08:37:40,351:INFO:Preloading libraries
2023-04-25 08:37:40,831:INFO:Uploading results into container
2023-04-25 08:37:40,832:INFO:Uploading model into container now
2023-04-25 08:37:40,839:INFO:_master_model_container: 21
2023-04-25 08:37:40,839:INFO:_display_container: 4
2023-04-25 08:37:40,839:INFO:LGBMRegressor(random_state=7854)
2023-04-25 08:37:40,839:INFO:create_model() successfully completed......................................
2023-04-25 08:37:40,999:INFO:Initializing create_model()
2023-04-25 08:37:40,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:41,000:INFO:Checking exceptions
2023-04-25 08:37:41,022:INFO:Importing libraries
2023-04-25 08:37:41,023:INFO:Copying training dataset
2023-04-25 08:37:41,026:INFO:Defining folds
2023-04-25 08:37:41,026:INFO:Declaring metric variables
2023-04-25 08:37:41,030:INFO:Importing untrained model
2023-04-25 08:37:41,032:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:37:41,040:INFO:Starting cross validation
2023-04-25 08:37:41,040:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:41,754:INFO:Calculating mean and std
2023-04-25 08:37:41,754:INFO:Creating metrics dataframe
2023-04-25 08:37:41,758:INFO:Finalizing model
2023-04-25 08:37:42,101:INFO:Creating Dashboard logs
2023-04-25 08:37:42,104:INFO:Model: Random Forest Regressor
2023-04-25 08:37:42,147:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:42,229:INFO:Initializing predict_model()
2023-04-25 08:37:42,230:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A9DB2E0>)
2023-04-25 08:37:42,230:INFO:Checking exceptions
2023-04-25 08:37:42,230:INFO:Preloading libraries
2023-04-25 08:37:42,684:INFO:Uploading results into container
2023-04-25 08:37:42,685:INFO:Uploading model into container now
2023-04-25 08:37:42,692:INFO:_master_model_container: 22
2023-04-25 08:37:42,692:INFO:_display_container: 5
2023-04-25 08:37:42,693:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:37:42,693:INFO:create_model() successfully completed......................................
2023-04-25 08:37:42,854:INFO:Initializing tune_model()
2023-04-25 08:37:42,854:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=7854), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>)
2023-04-25 08:37:42,854:INFO:Checking exceptions
2023-04-25 08:37:42,878:INFO:Copying training dataset
2023-04-25 08:37:42,881:INFO:Checking base model
2023-04-25 08:37:42,882:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:37:42,885:INFO:Declaring metric variables
2023-04-25 08:37:42,888:INFO:Defining Hyperparameters
2023-04-25 08:37:43,018:INFO:Tuning with n_jobs=-1
2023-04-25 08:37:43,018:INFO:Initializing RandomizedSearchCV
2023-04-25 08:37:51,201:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.01}
2023-04-25 08:37:51,202:INFO:Hyperparameter search completed
2023-04-25 08:37:51,202:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:51,202:INFO:Initializing create_model()
2023-04-25 08:37:51,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56AC9C4F0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 210, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 8, 'learning_rate': 0.01})
2023-04-25 08:37:51,203:INFO:Checking exceptions
2023-04-25 08:37:51,203:INFO:Importing libraries
2023-04-25 08:37:51,203:INFO:Copying training dataset
2023-04-25 08:37:51,206:INFO:Defining folds
2023-04-25 08:37:51,206:INFO:Declaring metric variables
2023-04-25 08:37:51,209:INFO:Importing untrained model
2023-04-25 08:37:51,209:INFO:Declaring custom model
2023-04-25 08:37:51,212:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:37:51,216:INFO:Starting cross validation
2023-04-25 08:37:51,217:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:51,968:INFO:Calculating mean and std
2023-04-25 08:37:51,969:INFO:Creating metrics dataframe
2023-04-25 08:37:51,973:INFO:Finalizing model
2023-04-25 08:37:52,386:INFO:Uploading results into container
2023-04-25 08:37:52,387:INFO:Uploading model into container now
2023-04-25 08:37:52,387:INFO:_master_model_container: 23
2023-04-25 08:37:52,388:INFO:_display_container: 6
2023-04-25 08:37:52,388:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features=1.0,
                          min_impurity_decrease=0.0005, min_samples_leaf=5,
                          min_samples_split=7, n_estimators=210,
                          random_state=7854, subsample=0.7)
2023-04-25 08:37:52,388:INFO:create_model() successfully completed......................................
2023-04-25 08:37:52,515:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:52,515:INFO:choose_better activated
2023-04-25 08:37:52,517:INFO:SubProcess create_model() called ==================================
2023-04-25 08:37:52,518:INFO:Initializing create_model()
2023-04-25 08:37:52,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:37:52,518:INFO:Checking exceptions
2023-04-25 08:37:52,519:INFO:Importing libraries
2023-04-25 08:37:52,519:INFO:Copying training dataset
2023-04-25 08:37:52,521:INFO:Defining folds
2023-04-25 08:37:52,521:INFO:Declaring metric variables
2023-04-25 08:37:52,521:INFO:Importing untrained model
2023-04-25 08:37:52,521:INFO:Declaring custom model
2023-04-25 08:37:52,522:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:37:52,522:INFO:Starting cross validation
2023-04-25 08:37:52,523:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:37:53,268:INFO:Calculating mean and std
2023-04-25 08:37:53,269:INFO:Creating metrics dataframe
2023-04-25 08:37:53,270:INFO:Finalizing model
2023-04-25 08:37:53,500:INFO:Uploading results into container
2023-04-25 08:37:53,501:INFO:Uploading model into container now
2023-04-25 08:37:53,501:INFO:_master_model_container: 24
2023-04-25 08:37:53,501:INFO:_display_container: 7
2023-04-25 08:37:53,501:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:37:53,501:INFO:create_model() successfully completed......................................
2023-04-25 08:37:53,619:INFO:SubProcess create_model() end ==================================
2023-04-25 08:37:53,620:INFO:GradientBoostingRegressor(random_state=7854) result for RMSE is 4442.3599
2023-04-25 08:37:53,620:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features=1.0,
                          min_impurity_decrease=0.0005, min_samples_leaf=5,
                          min_samples_split=7, n_estimators=210,
                          random_state=7854, subsample=0.7) result for RMSE is 4622.0676
2023-04-25 08:37:53,620:INFO:GradientBoostingRegressor(random_state=7854) is best model
2023-04-25 08:37:53,621:INFO:choose_better completed
2023-04-25 08:37:53,621:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:37:53,621:INFO:Creating Dashboard logs
2023-04-25 08:37:53,623:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:37:53,676:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7854, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:37:53,755:INFO:Initializing predict_model()
2023-04-25 08:37:53,756:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56AB684C0>)
2023-04-25 08:37:53,756:INFO:Checking exceptions
2023-04-25 08:37:53,756:INFO:Preloading libraries
2023-04-25 08:37:54,200:INFO:_master_model_container: 24
2023-04-25 08:37:54,200:INFO:_display_container: 6
2023-04-25 08:37:54,201:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:37:54,201:INFO:tune_model() successfully completed......................................
2023-04-25 08:37:54,465:INFO:Initializing tune_model()
2023-04-25 08:37:54,465:INFO:tune_model(estimator=LGBMRegressor(random_state=7854), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>)
2023-04-25 08:37:54,465:INFO:Checking exceptions
2023-04-25 08:37:54,491:INFO:Copying training dataset
2023-04-25 08:37:54,493:INFO:Checking base model
2023-04-25 08:37:54,493:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:37:54,497:INFO:Declaring metric variables
2023-04-25 08:37:54,503:INFO:Defining Hyperparameters
2023-04-25 08:37:54,632:INFO:Tuning with n_jobs=-1
2023-04-25 08:37:54,632:INFO:Initializing RandomizedSearchCV
2023-04-25 08:38:02,283:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 1.0}
2023-04-25 08:38:02,284:INFO:Hyperparameter search completed
2023-04-25 08:38:02,284:INFO:SubProcess create_model() called ==================================
2023-04-25 08:38:02,284:INFO:Initializing create_model()
2023-04-25 08:38:02,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A6B9CF0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.3, 'reg_alpha': 0.4, 'num_leaves': 150, 'n_estimators': 170, 'min_split_gain': 0.8, 'min_child_samples': 66, 'learning_rate': 0.3, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 1.0})
2023-04-25 08:38:02,284:INFO:Checking exceptions
2023-04-25 08:38:02,285:INFO:Importing libraries
2023-04-25 08:38:02,285:INFO:Copying training dataset
2023-04-25 08:38:02,287:INFO:Defining folds
2023-04-25 08:38:02,287:INFO:Declaring metric variables
2023-04-25 08:38:02,290:INFO:Importing untrained model
2023-04-25 08:38:02,290:INFO:Declaring custom model
2023-04-25 08:38:02,293:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:38:02,300:INFO:Starting cross validation
2023-04-25 08:38:02,300:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:38:02,965:INFO:Calculating mean and std
2023-04-25 08:38:02,966:INFO:Creating metrics dataframe
2023-04-25 08:38:02,969:INFO:Finalizing model
2023-04-25 08:38:02,994:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:38:02,994:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:38:02,994:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-04-25 08:38:03,223:INFO:Uploading results into container
2023-04-25 08:38:03,224:INFO:Uploading model into container now
2023-04-25 08:38:03,225:INFO:_master_model_container: 25
2023-04-25 08:38:03,225:INFO:_display_container: 7
2023-04-25 08:38:03,226:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3)
2023-04-25 08:38:03,226:INFO:create_model() successfully completed......................................
2023-04-25 08:38:03,352:INFO:SubProcess create_model() end ==================================
2023-04-25 08:38:03,352:INFO:choose_better activated
2023-04-25 08:38:03,355:INFO:SubProcess create_model() called ==================================
2023-04-25 08:38:03,355:INFO:Initializing create_model()
2023-04-25 08:38:03,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:38:03,355:INFO:Checking exceptions
2023-04-25 08:38:03,356:INFO:Importing libraries
2023-04-25 08:38:03,356:INFO:Copying training dataset
2023-04-25 08:38:03,359:INFO:Defining folds
2023-04-25 08:38:03,359:INFO:Declaring metric variables
2023-04-25 08:38:03,359:INFO:Importing untrained model
2023-04-25 08:38:03,359:INFO:Declaring custom model
2023-04-25 08:38:03,360:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:38:03,360:INFO:Starting cross validation
2023-04-25 08:38:03,361:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:38:04,026:INFO:Calculating mean and std
2023-04-25 08:38:04,026:INFO:Creating metrics dataframe
2023-04-25 08:38:04,027:INFO:Finalizing model
2023-04-25 08:38:04,286:INFO:Uploading results into container
2023-04-25 08:38:04,286:INFO:Uploading model into container now
2023-04-25 08:38:04,287:INFO:_master_model_container: 26
2023-04-25 08:38:04,287:INFO:_display_container: 8
2023-04-25 08:38:04,287:INFO:LGBMRegressor(random_state=7854)
2023-04-25 08:38:04,287:INFO:create_model() successfully completed......................................
2023-04-25 08:38:04,406:INFO:SubProcess create_model() end ==================================
2023-04-25 08:38:04,406:INFO:LGBMRegressor(random_state=7854) result for RMSE is 4742.7859
2023-04-25 08:38:04,407:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3) result for RMSE is 4627.5319
2023-04-25 08:38:04,407:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3) is best model
2023-04-25 08:38:04,407:INFO:choose_better completed
2023-04-25 08:38:04,407:INFO:Creating Dashboard logs
2023-04-25 08:38:04,410:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:38:04,455:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': -1, 'min_child_samples': 66, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 170, 'n_jobs': -1, 'num_leaves': 150, 'objective': None, 'random_state': 7854, 'reg_alpha': 0.4, 'reg_lambda': 0.3, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 1.0}
2023-04-25 08:38:04,536:INFO:Initializing predict_model()
2023-04-25 08:38:04,537:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A9DA9E0>)
2023-04-25 08:38:04,537:INFO:Checking exceptions
2023-04-25 08:38:04,537:INFO:Preloading libraries
2023-04-25 08:38:05,043:INFO:_master_model_container: 26
2023-04-25 08:38:05,043:INFO:_display_container: 7
2023-04-25 08:38:05,043:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3)
2023-04-25 08:38:05,044:INFO:tune_model() successfully completed......................................
2023-04-25 08:38:05,303:INFO:Initializing tune_model()
2023-04-25 08:38:05,303:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=5, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>)
2023-04-25 08:38:05,303:INFO:Checking exceptions
2023-04-25 08:38:05,328:INFO:Copying training dataset
2023-04-25 08:38:05,330:INFO:Checking base model
2023-04-25 08:38:05,331:INFO:Base model : Random Forest Regressor
2023-04-25 08:38:05,335:INFO:Declaring metric variables
2023-04-25 08:38:05,340:INFO:Defining Hyperparameters
2023-04-25 08:38:05,472:INFO:Tuning with n_jobs=-1
2023-04-25 08:38:05,472:INFO:Initializing RandomizedSearchCV
2023-04-25 08:38:06,367:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:38:17,279:INFO:best_params: {'actual_estimator__n_estimators': 40, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2023-04-25 08:38:17,279:INFO:Hyperparameter search completed
2023-04-25 08:38:17,280:INFO:SubProcess create_model() called ==================================
2023-04-25 08:38:17,280:INFO:Initializing create_model()
2023-04-25 08:38:17,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A54D8A0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 8, 'criterion': 'absolute_error', 'bootstrap': False})
2023-04-25 08:38:17,280:INFO:Checking exceptions
2023-04-25 08:38:17,280:INFO:Importing libraries
2023-04-25 08:38:17,280:INFO:Copying training dataset
2023-04-25 08:38:17,283:INFO:Defining folds
2023-04-25 08:38:17,283:INFO:Declaring metric variables
2023-04-25 08:38:17,286:INFO:Importing untrained model
2023-04-25 08:38:17,286:INFO:Declaring custom model
2023-04-25 08:38:17,289:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:38:17,294:INFO:Starting cross validation
2023-04-25 08:38:17,295:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:38:18,290:INFO:Calculating mean and std
2023-04-25 08:38:18,291:INFO:Creating metrics dataframe
2023-04-25 08:38:18,295:INFO:Finalizing model
2023-04-25 08:38:18,657:INFO:Uploading results into container
2023-04-25 08:38:18,658:INFO:Uploading model into container now
2023-04-25 08:38:18,659:INFO:_master_model_container: 27
2023-04-25 08:38:18,659:INFO:_display_container: 8
2023-04-25 08:38:18,659:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=8,
                      max_features='log2', min_impurity_decrease=0.001,
                      min_samples_leaf=2, min_samples_split=5, n_estimators=40,
                      n_jobs=-1, random_state=7854)
2023-04-25 08:38:18,660:INFO:create_model() successfully completed......................................
2023-04-25 08:38:18,801:INFO:SubProcess create_model() end ==================================
2023-04-25 08:38:18,801:INFO:choose_better activated
2023-04-25 08:38:18,804:INFO:SubProcess create_model() called ==================================
2023-04-25 08:38:18,804:INFO:Initializing create_model()
2023-04-25 08:38:18,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:38:18,804:INFO:Checking exceptions
2023-04-25 08:38:18,806:INFO:Importing libraries
2023-04-25 08:38:18,806:INFO:Copying training dataset
2023-04-25 08:38:18,808:INFO:Defining folds
2023-04-25 08:38:18,809:INFO:Declaring metric variables
2023-04-25 08:38:18,809:INFO:Importing untrained model
2023-04-25 08:38:18,809:INFO:Declaring custom model
2023-04-25 08:38:18,809:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:38:18,809:INFO:Starting cross validation
2023-04-25 08:38:18,810:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:38:19,588:INFO:Calculating mean and std
2023-04-25 08:38:19,588:INFO:Creating metrics dataframe
2023-04-25 08:38:19,589:INFO:Finalizing model
2023-04-25 08:38:19,814:INFO:Uploading results into container
2023-04-25 08:38:19,814:INFO:Uploading model into container now
2023-04-25 08:38:19,815:INFO:_master_model_container: 28
2023-04-25 08:38:19,815:INFO:_display_container: 9
2023-04-25 08:38:19,815:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:38:19,815:INFO:create_model() successfully completed......................................
2023-04-25 08:38:19,937:INFO:SubProcess create_model() end ==================================
2023-04-25 08:38:19,937:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854) result for RMSE is 4605.5636
2023-04-25 08:38:19,938:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=8,
                      max_features='log2', min_impurity_decrease=0.001,
                      min_samples_leaf=2, min_samples_split=5, n_estimators=40,
                      n_jobs=-1, random_state=7854) result for RMSE is 4610.2274
2023-04-25 08:38:19,938:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854) is best model
2023-04-25 08:38:19,938:INFO:choose_better completed
2023-04-25 08:38:19,938:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:38:19,938:INFO:Creating Dashboard logs
2023-04-25 08:38:19,941:INFO:Model: Random Forest Regressor
2023-04-25 08:38:19,991:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:38:20,070:INFO:Initializing predict_model()
2023-04-25 08:38:20,070:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A9DAF80>)
2023-04-25 08:38:20,070:INFO:Checking exceptions
2023-04-25 08:38:20,070:INFO:Preloading libraries
2023-04-25 08:38:20,552:INFO:_master_model_container: 28
2023-04-25 08:38:20,552:INFO:_display_container: 8
2023-04-25 08:38:20,552:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:38:20,552:INFO:tune_model() successfully completed......................................
2023-04-25 08:38:20,840:INFO:Initializing plot_model()
2023-04-25 08:38:20,840:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:38:20,840:INFO:Checking exceptions
2023-04-25 08:38:20,847:INFO:Preloading libraries
2023-04-25 08:38:20,852:INFO:Copying training dataset
2023-04-25 08:38:20,852:INFO:Plot type: error
2023-04-25 08:38:20,913:INFO:Fitting Model
2023-04-25 08:38:20,913:INFO:Scoring test/hold-out set
2023-04-25 08:38:21,079:INFO:Visual Rendered Successfully
2023-04-25 08:38:21,207:INFO:plot_model() successfully completed......................................
2023-04-25 08:38:21,214:INFO:Initializing plot_model()
2023-04-25 08:38:21,214:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:38:21,214:INFO:Checking exceptions
2023-04-25 08:38:21,217:INFO:Preloading libraries
2023-04-25 08:38:21,223:INFO:Copying training dataset
2023-04-25 08:38:21,223:INFO:Plot type: error
2023-04-25 08:38:21,289:INFO:Fitting Model
2023-04-25 08:38:21,289:INFO:Scoring test/hold-out set
2023-04-25 08:38:21,468:INFO:Visual Rendered Successfully
2023-04-25 08:38:21,590:INFO:plot_model() successfully completed......................................
2023-04-25 08:38:21,598:INFO:Initializing plot_model()
2023-04-25 08:38:21,598:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:38:21,598:INFO:Checking exceptions
2023-04-25 08:38:21,615:INFO:Preloading libraries
2023-04-25 08:38:21,624:INFO:Copying training dataset
2023-04-25 08:38:21,624:INFO:Plot type: error
2023-04-25 08:38:21,675:INFO:Fitting Model
2023-04-25 08:38:21,675:INFO:Scoring test/hold-out set
2023-04-25 08:38:21,846:INFO:Visual Rendered Successfully
2023-04-25 08:38:21,977:INFO:plot_model() successfully completed......................................
2023-04-25 08:38:22,012:INFO:Initializing plot_model()
2023-04-25 08:38:22,012:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:38:22,012:INFO:Checking exceptions
2023-04-25 08:38:22,016:INFO:Preloading libraries
2023-04-25 08:38:22,021:INFO:Copying training dataset
2023-04-25 08:38:22,021:INFO:Plot type: feature
2023-04-25 08:38:22,022:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:38:22,150:INFO:Visual Rendered Successfully
2023-04-25 08:38:22,272:INFO:plot_model() successfully completed......................................
2023-04-25 08:38:22,273:INFO:Initializing plot_model()
2023-04-25 08:38:22,273:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:38:22,273:INFO:Checking exceptions
2023-04-25 08:38:22,276:INFO:Preloading libraries
2023-04-25 08:38:22,283:INFO:Copying training dataset
2023-04-25 08:38:22,283:INFO:Plot type: feature
2023-04-25 08:38:22,283:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:38:22,431:INFO:Visual Rendered Successfully
2023-04-25 08:38:22,551:INFO:plot_model() successfully completed......................................
2023-04-25 08:38:22,552:INFO:Initializing plot_model()
2023-04-25 08:38:22,552:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:38:22,552:INFO:Checking exceptions
2023-04-25 08:38:22,571:INFO:Preloading libraries
2023-04-25 08:38:22,583:INFO:Copying training dataset
2023-04-25 08:38:22,583:INFO:Plot type: feature
2023-04-25 08:38:22,583:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:38:22,714:INFO:Visual Rendered Successfully
2023-04-25 08:38:22,833:INFO:plot_model() successfully completed......................................
2023-04-25 08:38:22,853:INFO:Initializing predict_model()
2023-04-25 08:38:22,853:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0FE4D0>)
2023-04-25 08:38:22,853:INFO:Checking exceptions
2023-04-25 08:38:22,854:INFO:Preloading libraries
2023-04-25 08:38:23,027:INFO:Initializing predict_model()
2023-04-25 08:38:23,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0FE4D0>)
2023-04-25 08:38:23,027:INFO:Checking exceptions
2023-04-25 08:38:23,028:INFO:Preloading libraries
2023-04-25 08:38:23,228:INFO:Initializing predict_model()
2023-04-25 08:38:23,229:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0FC700>)
2023-04-25 08:38:23,229:INFO:Checking exceptions
2023-04-25 08:38:23,229:INFO:Preloading libraries
2023-04-25 08:38:23,414:INFO:Initializing finalize_model()
2023-04-25 08:38:23,414:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:38:23,414:INFO:Finalizing GradientBoostingRegressor(random_state=7854)
2023-04-25 08:38:23,417:INFO:Initializing create_model()
2023-04-25 08:38:23,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:38:23,417:INFO:Checking exceptions
2023-04-25 08:38:23,421:INFO:Importing libraries
2023-04-25 08:38:23,421:INFO:Copying training dataset
2023-04-25 08:38:23,422:INFO:Defining folds
2023-04-25 08:38:23,422:INFO:Declaring metric variables
2023-04-25 08:38:23,422:INFO:Importing untrained model
2023-04-25 08:38:23,422:INFO:Declaring custom model
2023-04-25 08:38:23,423:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:38:23,423:INFO:Cross validation set to False
2023-04-25 08:38:23,423:INFO:Fitting Model
2023-04-25 08:38:23,511:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))])
2023-04-25 08:38:23,511:INFO:create_model() successfully completed......................................
2023-04-25 08:38:23,632:INFO:Creating Dashboard logs
2023-04-25 08:38:23,633:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:38:23,672:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7854, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:38:24,011:INFO:_master_model_container: 28
2023-04-25 08:38:24,011:INFO:_display_container: 11
2023-04-25 08:38:24,015:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))])
2023-04-25 08:38:24,015:INFO:finalize_model() successfully completed......................................
2023-04-25 08:38:24,274:INFO:Initializing finalize_model()
2023-04-25 08:38:24,274:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:38:24,275:INFO:Finalizing LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3)
2023-04-25 08:38:24,277:INFO:Initializing create_model()
2023-04-25 08:38:24,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:38:24,277:INFO:Checking exceptions
2023-04-25 08:38:24,278:INFO:Importing libraries
2023-04-25 08:38:24,278:INFO:Copying training dataset
2023-04-25 08:38:24,279:INFO:Defining folds
2023-04-25 08:38:24,279:INFO:Declaring metric variables
2023-04-25 08:38:24,279:INFO:Importing untrained model
2023-04-25 08:38:24,279:INFO:Declaring custom model
2023-04-25 08:38:24,279:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:38:24,280:INFO:Cross validation set to False
2023-04-25 08:38:24,280:INFO:Fitting Model
2023-04-25 08:38:24,297:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:38:24,297:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:38:24,297:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-04-25 08:38:24,344:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=0,
                               feature_fraction=0.5, learning_rate=0.3,
                               min_child_samples=66, min_split_gain=0.8,
                               n_estimators=170, num_leaves=150,
                               random_state=7854, reg_alpha=0.4,
                               reg_lambda=0.3))])
2023-04-25 08:38:24,344:INFO:create_model() successfully completed......................................
2023-04-25 08:38:24,492:INFO:Creating Dashboard logs
2023-04-25 08:38:24,493:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:38:24,536:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': -1, 'min_child_samples': 66, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 170, 'n_jobs': -1, 'num_leaves': 150, 'objective': None, 'random_state': 7854, 'reg_alpha': 0.4, 'reg_lambda': 0.3, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 1.0}
2023-04-25 08:38:24,891:INFO:_master_model_container: 28
2023-04-25 08:38:24,892:INFO:_display_container: 11
2023-04-25 08:38:24,896:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=0,
                               feature_fraction=0.5, learning_rate=0.3,
                               min_child_samples=66, min_split_gain=0.8,
                               n_estimators=170, num_leaves=150,
                               random_state=7854, reg_alpha=0.4,
                               reg_lambda=0.3))])
2023-04-25 08:38:24,896:INFO:finalize_model() successfully completed......................................
2023-04-25 08:38:25,147:INFO:Initializing finalize_model()
2023-04-25 08:38:25,147:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:38:25,147:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:38:25,149:INFO:Initializing create_model()
2023-04-25 08:38:25,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:38:25,149:INFO:Checking exceptions
2023-04-25 08:38:25,150:INFO:Importing libraries
2023-04-25 08:38:25,150:INFO:Copying training dataset
2023-04-25 08:38:25,150:INFO:Defining folds
2023-04-25 08:38:25,150:INFO:Declaring metric variables
2023-04-25 08:38:25,150:INFO:Importing untrained model
2023-04-25 08:38:25,150:INFO:Declaring custom model
2023-04-25 08:38:25,151:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:38:25,151:INFO:Cross validation set to False
2023-04-25 08:38:25,151:INFO:Fitting Model
2023-04-25 08:38:25,322:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=7854))])
2023-04-25 08:38:25,322:INFO:create_model() successfully completed......................................
2023-04-25 08:38:25,441:INFO:Creating Dashboard logs
2023-04-25 08:38:25,442:INFO:Model: Random Forest Regressor
2023-04-25 08:38:25,487:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:38:25,833:INFO:_master_model_container: 28
2023-04-25 08:38:25,833:INFO:_display_container: 11
2023-04-25 08:38:25,837:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=7854))])
2023-04-25 08:38:25,837:INFO:finalize_model() successfully completed......................................
2023-04-25 08:38:26,102:INFO:Initializing predict_model()
2023-04-25 08:38:26,103:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561FF0550>)
2023-04-25 08:38:26,103:INFO:Checking exceptions
2023-04-25 08:38:26,103:INFO:Preloading libraries
2023-04-25 08:38:26,106:INFO:Set up data.
2023-04-25 08:38:26,110:INFO:Set up index.
2023-04-25 08:38:26,304:INFO:Initializing predict_model()
2023-04-25 08:38:26,304:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=0,
                               feature_fraction=0.5, learning_rate=0.3,
                               min_child_samples=66, min_split_gain=0.8,
                               n_estimators=170, num_leaves=150,
                               random_state=7854, reg_alpha=0.4,
                               reg_lambda=0.3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561FF1AB0>)
2023-04-25 08:38:26,305:INFO:Checking exceptions
2023-04-25 08:38:26,305:INFO:Preloading libraries
2023-04-25 08:38:26,307:INFO:Set up data.
2023-04-25 08:38:26,313:INFO:Set up index.
2023-04-25 08:38:26,541:INFO:Initializing predict_model()
2023-04-25 08:38:26,541:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=7854))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561FF0790>)
2023-04-25 08:38:26,541:INFO:Checking exceptions
2023-04-25 08:38:26,541:INFO:Preloading libraries
2023-04-25 08:38:26,543:INFO:Set up data.
2023-04-25 08:38:26,549:INFO:Set up index.
2023-04-25 08:42:19,327:INFO:Initializing tune_model()
2023-04-25 08:42:19,327:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=7854), fold=10, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>)
2023-04-25 08:42:19,327:INFO:Checking exceptions
2023-04-25 08:42:19,349:INFO:Copying training dataset
2023-04-25 08:42:19,351:INFO:Checking base model
2023-04-25 08:42:19,352:INFO:Base model : Gradient Boosting Regressor
2023-04-25 08:42:19,355:INFO:Declaring metric variables
2023-04-25 08:42:19,360:INFO:Defining Hyperparameters
2023-04-25 08:42:19,503:INFO:Tuning with n_jobs=-1
2023-04-25 08:42:19,503:INFO:Initializing RandomizedSearchCV
2023-04-25 08:42:37,981:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.01}
2023-04-25 08:42:37,982:INFO:Hyperparameter search completed
2023-04-25 08:42:37,982:INFO:SubProcess create_model() called ==================================
2023-04-25 08:42:37,983:INFO:Initializing create_model()
2023-04-25 08:42:37,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56233CCD0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 210, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 8, 'learning_rate': 0.01})
2023-04-25 08:42:37,983:INFO:Checking exceptions
2023-04-25 08:42:37,983:INFO:Importing libraries
2023-04-25 08:42:37,983:INFO:Copying training dataset
2023-04-25 08:42:37,987:INFO:Defining folds
2023-04-25 08:42:37,988:INFO:Declaring metric variables
2023-04-25 08:42:37,990:INFO:Importing untrained model
2023-04-25 08:42:37,990:INFO:Declaring custom model
2023-04-25 08:42:37,993:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:42:37,998:INFO:Starting cross validation
2023-04-25 08:42:37,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:42:39,766:INFO:Calculating mean and std
2023-04-25 08:42:39,767:INFO:Creating metrics dataframe
2023-04-25 08:42:39,772:INFO:Finalizing model
2023-04-25 08:42:40,022:INFO:Uploading results into container
2023-04-25 08:42:40,023:INFO:Uploading model into container now
2023-04-25 08:42:40,024:INFO:_master_model_container: 29
2023-04-25 08:42:40,024:INFO:_display_container: 15
2023-04-25 08:42:40,024:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features=1.0,
                          min_impurity_decrease=0.0005, min_samples_leaf=5,
                          min_samples_split=7, n_estimators=210,
                          random_state=7854, subsample=0.7)
2023-04-25 08:42:40,024:INFO:create_model() successfully completed......................................
2023-04-25 08:42:40,183:INFO:SubProcess create_model() end ==================================
2023-04-25 08:42:40,183:INFO:choose_better activated
2023-04-25 08:42:40,186:INFO:SubProcess create_model() called ==================================
2023-04-25 08:42:40,186:INFO:Initializing create_model()
2023-04-25 08:42:40,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:42:40,187:INFO:Checking exceptions
2023-04-25 08:42:40,188:INFO:Importing libraries
2023-04-25 08:42:40,188:INFO:Copying training dataset
2023-04-25 08:42:40,191:INFO:Defining folds
2023-04-25 08:42:40,191:INFO:Declaring metric variables
2023-04-25 08:42:40,191:INFO:Importing untrained model
2023-04-25 08:42:40,191:INFO:Declaring custom model
2023-04-25 08:42:40,192:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:42:40,192:INFO:Starting cross validation
2023-04-25 08:42:40,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:42:41,937:INFO:Calculating mean and std
2023-04-25 08:42:41,937:INFO:Creating metrics dataframe
2023-04-25 08:42:41,939:INFO:Finalizing model
2023-04-25 08:42:42,200:INFO:Uploading results into container
2023-04-25 08:42:42,201:INFO:Uploading model into container now
2023-04-25 08:42:42,201:INFO:_master_model_container: 30
2023-04-25 08:42:42,201:INFO:_display_container: 16
2023-04-25 08:42:42,202:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:42:42,202:INFO:create_model() successfully completed......................................
2023-04-25 08:42:42,341:INFO:SubProcess create_model() end ==================================
2023-04-25 08:42:42,342:INFO:GradientBoostingRegressor(random_state=7854) result for RMSE is 4368.5465
2023-04-25 08:42:42,342:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features=1.0,
                          min_impurity_decrease=0.0005, min_samples_leaf=5,
                          min_samples_split=7, n_estimators=210,
                          random_state=7854, subsample=0.7) result for RMSE is 4549.2736
2023-04-25 08:42:42,342:INFO:GradientBoostingRegressor(random_state=7854) is best model
2023-04-25 08:42:42,342:INFO:choose_better completed
2023-04-25 08:42:42,343:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:42:42,344:INFO:Creating Dashboard logs
2023-04-25 08:42:42,347:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:42:42,400:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7854, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:42:42,494:INFO:Initializing predict_model()
2023-04-25 08:42:42,494:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A9D8280>)
2023-04-25 08:42:42,494:INFO:Checking exceptions
2023-04-25 08:42:42,494:INFO:Preloading libraries
2023-04-25 08:42:42,963:INFO:_master_model_container: 30
2023-04-25 08:42:42,963:INFO:_display_container: 15
2023-04-25 08:42:42,963:INFO:GradientBoostingRegressor(random_state=7854)
2023-04-25 08:42:42,963:INFO:tune_model() successfully completed......................................
2023-04-25 08:42:43,262:INFO:Initializing tune_model()
2023-04-25 08:42:43,262:INFO:tune_model(estimator=LGBMRegressor(random_state=7854), fold=10, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>)
2023-04-25 08:42:43,262:INFO:Checking exceptions
2023-04-25 08:42:43,288:INFO:Copying training dataset
2023-04-25 08:42:43,290:INFO:Checking base model
2023-04-25 08:42:43,291:INFO:Base model : Light Gradient Boosting Machine
2023-04-25 08:42:43,294:INFO:Declaring metric variables
2023-04-25 08:42:43,299:INFO:Defining Hyperparameters
2023-04-25 08:42:43,434:INFO:Tuning with n_jobs=-1
2023-04-25 08:42:43,434:INFO:Initializing RandomizedSearchCV
2023-04-25 08:43:01,208:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 1.0}
2023-04-25 08:43:01,210:INFO:Hyperparameter search completed
2023-04-25 08:43:01,210:INFO:SubProcess create_model() called ==================================
2023-04-25 08:43:01,210:INFO:Initializing create_model()
2023-04-25 08:43:01,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(random_state=7854), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D562A0B760>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.3, 'reg_alpha': 0.4, 'num_leaves': 150, 'n_estimators': 170, 'min_split_gain': 0.8, 'min_child_samples': 66, 'learning_rate': 0.3, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 1.0})
2023-04-25 08:43:01,210:INFO:Checking exceptions
2023-04-25 08:43:01,210:INFO:Importing libraries
2023-04-25 08:43:01,210:INFO:Copying training dataset
2023-04-25 08:43:01,213:INFO:Defining folds
2023-04-25 08:43:01,213:INFO:Declaring metric variables
2023-04-25 08:43:01,215:INFO:Importing untrained model
2023-04-25 08:43:01,215:INFO:Declaring custom model
2023-04-25 08:43:01,219:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:43:01,226:INFO:Starting cross validation
2023-04-25 08:43:01,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:43:02,875:INFO:Calculating mean and std
2023-04-25 08:43:02,876:INFO:Creating metrics dataframe
2023-04-25 08:43:02,880:INFO:Finalizing model
2023-04-25 08:43:02,907:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:43:02,907:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:43:02,907:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-04-25 08:43:03,161:INFO:Uploading results into container
2023-04-25 08:43:03,162:INFO:Uploading model into container now
2023-04-25 08:43:03,162:INFO:_master_model_container: 31
2023-04-25 08:43:03,163:INFO:_display_container: 16
2023-04-25 08:43:03,163:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3)
2023-04-25 08:43:03,163:INFO:create_model() successfully completed......................................
2023-04-25 08:43:03,292:INFO:SubProcess create_model() end ==================================
2023-04-25 08:43:03,293:INFO:choose_better activated
2023-04-25 08:43:03,295:INFO:SubProcess create_model() called ==================================
2023-04-25 08:43:03,296:INFO:Initializing create_model()
2023-04-25 08:43:03,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(random_state=7854), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:43:03,296:INFO:Checking exceptions
2023-04-25 08:43:03,297:INFO:Importing libraries
2023-04-25 08:43:03,298:INFO:Copying training dataset
2023-04-25 08:43:03,300:INFO:Defining folds
2023-04-25 08:43:03,300:INFO:Declaring metric variables
2023-04-25 08:43:03,300:INFO:Importing untrained model
2023-04-25 08:43:03,300:INFO:Declaring custom model
2023-04-25 08:43:03,301:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:43:03,301:INFO:Starting cross validation
2023-04-25 08:43:03,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:43:04,898:INFO:Calculating mean and std
2023-04-25 08:43:04,898:INFO:Creating metrics dataframe
2023-04-25 08:43:04,899:INFO:Finalizing model
2023-04-25 08:43:05,182:INFO:Uploading results into container
2023-04-25 08:43:05,182:INFO:Uploading model into container now
2023-04-25 08:43:05,183:INFO:_master_model_container: 32
2023-04-25 08:43:05,183:INFO:_display_container: 17
2023-04-25 08:43:05,183:INFO:LGBMRegressor(random_state=7854)
2023-04-25 08:43:05,183:INFO:create_model() successfully completed......................................
2023-04-25 08:43:05,302:INFO:SubProcess create_model() end ==================================
2023-04-25 08:43:05,302:INFO:LGBMRegressor(random_state=7854) result for RMSE is 4641.0732
2023-04-25 08:43:05,303:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3) result for RMSE is 4567.0983
2023-04-25 08:43:05,303:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3) is best model
2023-04-25 08:43:05,303:INFO:choose_better completed
2023-04-25 08:43:05,303:INFO:Creating Dashboard logs
2023-04-25 08:43:05,306:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:43:05,350:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': -1, 'min_child_samples': 66, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 170, 'n_jobs': -1, 'num_leaves': 150, 'objective': None, 'random_state': 7854, 'reg_alpha': 0.4, 'reg_lambda': 0.3, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 1.0}
2023-04-25 08:43:05,430:INFO:Initializing predict_model()
2023-04-25 08:43:05,431:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A48ED40>)
2023-04-25 08:43:05,431:INFO:Checking exceptions
2023-04-25 08:43:05,431:INFO:Preloading libraries
2023-04-25 08:43:05,946:INFO:_master_model_container: 32
2023-04-25 08:43:05,946:INFO:_display_container: 16
2023-04-25 08:43:05,947:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3)
2023-04-25 08:43:05,947:INFO:tune_model() successfully completed......................................
2023-04-25 08:43:06,229:INFO:Initializing tune_model()
2023-04-25 08:43:06,229:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=10, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>)
2023-04-25 08:43:06,229:INFO:Checking exceptions
2023-04-25 08:43:06,255:INFO:Copying training dataset
2023-04-25 08:43:06,258:INFO:Checking base model
2023-04-25 08:43:06,258:INFO:Base model : Random Forest Regressor
2023-04-25 08:43:06,263:INFO:Declaring metric variables
2023-04-25 08:43:06,269:INFO:Defining Hyperparameters
2023-04-25 08:43:06,400:INFO:Tuning with n_jobs=-1
2023-04-25 08:43:06,400:INFO:Initializing RandomizedSearchCV
2023-04-25 08:43:07,270:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:43:07,293:WARNING:C:\Users\danie\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 08:43:32,394:INFO:best_params: {'actual_estimator__n_estimators': 40, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2023-04-25 08:43:32,395:INFO:Hyperparameter search completed
2023-04-25 08:43:32,395:INFO:SubProcess create_model() called ==================================
2023-04-25 08:43:32,396:INFO:Initializing create_model()
2023-04-25 08:43:32,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D56A5B25F0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 8, 'criterion': 'absolute_error', 'bootstrap': False})
2023-04-25 08:43:32,396:INFO:Checking exceptions
2023-04-25 08:43:32,396:INFO:Importing libraries
2023-04-25 08:43:32,396:INFO:Copying training dataset
2023-04-25 08:43:32,400:INFO:Defining folds
2023-04-25 08:43:32,401:INFO:Declaring metric variables
2023-04-25 08:43:32,403:INFO:Importing untrained model
2023-04-25 08:43:32,403:INFO:Declaring custom model
2023-04-25 08:43:32,406:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:43:32,411:INFO:Starting cross validation
2023-04-25 08:43:32,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:43:34,835:INFO:Calculating mean and std
2023-04-25 08:43:34,836:INFO:Creating metrics dataframe
2023-04-25 08:43:34,839:INFO:Finalizing model
2023-04-25 08:43:35,111:INFO:Uploading results into container
2023-04-25 08:43:35,112:INFO:Uploading model into container now
2023-04-25 08:43:35,112:INFO:_master_model_container: 33
2023-04-25 08:43:35,112:INFO:_display_container: 17
2023-04-25 08:43:35,113:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=8,
                      max_features='log2', min_impurity_decrease=0.001,
                      min_samples_leaf=2, min_samples_split=5, n_estimators=40,
                      n_jobs=-1, random_state=7854)
2023-04-25 08:43:35,113:INFO:create_model() successfully completed......................................
2023-04-25 08:43:35,247:INFO:SubProcess create_model() end ==================================
2023-04-25 08:43:35,247:INFO:choose_better activated
2023-04-25 08:43:35,251:INFO:SubProcess create_model() called ==================================
2023-04-25 08:43:35,251:INFO:Initializing create_model()
2023-04-25 08:43:35,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 08:43:35,251:INFO:Checking exceptions
2023-04-25 08:43:35,253:INFO:Importing libraries
2023-04-25 08:43:35,253:INFO:Copying training dataset
2023-04-25 08:43:35,256:INFO:Defining folds
2023-04-25 08:43:35,256:INFO:Declaring metric variables
2023-04-25 08:43:35,257:INFO:Importing untrained model
2023-04-25 08:43:35,257:INFO:Declaring custom model
2023-04-25 08:43:35,257:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:43:35,257:INFO:Starting cross validation
2023-04-25 08:43:35,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 08:43:37,681:INFO:Calculating mean and std
2023-04-25 08:43:37,681:INFO:Creating metrics dataframe
2023-04-25 08:43:37,683:INFO:Finalizing model
2023-04-25 08:43:37,987:INFO:Uploading results into container
2023-04-25 08:43:37,988:INFO:Uploading model into container now
2023-04-25 08:43:37,988:INFO:_master_model_container: 34
2023-04-25 08:43:37,988:INFO:_display_container: 18
2023-04-25 08:43:37,989:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:43:37,989:INFO:create_model() successfully completed......................................
2023-04-25 08:43:38,139:INFO:SubProcess create_model() end ==================================
2023-04-25 08:43:38,140:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854) result for RMSE is 4527.6768
2023-04-25 08:43:38,141:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=8,
                      max_features='log2', min_impurity_decrease=0.001,
                      min_samples_leaf=2, min_samples_split=5, n_estimators=40,
                      n_jobs=-1, random_state=7854) result for RMSE is 4592.7278
2023-04-25 08:43:38,141:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854) is best model
2023-04-25 08:43:38,141:INFO:choose_better completed
2023-04-25 08:43:38,142:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-25 08:43:38,142:INFO:Creating Dashboard logs
2023-04-25 08:43:38,145:INFO:Model: Random Forest Regressor
2023-04-25 08:43:38,194:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:43:38,270:INFO:Initializing predict_model()
2023-04-25 08:43:38,271:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A63FD00>)
2023-04-25 08:43:38,271:INFO:Checking exceptions
2023-04-25 08:43:38,271:INFO:Preloading libraries
2023-04-25 08:43:38,781:INFO:_master_model_container: 34
2023-04-25 08:43:38,781:INFO:_display_container: 17
2023-04-25 08:43:38,781:INFO:RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:43:38,781:INFO:tune_model() successfully completed......................................
2023-04-25 08:43:39,133:INFO:Initializing plot_model()
2023-04-25 08:43:39,133:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:43:39,133:INFO:Checking exceptions
2023-04-25 08:43:39,137:INFO:Preloading libraries
2023-04-25 08:43:39,143:INFO:Copying training dataset
2023-04-25 08:43:39,143:INFO:Plot type: error
2023-04-25 08:43:39,194:INFO:Fitting Model
2023-04-25 08:43:39,194:INFO:Scoring test/hold-out set
2023-04-25 08:43:39,367:INFO:Visual Rendered Successfully
2023-04-25 08:43:39,509:INFO:plot_model() successfully completed......................................
2023-04-25 08:43:39,516:INFO:Initializing plot_model()
2023-04-25 08:43:39,517:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:43:39,517:INFO:Checking exceptions
2023-04-25 08:43:39,519:INFO:Preloading libraries
2023-04-25 08:43:39,526:INFO:Copying training dataset
2023-04-25 08:43:39,526:INFO:Plot type: error
2023-04-25 08:43:39,596:INFO:Fitting Model
2023-04-25 08:43:39,596:INFO:Scoring test/hold-out set
2023-04-25 08:43:39,791:INFO:Visual Rendered Successfully
2023-04-25 08:43:39,936:INFO:plot_model() successfully completed......................................
2023-04-25 08:43:39,945:INFO:Initializing plot_model()
2023-04-25 08:43:39,946:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:43:39,946:INFO:Checking exceptions
2023-04-25 08:43:39,963:INFO:Preloading libraries
2023-04-25 08:43:39,972:INFO:Copying training dataset
2023-04-25 08:43:39,972:INFO:Plot type: error
2023-04-25 08:43:40,024:INFO:Fitting Model
2023-04-25 08:43:40,024:INFO:Scoring test/hold-out set
2023-04-25 08:43:40,205:INFO:Visual Rendered Successfully
2023-04-25 08:43:40,335:INFO:plot_model() successfully completed......................................
2023-04-25 08:43:40,381:INFO:Initializing plot_model()
2023-04-25 08:43:40,381:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:43:40,381:INFO:Checking exceptions
2023-04-25 08:43:40,385:INFO:Preloading libraries
2023-04-25 08:43:40,391:INFO:Copying training dataset
2023-04-25 08:43:40,391:INFO:Plot type: feature
2023-04-25 08:43:40,392:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:43:40,533:INFO:Visual Rendered Successfully
2023-04-25 08:43:40,659:INFO:plot_model() successfully completed......................................
2023-04-25 08:43:40,660:INFO:Initializing plot_model()
2023-04-25 08:43:40,660:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:43:40,660:INFO:Checking exceptions
2023-04-25 08:43:40,663:INFO:Preloading libraries
2023-04-25 08:43:40,670:INFO:Copying training dataset
2023-04-25 08:43:40,670:INFO:Plot type: feature
2023-04-25 08:43:40,671:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:43:40,817:INFO:Visual Rendered Successfully
2023-04-25 08:43:40,942:INFO:plot_model() successfully completed......................................
2023-04-25 08:43:40,943:INFO:Initializing plot_model()
2023-04-25 08:43:40,944:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'ax': <AxesSubplot: >}, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, system=True)
2023-04-25 08:43:40,944:INFO:Checking exceptions
2023-04-25 08:43:40,962:INFO:Preloading libraries
2023-04-25 08:43:40,974:INFO:Copying training dataset
2023-04-25 08:43:40,974:INFO:Plot type: feature
2023-04-25 08:43:40,974:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 08:43:41,124:INFO:Visual Rendered Successfully
2023-04-25 08:43:41,258:INFO:plot_model() successfully completed......................................
2023-04-25 08:43:41,275:INFO:Initializing predict_model()
2023-04-25 08:43:41,275:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59F010>)
2023-04-25 08:43:41,276:INFO:Checking exceptions
2023-04-25 08:43:41,276:INFO:Preloading libraries
2023-04-25 08:43:41,446:INFO:Initializing predict_model()
2023-04-25 08:43:41,447:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56F000AF0>)
2023-04-25 08:43:41,447:INFO:Checking exceptions
2023-04-25 08:43:41,447:INFO:Preloading libraries
2023-04-25 08:43:41,680:INFO:Initializing predict_model()
2023-04-25 08:43:41,681:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A0316C0>)
2023-04-25 08:43:41,681:INFO:Checking exceptions
2023-04-25 08:43:41,681:INFO:Preloading libraries
2023-04-25 08:45:33,758:INFO:Initializing predict_model()
2023-04-25 08:45:33,758:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D5693C9D80>)
2023-04-25 08:45:33,758:INFO:Checking exceptions
2023-04-25 08:45:33,758:INFO:Preloading libraries
2023-04-25 08:45:38,549:INFO:Initializing predict_model()
2023-04-25 08:45:38,550:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561DD2050>)
2023-04-25 08:45:38,550:INFO:Checking exceptions
2023-04-25 08:45:38,550:INFO:Preloading libraries
2023-04-25 08:45:50,110:INFO:Initializing predict_model()
2023-04-25 08:45:50,110:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561F2BD00>)
2023-04-25 08:45:50,110:INFO:Checking exceptions
2023-04-25 08:45:50,110:INFO:Preloading libraries
2023-04-25 08:46:03,476:INFO:Initializing finalize_model()
2023-04-25 08:46:03,476:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:46:03,477:INFO:Finalizing GradientBoostingRegressor(random_state=7854)
2023-04-25 08:46:03,479:INFO:Initializing create_model()
2023-04-25 08:46:03,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=GradientBoostingRegressor(random_state=7854), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:46:03,479:INFO:Checking exceptions
2023-04-25 08:46:03,481:INFO:Importing libraries
2023-04-25 08:46:03,481:INFO:Copying training dataset
2023-04-25 08:46:03,481:INFO:Defining folds
2023-04-25 08:46:03,481:INFO:Declaring metric variables
2023-04-25 08:46:03,481:INFO:Importing untrained model
2023-04-25 08:46:03,481:INFO:Declaring custom model
2023-04-25 08:46:03,482:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 08:46:03,482:INFO:Cross validation set to False
2023-04-25 08:46:03,482:INFO:Fitting Model
2023-04-25 08:46:03,580:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))])
2023-04-25 08:46:03,580:INFO:create_model() successfully completed......................................
2023-04-25 08:46:03,698:INFO:Creating Dashboard logs
2023-04-25 08:46:03,698:INFO:Model: Gradient Boosting Regressor
2023-04-25 08:46:03,744:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7854, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 08:46:04,105:INFO:_master_model_container: 34
2023-04-25 08:46:04,105:INFO:_display_container: 23
2023-04-25 08:46:04,110:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))])
2023-04-25 08:46:04,110:INFO:finalize_model() successfully completed......................................
2023-04-25 08:46:04,389:INFO:Initializing finalize_model()
2023-04-25 08:46:04,389:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:46:04,389:INFO:Finalizing LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3)
2023-04-25 08:46:04,391:INFO:Initializing create_model()
2023-04-25 08:46:04,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:46:04,391:INFO:Checking exceptions
2023-04-25 08:46:04,392:INFO:Importing libraries
2023-04-25 08:46:04,392:INFO:Copying training dataset
2023-04-25 08:46:04,393:INFO:Defining folds
2023-04-25 08:46:04,393:INFO:Declaring metric variables
2023-04-25 08:46:04,393:INFO:Importing untrained model
2023-04-25 08:46:04,393:INFO:Declaring custom model
2023-04-25 08:46:04,393:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 08:46:04,394:INFO:Cross validation set to False
2023-04-25 08:46:04,394:INFO:Fitting Model
2023-04-25 08:46:04,411:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-04-25 08:46:04,411:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-04-25 08:46:04,411:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-04-25 08:46:04,453:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=0,
                               feature_fraction=0.5, learning_rate=0.3,
                               min_child_samples=66, min_split_gain=0.8,
                               n_estimators=170, num_leaves=150,
                               random_state=7854, reg_alpha=0.4,
                               reg_lambda=0.3))])
2023-04-25 08:46:04,453:INFO:create_model() successfully completed......................................
2023-04-25 08:46:04,598:INFO:Creating Dashboard logs
2023-04-25 08:46:04,598:INFO:Model: Light Gradient Boosting Machine
2023-04-25 08:46:04,640:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': -1, 'min_child_samples': 66, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 170, 'n_jobs': -1, 'num_leaves': 150, 'objective': None, 'random_state': 7854, 'reg_alpha': 0.4, 'reg_lambda': 0.3, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 1.0}
2023-04-25 08:46:05,018:INFO:_master_model_container: 34
2023-04-25 08:46:05,019:INFO:_display_container: 23
2023-04-25 08:46:05,024:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=0,
                               feature_fraction=0.5, learning_rate=0.3,
                               min_child_samples=66, min_split_gain=0.8,
                               n_estimators=170, num_leaves=150,
                               random_state=7854, reg_alpha=0.4,
                               reg_lambda=0.3))])
2023-04-25 08:46:05,024:INFO:finalize_model() successfully completed......................................
2023-04-25 08:46:05,302:INFO:Initializing finalize_model()
2023-04-25 08:46:05,302:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 08:46:05,303:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=7854)
2023-04-25 08:46:05,304:INFO:Initializing create_model()
2023-04-25 08:46:05,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 08:46:05,305:INFO:Checking exceptions
2023-04-25 08:46:05,306:INFO:Importing libraries
2023-04-25 08:46:05,306:INFO:Copying training dataset
2023-04-25 08:46:05,306:INFO:Defining folds
2023-04-25 08:46:05,306:INFO:Declaring metric variables
2023-04-25 08:46:05,306:INFO:Importing untrained model
2023-04-25 08:46:05,306:INFO:Declaring custom model
2023-04-25 08:46:05,306:INFO:Random Forest Regressor Imported successfully
2023-04-25 08:46:05,307:INFO:Cross validation set to False
2023-04-25 08:46:05,307:INFO:Fitting Model
2023-04-25 08:46:05,356:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=7854))])
2023-04-25 08:46:05,356:INFO:create_model() successfully completed......................................
2023-04-25 08:46:05,474:INFO:Creating Dashboard logs
2023-04-25 08:46:05,475:INFO:Model: Random Forest Regressor
2023-04-25 08:46:05,517:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7854, 'verbose': 0, 'warm_start': False}
2023-04-25 08:46:05,888:INFO:_master_model_container: 34
2023-04-25 08:46:05,888:INFO:_display_container: 23
2023-04-25 08:46:05,891:INFO:Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=7854))])
2023-04-25 08:46:05,891:INFO:finalize_model() successfully completed......................................
2023-04-25 08:46:12,754:INFO:Initializing predict_model()
2023-04-25 08:46:12,754:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561F2BD00>)
2023-04-25 08:46:12,754:INFO:Checking exceptions
2023-04-25 08:46:12,754:INFO:Preloading libraries
2023-04-25 08:46:12,756:INFO:Set up data.
2023-04-25 08:46:12,760:INFO:Set up index.
2023-04-25 08:46:15,506:INFO:Initializing predict_model()
2023-04-25 08:46:15,506:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=1.0, bagging_freq=0,
                               feature_fraction=0.5, learning_rate=0.3,
                               min_child_samples=66, min_split_gain=0.8,
                               n_estimators=170, num_leaves=150,
                               random_state=7854, reg_alpha=0.4,
                               reg_lambda=0.3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59C280>)
2023-04-25 08:46:15,507:INFO:Checking exceptions
2023-04-25 08:46:15,507:INFO:Preloading libraries
2023-04-25 08:46:15,509:INFO:Set up data.
2023-04-25 08:46:15,513:INFO:Set up index.
2023-04-25 08:46:17,168:INFO:Initializing predict_model()
2023-04-25 08:46:17,168:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=7854))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59C280>)
2023-04-25 08:46:17,169:INFO:Checking exceptions
2023-04-25 08:46:17,169:INFO:Preloading libraries
2023-04-25 08:46:17,170:INFO:Set up data.
2023-04-25 08:46:17,174:INFO:Set up index.
2023-04-25 08:53:37,681:INFO:Initializing predict_model()
2023-04-25 08:53:37,681:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\danie\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'bmi', 'children',
                                             'smoker', 'region',
                                             'bmi_category'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=7854))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D561F2BD00>)
2023-04-25 08:53:37,681:INFO:Checking exceptions
2023-04-25 08:53:37,682:INFO:Preloading libraries
2023-04-25 08:53:47,973:INFO:Initializing predict_model()
2023-04-25 08:53:47,973:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=LGBMRegressor(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=66, min_split_gain=0.8,
              n_estimators=170, num_leaves=150, random_state=7854,
              reg_alpha=0.4, reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59F010>)
2023-04-25 08:53:47,973:INFO:Checking exceptions
2023-04-25 08:53:47,973:INFO:Preloading libraries
2023-04-25 08:53:59,301:INFO:Initializing predict_model()
2023-04-25 08:53:59,302:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D56A10EFB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7854), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D56A59F010>)
2023-04-25 08:53:59,302:INFO:Checking exceptions
2023-04-25 08:53:59,302:INFO:Preloading libraries
